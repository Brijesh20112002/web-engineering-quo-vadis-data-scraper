Venue,Year,Title,Author,Affiliation,Country,Author Keywords,IEEE Keywords,Volume Number,Issue,Issue Identifier,Citation count,URL,Page number,Abstract
JWE,2019,Special Issue on Advanced Practices in Web Engineering,J. G. Enríquez - | F. J. Domínguez-Mayo | M. J. Escalona,"Computer Languages and Systems, University of Seville, Avenida Reina Mercedes, Sevilla | Computer Languages and Systems, University of Seville, Avenida Reina Mercedes, Sevilla | Computer Languages and Systems, University of Seville, Avenida Reina Mercedes, Sevilla",Sevilla,,,18,4–6,,0,https://ieeexplore.ieee.org/document/10251818/,1-4,"Technological disruption is causing great changes and impact in our society in the way we live, work and how we relate to each other. This is due to the fact that Internet is a great communication tool as a means of influence is reflected in the advances and the continuous adaptation of users, practitioners and researchers to it. As soon as we implement intelligent technologies in our homes, factories or workplaces, the machinery and systems connected to the Internet are interacting, processing information and making decisions autonomously. Increasing new technologies and paradigms such as Artificial Intelligence or the Internet of Things and System of Systems, together with technologies such as Cloud Computing or Big Data, make the Fourth Industrial Revolution that we are living developing towards the optimization of processes and resources through the collection, use, and an intelligent analysis of processing of data."
JWE,2019,Discovery and Analysis About the Evolution of Service Composition Patterns,Zhenfeng Gao | Yushun Fan | Xiu Li | Liang Gu | Cheng Wu | Jia Zhang,"Graduate School at Shenzhen, Tsinghua University, Shenzhen, China | Tsinghua National Laboratory for Information Science and Technology, Beijing, China | Graduate School at Shenzhen, Tsinghua University, Shenzhen, China | Sangfor Technologies Inc., Shenzhen, China | Tsinghua National Laboratory for Information Science and Technology, Beijing, China | Department of Electrical and Computer Engineering, Carnegie Mellon University, Silicon Valley, California, USA",China | USA,Topic evolution graph | service composition recommendation | topic model,Mashups | Ecosystems | Market research | Stability analysis | Data models,18,7,,9,https://ieeexplore.ieee.org/document/10251866/,579-625,"Service ecosystems, consisting of various kinds of services and mashups, usually keep evolving over time. Existing works on the evolution of service ecosystems focus on either evaluating the impacts of single services' changes on the usage of services and the stability of the whole ecosystem, or discovering co-occurrence relationship between services, but fail to disclose any knowledge from the aspect of the evolution of service composition patterns. Based on our previous work, this paper moves one step further, revealing the latent service composition trends in a service ecosystem and providing more distinct explanation of different topic evolution patterns. A novel methodology, named Extended Dependency-Compensated Service Co-occurrence LDA (EDC-SeCo-LDA), is developed to calculate the directed dependencies between different topics and build topic evolution graph. The evolution trend of service composition could be disclosed by the graph intuitively. What's more, EDC-SeCo-LDA proposes five different ways to adopt dependency compensation to improve the performance when making service recommendation. Experiments on ProgrammableWeb.com show that EDC-SeCo-LDA can reveal significant topic dependencies, and recommend service compo-sition more effectively, i.e., 6% better in terms of Mean Average Precision compared with baseline approaches."
JWE,2019,Model Driven Development of Gamified Applications,Piero Fraternali | Sergio Luis Herrera Gonzalez,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy | Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy",Italy,Model Driven Engineering | gamification | rapid prototyping | code generation | IFML,Games | Data models | Business,18,7,,8,https://ieeexplore.ieee.org/document/10251861/,655-694,"Gamification is defined as the injection of game elements in applications with non-gaming purposes. This technique has shown outstanding results in promoting the engagement and activity on communities of users, in both business and non-for-profits fields. Often, gamification features are added late in the application life-cycle and must be weaved into the existing functions. In this paper, we present a model-driven approach to the design of gamified applications, which accelerates the introduction of gamification elements in pre-existing or new applications. The approach relies on a data model of gamification features and on design patterns for the front-end, which encode the essential elements of gamification in a platform independent way."
JWE,2019,Privacy-Preserving Reengineering of Model-View-Controller Application Architectures Using Linked Data,Juan Manuel Dodero | Mercedes Rodriguez-Garcia | Iván Ruiz-Rube | Manuel Palomo-Duarte,"School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain | School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain | School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain | School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain",Spain,Privacy by design | Web of data | Software architecture | Model View-Controller,Data privacy | Privacy | Adaptation models | Linked data | Source coding | Computer architecture | Data models,18,7,,0,https://ieeexplore.ieee.org/document/10251874/,695-727,"When a legacy system's software architecture cannot be redesigned, implementing additional privacy requirements is often complex, unreliable and costly to maintain. This paper presents a privacy-by-design approach to reengineer web applications as linked data-enabled and implement access control and privacy preservation properties. The method is based on the knowledge of the application architecture, which for the Web of data is commonly designed on the basis of a model-view-controller pattern. Whereas wrapping techniques commonly used to link data of web applications duplicate the security source code, the new approach allows for the controlled disclosure of an application's data, while preserving non-functional properties such as privacy preservation. The solution has been implemented and compared with existing linked data frameworks in terms of reliability, maintainability and complexity."
JWE,2019,A Semantic Web Approach to Enable a Smart Route to Historical Archives,Annamaria Goy | Diego Magro | Alessandro Baldo,"Dipartimento di Informatica, Università di Torino, Turin, Italy | Dipartimento di Informatica, Università di Torino, Turin, Italy | Dipartimento di Informatica, Università di Torino, Turin, Italy",Italy,Semantic Web | Intelligent Web applications | Ontology-driven Web applications | Digital Humanities | Web-based access to historical archives,Semantics | OWL | Collaboration | Ontologies | Resource description framework | Cultural differences | Standards,18,4–6,,5,https://ieeexplore.ieee.org/document/10251822/,287-318,"In this paper we show that an ontology-based approach can be beneficial for enhancing the access to cultural resources, and in particular historical documents. The paper starts with an overview of our approach, aimed at providing online archival systems with a semantic layer based on Semantic Web standards (OWL 2 and RDF). Two projects are introduced, namely Harlock900 and PRiSMHA, carried out in collaboration with local cultural institutions owning rich historical archives. In particular, the paper describes the computational ontologies supporting the approach, and then focuses on two case studies showing that our framework provides better results if compared with standard access systems. The case studies show the enhancement provided by a semantically rich representation of time intervals and a detailed formal description of events and their participants."
JWE,2019,A Boxology of Design Patterns for Hybrid Learning and Reasoning Systems,Frank van Harmelen | Annette ten Teije,"Department of Computer Science, Vrije Universiteit, Amsterdam, Netherlands | Department of Computer Science, Vrije Universiteit, Amsterdam, Netherlands",Netherlands,Hybrid systems | neurosymbolic systems | knowledge representation | machine learning | design patters,Computer science | Machine learning | Ontologies | Software | Cognition | Hybrid learning | Data mining,18,1-3,,115,https://ieeexplore.ieee.org/document/10247288/,97-123,"We propose a set of compositional design patterns to describe a large variety of systems that combine statistical techniques from machine learning with symbolic techniques from knowledge representation. As in other areas of computer science (knowledge engineering, software engineering, ontology engineering, process mining and others), such design patterns help to systematize the literature, clarify which combinations of techniques serve which purposes, and encourage re-use of software components. We have validated our set of compositional design patterns against a large body of recent literature."
JWE,2019,Towards Improving Productivity in NMap Security Audits,Jose Manuel Redondo | Daniel Cuesta,"Department of Computer Science, Computational Reflection Research Group, University of Oviedo, Science Faculty, Oviedo, Spain | Computer Network Attack (CNA), S2Grupo, Valencia, Spain",Spain,nmap | web GUI | advanced features | productivity | Domain Specific Language | static type checking,Productivity | Runtime | Feature extraction | Complexity theory | Security | DSL | Task analysis,18,7,,13,https://ieeexplore.ieee.org/document/10251826/,539-577,"Maintaining an adequate security level in computer infrastructures, like Internet-facing web servers, requires periodic assessment of their vulnerabilities with specialized security tools. nmap is arguably the most popular one, due to its versatility, powerful features, and low resource usage. However, this versatility can turn its usage difficult and error-prone, as it implements a lot of features and reports errors at runtime. This can lead to suboptimal results while designing auditing tasks. This research aims to decrease this complexity by developing a web GUI that favors experimentation, on-demand scans, and provides solutions to several shortcomings detected in the official one. We complemented it with a Domain Specific Language that implements early detection and reporting of syntax, type, and semantic errors when creating audit tasks. Both expand nmap possibilities, creating robust, schedulable, distributable, and portable auditing tasks able to find anomalies analyzing their output. Our initial release shows that the web GUI has been well received by several security related media and professionals. The language can detect and report a wide range of potential errors, substantially increasing the robustness of the created tasks. Therefore, Domain Specific Languages with early detection of type errors turned to be suitable to lower the complexity and expand the usage possibilities of complex tools like nmap."
JWE,2019,On Twitter Bots Behaving Badly: A Manual and Automated Analysis of Python Code Patterns on GitHub,Andrea Millimaggi | Florian Daniel,"Politecnico di Milano, Milan, Italy | Politecnico di Milano, Milan, Italy",Italy,Bots | Harm | Abuse | Code patterns | Pattern recognition | GitHub | Twitter | Python,Codes | Social networking (online) | Blogs | Taxonomy | Oral communication | Manuals | Chatbots,18,8,,11,https://ieeexplore.ieee.org/document/10247296/,801-835,"Bots, i.e., algorithmically driven entities that behave like humans in online communications, are increasingly infiltrating social conversations on the Web. If not properly prevented, this presence of bots may cause harm to the humans they interact with. This article aims to understand which types of abuse may lead to harm and whether these can be considered intentional or not. We manually review a dataset of 60 Twitter bot code repositories on GitHub, derive a set of potentially abusive actions, characterize them using a taxonomy of abstract code patterns, and assess the potential abusiveness of the patterns. The article then describes the design and implementation of a code pattern recognizer and uses the pattern recognizer to automatically analyze a dataset of 786 Python bot code repositories. The study does not only reveal the existence of 28 communication-specific code patterns - which could be used to assess the harmfulness of bot code - but also their consistent presence throughout all studied repositories."
JWE,2019,Citation Count Prediction Using Abstracts,Takahiro Baba | Kensuke Baba | Daisuke Ikeda,"Kyushu University, Fukuoka, Japan | Fujitsu Laboratories, Kawasaki, Japan | Kyushu University, Fukuoka, Japan",Japan,Citation count prediction | Document classification | Text analysis | Machine learning,Support vector machines | Vocabulary | Machine learning | Writing | Market research | Feature extraction | Planning,18,1-3,,8,https://ieeexplore.ieee.org/document/10247226/,207-228,"Researchers are expected to find previous literature that is related to their research and potentially has a scientific impact from among a large number of publications. This paper addresses the problem of predicting the citation count of each research paper, that is, the number of citations from other papers to that paper. Previous literature related to the problem claims that the textual data of papers do not deeply affect the prediction compared with data about the authors and venues of publication. In contrast, the authors of this paper detected the citation counts of papers using only the paper abstracts. Additionally, they investigated the effect of technical terms used in the abstracts on the detection. They classified abstracts of papers with high and low citation counts and applied the classification to the abstracts modified by hiding the technical terms used in them. The results of their experiments indicate that the high and low of citation counts of research papers can be detected using their abstracts, and the effective features used in the prediction are related to the trend of research topics."
JWE,2019,Multi-Device Complementary View Adaptation with Liquid Media Queries,Andrea Gallidabino | Cesare Pautasso,"Faculty of Informatics, Software Institute, Università della Svizzera italiana, Lugano, Switzerland | Faculty of Informatics, Software Institute, Università della Svizzera italiana, Lugano, Switzerland",Switzerland,Liquid software | CSS media queries | multi-device adaptation | responsive user interface | complementary view adaptation,Liquids | Heuristic algorithms | Media | User interfaces | Feature extraction | Software | Complexity theory,18,8,,4,https://ieeexplore.ieee.org/document/10247305/,761-800,"Responsive Web applications assume that they run on a single device at a time. Developers use CSS3 media queries to declare how the Web application user interface adapts to specific capabilities (e.g., screen size or resolution) of individual devices. As users own and use multiple devices across which they attempt to run the same Web application at the same time, we propose to extend CSS media queries so that developers can also use them to dynamically adapt so-called liquid Web applications as they are seamlessly deployed across multiple devices. In this paper we present the concept of liquid media queries. They support features to detect the number of connected devices, the number of users running the application, or the role played by each device during the application execution. The liquid media query types and features defined in this paper are designed for component-based Web applications, and they enable developers to control the deployment and dynamic migration and cloning of individual Web components across multiple browsers. Furthermore we present the design of how liquid media queries are implemented within the Liquid.js for Polymer framework and the corresponding distributed adaptation algorithms. We discuss the implications of multi-device adaptation from the perspective of the developers and also the users of a liquid Web application. Finally we showcase the expressiveness of the liquid media queries to support real-world examples and evaluate the algorithmic complexity of our approach."
JWE,2019,Design Guidelines for Web Interfaces of Home Automation Systems Accessible via Screen Reader,Marina Buzzi | Barbara Leporini | Clara Meattini,"IIT-CNR, Pisa, Italy | ISTI-CNR, Pisa, Italy | ISTI-CNR, Pisa, Italy",Italy,Smart homes | home automation | accessible interfaces | blind users,Wireless communication | Wireless sensor networks | Visual impairment | Prototypes | Smart homes | User interfaces | Assistive technologies,18,4–6,,20,https://ieeexplore.ieee.org/document/10251852/,477-511,"Home Automation Systems (HAS) - also referred to as smart homes - exploit multiple components such as sensors, RFID readers, wireless devices, and remote control systems to enable easy interaction with smart appliances and devices, and to automate performing sequences of tasks to make human-device interaction simpler and life more comfortable. For people with vision impairment, especially those who are unable to see at all, smart homes can be a powerful tool for enhancing personal autonomy, provided that the system offers suitable device integration and accessible interfaces with a simple interaction via keyboard, assistive technology and other modalities such as voice and gestures. This paper investigates the accessibility of web interfaces when interacting with HAS components via screen reader assistive technology, in order to propose potential suggestions to developers. Web interfaces are particularly considered in this study in order to support screen reader users who are not yet skilled in using touch-screen devices. Specifically, based on collected accessibility and usability issues, as well as users' expectations and preferences, a Web-based prototype has been designed and optimized especially for interaction via screen reader. After describing an evaluation conducted with a small group of skilled screen reader users, several guidelines are suggested for designers of HAS interfaces."
JWE,2019,"Applying Feature-Oriented Software Development in SaaS Systems: Real Experience, Measurements, and Findings",Oscar Pedreira | Fernando Silva-Coira | Ángeles Saavedra Places | Miguel R. Luaces | Leticia González Folgueira,"Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Enxenio S.L., A Coruña, Spain",Spain,feature oriented software development | feature oriented domain analysis | variability management | software as a service | feature model metrics,Analytical models | Systematics | Software as a service | Companies | Solids | Market research | Feature extraction,18,4–6,,2,https://ieeexplore.ieee.org/document/10251854/,447-475,"Distributing software as a service (SaaS) has become a major trend for web-based systems. However, this software distribution model poses many challenges. One of them is feature variability, that is, some features of the system may be required by some users, but not by all of them. In addition, variability is more complex than just including or excluding a feature, since different types of relationships may exist between features. The implementation of this variability, and the parametrization and configuration of the system can be complex in this context, so the development process of a SaaS system must adequately address variability management. In this paper we present an experience applying feature oriented software development (FOSD) in the context of SaaS web-based systems development. We present a real experience in the development of a web-based system for managing home care services for dependent people. The article describes the problem of variability management in this domain, and the feature model of the system. Finally, we present an empirical evaluation of the feature model of the system based on data obtained from its real deployment after two years of use. The empirical evaluation was based on state-of-the-art measures for variability management, and revealed relevant insights for software development in this context."
JWE,2019,Traceability Management of Systems of Systems: A Systematic Review in the Assisted Reproduction Domain,Leticia Morales Trujillo | Julián Alberto García | David Lizcano | Manuel Mejías,"Web Engineering and Early Testing (IWT2) group, University of Seville, Escuela Té cnica Superior de Ingenierí a Informá tica, Sevilla, Spain | Web Engineering and Early Testing (IWT2) group, University of Seville, Escuela Té cnica Superior de Ingenierí a Informá tica, Sevilla, Spain | Universidad a Distancia de Madrid (UDIMA), Madrid, Spain | Web Engineering and Early Testing (IWT2) group, University of Seville, Escuela Té cnica Superior de Ingenierí a Informá tica, Sevilla, Spain",Spain,Systematic Literature Review | Systems of Systems | Biological Sample Management | Assisted Reproductive Treatment,Systematics | Subspace constraints | Process control | Manuals | Market research | Biology | Safety,18,4–6,,5,https://ieeexplore.ieee.org/document/10251823/,409-445,"Over last decade, Assisted Reproductive Treatment (ART) has become a very used health service by more and more people around the world because of problems such as the delay in the maternity age, singleparent couples, etc. In this context, health agencies have performed innovations to improve healthcare processes of ARTs, to optimize the performance of health professionals who work in fertilization laboratories and to improve Biological Sample Management (BSM) and sample traceability in ART. However, there are important handicaps in ART processes from the point of view of quality, safety and management. On the one hand, these processes are mainly based on manual execution tasks and manual control tasks. This excess of manual tasks could lead to fatal traceability and safety errors during BSM. On the other hand, ART processes require real, interoperable and traceable communications between different software systems that have to collaborate together (health information systems, biological sample management systems, patient management systems, etc.), but, at present, it is possible to identify some limitations in this domain, that is, the domain of systems of systems (SoS). This paper aims to conduct an exhaustive study was carried out both in the research community and in the commercial field to identify and analyze SoS solutions and theoretical proposals for BSM in ART processes. We have applied the Systematic Literature Review (SLR) methodology to carry out our study and we conclude it is a very young research line that shows a growing trend and that in the actuality there are very few technologies that deal with the problem of the BSM in ART.After analyzing the results, this paper presents as future work an initial Model-Driven conceptual solution to improve BSM in ART."
JWE,2019,Automatic Detection and Analysis of the “Game Hack” Scam,Emad Badawi | Guy-Vincent Jourdan | Gregor Bochmann | Iosif-Viorel Onut,"Faculty of Engineering, University of Ottawa, Ottawa, Canada | Faculty of Engineering, University of Ottawa, Ottawa, Canada | Faculty of Engineering, University of Ottawa, Ottawa, Canada | IBM Centre for Advanced Studies, Ottawa, Canada",Canada,Game Hack scam | scam analysis | fraud detection | cyberattack,Surveys | Knowledge engineering | Computer hacking | Estimation | Games | Search engines | Data collection,18,8,,8,https://ieeexplore.ieee.org/document/10247291/,729-760,"The “Game Hack” Scam (GHS) is a mostly unreported cyberattack in which attackers attempt to convince victims that they will be provided with free, unlimited “resources” or other advantages for their favorite game. The endgame of the scammers ranges from monetizing for themselves the victims time and resources by having them click through endless “surveys”, filing out “market research” forms, etc., to collecting personal information, getting the victims to subscribe to questionable services, up to installing questionable executable files on their machines. Other scams such as the “Technical Support Scam”, the “Survey Scam”, and the “Romance Scam” have been analyzed before but to the best of our knowledge, GHS has not been well studied so far and is indeed mostly unknown. In this paper, our aim is to investigate and gain more knowledge on this type of scam by following a data-driven approach; we formulate GHS-related search queries, and used multiple search engines to collect data about the websites to which GHS victims are directed when they search online for various game hacks and tricks. We analyze the collected data to provide new insight into GHS and research the extent of this scam. We show that despite its low profile, the click traffic generated by the scam is in the hundreds of millions. We also show that GHS attackers use social media, streaming sites, blogs, and even unrelated sites such as change.org or jeuxvideo.com to carry out their attacks and reach a large number of victims. Our data collection spans a year; in that time, we uncovered 65,905 different GHS URLs, mapped onto over 5,900 unique domains. We were able to link attacks to attackers and found that they routinely target a vast array of games. Furthermore, we find that GHS instances are on the rise, and so is the number of victims. Our low-end estimation is that these attacks have been clicked at least 150 million times in the last five years. Finally, in keeping with similar large-scale scam studies, we find that the current public blacklists are inadequate and suggest that our method is more effective at detecting these attacks."
JWE,2019,OPT+: A Monotonic Alternative to OPTIONAL in SPARQL,Sijin Cheng | Olaf Hartig,"Department of Computer and Information Science (IDA), Linköping University, Sweden | Department of Computer and Information Science (IDA), Linköping University, Sweden",Sweden,Semantic web | linked data | query language | optimization,Soft sensors | Query processing | Triples (Data structure) | Semantics | Data integration | Time factors | Servers,18,1-3,,8,https://ieeexplore.ieee.org/document/10247308/,169-206,"Due to the OPTIONAL operator, the core fragment of the SPARQL query language is non-monotonic. That is, some solutions of a query result can be returned to the user only after having consulted all relevant parts of the queried dataset(s). This property presents an obstacle when developing query execution approaches that aim to reduce responses times rather than the overall query execution times. Reducing the response times–i.e., returning as many solutions as early as possible–is important in particular in Web-based client-server query processing scenarios in which network latencies dominate query execution times. Such scenarios are typical in the context of integration of Web data sources where a data integration component executes queries over a decentralized federation of such data sources. In this paper we introduce an alternative operator that is similar in spirit to OPTIONAL but without causing non-monotonicity. We show fundamental properties of this operator and observe that the downside of achieving the desired monotonicity property is a potentially significant increase in query result sizes. We study the extend of this trade-off in practice. Thereafter, we introduce different algorithms to implement the new operator and evaluate them regarding their potential to reduce response times."
JWE,2019,A Brief Overview on the Strategies to Fight Back the Spread of False Information,Álvaro Figueira | Nuno Guimaraes | Luis Torgo,"CRACS-INESCTEC and University of Porto, Porto, Portugal | CRACS-INESCTEC and University of Porto, Porto, Portugal | Faculty of Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada",Portugal | Canada,false information | social networks,Emotion recognition | Sentiment analysis | Machine learning algorithms | Social networking (online) | Face recognition | Blogs | Software,18,4–6,,9,https://ieeexplore.ieee.org/document/10251847/,319-352,"The proliferation of false information on social networks is one of the hardest challenges in today's society, with implications capable of changing users perception on what is a fact or rumor. Due to its complexity, there has been an overwhelming number of contributions from the research community like the analysis of specific events where rumors are spread, analysis of the propagation of false content on the network, or machine learning algorithms to distinguish what is a fact and what is “fake news”. In this paper, we identify and summarize some of the most prevalent works on the different categories studied. Finally, we also discuss the methods applied to deceive users and what are the next main challenges of this area."
JWE,2019,Model-Driven Skills Assessment in Knowledge Management Systems,Antonio Balderas | Juan Antonio Caballero-Hernández | Juan Manuel Dodero | Manuel Palomo-Duarte | Iván Ruiz-Rube,"Department of Computer Science, University of Cadiz, Puerto Real, Spain | EVAL for Research Group, University of Cadiz, Puerto Real, Spain | Department of Computer Science, University of Cadiz, Puerto Real, Spain | Department of Computer Science, University of Cadiz, Puerto Real, Spain | Department of Computer Science, University of Cadiz, Puerto Real, Spain",Spain,knowledge management system | generic skills assessment | organizational learning | Model-Driven engineering,Training | Systematics | Employment | Virtual environments | Organizations | Knowledge management | Model driven engineering,18,4–6,,9,https://ieeexplore.ieee.org/document/10251851/,353-379,"Organizations need employees who perform satisfactorily in generic skills, such as teamwork, leadership, problem solving or interpersonal abilities, among others. In organizational environments, employees perform work that is not always visible for supervisors and, thus, they can hardly assess their performance in generic skills. By using a knowledge management system, the users are able to leave a trace of their activity in the system's records. This research aims to address a computer supported assessment of the user's generic skills from the perspective of Model-Driven engineering. First, a systematic mapping study is carried out to understand the state of the art. Second, a proposal based on Model-Driven engineering is presented and is then validated through an organizational learning process model. Our results are promising and we are able to conduct a scalable assessment based on objective indicators of the employee's planning, time management and problem solving skills."
JWE,2019,Model-Driven Integration Testing of Hypermedia Systems,Henry Vu | Tobias Fertig | Peter Braun,"PENTASYS AG, Munich, Germany | PENTASYS AG, Munich, Germany | PENTASYS AG, Munich, Germany",Germany,REST | Integration Testing | RESTful API | Hypermedia Testing | MDSD | MDE | MDT | Model-Driven Testing,Navigation | Source coding | Crawlers | Restful API | Hypermedia | Data models | Generators,18,4–6,,2,https://ieeexplore.ieee.org/document/10251853/,381-407,"The proper design of Representational State Transfer (REST) APIs is not trivial because developers have to deal with a flood of recommendations and best practices, especially the proper application of the hypermedia constraint requires some decent experience. Furthermore, testing RESTful APIs is a missing topic within literature. Especially hypermedia testing is not mentioned at all. Manual hypermedia testing is time-consuming and hard to maintain. Testing a hypermedia API requires many test cases that have similar structure, especially when different user roles and error cases are considered. In order to tackle this problem, we proposed a Model-Driven Testing (MDT) approach for hypermedia systems using the metamodel within our existing Model Driven Software Development (MDSD) approach. This work discusses challenges and results of hypermedia testing for RESTful APIs using MDT techniques that were discovered within our research. MDT allows white-box testing, hence covering complete program structure and behavior of the generated application. By doing this, we are able to achieve a high automated test coverage. Moreover, any runtime behavior deviated from the metamodel reveals bugs within the generators."
JWE,2019,LOD Construction Through Supervised Web Relation Extraction and Crowd Validation,Goran Rumin | Igor Mekterović,"Infobip, Zagreb, Croatia | University of Zagreb Faculty of Electrical Engineering and Computing, Croatia",Croatia,Relation Extraction | Machine Learning | RDF | Linked Open Data | Crowd validation | Semantic Web | Web Application,Machine learning algorithms | Semantics | Pipelines | Buildings | Feature extraction | Resource description framework | Browsers,18,1-3,,1,https://ieeexplore.ieee.org/document/10247224/,229-255,"Free, unstructured text is the dominant format in which information is stored and published. To interpret such vast amount of data one must employ a programmatic approach. In this paper, we describe a novel approach – a pipeline in which interesting relations are extracted from web portals news texts, stored as RDF triplets, and finally validated by end user via browser extension. In the process, different machine learning algorithms were tested on relation extraction, enhanced with our own set of features and thoroughly evaluated, with excellent precision and recall results compared to models used for semantic knowledge expansion. Building on those results, we implement and describe the component to resolve discovered entities to existing semantic entities from three major online repositories. Finally, we implement and describe the validation process in which RDF triplets are presented to the web portal reader for validation via Chrome extension."
JWE,2019,Ontology-Driven News Classification with Aethalides,Wouter Rijvordt | Frederik Hogenboom | Flavius Frasincar,"Econometric Institute, Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands | Econometric Institute, Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands | Econometric Institute, Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands",the Netherlands,News personalization | word sense disambiguation | ontology learning | semantic web,Learning systems | Knowledge engineering | Feedback loop | Semantics | Pipelines | Buildings | Finance,18,7,,4,https://ieeexplore.ieee.org/document/10251873/,627-654,"The ever-increasing amount of Web information offered to news readers (e.g., news analysts) stimulates the need for news selection, so that informed decisions can be made with up-to-date knowledge. Hermes is an ontologybased framework for building news personalization services. It uses an ontology crafted from available news sources, allowing users to select and filter interesting concepts from a domain ontology. The Aethalides framework enhances the Hermes framework by enabling news classification through lexicographic and semantic properties. For this, Aethalides applies word sense disambiguation and ontology learning methods to news items. When tested on a set of news items on finance and politics, the Aethalides implementation yields a precision and recall of 74.4% and 49.4%, respectively, yielding an F0.5-measure of 67.6% when valuing precision more than recall."
JWE,2019,Integrating Semantic Run-Time Models for Adaptive Software Systems,Francesco Poggi | Davide Rossi | Paolo Ciancarini,"Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, Italy | Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, Italy | University of Bologna, Italy",Italy,Autonomic systems | adaptive software | MAPE-K | Semantic Web | ontology,Semantic Web | Knowledge engineering | Adaptation models | Soft sensors | Semantics | Knowledge based systems | Ontologies,18,1-3,,9,https://ieeexplore.ieee.org/document/10247311/,1-41,"Software-intensive systems work in ever-changing environments requiring expensive technical efforts to manage their evolution. In order to mitigate their risks and costs they should dynamically self-adapt to any modification of their environment. MAPE-K (Monitor, Analyze, Plan, Execute – Knowledge) is the basic architectural pattern for building software-intensive self-adaptable systems. In this paper we propose an approach in which all the information about a system and its environment is unified by using Semantic Web technologies into a set of semantic run-time models which enhance the Knowledge in MAPE-K. Ontologies are used to manage the interaction and integration of these models with disparate data sources. The resulting knowledge base is then used to drive adaptation activities exploiting well known languages and notations. We discuss how MAPE-K can be exploited in order to take advantage of ontological representations, along with Semantic Web languages and tools, by studying a real-word case study: a legacy system that was not designed to perform automatic adaptation. We discuss merits and limits of our approach based on semantic run-time models both in the context of this specific case study and in a broader scope."
JWE,2019,Leveraging Conceptual Data Models to Ensure the Integrity of Cassandra Databases,Pablo Suárez-Otero | María José Suárez-Cabal | Javier Tuya,"Computer Science Department, University of Oviedo, Gijón, Spain | Computer Science Department, University of Oviedo, Gijón, Spain | Computer Science Department, University of Oviedo, Gijón, Spain",Spain,NoSQL | Cloud | Conceptual Model | Logical Model | Cassandra | Logical Data Integrity,Databases | Web services | Data integrity | NoSQL databases | Relational databases | Production | Big Data,18,4–6,,7,https://ieeexplore.ieee.org/document/10251850/,257-286,"The use of NoSQL databases for cloud environments has been increasing due to their performance advantages when working with big data. One of the most popular NoSQL databases used for cloud services is Cassandra, in which each table is created to satisfy one query. This means that as the same data could be retrieved by several queries, these data may be repeated in several different tables. The integrity of these data must be maintained in the application that works with the database, instead of in the database itself as in relational databases. In this paper, we propose a method to ensure the data integrity when there is a modification of data by using a conceptual model that is directly connected to the logical model that represents the Cassandra tables. This method identifies which tables are affected by the modification of the data and also proposes how the data integrity of the database may be ensured. We detail the process of this method along with two examples where we apply it in two insertions of tuples in a conceptual model. We also apply this method to a case study where we insert several tuples in the conceptual model, and then we discuss the results. We have observed how in most cases several insertions are needed to ensure the data integrity as well as needing to look for values in the database in order to do it."
JWE,2019,Temporal Extensions to RDF,Hsien-Tseng Wang | Abdullah Uz Tansel,"Department of Computer Science, The Graduate Center, The City University of New York, USA | Department of Computer Science, The Graduate Center, The City University of New York, USA",USA,The Semantic Web | Resource Description Framework | Taxonomy | Temporal Data | Temporal Knowledge,Knowledge engineering | OWL | Semantics | Taxonomy | Ontologies | Writing | Resource description framework,18,1-3,,20,https://ieeexplore.ieee.org/document/10247309/,125-168,"The Semantic Web aims at building a foundation of semantic-based data models and languages for not only manipulating data and knowledge, but also in decision making by machines. Naturally, time-varying data and knowledge are required in Semantic Web applications to incorporate time and further reason about it. However, the original specifications of RDF and OWL do not include constructs for handling time-varying data and knowledge. For simplicity, RDF model is confined to binary predicates, hence some form of reification is needed to represent higher-arity predicates. To this date, there are many proposals extending RDF and OWL for handling temporal data and knowledge. They all focus on the valid time. In this paper, we examine each of these proposals and develop a taxonomy to classify them according to the form of reification employed: explicit reification or implicit reification. The implicit reification proposals are further divided into three sub-categories according to semantic constructs they use. Some of these proposals stay compliant to the RDF and OWL standards whereas others add new constructs to RDF model and SPARQL query language. Additionally, we compare these proposed models with respect to characteristics, such as their syntax and semantics, their compliance to RDF and OWL specifications, their need for additional objects, etc. The comparison provides a useful guideline for the researchers and practitioners of the Semantic Web in managing temporal data and knowledge."
JWE,2019,"PLEC, A Participative Process for GUI Prototyping",Javier J. Gutiérrez | Carlos Arévalo | David Lizcano,"Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | School of Computer Science, Universidad a Distancia de Madrid, UDIMA, Madrid, Spain",Spain,GUI | prototyping | team work,Conferences | Prototypes | Organizations | Software | Teamwork | Stakeholders | Requirements engineering,18,4–6,,1,https://ieeexplore.ieee.org/document/10251821/,513-538,"GUI is one of the key aspect of an information system from the point of view of customers and users. This paper introduces PLEC, a participative process for designing GUI interfaces with the collaboration of the final users and stakeholders. Participants do not need technical knowledge of GUI prototype. A case study has been developed and carried out to verify if PLEC process is feasible."
JWE,2019,RiAiR: A Framework for Sensitive RDF Protection,M. Irvin Dongo | Richard Chbeir,"Univ. Pau & Pays Adour, UPPA / E2S, LIUPPA, Anglet, France | Univ. Pau & Pays Adour, UPPA / E2S, LIUPPA, Anglet, France",France,RDF protection | Sensitive information | Semantic Web | Disclosure source,Knowledge engineering | Semantics | Syntactics | Resource description framework | Complexity theory | Proposals | Open data,18,1-3,,1,https://ieeexplore.ieee.org/document/10247289/,43-95,"The Semantic Web and the Linked Open Data (LOD) initiatives promote the integration and combination of RDF data on the Web. In some cases, data need to be analyzed and protected before publication in order to avoid the disclosure of sensitive information. However, existing RDF techniques do not ensure that sensitive information cannot be discovered since all RDF resources are linked in the Semantic Web and the combination of different datasets could produce or disclose unexpected sensitive information. In this context, we propose a framework, called RiAiR, which reduces the complexity of the RDF structure in order to decrease the interaction of the expert user for the classification of RDF data into identifiers, quasi-identifiers, etc. An intersection process suggests disclosure sources that can compromise the data. Moreover, by a generalization method, we decrease the connections among resources to comply with the main objectives of integration and combination of the Semantic Web. Results show a viability and high performance for a scenario where heterogeneous and linked datasets are present."
JWE,2019,DotCHA: An Interactive 3D Text-based CAPTCHA,Suzi Kim | Sunghee Choi,"School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Republic of Korea,CAPTCHA | 3D CAPTCHA | text-based CAPTCHA | 3D typography | mental rotation | security | usability,Solid modeling | Three-dimensional displays | Interactive systems | Resists | Machine learning | Solids | Security,18,8,,1,https://ieeexplore.ieee.org/document/10247295/,837-863,"We introduce a new type of 3D text-based CAPTCHA, called DotCHA, which relies on human interaction and overcomes the limitations of existing 2D and 3D CAPTCHAs. DotCHA asks users to rotate a 3D text model to identify the correct letters. The 3D text model is a twisted form of sequential 3D letters around a center pivot axis, and it shows different letters depending on the rotation angle. Because each model consists of many small spheres instead of a solid letter model, DotCHA is classified as a scatter-type CAPTCHA and resists character segmentation attacks. Moreover, DotCHA is resistant to machine learning attacks because each letter is only identified in a particular direction. We demonstrate that DotCHA is resistant to existing types of attacks while maintaining usability."
