title,authors,affiliations,keywords,abstract,venue,year,track_or_issue_name,volume_number,issue,issue_name,pages,length,citations,url
Web Page Structured Content Detection Using Supervised Machine Learning,Roberto Panerai Velloso & Carina F. Dorneles,"Universidade Federal de Santa Catarina - UFSC, Florianopolis, SC, Brazil",Web mining; Content detection; Noise removal; Record extraction; Structure detection; Information retrieval,"In this paper we present a comparative study using several supervised machine learning techniques, including homogeneous and heterogeneous ensembles, to solve the problem of classifying content and noise in web pages. We specifically tackle the problem of detecting content in semi-structured data (e.g., e-commerce search results) under two different settings: a controlled environment with only structured content documents and; an open environment where the web page being processed may or may not have structured content. The features are automatically obtained from a preexisting and publicly available extraction technique that processes web pages as a sequence of tag paths, thus the features are extracted from these sequences instead of the DOM tree. Besides comparing the performance between different models we have also conducted extensive feature selection/combination experiments. We have achieved an average F-score of about 93% in a controlled setting and 91% in an open setting.",International Conference on Web Engineering,2019,,,,,Mar-18,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_1
Streaming Event Detection in Microblogs: Balancing Accuracy and Performance,Ozlem Ceren Sahin & Pinar Karagoz; Nesime Tatbul,"METU, Ankara, Turkey; Intel Labs and MIT, Cambridge, MA, USA",Online event detection; Burst detection; Stream processing; Data stream management; Microblogging,"In this work, we model the problem of online event detection in microblogs as a stateful stream processing problem and offer a novel solution that balances result accuracy and performance. Our new approach builds on two state of the art algorithms. The first algorithm is based on identifying bursty keywords inside blocks of blog messages. The second one involves clustering blog messages based on similarity of their contents. To combine the computational simplicity of the keyword-based algorithm with the semantic accuracy of the clustering-based algorithm, we propose a new hybrid algorithm. We then implement these algorithms in a streaming manner, on top of Apache Storm augmented with Apache Cassandra for state management. Experiments with a 12M tweet dataset from Twitter show that our hybrid approach provides a better accuracy-performance compromise than the previous approaches.",International Conference on Web Engineering,2019,,,,,123-138,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_10
Supervised Group Embedding for Rumor Detection in Social Media,"Yuwei Liu, Xingming Chen & Yanghui Rao; Haoran Xie; Qing Li; Jun Zhang; Yingchao Zhao; Fu Lee Wang","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Department of Mathematics and Information Technology, The Education University of Hong Kong, Tai Po, Hong Kong; School of Computing and Information Sciences, Caritas Institute of Higher Education, Tseung Kwan O, Hong Kong; School of Science and Technology, The Open University of Hong Kong, Kowloon, Hong Kong; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong",Rumor detection; Social media; Convolutional Neural Network,"To detect rumors automatically in social media, methods based on recurrent neural network and convolutional neural network have been proposed. These methods split a stream of posts related to an event into several groups along time, and represent each group using unsupervised methods such as paragraph vector. However, many posts in a group (e.g., retweeted posts) do not contribute much to rumor detection, which deteriorates the performance of rumor detection based on unsupervised group embedding. In this paper, we propose a Supervised Group Embedding based Rumor Detection (SGERD) model that considers both textual and temporal information. Particularly, SGERD exploits post-level textual information to generate group embeddings, and is able to identify salient posts for further analysis. Experimental results on two real-world datasets demonstrate the effectiveness of our proposed model.",International Conference on Web Engineering,2019,,,,,139-153,2,4,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_11
Fast Incremental PageRank on Dynamic Networks,"Zexing Zhan, Ruimin Hu, Xiyue Gao & Nian Huai; Zexing Zhan, Ruimin Hu, Xiyue Gao & Nian Huai","Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University, Wuhan, 430072, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, 430072, China",PageRank tracking; Monte Carlo; Random walk; Incremental computing; Dynamic networks,"Real-world networks are very large and are constantly changing. Computing PageRank values for such dynamic networks is an important challenge in network science. In this paper, we propose an efficient Monte Carlo based algorithm for PageRank tracking on dynamic networks. A revisit probability model is also presented to provide theoretical support for our algorithm. For a graph with n nodes, the proposed algorithm maintains only nR random walk segments (R random walks starting from each node) in memory. The time cost to update PageRank scores for each graph modification is proportional to \(n/|\varvec{E}|\) (\(\varvec{E}\) is the edge set). Experiments on 5 real-world networks indicate that our algorithm is 1.3–30 times faster than state-of-the-art algorithms and does not accumulate any errors.",International Conference on Web Engineering,2019,,,,,154-168,2,16,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_12
Crowdsourced Time-Sync Video Recommendation via Semantic-Aware Neural Collaborative Filtering,"Zhanpeng Wu, Yan Zhou & Di Wu; Zhanpeng Wu, Yan Zhou & Di Wu; Yipeng Zhou; Jing Qin","School of Nursing, The Hong Kong Polytechnic University, Hong Kong, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, 510006, China; Department of Computing, Faculty of Science and Engineering, Macquarie University, Sydney, NSW, 2109, Australia; Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, 510006, China",Recommender system; Time-synchronized comment; Collaborative filtering,"As an emerging type of video comments, time-sync comments (TSCs) enable viewers to make comments on video shots in a real-time manner. Such comments well reflect user interests in the frame level, which can be utilized to further improve the accuracy of video recommendation. In this paper, we make the first attempt in this direction and propose a new video recommendation algorithm called SACF by exploiting temporal relationship between time-sync comments and video frames. Our algorithm can extract a rich set of semantic features from crowdsourced time-sync comments, and combine latent semantic representations of users and videos by neural collaborative filtering. We conduct extensive experiments using real TSC datasets, and our results show that our proposed algorithm can improve the recommendation performance by 9.73% in HR@10 and 5.72% in NDCG@10 compared with other baseline solutions.",International Conference on Web Engineering,2019,,,,,171-186,2,4,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_13
On Twitter Bots Behaving Badly: Empirical Study of Code Patterns on GitHub,Andrea Millimaggi & Florian Daniel,"Politecnico di Milano, Via Ponzio 34/5, 20133, Milan, Italy",Bots; Harm; Abuse; Code patterns; GitHub; Twitter,"Bots, i.e., algorithmically driven entities that behave like humans in online communications, are increasingly infiltrating social conversations on the Web. If not properly prevented, this presence of bots may cause harm to the humans they interact with. This paper aims to understand which types of abuse may lead to harm and whether these can be considered intentional or not. We manually review a dataset of 60 Twitter bot code repositories on GitHub, derive a set of potentially abusive actions, characterize them using a taxonomy of abstract code patterns, and assess the potential abusiveness of the patterns. The study does not only reveal the existence of 31 communication-specific code patterns – which could be used to assess the harmfulness of bot code – but also their presence throughout all studied repositories.",International Conference on Web Engineering,2019,,,,,187-202,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_14
CrowDIY: How to Design and Adapt Collaborative Crowdsourcing Workflows Under Budget Constraints,"Rong Chen, Bo Li, Hu Xing & Yijing Wang","Dalian Maritime University, Dalian, 116026, China",Crowdsourcing workflow; Workflow design and plan; Task publishing; Optimization,"Workflow quality is a key determinant of crowdsourcing complex work, but finding ways to task design and plan has proved illusive. Instead, we formulate it as an optimization problem with budget constraints and fewer decision variables to set. We propose a two-staged approach CrowDIY that can not only estimate task attributes based on previous tasks but also optimize them with budget constraints in order to publish tasks more wisely in a timely manner. Several experimental studies have been conducted, and the results show compelling evidence that, under different conditions, the proposed approach can effectively reduce the workload of workflow design and plan, while avoiding commonly encountered trial-and-error in crowdsourcing workflows and leading up to successful complex outcomes.",International Conference on Web Engineering,2019,,,,,203-210,2,2,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_15
Finding Baby Mothers on Twitter,Yihong Zhang & Adam Jatowt; Yukiko Kawai,"Kyoto Sangyo University, Kyoto, Japan; Kyoto University, Kyoto, Japan",Twitter; Social media analysis; User discovery,"In this paper, we study the task of detecting mothers of babies on Twitter. This could be beneficial for baby mother users to find friends, and for companies, organizations or experts to deliver accurately targeted information. Prior works have proposed supervised classification methods to detect generic latent attributes of Twitter users such as age, gender, and political orientation. However, methods and features for classifying generic attributes do not perform well for more specific attributes, such as whether a user is a mother of a young baby. We design feature sets based on followed accounts and profile pictures, which are largely overlooked in existing work. Comparing to three established feature sets, the experimental evaluation shows that our specifically-designed feature sets considerably improve classification accuracy.",International Conference on Web Engineering,2019,,,,,211-219,2,1,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_16
An End-User Pipeline for Scraping and Visualizing Semi-Structured Data over the Web,"Gabriela Bosetti, Sergio Firmenich, Gustavo Rossi & Ulises Cornejo Fandos; Sergio Firmenich & Gustavo Rossi; Marco Winckler; Előd Egyed-Zsigmond","i3S, Université Nice Sophia Antipolis, 2000, route des Lucioles, bât. Euclide B, BP 121, Sophia Antipolis, France; LIFIA, Facultad de Informática, UNLP, 50th St. and 120th St., La Plata, Argentina; Université de Lyon, LIRIS, INSA-Lyon, 7 Av. Jean Capelle, Villeurbanne, France; CONICET, Buenos Aires, Argentina",Infovis; Web augmentation; Web Scraping,"The Web is a vast source of semi-structured datasets that are made readily available to support the construction of new knowledge. Information visualization techniques have been demonstrated as a suitable alternative for allowing users to analyze and understand a large amount of data. However, the steps required for visualizing semi-structured data obtained from the Web is not straightforward, and it requires proper treatment before information visualization techniques could be applied. In this work, we present a visualization pipeline for describing the fundamental operations required for visualizing semi-structured data over the Web. We employ Web Scraping and Web Augmentation techniques for supporting interactive visualizations and solving tasks without changing the context of use of the data. Our approach is duly supported by a framework including scraping-, augmenting- and visualization-tools and it has been applied to different kinds of websites to demonstrate its validity and feasibility. Our ultimate goal is to expand the limits of our technology for improving the user interaction with websites and creating new experiences for a better understanding of large datasets.",International Conference on Web Engineering,2019,,,,,223-237,2,4,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_17
DotCHA: A 3D Text-Based Scatter-Type CAPTCHA,Suzi Kim & Sunghee Choi,"School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",CAPTCHA; 3D CAPTCHA; Text-based CAPTCHA; 3D typography; Mental rotation; Security; Usability,"We introduce a new type of 3D text-based CAPTCHA, called DotCHA, which relies on human interaction. DotCHA asks users to rotate a 3D text model to identify the correct letters. The 3D text model is a twisted form of sequential 3D letters around a center pivot axis, and it shows different letters depending on the rotation angle. The model is not composed of a solid letter model, but a number of spheres to resist character segmentation attacks, and this is why DotCHA is classified as a scatter-type CAPTCHA. DotCHA is tolerant to machine learning attacks because each letter is only identified in each particular direction. We demonstrate that DotCHA, while maintaining usability, is resistant to existing types of attacks.",International Conference on Web Engineering,2019,,,,,238-252,2,18,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_18
Entropy and Compression Based Analysis of Web User Interfaces,Egor Boychuk & Maxim Bakaev,"Novosibirsk State Technical University, Novosibirsk, Russia",Information entropy; Web interfaces; Cognitive models,"In our paper we explore whether user visual perception of web interfaces (WUI) can be predicted by certain quantitative characteristics of WUI screenshots. The considered metrics are JPEG file size, PNG file size, and information entropy value calculated with frequency-based MATLAB’s entropy(I) function. We ran survey with 70 subjects who provided subjective evaluations of complexity, aesthetics and orderliness for 497 website homepages. The results suggest that all the three metrics were significant, and the proposed regression models were considerably better than the respective baseline models that only used the popular JPEG-based metric. Remarkably, the entropy metric had significant positive correlations with aesthetic and orderliness evaluations, but not with the size of the image. We believe our findings might be used in development of automated WUI analysis tools to aid web engineers in their work.",International Conference on Web Engineering,2019,,,,,253-261,2,27,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_19
Augmenting LOD-Based Recommender Systems Using Graph Centrality Measures,Bart van Rossum & Flavius Frasincar,"Erasmus University Rotterdam, PO Box 1738, 3000 DR, Rotterdam, The Netherlands",Top-N recommendations; Linked Open Data; Information network schema; Random forest,"In this paper we investigate the incorporation of graph-based features into LOD path-based recommender systems, an approach that so far has received little attention. More specifically, we propose two normalisation procedures that adjust user-item path counts by the degree centrality of the nodes connecting them. Evaluation on the MovieLens 1M dataset shows that the linear normalisation approach yields a significant increase in recommendation accuracy as compared to the default case, especially in settings where the most popular movies are omitted. These results serve as a fruitful base for further incorporation of graph measures into recommender systems, and might help in establishing the recommendation diversity that has recently gained much attention.",International Conference on Web Engineering,2019,,,,,19-31,2,7,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_2
Domain Classifier: Compromised Machines Versus Malicious Registrations,"Sophie Le Page, Guy-Vincent Jourdan & Gregor V. Bochmann; Iosif-Viorel Onut; Jason Flood","IBM Security Data Matrices, Dublin, Ireland; Faculty of Engineering, University of Ottawa, Ottawa, Canada; IBM Centre for Advanced Studies, Ottawa, Canada",Phishing attacks; Machine learning; Compromised domains; Malicious domains,"In “phishing attacks”, phishing websites disguised as trustworthy websites attempt to steal sensitive information. Remediation and mitigation options differ depending on whether the phishing website is hosted on a legitimate but compromised domain, in which case the domain owner is also a victim, or whether the domain itself is maliciously registered. We accordingly attempt to tackle here the important question of classifying known phishing sites as either compromised or maliciously registered. Following the recent adoption of GDPR standards now putting off-limits any personal data, few relevant literature criteria still satisfy those standards. We propose here a machine-learning based domain classifier, introducing nine novel features which exploit the internet presence and history of a domain, using only publicly available information. Evaluation of our domain classifier was performed with a corpus of phishing websites hosted on over 1,000 compromised domains and 10,000 malicious domains. In the randomized evaluation, our domain classifier achieved over 92% accuracy with under 8% false positive rate, with compromised cases as the positive class. We have also collected over 180,000 phishing website instances over the past 3 years. Using our classifier we show that 73% of the websites hosting attacks are compromised while the remaining 27% belong to the attackers.",International Conference on Web Engineering,2019,,,,,265-279,2,24,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_20
The “Game Hack” Scam,"Emad Badawi, Guy-Vincent Jourdan & Gregor Bochmann; Iosif-Viorel Onut; Jason Flood","IBM Security Data Matrices, Dublin, Ireland; Faculty of Engineering, University of Ottawa, Ottawa, Canada; IBM Centre for Advanced Studies, Ottawa, Canada",Game scam; Scam analysis; Fraud detection; Cyberattack,"Game Hack Scam (GHS) is a cyberattack in which the attacker attempts to convince the victim, often a child or a young adult, that they will be provided with free, unlimited resources or other advantages for their favorite game. To obtain these claimed advantages, the victims are asked to complete one or more tasks, called “offers”. These so-called offers include, but are not limited to, subscriptions to questionable services and installation of executable files on the victim’s device. Although recent research has provided important insights into different types of scam such as “Technical Support Scam”, “Survey Scam”, and “Romance Scam”, to the best of our knowledge GHS has not been studied up to now.",International Conference on Web Engineering,2019,,,,,280-295,2,14,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_21
Decentralized Service Registry and Discovery in P2P Networks Using Blockchain Technology,"Peter de Lange, Tom Janson & Ralf Klamma","RWTH Aachen University, Lehrstuhl Informatik 5, Ahornstr. 55, 52074, Aachen, Germany",Service discovery; Decentralization; Microservices; Blockchain,"Decentralized information systems radically change the power dynamics of the Web by establishing participants as equal peers, which form a self-governing community. However, decentralized infrastructures currently do not offer a way for users to easily explore available services in the network, nor the ability to securely verify their origin and history. In this contribution, we approach these challenges by exploiting the tamper-proofness of blockchain technology to build a decentralized service registry and discovery system for an existing decentralized microservice infrastructure. With this, users are able to find services in a network and are also able to verify their integrity and origin. Our first evaluations show promising results with this kind of system in the domain of decentralized service provisioning, while also raising research questions for future research in this field.",International Conference on Web Engineering,2019,,,,,296-311,2,16,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_22
Amalgam: Hardware Hacking for Web Developers with Style (Sheets),"Jorge Garza, Devon J. Merrill & Steven Swanson","Department of Computer Science and Engineering, University of California San Diego, San Diego, CA, USA",Rapid development; Embedded devices; IoT; Web user interface; CSS; HTML,"Web programming technologies such as HTML, JavaScript, and CSS have become a popular choice for user interface design due to their capabilities: flexible interface, first-class networking, and available libraries. In parallel, driven by the standards set by the mobile companies, embedded devices manufacturers now want to replicate these capabilities. As a result, embedded devices that use web technologies for their graphical interface have started to emerge. However, the programming effort required to integrate web technologies with embedded software hinders its adaption. In this paper, we introduce Amalgam, a system that facilitates the development of embedded devices that use web programming technologies. Amalgam does this by translating the physical interface of embedded hardware components found (e.g., a push button) directly into the HTML and CSS syntax. Our system reduces the programming effort required to develop new embedded devices that use web technologies, as well as adds new interesting capabilities to the design of these. We show Amalgam’s capabilities by exploring three embedded devices built using web programming technologies. Also, we demonstrate how Amalgam reduces programming effort by comparing two traditional approaches of building one of these devices against Amalgam. Results show our system reduces the lines of code required to integrate hardware elements into an embedded device application to a line of code per hardware component added to the device.",International Conference on Web Engineering,2019,,,,,315-330,2,1,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_23
Jekyll RDF: Template-Based Linked Data Publication with Minimized Effort and Maximum Scalability,Natanael Arndt; Natanael Arndt & Sebastian Zänker; Gezim Sejdiu; Sebastian Tramp,"eccenca GmbH, Hainstr. 8, 04109, Leipzig, Germany; Institut für Angewandte Informatik e.V., Goerdelerring 9, 04109, Leipzig, Germany; AKSW, Leipzig University, Augustusplatz 10, 04109, Leipzig, Germany; Smart Data Analytics, University of Bonn, Endenicher Allee 19a, 53115, Bonn, Germany",Data visualization; Data publication; Static site generation; Content Management; Semantic templating; Linked Data,"Over the last decades the Web has evolved from a human–human communication network to a network of complex human–machine interactions. An increasing amount of data is available as Linked Data which allows machines to “understand” the data, but RDF is not meant to be understood by humans. With Jekyll RDF we present a method to close the gap between structured data and human accessible exploration interfaces by publishing RDF datasets as customizable static HTML sites. It consists of an RDF resource mapping system to serve the resources under their respective IRI, a template mapping based on schema classes, and a markup language to define templates to render customized resource pages. Using the template system, it is possible to create domain specific browsing interfaces for RDF data next to the Linked Data resources. This enables content management and knowledge management systems to serve datasets in a highly customizable, low effort, and scalable way to be consumed by machines as well as humans.",International Conference on Web Engineering,2019,,,,,331-346,2,7,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_24
On the Web Platform Cornucopia,Tommi Mikkonen; Cesare Pautasso; Kari Systä; Antero Taivalsaari,"USI, Lugano, Switzerland; Nokia Bell Labs, Tampere, Finland; Tampere University, Tampere, Finland; University of Helsinki, Helsinki, Finland",Web platform; Technology design space; Software engineering principles; Web Engineering; Progressive Web applications; HTML5,"The evolution of the Web browser has been organic, with new features introduced on a pragmatic basis rather than following a clear rational design. This evolution has resulted in a cornucopia of overlapping features and redundant choices for developing Web applications. These choices include multiple architecture and rendering models, different communication primitives and protocols, and a variety of local storage mechanisms. In this position paper we examine the underlying reasons for this historic evolution. We argue that without a sound engineering approach and some fundamental rethinking there will be a growing risk that the Web may no longer be a viable, open software platform in the long run.",International Conference on Web Engineering,2019,,,,,347-355,2,5,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_25
Linked USDL Extension for Cloud Services Description,"Hajer Nabli, Raoudha Ben Djemaa & Ikram Amous Ben Amor; Raoudha Ben Djemaa; Ikram Amous Ben Amor","Higher Institute of Computer Science and Communication Techniques of H. Sousse, University of Sousse, 4011, H. Sousse, Tunisia; National School of Electronics and Telecommunications of Sfax, University of Sfax, 3018, Sfax, Tunisia; Higher Institute of Computer Science and Multimedia of Sfax, University of Sfax, MIRACL, 3021, Sfax, Tunisia",Cloud service; Cloud service description ontology; Cloud characteristics; Linked USDL,"Cloud computing has become the most influential paradigm in recent years, both in industry and academia. A Cloud provider delivers Cloud services to businesses or individuals. However, each Cloud provider uses its own techniques to describe their Cloud services. It is therefore difficult to compare Cloud offers and then provide the appropriate service to the user. Especially that the Cloud services can provide the same functionalities, but they differ by their quality of service, price, Cloud characteristics, service credibility, and so on. The variety of these techniques is due to the lack of Cloud service description standardization. To deal with such issues, we propose in this paper a Cloud service description ontology that assists the Cloud service publication, discovery and selection processes. The proposed description will be extended from the Linked USDL language to describe Cloud services thanks to its expressiveness by covering four aspects namely technical, operational, business and semantic.",International Conference on Web Engineering,2019,,,,,359-373,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_26
An Automatic Data Service Generation Approach for Cross-origin Datasets,"Yuanming Zhang, Langyou Huang, Jiawei Lu & Gang Xiao","Zhejiang University of Technology, Hangzhou, China",Data service; Service extraction; Service encapsulation; Service dependency graph; Cross-origin datasets,"As a unified data access model, data service has become a promising technique to integrate and share heterogeneous datasets. In order to publish overwhelming data on the web, it is a key to automatically extract and encapsulate data services from various datasets in cloud environment. In this paper, a novel data service generation approach for cross-origin datasets is proposed. An attribute dependency graph (ADG) is constructed by using inherent data dependency. Based on the ADG, an automatic data service extraction algorithm is implemented. The extracted atomic data services are further organized into another representation named data service dependency graph (DSDG). Then, a data service encapsulation framework, which includes an entity layer, a data access object layer and a service layer, is designed. Via a flexible RESTful service template, this framework can automatically encapsulate the extracted data services into the RESTful services which can be accessed by the exposed interfaces. In addition, a data service generation system has been developed. Experimental results show that the system has high efficiency and good quality for data service generation.",International Conference on Web Engineering,2019,,,,,374-390,2,0,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_27
Merging Intelligent API Responses Using a Proportional Representation Approach,"Tomohiro Ohtake, Mohamed Abdelrazek & Rajesh Vasa; Alex Cummaudo; John Grundy","Applied Artificial Intelligence Institute, Deakin University, Geelong, Australia; Faculty of Information Technology, Monash University, Caulfield, Australia; Faculty of Science, Engineering and Built Environment, Deakin University, Geelong, Australia",Application programming interfaces; Web services; Data integration; Artificial intelligence; Supervised learning,"Intelligent APIs, such as Google Cloud Vision or Amazon Rekognition, are becoming evermore pervasive and easily accessible to developers to build applications. Because of the stochastic nature that machine learning entails and disparate datasets used in their training, the output from different APIs varies over time, with low reliability in some cases when compared against each other. Merging multiple unreliable API responses from multiple vendors may increase the reliability of the overall response, and thus the reliability of the intelligent end-product. We introduce a novel methodology – inspired by the proportional representation used in electoral systems – to merge outputs of different intelligent computer vision APIs provided by multiple vendors. Experiments show that our method outperforms both naive merge methods and traditional proportional representation methods by 0.015 F-measure.",International Conference on Web Engineering,2019,,,,,391-406,2,4,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_28
Analyzing the Evolution of Linked Vocabularies,Mohammad Abdel-Qader; Mohammad Abdel-Qader & Iacopo Vagliano; Ansgar Scherp,"Christian-Albrechts University, Kiel, Germany; University of Essex, Colchester, UK; ZBW – Leibniz Information Centre for Economics, Kiel, Germany",,"Reusing terms results in a Network of Linked vOcabularies (NeLO), where the nodes are the vocabularies that use at least one term from some other vocabulary and thus depend on each other. These dependencies become a problem when vocabularies in the network change, e. g., when terms are deprecated or deleted. In these cases, all dependent vocabularies in the network need to be updated. So far, there has been no study that analyzes vocabulary changes in NeLO over time. To address this shortcoming, we compute the state of NeLO from the available versions of the vocabularies over 17 years. We analyze static parameters of NeLO such as its size, density, average degree, and the most important vocabularies at certain points in time. We further investigate how NeLO changes over time. Specifically, we measure the impact of a change in one vocabulary to others, how the reuse of terms changes, and the importance of vocabularies changes. Our analyses provide for the first time in-depth insights into the structure and evolution of NeLO. This study helps ontology engineers to identify shortcomings of the data modeling and to assess the dependencies implied with reusing a specific vocabulary.",International Conference on Web Engineering,2019,,,,,409-424,2,3,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_29
ST-Sem: A Multimodal Method for Points-of-Interest Classification Using Street-Level Imagery,"Shahin Sharifi Noorian, Achilleas Psyllidis & Alessandro Bozzon","Delft University of Technology, Delft, The Netherlands",Points of Interest; Street-level imagery; Convolutional Neural Networks; Word embeddings; Semantic similarity,"Street-level imagery contains a variety of visual information about the facades of Points of Interest (POIs). In addition to general morphological features, signs on the facades of, primarily, business-related POIs could be a valuable source of information about the type and identity of a POI. Recent advancements in computer vision could leverage visual information from street-level imagery, and contribute to the classification of POIs. However, there is currently a gap in existing literature regarding the use of visual labels contained in street-level imagery, where their value as indicators of POI categories is assessed. This paper presents Scene-Text Semantics (ST-Sem), a novel method that leverages visual labels (e.g., texts, logos) from street-level imagery as complementary information for the categorization of business-related POIs. Contrary to existing methods that fuse visual and textual information at a feature-level, we propose a late fusion approach that combines visual and textual cues after resolving issues of incorrect digitization and semantic ambiguity of the retrieved textual components. Experiments on two existing and a newly-created datasets show that ST-Sem can outperform visual-only approaches by 80% and related multimodal approaches by 4%.",International Conference on Web Engineering,2019,,,,,32-46,2,12,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_3
Comparison Matrices of Semantic RESTful APIs Technologies,Antoine Cheron & Antoine Michel; Johann Bourcier & Olivier Barais,"Univ Rennes, Inria, CNRS, IRISA, 263 Avenue General Leclerc, 35000, Rennes, France; FABERNOVEL, 46 rue Saint-Lazare, 75009, Paris, France",Hateoas; Semantic REST; Comparison; Linked Data; Web,"Semantic RESTful APIs combine the power of the REST architectural style, the Semantic Web and Linked Data. They picture a world in which Web APIs are easier to browse and more meaningful for humans while also being machine-interpretable, turning them into platforms that developers and companies can build on. We counted 36 technologies that target building such APIs. As there is no one-size-fits-all technology, they have to be combined. This makes selecting the appropriate set of technologies to a specific context a difficult task for architects and developers. So, how the selection of such a set of technologies can be eased? In this paper we propose three comparison matrices of Semantic RESTful APIs enabling technologies. It is based on the analysis of the differences and commonalities between existing technologies. It intends to help developers and architects in making an informed decision on the technologies to use. It also highlights the limitations of state-of-the-art technologies from which open challenges are derived.",International Conference on Web Engineering,2019,,,,,425-440,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_30
Dragon: Decision Tree Learning for Link Discovery,Daniel Obraczka; Axel-Cyrille Ngonga Ngomo,"University of Leipzig, 04109, Leipzig, Germany; University of Paderborn, 33098, Paderborn, Germany",Link discovery; Decision trees; Machine learning; Entity resolution; Semantic web,"The provision of links across RDF knowledge bases is regarded as fundamental to ensure that knowledge bases can be used joined to address real-world needs of applications. The growth of knowledge bases both with respect to their number and size demands the development of time-efficient and accurate approaches for the computation of such links. This is generally done with the aid of machine learning approaches, such as e.g. Decision Trees. While Decision Trees are known to be fast, they are generally outperformed in the link discovery task by the state-of-the-art in terms of quality, i.e. F-measure. In this work, we present Dragon, a fast decision-tree-based approach that is both efficient and accurate. Our approach was evaluated by comparing it with state-of-the-art link discovery approaches as well as the common decision-tree-learning approach J48. Our results suggest that our approach achieves state-of-the-art performance with respect to its F-measure while being 18 times faster on average than existing algorithms for link discovery on RDF knowledge bases. Furthermore, we investigate why Dragon significantly outperforms J48 in terms of link accuracy. We provide an open-source implementation of our algorithm in the LIMES framework.",International Conference on Web Engineering,2019,,,,,441-456,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_31
Catch & Release: An Approach to Debugging Distributed Full-Stack JavaScript Applications,Kijin An & Eli Tilevich,"Software Innovations Lab, Virginia Tech, Blacksburg, USA",Full-stack JavaScript applications; Distributed computing; Debugging,"Localizing bugs in distributed applications is complicated by the potential presence of server/middleware misconfigurations and intermittent network connectivity. In this paper, we present a novel approach to localizing bugs in distributed web applications, targeting the important domain of full-stack JavaScript applications. The debugged application is first automatically refactored to create its semantically equivalent centralized version by gluing together the application’s client and server parts, thus separating the programmer-written code from configuration/environmental issues as suspected bug causes. The centralized version is then debugged to fix various bugs. Finally, based on the bug fixing changes of the centralized version, a patch is automatically generated to fix the original application source files. We show how our approach can be used to catch bugs that include performance bottlenecks and memory leaks. These results indicate that our debugging approach can facilitate the challenges of localizing and fixing bugs in web applications.",International Conference on Web Engineering,2019,,,,,459-473,2,12,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_32
Multi-device Adaptation with Liquid Media Queries,Andrea Gallidabino & Cesare Pautasso,"Software Institute, Faculty of Informatics, Università della Svizzera italiana (USI), Lugano, Switzerland",Liquid software; Media queries; Multi-device adaptation; Responsive user interface; Complementary view adaptation,"The design of responsive Web applications is traditionally based on the assumption that they run on a single client at a time. Thanks to CSS3 media queries, developers can declaratively specify how the Web application UI adapts to the capabilities of specific devices. As users own more and more devices and they attempt to use them to run Web applications in parallel, we propose to extend CSS media queries so that they can be used to adapt the UI of liquid Web applications while they are dynamically deployed across multiple devices. In this paper we present our extension of CSS media queries with liquid-related types and features, allowing to detect the number of devices connected, the number of users running the application, or the role played by each device. The liquid media query types and features defined in this paper are designed and suitable for liquid component-based Web architectures, and they enable developers to control the deployment of individual Web components across multiple browsers. Furthermore we show the design of liquid media queries in the Liquid.js for Polymer framework and propose different adaptation algorithms. Finally we showcase the expressiveness of the liquid media queries to support real-world examples and evaluate the algorithmic complexity of our approach.",International Conference on Web Engineering,2019,,,,,474-489,2,3,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_33
Conversational Data Exploration,"Nicola Castaldo, Florian Daniel, Maristella Matera & Vittorio Zaccaria","Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Piazza Leonardo da Vinci, 32, 20133, Milan, Italy",Chatbots for data exploration; Chatbot design; Conversational UIs,"This paper presents a framework for the design of chatbots for data exploration. With respect to conversational virtual assistants (such as Amazon Alexa or Apple Siri), this class of chatbots exploits structured input to retrieve data from known data sources. The approach is based on a conceptual representation of the available data sources, and on a set of modeling abstractions that allow designers to characterize the role that key data elements play in the user requests to be handled. Starting from the resulting specifications, the framework then generates a conversation for exploring the content exposed by the considered data sources.",International Conference on Web Engineering,2019,,,,,490-497,2,24,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_34
Distributed Intelligent Client-Centric Personalisation,Rebekah Storan Clarke & Vincent Wade,"Trinity College Dublin, Dublin, Ireland",Client side personalisation; Privacy; Prefetching; Click prediction; Interaction modelling,"Personalisation is used extensively to improve user engagement, to optimise user experience and to enhance marketing and advertising online. While privacy has always been an issue in personalised websites, only recently have we seen a noticeable change in consumer’s behaviour’s. User’s are seeing breaches of the personal information harvested, stored and shared by content providers and increasingly adjusting privacy controls, thus negatively impacting the effectiveness of personalisation services. Client-Side personalisation (CSP) approaches offer a privacy-conscious solution, keeping the user data and user model on the client’s own device, allowing users to enjoy personalised content without compromising the privacy of their personal data. However, these solutions have significant problems with scalability and performance due to client-device resource limitations. With an ever-increasing demand for rich multimedia, particularly on more lightweight mobile devices, performance is critical to provide a seamless user experience. This research proposes a hybrid approach which we term Intelligent Client-Centric Personalisation (ICCP), this minimises the leakage of user data while enhancing performance through predictive webpage prefetching. This paper performs a comparative framework evaluation, comparing the ICCP framework performance with a typical client-server personalisation approach. It uses a large dataset of user interactions across three contrasting consumer websites, following case study based methodology. Evaluation shows that such a framework can realise the performance benefits of a client-server approach but with enhanced privacy and reduced personal data leakage.",International Conference on Web Engineering,2019,,,,,498-505,2,3,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_35
Webifying Heterogenous Internet of Things Devices,"Mahda Noura, Sebastian Heil & Martin Gaedke","Technische Universität Chemnitz, Chemnitz, Germany",Internet of Things; Web of Things; Semantic web; OpenAPI; Interoperability,"Internet of Things (IoT) applications incorporate heterogenous smart devices that support different communication protocols (Zigbee, RFID, Bluetooth, custom protocols). Enabling application development employing different protocols require interoperability between the different types of heterogenous devices that co-exist in the IoT ecosystem. In this paper we propose WoTDL2API tool, that automatically generates a running RESTful API based on the popular OpenAPI specification and integrating with the existing OpenAPI code generation toolchain. This solution provides interoperability between the devices by wrapping IoT devices with a Web-based interface enabling easier integration with other platforms. We showcase our approach using a smart home scenario available online.",International Conference on Web Engineering,2019,,,,,509-513,2,19,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_36
VR-Powered Scenario-Based Testing for Visual and Acoustic Web of Things Services,"KyeongDeok Baek, HyeongCheol Moon & In-Young Ko","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Scenario-based testing; Virtual reality-powered testing; Web of things services,"Web of Things (WoT) services are Web services that interact with physical things in the environment. Testing of WoT services should be performed considering the physical and human factors that affect their quality. Scenario-based testing is known to be one of the most effective testing techniques by which we can test software while considering various real-world scenarios. However, applying scenario-based testing to real-world WoT testbed environments is not practical in terms of cost and reconfigurability. In this work, we utilize Virtual Reality (VR) technology to mimic real-world WoT environments for cost-effective testing over various scenarios.",International Conference on Web Engineering,2019,,,,,514-518,2,4,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_37
User’s Emotional eXperience Analysis of Wizard Form Pattern Using Objective and Subjective Measures,"Muhammad Zaki Ansaar, Jamil Hussain, Asim Abass, Musarrat Hussain & Sungyoung Lee","Department of Computer Science and Engineering, Kyung Hee University, Seoul, South Korea",User experience; Multi-steps form; Emotional experience,"Forms are the ordinary medium to collect data from prospective users and indirectly build a cordial relationship with them. This communication bridge can affect the user emotional reaction, whenever a user finds an unexpected error during or submitting the form. This paper presents an empirical user emotional eXperience study on wizard form pattern (Multi Step Form). The study mainly uses both objective measures through brain wave activity (EEG) with eye tracking data and subjective measures through a self-reported metrics. Fifteen participants (N = 15) joined the experiment by filling the wizard form pattern. We manipulated the experiment by generating a sudden error at one step and grouped these experiments by their step number. We observe that the error affects the motivational emotion of group1 (got an error on the first step), the excitement emotion of group2 (got an error on the second step), the frustration emotion of group3 (got an error on the third step) and group4 (got no error). We thus argue that an error while filling or submitting a form is more emotional than technical.",International Conference on Web Engineering,2019,,,,,521-524,2,1,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_38
Integration Platform for Metric-Based Analysis of Web User Interfaces,Maxim Bakaev & Nikita Perminov; Sebastian Heil & Martin Gaedke,"Technische Universität Chemnitz, Chemnitz, Germany; Novosibirsk State Technical University, Novosibirsk, Russia",User interaction quality; Design mining; HCI vision; User behavior modeling,"We present a software tool for collecting web UI metrics from different providers and integrating them in a single database for further analysis. The platform’s architecture supports both code- and image-based UI assessment, thus allowing to combine advantages of the two approaches. The data structures are based on a web UI measurement domain ontology (OWL) that organizes the currently disperse set of metrics and services. Our platform can be of use to interface designers, researchers, and UI analysis tools developers.",International Conference on Web Engineering,2019,,,,,525-529,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_39
Time and Location Recommendation for Crime Prevention,Yihong Zhang & Adam Jatowt; Panote Siriaraya & Yukiko Kawai,"Kyoto Sangyo University, Kyoto, Japan; Kyoto University, Kyoto, Japan",Crime prediction; Web open data; Recommendation,"In recent years we have seen more and more open government and administrative data made available on the Web. Crime data, for example, allows civic organizations and ordinary citizens to obtain safety-related information on their surroundings. In this paper, we study crime prediction as a recommendation problem, using fine-grained open crime data. A common issue in current crime prediction methods is that, given fine-grained spatial temporal units, crime data would become very sparse, and prediction would not work properly. By modeling crime prediction as a recommendation problem, however, we can make use of the abundant selection of methods in recommendation systems that inherently consider data sparsity. We present our model and show how collaborative filtering and contextual-based recommendation methods can be applied. Focusing on two major types of crimes in the city of San Francisco, our empirical results show that recommendation methods can outperform traditional crime prediction methods, given small spatial and temporal granularity. Specifically, we show that by using recommendation methods, we can capture 70% of future thefts using only 20% man-hour, 13% more than traditional methods.",International Conference on Web Engineering,2019,,,,,47-62,2,7,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_4
Personal Information Controller Service (PICS),"Marco Winckler; Laurent Goncalves & Olivier Nicolas; Frédérique Biennier & Hind Benfenatki; Thierry Despeyroux & Nourhène Alaya; Alex Deslée, Mbaye Fall Diallo & Isabelle Collin-Lachaud; Gautier Ubersfeld; Christophe Cianchi","Université Nice Sophia Antipolis, Nice, France; Business Card Associates, Paris, France; Université de Lille, Lille, France; Softeam, Toulouse, France; LIRIS, INSA Lyon, Lyon, France; Anyware Service, Labège, France; Inria, Le Chesnay, France",Personal data protection; Personal information systems; GDPR,"This paper presents a view at glance of the project PICS (which stands for Personal Information Controller Service) that is concerned by personal data protection. More specifically we present a software platform that allows users to control the exchanges between Web-based Personal Information Management Systems (the so-called PIMS that store users’ personal data) and SaaS services (such as e-commerce applications) using a reinforced authentication. The ultimate goal of this platform is to empower users by allowing them to have full control on personal data exchange. Moreover, the platform includes specific components to help users to solve cognitive demanding tasks related to the data protection such as how to properly interpret Terms of Service (ToS) imposed by the SaaS, recall previous users interactions with the SaaS (ex. personal data exchanged with the SaaS and the corresponding term of services), and detect unauthorized use of personal data. The technical solution proposed by PICS is a suitable implementation of the General Data Protection Regulation (GDPR). We present the motivations, challenges and research questions that lead to the technical solution proposed by PICS.",International Conference on Web Engineering,2019,,,,,530-533,2,1,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_40
Enabling the Interconnection of Smart Devices Through Semantic Web Techniques,"Daniel Flores-Martin, Javier Berrocal, José Garcí­a-Alonso & Juan M. Murillo; Carlos Canal","Universidad de Málaga, Málaga, Spain; Universidad de Extremadura, Badajoz, Spain",Web of Things; Semantic web; Collaboration,"Nowadays, there are millions of devices connected to the Internet. This is what we know as called Internet of Things. The integration of these smart devices with the web protocols makes them more accessible and understandable by people. The purpose of these devices is to make people’s lives easier. Thanks to the collaboration between devices, the possibilities that the Web of Things offers can be even more exploited. However, many manufacturers develop their own devices and protocols in order to protect their market share, limiting in many ways the collaboration between devices of different manufacturers. This paper presents a solution based on semantic web techniques with the purpose of achieving collaboration between devices regardless of the technologies and protocols developed by their manufacturers.",International Conference on Web Engineering,2019,,,,,534-537,2,8,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_41
Content- and Context-Related Trust in Open Multi-agent Systems Using Linked Data,Valentin Siegert,"Technische Universität Chemnitz, Chemnitz, Germany",Solid; Trust; Content trust; Multi-agent systems; Linked data,"In open multi-agent systems, linked data enables agents to communicate with each other and to gather knowledge for autonomous decision. Until now, trust is a factor for starting communications and ignores doubts about the content or context of ongoing communications. Several approaches are used to identify whom to trust and how human trust can be computationally modeled. Yet, they do not consider a change of context or of other agents’ behavior at runtime. The proposed doctoral work aims to support content- and context-related trust in open multi-agent systems using linked data. Existing trust models need to be surveyed with respect to content- and context-related trust. A framework based on a fitting trust model and working with linked data must be developed to establish and dynamically refine trust relationships on the autonomous agents’ point of view. This would enhance the applicability of decentralized systems without introducing central units as the history of the web demonstrates. Web engineers are hereby supported to work on a new level of abstraction using the decentralization, but not scrutinizing specific communication sequences.",International Conference on Web Engineering,2019,,,,,541-547,2,3,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_42
Facilitating the Evolutionary Modifications in Distributed Apps via Automated Refactoring,Kijin An,"Software Innovations Lab, Virginia Tech, Blacksburg, USA",Distributed applications; Evolutionary modifications; Automated refactoring,"Actively used software applications must be changed continuously to ensure their utility, correctness, and performance. To perform these changes, programmers spend a considerable amount of time and effort pinpointing the exact locations in the code to modify, a particularly hard task for distributed applications. In distributed applications, server/middleware misconfigurations and network volatility often cause performance and correctness problems. My dissertation research puts forward a novel approach to facilitating the evolutionary modifications of distributed applications that introduces a novel automated refactoring—Client Insourcing. This refactoring transforms a distributed application into its semantically equivalent centralized variant, in which the remote parts are glued together and communicate with each other by means of regular function calls, eliminating any middleware, server, and network-related problems from the list of potential problem causes. Programmers then can use the resulting centralized variant to facilitate debugging, security enhancements, and fault-tolerance adaptations (Some of the preliminary work of this dissertation is described in a paper accepted for presentation in the main technical program of ICWE 2019 [4]).",International Conference on Web Engineering,2019,,,,,548-553,2,7,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_43
Effect-Driven Selection of Web of Things Services in Cyber-Physical Systems Using Reinforcement Learning,KyeongDeok Baek & In-Young Ko,"School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Service effectiveness; Effect-driven WoT service selection; Reinforcement learning; Cyber-physical System,"Recently, Web of Things (WoT) expands its boundary to Cyber-physical Systems (CPS) that actuate or sense physical environments. However, there is no quantitative metric to measure the quality of physical effects generated by WoT services. Furthermore, there is no dynamic service selection algorithm that can be used to replace services with alternative ones to manage the quality of service provisioning. In this work, we study how to measure the effectiveness of delivering various types of WoT service effects to users, and develop a dynamic service handover algorithm using reinforcement learning to ensure the consistent provision of WoT services under dynamically changing conditions due to user mobility and changing availability of WoT media to deliver service effects. The preliminary results show that the simple distance-based metric is insufficient to select appropriate WoT services in terms of the effectiveness of delivering service effects to users, and the reinforcement-learning-based algorithm performs well with learning the optimal selection policy from simulated experiences in WoT environments.",International Conference on Web Engineering,2019,,,,,554-559,2,3,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_44
Liquid Web Architectures,Andrea Gallidabino,"Software Institute, Faculty of Informatics, Università della Svizzera italiana (USI), Lugano, Switzerland",Liquid software; Multi-device adaptation; Web design,"Nowadays users access the Web differently from what they used to in the past, the devices we use to fetch applications from the Web are not the same as the slow desktop computers that we owned twenty years ago. The Web can be accessed by devices with different sizes and capabilities, ranging from desktop to laptop computers, or even from tablets to phones. More recently, also smart and embedded devices, such as smart televisions, smart watches or parts of smart cars, are able to communicate with remote Web servers through the Web. The average number of Web-enabled devices owned by a single user has also increased and the connected user usually access the Web with multiple devices concurrently.",International Conference on Web Engineering,2019,,,,,560-565,2,18,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_45
Exploiting Side Information for Recommendation,Qing Guo & Yin-Leng Theng; Zhu Sun,"Nanyang Technological University, 50 Nanyang Ave, Singapore, 639798, Singapore; Shopee, 2 Science Park Drive, Singapore, 118222, Singapore",,"Recommender systems have become extremely essential tools to help resolve the information overload problem for users. However, traditional recommendation techniques suffer from critical issues such as data sparsity and cold start problems. To address these issues, a great number of recommendation algorithms have been proposed by exploiting the side information. This tutorial aims to provide a comprehensive analysis of how to exploit various kinds of side information for improving recommendation performance. Specifically, we present the usage of side information from two perspectives: the representation and methodology. By this tutorial, researchers of recommender system would gain an in-depth understanding of how side information can be utilized for better recommendation performance.",International Conference on Web Engineering,2019,,,,,569-573,2,16,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_46
"Deep Learning-Based Sequential Recommender Systems: Concepts, Algorithms, and Evaluations",Hui Fang & Danning Zhang; Guibing Guo & Yiheng Shu,"Shanghai University of Finance and Economics, Shanghai, China; Northeastern University, Shenyang, China",Sequential recommendation; Deep learning techniques,"What is sequential recommendation? What challenges are traditional sequential recommendation models facing? How to address these challenges in sequential recommendation using advanced deep learning (DL) techniques? What factors do affect the performance of a DL-based sequential recommendation system? And how to utilize these factors to improve DL models? In this tutorial, we will carefully answer these questions by combining DL techniques with sequential recommendation, and provide a comprehensive overview of DL-based sequential recommender system. Specifically, we propose a novel classification framework for sequential recommendation tasks, with which we systematically introduce representative DL-based algorithms for different sequential recommendation scenarios. We further summarize the potentially influential factors of DL-based sequential recommendation, and thoroughly demonstrate their effects via a carefully designed experimental framework, which will be of great help to future research.",International Conference on Web Engineering,2019,,,,,574-577,2,65,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_47
Architectures Server-Centric vs Mobile-Centric for Developing WoT Applications,"Javier Berrocal, Jose Garcia-Alonso & Juan Manuel Murillo","Escuela Politécnica, Quercus Software Engineering Group, University of Extremadura, Avda. de la Universidad s/n, 10003, Cáceres, Spain",Web of Things; Web application development; Mobile-centric; Server-centric,"The massive adoption of smart devices has fostered the development of Web of Things (WoT) applications. Due to the limited capabilities of these devices (some of them are battery powered, or the data exchange is limited), these applications have very stringent requirements. The success or failure of these applications largely depends on how they address these requirements, being the resource consumption a crucial one. Our experience has shown us that with different architectural styles we can obtain a similar behaviour, but the selected style directly impacts on the resource consumption. During the last few years, different frameworks, tools and activities have been proposed to estimate this consumption in early development phases in order to guide the decision making process. However, they are still not incorporated by the industry and researchers. This tutorial delves into different architectural styles that can be applied and what tools can be used to early estimate their consumption.",International Conference on Web Engineering,2019,,,,,578-581,2,4,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_48
Powerful Data Analysis and Composition with the UNIX-Shell,Andreas Schmidt; Andreas Schmidt & Steffen Scholz,"University of Applied Sciences, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",Unix-Shell; Filter and Pipes; Transformation of data,"In addition to a wide range of commercially available data processing tools for data analysis and knowledge discovery, there are a bundle of Unix-shell scripting and text processing tools practically available on every computer. This paper reports on some of these data processing tools and presents how they can be used together to manipulate and transform data and also to perform some sort of analysis like aggregation, etc. Beside the free availability, these tools have the advantage that they can be used immediately, without prior transformation and loading the data into the target system. Another important point is, that they are typically stream-based and thus, huge amounts of data can be processed without running out of main-memory.",International Conference on Web Engineering,2019,,,,,582-585,2,0,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_49
Incremental PARAFAC Decomposition for Three-Dimensional Tensors Using Apache Spark,Hye-Kyung Yang & Hwan-Seung Yong,"Department of Computer Science and Engineering, Ewha Womans University, Seoul, Korea",PARAFAC decomposition; Incremental tensor decomposition; Apache Spark,"Recent studies have focused on the use of tensor analysis for tensor decomposition because this method can identify more latent factor and patterns, compared to the matrix factorization approach. The existing tensor decomposition studies used static dataset in their analyses. However, in practice, data change and increase over time. Therefore, this paper proposes an incremental Parallel Factor Analysis (PARAFAC) tensor decomposition algorithm for three-dimensional tensors. The method of incremental tensor decomposition can reduce recalculation costs associated with the addition of new tensors. The proposed method is called InParTen; it performs distributed incremental PARAFAC tensor decomposition based on the Apache Spark framework. The proposed method decomposes only new tensors and then combines them with existing results without recalculating the complete tensors. In this study, it was assumed that the tensors grow with time as the majority of the dataset is added over a period. In this paper, the performance of InParTen was evaluated by comparing the obtained results for execution time and relative errors against existing tensor decomposition tools. Consequently, it has been observed that the method can reduce the recalculation cost of tensor decomposition.",International Conference on Web Engineering,2019,,,,,63-71,2,5,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_5
Non-monotonic Reasoning on the Web,Matteo Cristani,"Dipartimento di Informatica, Università di Verona, Verona, Italy",,"In this tutorial we describe the approaches to non monotonic reasoning as a means for inference on the web. In particular we are focusing on the ways in which reasoning technologies have adapted to five different issues of the modern era world wide web: (a) epistemic aspects, bound by the new models of the social web, (b) changes over time, (c) language variants, including different languages of deployment of a web site, (d) agent-based knowledge deployment, due to social networks and blogs, (e) dialogue aspects, introduced again in blogs and social networks. The presentation covers these aspects by a technical viewpoint, including the introduction of specific knowledge-driven methods. The technical issues will be provided within a general logical framework known as defeasible logic.",International Conference on Web Engineering,2019,,,,,586-589,2,0,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_50
Correction to: Dragon: Decision Tree Learning for Link Discovery,Daniel Obraczka; Axel-Cyrille Ngonga Ngomo,"University of Leipzig, 04109, Leipzig, Germany; University of Paderborn, 33098, Paderborn, Germany",,,International Conference on Web Engineering,2019,,,,,C1-C1,2,0,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_51
Modeling Heterogeneous Influences for Point-of-Interest Recommendation in Location-Based Social Networks,"Qing Guo, Jie Zhang & Yin-Leng Theng; Zhu Sun","Nanyang Technological University, 50 Nanyang Ave, Singapore, 639798, Singapore; Shopee, 2 Science Park Drive, Singapore, 118222, Singapore",Location-based social network; POI recommendation; Knowledge graph; Matrix factorization,"The huge amount of heterogeneous information in location-based social networks (LBSNs) creates great challenges for POI recommendation. User check-in behavior exhibits two properties, diversity and imbalance. To effectively model both properties, we propose an Aspect-aware Geo-Social Matrix Factorization (AGS-MF) approach to exploit various factors in a unified manner for more effective POI recommendation. Specifically, we first construct a novel knowledge graph (KG), named as Aspect-aware Geo-Social Influence Graph (AGS-IG), to unify multiple influential factors by integrating the heterogeneous information about users, POIs and aspects from reviews. We design an efficient meta-path based random walk to discover relevant neighbors of each user and POI based on multiple influential factors. The extracted neighbors are further incorporated into AGS-MF with automatically learned personalized weights for each user and POI. By doing so, both diversity and imbalance can be modeled for better capturing the characteristics of users and POIs. Experimental results on several real-world datasets demonstrate that AGS-MF outperforms state-of-the-art methods.",International Conference on Web Engineering,2019,,,,,72-80,2,6,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_6
Exploring Semantic Change of Chinese Word Using Crawled Web Data,"Xiaofei Xu, Yukun Cao & Li Li","College of Computer and Information Science, Southwest University, Chongqing, 400715, China",Diachronic analysis; Word embedding; Web data mining; Chinese word evolution,"Words changing their meanings over time reflects various shifts in socio-cultural attitudes and conceptual structures. Understanding semantic change of words over time is important in order to study models of language and cultural evolution. Word embeddings methods such as PPMI, SVD and word2vec have been evaluated in recent years. These kinds of representation methods, sometimes referring as semantic maps of words, are able to facilitate the whole process of language processing. Chinese language is no exception. The development of technology gradually influences people’s communication and the language they are using. In the paper, a huge amount of data (300 GB) is provided by Sogou, a Chinese web search engine provider. After pre-processing, the Chinese language corpus is obtained. Three different word representation methods are extended to including temporal information. They are trained and tested based on the above dataset. A thorough analysis (both qualitative and quantitative analysis) is conducted with different thresholds to capture different semantic accuracy and alignment quality of the shifted words. A comparison between three methods is provided and possible reasons behind experiment results are discussed.",International Conference on Web Engineering,2019,,,,,81-88,2,0,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_7
A Customisable Pipeline for Continuously Harvesting Socially-Minded Twitter Users,"Flavio Primo, Paolo Missier & Alexander Romanovsky; Mickael Figueredo & Nelio Cacho","School of Computing, Newcastle University, Science Central, Newcastle upon Tyne, UK; Universidade Federal do Rio Grande do Norte, Natal, RN, Brazil",Twitter analytics; Online user discovery; Online activists; Online influencers; Influence theories,"On social media platforms and Twitter in particular, specific classes of users such as influencers have been given satisfactory operational definitions in terms of network and content metrics. Others, for instance online activists, are not less important but their characterisation still requires experimenting. We make the hypothesis that such interesting users can be found within temporally and spatially localised contexts, i.e., small but topical fragments of the network containing interactions about social events or campaigns with a significant footprint on Twitter. To explore this hypothesis, we have designed a continuous user profile discovery pipeline that produces an ever-growing dataset of user profiles by harvesting and analysing contexts from the Twitter stream. The profiles dataset includes key network and content-based users metrics, enabling experimentation with user-defined score functions that characterise specific classes of online users. The paper describes the design and implementation of the pipeline and its empirical evaluation on a case study consisting of healthcare-related campaigns in the UK, showing how it supports the operational definitions of online activism, by comparing three experimental ranking functions. The code is publicly available.",International Conference on Web Engineering,2019,,,,,91-106,2,1,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_8
Predicting Graph Operator Output over Multiple Graphs,"Tasos Bakogiannis, Ioannis Giannakopoulos & Nectarios Koziris; Dimitrios Tsoumakos","Department of Informatics, Ionian University, Corfu, Greece; CSLab, School of ECE, National Technical University of Athens, Athens, Greece",Graph analytics; Operator modeling; Graph similarity,"A growing list of domains, in the forefront of which are Web data and applications, are modeled by graph representations. In content-driven graph analytics, knowledge must be extracted from large numbers of available data graphs. As the number of datasets (a different type of volume) can reach immense sizes, a thorough evaluation of each input is prohibitively expensive. To date, there exists no efficient method to quantify the impact of numerous available datasets over different graph analytics tasks. To address this challenge, we propose an efficient graph operator modeling methodology. Our novel, operator-agnostic approach focuses on the inputs themselves, utilizing graph similarity to infer knowledge about them. An operator is executed for a small subset of the available inputs and its behavior is modeled for the rest of the graphs utilizing machine learning. We propose a family of similarity measures based on the degree distribution that prove capable of producing high quality models for many popular graph tasks, even compared to modern, state of the art similarity functions. Our evaluation over both real-world and synthetic graph datasets indicates that our method achieves extremely accurate modeling of many commonly encountered operators, managing massive speedups over a brute-force alternative.",International Conference on Web Engineering,2019,,,,,107-122,2,2,https://link.springer.com/chapter/10.1007/978-3-030-19274-7_9
Detecting Responsive Web Design Bugs with Declarative Specifications,"Oussama Beroual, Francis Guérin & Sylvain Hallé","Laboratoire d’informatique formelle, Université du Québec à Chicoutimi, Saguenay, Canada",,"Responsive Web Design (RWD) is a concept that is born from the need to provide users with a positive and intuitive experience, no matter what device they use. Complex Cascading Style Sheets (CSS) are used in RWD to smoothly change the appearance of a website based on the window width of the device being used. The paper presents an automated approach for testing these dynamic web applications, where a combination of dynamic crawling and back-end testing is used to automatically detect RWD bugs.",International Conference on Web Engineering,2020,,,,,Mar-18,2,6,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_1
Who’s Behind That Website? Classifying Websites by the Degree of Commercial Intent,Michael Färber & Frederic Bartscherer; Benjamin Scheer,"Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; 1&1 IONOS SE, Karlsruhe, Germany",Document classification; Web; Text mining; Machine learning,"Web hosting companies strive to provide customised customer services and want to know the commercial intent of a website. Whether a website is run by an individual person, a company, a non-profit organisation, or a public institution constitutes a great challenge in website classification as website content might be sparse. In this paper, we present a novel approach for determining the commercial intent of websites by using both supervised and unsupervised machine learning algorithms. Based on a large real-world data set, we evaluate our model with respect to its effectiveness and efficiency and observe the best performance with a multilayer perceptron.",International Conference on Web Engineering,2020,,,,,130-145,2,0,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_10
I Don’t Have That Much Data! Reusing User Behavior Models for Websites from Different Domains,Maxim Bakaev; Maximilian Speicher; Sebastian Heil & Martin Gaedke,"C&A Europe, Düsseldorf, Germany; Technische Universität Chemnitz, Chemnitz, Germany; Novosibirsk State Technical University, Novosibirsk, Russia",Web design; User experience; Machine learning; Training data,"User behavior models see increased usage in automated evaluation and design of user interfaces (UIs). Obtaining training data for the models is costly, since it generally requires the involvement of human subjects. For interaction’s subjective quality parameters, like aesthetic impressions, it is even inevitable. In our paper, we study applicability of trained user behavior models between different domains of websites. We collected subjective assessments of Aesthetics, Complexity and Orderliness from 137 human participants for more than 3000 homepages from 7 domains, and used them to train 21 artificial neural network (ANN) models. The input neurons were 32 quantitative metrics obtained via computer vision-based analysis of the homepages screenshots. Then, we tested how well each ANN model can predict subjective assessments for websites from other domains, and correlated the changes in prediction accuracies with the pairwise distances between the domains. We found that the Complexity scale was rather domain-independent, whereas “foreign-domain” models for Aesthetics and Orderliness had on average greater prediction errors for other domains, by 60% and 45%, respectively. The results of our study provide web designers and engineers with a first framework to assess the reusability and difference in prediction accuracy of the models, for more informed decisions.",International Conference on Web Engineering,2020,,,,,146-162,2,20,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_11
Improving Detection Accuracy for Malicious JavaScript Using GAN,"Junxia Guo, Qiyun Cao, Rilian Zhao & Zheng Li","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China",Malicious code detection; JavaScript; GAN; Classifier,"Dynamic web pages are widely used in web applications to provide better user experience. Meanwhile, web applications have become a primary target in cybercriminals by injecting malware, especially JavaScript, to perform malicious activities through impersonation. Thus, in order to protect users from attacks, it is necessary to detect those malicious codes before they are executed. Since the types of malicious codes increase quickly, it is difficult for the traditional static and dynamic approaches to detect new style of malicious code. In recent years, machine learning has been used in malicious code identification approaches. However, a large number of labeled samples are required to achieve good performance, which is difficult to acquire. This paper proposes an efficient method for improving the classifiers’ recognition rate in detecting malicious JavaScript based on Generative Adversarial Networks (GAN). The output from the GAN is used to train classifiers. Experimental results show that our method can achieve better accuracy with a limited set of labeled sample.",International Conference on Web Engineering,2020,,,,,163-170,2,2,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_12
VISH: Does Your Smart Home Dialogue System Also Need Training Data?,"Mahda Noura, Sebastian Heil & Martin Gaedke","Technische Universität Chemnitz, Chemnitz, Germany",Smart home; Internet of Things; Web of Things; Goal-oriented interfaces; Training data generation; Dataset,"The main objective of smart homes is to improve the quality of life and comfort of their inhabitants through automation systems and ambient intelligence. Voice-based interaction like dialogue systems is the current emerging trend in these systems. Natural Language Understanding (NLU) model can identify the end-users’ intentions in the utterances provided to spoken dialogue systems. The utility of dialogue systems is reliant on the quality of NLU models, which is in turn significantly dependent on the availability of a high-quality and sufficiently large corpus for training, containing diverse utterance structures. However, building such corpora is a complex task even for companies possessing significant human and infrastructure resources. On the other hand, the existing corpora for the smart home domain are either concerned with web services, focus on direct goals only, follow static command structure, or are not publicly available in English language which limits the development of goal-oriented dialogue systems for smart homes. In this paper, we propose a generic method to create training data for the NLU component using a generative grammar-based approach. Our method outputs, Voice Interaction in Smart Home (VISH) dataset consisting of five million unique utterances for the smart home. This dataset can greatly facilitate research in the area of voice-based dialogue systems for smart homes. We evaluate the approach by using VISH to train several state-of-the-art NLU models. Our experiment results demonstrate the capability of the corpus to support the development of goal-oriented voice-based dialogue systems in the context of smart homes.",International Conference on Web Engineering,2020,,,,,171-187,2,8,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_13
Neighborhood Aggregation Embedding Model for Link Prediction in Knowledge Graphs,Changjian Wang; Changjian Wang; Ying Sha; Ying Sha,"Hubei Engineering Technology Research Center of Agricultural Big Data, Wuhan, China; College of Informatics, Huazhong Agricultural University, Wuhan, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",Knowledge graph embedding; Link prediction; Semantic web; Graph neural networks,"Link prediction has become a hot topic of knowledge graphs (KGs) in recent years. It aims at predicting missing links between entities to complement KGs. The most successful methods for this problem are embedding-based. Most previous works only consider the triples to learn the embeddings of entities and relations, so the information they can utilize is limited. However, KGs are graph-structured data, we can use the neighborhood information to improve the quality of embeddings, thus improving the performance of link prediction task. In this paper, we propose NAE (neighborhood aggregation embedding model), a novel approach for link prediction. NAE consists of an aggregator and a predictor. The aggregator aggregates the embeddings of multi-order neighbors with different weights to generate a new embedding for each entity. Further analysis shows that the performance of some existing methods such as TransE and DistMult can be improved by integrating our aggregators. The predictor predicts the probability distributions of target entities. It uses convolutional neural network (CNN) to capture more interactions between the new entity embeddings and the relation embeddings. We also propose a highly parameter efficient model NAE-S by simplifying the predictor, which can obtain competitive performance with fewer parameters. Compared with DistMult, NAE-S achieves the same performance with 16x fewer parameters. Experimental results show that our method outperforms several state-of-the-art methods on benchmark datasets.",International Conference on Web Engineering,2020,,,,,188-203,2,1,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_14
Automatic Model Completion for Web Applications,"Ruilian Zhao, Chen Chen, Weiwei Wang & Junxia Guo","Beijing University of Chemical Technology, Beijing, 100029, China",Model completion; Web applications; EFSM model; Lookahead search,"Model-based testing is one of the most effective methods for testing web applications, where the integrity of models determines the effectiveness and efficiency of testing. Static/dynamic analysis techniques are widely used to construct models for web applications. However, it is almost impossible to build a complete model for web applications by static analysis techniques since web applications are driven by events, and web pages are generated dynamically. Dynamic analysis techniques construct models through monitoring the execution of web applications and capturing the pivotal behavior information. But it is challenging to explore all possible behaviors, resulting in incomplete models. So, the combination of dynamic and static analysis techniques is a viable way to construct a more complete model for web applications. Extended Finite State Machine (EFSM) is considered more suitable to represent modern web applications. So this paper defines an integrity criterion for EFSM models of web applications and proposes a model completion method by combining dynamic analysis and static analysis techniques. Static analysis is used to collect all behaviors from the source code of web application, identify the uncovered ones from the EFSM model built according to the integrity criterion, and find feasible transition sequences for the uncovered behaviors on the EFSM model. Furthermore, we design multiple priority rules for transition sequence generation to improve its efficiency. The dynamic analysis is employed to simulate the execution of feasible transition sequences on the EFSM model such that the uncovered behaviors can be added into the model to improve its integrity. We implement our method in a prototype tool called AutoMC and conduct a series of experiments on five open-source web applications. The experiment results show that our method can complete the model of web applications, and the priority rules provide effective guidance in transition sequence generation. The model’s integrity improved by 22.68% on average.",International Conference on Web Engineering,2020,,,,,207-227,2,2,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_15
Almost Rerere: An Approach for Automating Conflict Resolution from Similar Resolved Conflicts,"Piero Fraternali, Sergio Luis Herrera Gonzalez & Mohammad Manan Tariq","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza Leonardo da Vinci 32, 20133, Milan, Italy",Automatic conflict resolution; GIT; Code integration,"Concurrent development requires the ability of reconciling conflicting updates to the code made independently. A specific case occurs when long living feature branches are integrated to a rapid changing code base. In this scenario, every integration test will require to manually resolve the same conflicts at every iteration. In this paper we propose a framework for automating the detection and resolution of conflicts in the code updated by distinct developers, one of which may be a code generator. The tool learns how to solve conflicts from past experience and applies resolutions, encoded as replacement regular expressions, to conflicts not seen before. Experiments show that the number of automatically resolved conflicts and the quality of the solution increase as the system acquires experience.",International Conference on Web Engineering,2020,,,,,228-243,2,3,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_16
Generation of Realistic Navigation Paths for Web Site Testing Using Recurrent Neural Networks and Generative Adversarial Neural Networks,Silvio Pavanetto & Marco Brambilla,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, P.za L. da Vinci 32, Milano, Italy",Web engineering; Data mining; Deep learning; Recurrent neural networks; Generative adversarial networks; Testing,"A robust technique for generating web navigation logs could be fundamental for applications not yet released, since developers could evaluate their applications as if they were used by real clients. This could allow to test and improve the applications faster and with lower costs, especially with respect to the usability and interaction aspects. In this paper we propose the application of deep learning techniques, like recurrent neural networks (RNN) and generative adversarial neural networks (GAN), aimed at generating high-quality weblogs, which can be used for automated testing and improvement of Web sites even before their release.",International Conference on Web Engineering,2020,,,,,244-258,2,2,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_17
Scalable Real-Time Confusion Detection for Personalized Onboarding Guides,"Michal Hucko, Robert Moro & Maria Bielikova","Faculty of Informatics and Information Technologies, Slovak University of Technology in Bratislava, Ilkovicova 2, 842 16, Bratislava, Slovakia",Affective computing; Confusion detection; Personalization; Scalability; Real-time detection; YesElf,"Onboarding of new employees is a common process in all companies. Many hours of qualified employees’ time need to be invested to teach new employees how to use the company’s internal systems. This process can be significantly eased by onboarding solutions leveraging application guides. However, if not personalized, the guides can quickly become annoying to users. This can be overcome by employing emotion detection in real-time, but the solutions face several major challenges, such as scalability, detection time, or model retraining. In this paper, we describe how we tackled these challenges and implemented an emotion detection-based personalization module in the onboarding solution YesElf. The module leverages the mouse interaction data of users to detect their confusion. We show the scalability of our solution in the production environment which has been deployed to three customers with more than 200 concurrent users.",International Conference on Web Engineering,2020,,,,,261-276,2,1,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_18
Creating and Capturing Artificial Emotions in Autonomous Robots and Software Agents,Claus Hoffmann; Maria-Esther Vidal,"TIB Leibniz Information Centre for Science and Technology, Hannover, Germany; Research Group Robots and Software Agents with Emotions, Sankt Augustin, Germany",Autonomous agents; Artificial emotions; Agent Knowledge Graphs,"This paper presents ARTEMIS, a control system for autonomous robots or software agents. ARTEMIS is able to create and capture artificial emotions during interactions with its environment, and we describe the underlying mechanisms for this. The control system also realizes the capturing of knowledge about its past artificial emotions. A specific interpretation of a knowledge graph, called an Agent Knowledge Graph, represents these artificial emotions. For this, we devise a formalism which enriches the traditional factual knowledge in knowledge graphs with the representation of artificial emotions. As proof of concept, we realize a concrete software agent based on the ARTEMIS control system. This software agent acts as a user assistant and executes the user’s orders. The environment of this user assistant consists of autonomous service agents. The execution of user’s orders requires interaction with these autonomous service agents. These interactions lead to artificial emotions within the assistant. The first experiments show that it is possible to realize an autonomous agent with plausible artificial emotions with ARTEMIS and to record these artificial emotions in its Agent Knowledge Graph. In this way, autonomous agents based on ARTEMIS can capture essential knowledge that supports successful planning and decision making in complex dynamic environments and surpass emotionless agents.",International Conference on Web Engineering,2020,,,,,277-292,2,7,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_19
Layout as a Service (LaaS): A Service Platform for Self-Optimizing Web Layouts,"Markku Laine, Ai Nakajima, Niraj Dayama & Antti Oulasvirta","Aalto University, Helsinki, Finland",Self-adaptive web interfaces; Web-based interaction; Web personalization; Web layouts; Web service architectures,"To personalize a web page, case-specific rules or templates must be specified that define the visuospatial layout of elements as well as device-specific adaptation rules for an individual. This approach scales poorly. We present LaaS, a service platform for self-optimizing web layouts to improve their usability at individual, group, and population levels. No hand-coded rules or templates are needed, as LaaS uses combinatorial optimization to generate web layouts for stated design objectives. This allows personalization to be controlled via intuitive objectives that affect the full web layout. We present an extensible architecture and solutions for (1) layout generation using integer programming, (2) data abstractions to mediate between browsers and layout generators, and (3) page restructuring. Moreover, we show how LaaS can be easily deployed as part of existing web pages. Results demonstrate that our approach can produce usable personalized web layouts in diverse scenarios.",International Conference on Web Engineering,2020,,,,,19-26,2,11,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_2
On Emotions in Conflict Wikipedia Talk Pages Discussions,Maksymilian Marcinowski & Agnieszka Ławrynowicz; Agnieszka Ławrynowicz,"Faculty of Computing and Telecommunications, Poznan University of Technology, Poznań, Poland; Center for Artificial Intelligence and Machine Learning (CAMIL), Poznan University of Technology, Poznań, Poland",Online discussion; Emotions; Conflictual interactions,"Unjustified anti-social behaviour in Internet discussions, such as vulgarisms and insults, is tantamount to the outbreak of an online conflict that destroys the merits of the discussion. Recognising the characteristics of conflict discussions and modelling their dynamics can help to predict and prevent derailing. We propose to use emotion labels as characteristics and propose a new dataset, extending the non-conflict and such conflict conversations from Wikipedia talk pages that derailed due to a personal attack with an emotional context based on the Plutchik’s model. We also present the results of the analysis of this dataset aimed at identifying specific, emotion-based features of conflict (derailed) discussions, which are potentially useful in predicting the outbreak of conflict in online conversations. Furthermore, we introduce the phenomenon of escalation of emotions using both the Plutchik’s model and EmoWordNet lexicon and show its dynamics in these approaches. With this new dataset and analysis, we hope to open up new possibilities for research in detecting the outbreak of an online conflict.",International Conference on Web Engineering,2020,,,,,293-301,2,2,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_20
Geospatial Partitioning of Open Transit Data,"Harm Delva, Julián Andrés Rojas, Pieter-Jan Vandenberghe, Pieter Colpaert & Ruben Verborgh","IDLab, Department of Electronics and Information Systems, Ghent University – imec, Ghent, Belgium",Linked open data; Mobility; Maintainability; Web API engineering,"Public transit operators often publish their open data as a single data dump, but developers with limited computational resources may not be able to process all this data. Existing work has already focused on fragmenting the data by departure time, so that data consumers can be more selective in the data they process. However, each fragment still contains data from the entire operator’s service area. We build upon this idea by fragmenting geospatially as well as by departure time. Our method is robust to changes in the original data, such as the deletion or the addition of stops, which is crucial in scenarios where data publishers do not control the data itself. In this paper we explore popular clustering methods such as k-means and METIS, alongside two simple domain-specific methods of our own. We compare the effectiveness of each for the use case of client-side route planning, focusing on the ease of use of the data and the cacheability of the data fragments. Our results show that simply clustering stops by their proximity to 8 transport hubs yields the most promising results: queries are 2.4 times faster and download 4 times less data. More than anything though, our results show that the difference between clustering methods is small, and that engineers can safely choose practical and simple solutions. We expect that this insight also holds true for publishing other geospatial data such as road networks, sensor data, or points of interest.",International Conference on Web Engineering,2020,,,,,305-320,2,3,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_21
Efficient Live Public Transport Data Sharing for Route Planning on the Web,"Julián Andrés Rojas, Dylan Van Assche, Harm Delva, Pieter Colpaert & Ruben Verborgh","IDLab, Department of Electronics and Information Systems, Ghent University – imec, Ghent, Belgium",Public transport; Web interfaces; Live updates; Route planning,"Web-based information services transformed how we interact with public transport. Discovering alternatives to reach destinations and obtaining live updates about them is necessary to optimize journeys and improve the quality of travellers’ experience. However, keeping travellers updated with opportune information is demanding. Traditional Web APIs for live public transport data follow a polling approach and allocate all data processing on either data providers, lowering data accessibility, or data consumers, increasing the costs of innovative solutions. Moreover, data processing load increases further because previously obtained route plans are fully recalculated when live updates occur. In between solutions sharing processing load between clients and servers, and alternative Web API architectures were not thoroughly investigated yet. We study performance trade-offs of polling and push-based Web architectures to efficiently publish and consume live public transport data. We implement (i) alternative architectures that allow sharing data processing load between clients and servers, and evaluate their performance following polling- and push-based approaches; (ii) a rollback mechanism that extends the Connection Scan Algorithm to avoid unnecessary full route plan recalculations upon live updates. Evaluations show polling as a more efficient alternative on CPU and RAM but hint towards push-based alternatives when bandwidth is a concern. Clients update route plan results 8–10 times faster with our rollback approach. Smarter API design combining polling and push-based Web interfaces for live public transport data reduces the intrinsic costs of data sharing by equitably distributing the processing load between clients and servers. Future work can investigate more complex multimodal transport scenarios.",International Conference on Web Engineering,2020,,,,,321-336,2,5,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_22
Web-Based Development and Visualization Dashboards for Smart City Applications,"Douglas Rolim, Jorge Silva, Thais Batista & Everton Cavalcante","DIMAp, Federal University of Rio Grande do Norte, Natal, Brazil",Smart city applications; Application development; Development dashboard; Visualization dashboard,"Smart city applications are inherently characterized by the integration of data from heterogeneous sources and the need of considering geographical information that represents the real-world urban space. To address these concerns, some platforms have been proposed in recent years offering common services and facilities to ease the development of smart city applications. Nonetheless, the existing platforms do not offer high-level interfaces to provide developers with proper tools that could reduce the complexity of developing applications, neither an interface to organize data visualization to end-users. Aiming at tackling such limitations, this work presents Web-based dashboards to support development and data visualization in smart city applications: the former is tailored to application developers, whereas the latter is suited to visualize data. This paper presents the use of these dashboards in association with a platform that integrates heterogeneous urban data with geographical information while supporting the development of smart city applications on top of this data.",International Conference on Web Engineering,2020,,,,,337-344,2,10,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_23
Detecting Rumor on Microblogging Platforms via a Hybrid Stance Attention Mechanism,"Zeng Lingyu, Wu Bin & Wang Bai","Beijing University of Posts and Telecommunications, Beijing, China",Rumor detection; Stance mining; Attention; Neural networks,"Microblogging platforms are important social media in the Internet age. Considering the amount of users on microblogging platforms, the rumor spreading on microblogging platform could have a negative effect on individuals, groups and the whole society. Hence, automatic rumor detection is an important research issue. Stance information contains crucial features for rumor detection, because users discussing rumors tend to express more querying and denying stances. Moreover, different user stances have different importance. Motivated by this inspiration, in this paper, we propose a Rumor Detection Model with a Hybrid Stance Attention Mechanism (RDM-HSAM). The RDM-HSAM consists of four modules. The first module is a stance module, in which the tweet-level stance representation is constructed. The second module is the attention module in which a hybrid attention mechanism is used to construct the event-level stance representation of a microblogging event. The hybrid attention mechanism is consisted of two attention mechanisms, i.e. content attention mechanism and user attention mechanism which are applied at the stance information and user profile respectively. The third module is a rumor module which captures the content features and temporal features of a microblogging event. The fourth module is an integrate module in which event-level stance representations and rumor representations are concatenated together to detect rumors. Experiments on a real-world dataset from Weibo platform demonstrate that our proposed model RDM-HSAM improves the performance of rumor detection in terms of both efficiency and accuracy compared to other methods, and the accuracy of our model achieves 94.9%.",International Conference on Web Engineering,2020,,,,,347-364,2,5,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_24
A Hybrid Approach for Aspect-Based Sentiment Analysis Using Deep Contextual Word Embeddings and Hierarchical Attention,"Maria Mihaela Truşcǎ; Daan Wassenberg, Flavius Frasincar & Rommert Dekker","Bucharest University of Economic Studies, 010374, Bucharest, Romania; Erasmus University Rotterdam, Burgemeester Oudlaan 50, 3062 PA, Rotterdam, The Netherlands",Multi-hop LCR-ROT; Hierarchical attention; Contextual word embeddings,"The Web has become the main platform where people express their opinions about entities of interest and their associated aspects. Aspect-Based Sentiment Analysis (ABSA) aims to automatically compute the sentiment towards these aspects from opinionated text. In this paper we extend the state-of-the-art Hybrid Approach for Aspect-Based Sentiment Analysis (HAABSA) method in two directions. First we replace the non-contextual word embeddings with deep contextual word embeddings in order to better cope with the word semantics in a given text. Second, we use hierarchical attention by adding an extra attention layer to the HAABSA high-level representations in order to increase the method flexibility in modeling the input data. Using two standard datasets (SemEval 2015 and SemEval 2016) we show that the proposed extensions improve the accuracy of the built model for ABSA.",International Conference on Web Engineering,2020,,,,,365-380,2,63,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_25
Just the Right Mood for HIT!,"Sihang Qiu, Ujwal Gadiraju & Alessandro Bozzon","Web Information Systems Group, Delft University of Technology, Delft, Netherlands",Crowdsourcing; Conversational agent; Conversational style; Worker moods; Worker performance; Moods,"Conversational agents are playing an increasingly important role in providing users with natural communication environments, improving outcomes in a variety of domains in human-computer interaction. Crowdsourcing marketplaces are simultaneously flourishing, and it has never been easier to acquire large-scale human input from online workers. Recent works have revealed the potential of conversational interfaces in improving worker engagement and satisfaction. At the same time, worker moods have been shown to have significant effects on quality related outcomes. Little is known about the role of worker moods in shaping work in conversational microtask crowdsourcing. In this paper, we conducted a crowdsourcing study addressing 600 unique online workers, to investigate the role that worker moods play in conversational microtask crowdsourcing. We also explore whether suitable conversational styles of the agent can affect the performance of workers in different moods. Our results show that workers in a pleasant mood tend to produce significantly higher quality results (over 20%), exhibit greater engagement (an increase by around 19%) and report a lower cognitive load (by over 12%), and a suitable conversational style can have a significant impact on workers in different moods. Our findings advance the current understanding of conversational microtask crowdsourcing and have important implications on designing future conversational crowdsourcing systems.",International Conference on Web Engineering,2020,,,,,381-396,2,16,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_26
SolidRDP: Applying Solid Data Containers for Research Data Publishing,"André Langer, Dang Vu Nguyen Hai & Martin Gaedke","Chemnitz University of Technology, Chemnitz, Germany",Linked Data; Research data management; Data publishing; Solid; Data container; Decentralization,"In the context of Open Science, researchers are encouraged to publish their research datasets in digital data repositories so that others can find and reuse it.",International Conference on Web Engineering,2020,,,,,399-415,2,4,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_27
Applying Natural Language Processing Techniques to Generate Open Data Web APIs Documentation,"César González-Mora, Cristina Barros, Irene Garrigós, Jose Zubcoff, Elena Lloret & Jose-Norberto Mazón","Department of Software and Computing Systems, University of Alicante, Alicante, Spain",Open data Web API; Natural Language Processing; Natural Language Generation,"Information access globalisation has resulted in the continuous growing of online available data on the Web, especially open data portals. However, in current open data portals, data is difficult to understand and access. One of the reasons of such difficulty is the lack of suitable mechanisms to extract and learn valuable information from existing open data, such as Web Application Programming Interfaces (APIs) with proper documentation. Actually, in most cases, open data Web APIs documentation is very rudimentary, hard to follow, and sometimes incomplete or even inaccurate. To solve these data management problems, this paper proposes an approach to automatically generate Web API’s documentation which is both machine and user readable. Our approach consists of applying natural language processing techniques to create OpenAPI documentations. This manner, the access to data is facilitated because of the improvement on the comprehension of the APIs, thus promoting the reusability of data. The feasibility of our approach is presented through a case study that shows and compares the benefits of using our OpenAPI documentation process within an open data web API.",International Conference on Web Engineering,2020,,,,,416-432,2,4,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_28
WebDelta: Lightweight Migration of Web Applications with Modified Execution State,"Jin-woo Kwon, Hyeon-Jae Lee & Soo-Mook Moon","Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul, Republic of Korea",Internet of Things; Serialization; Migration; Productivity,"Web applications (apps) can play an important role for the era of ubiquitous computing since they can run on any smart or IoT devices equipped with a browser. This advantage of portability and simplicity can be extended further to allow an interesting user experience called app migration. That is, we can save the execution state of a running web app into a file named snapshot, transmit it to another device, and continue the execution by loading the snapshot. One issue is that saving the whole execution state of a running app including all objects in the runtime heap will be inefficient, since most of the current states are unchanged from the initial state. To reduce this inefficiency, we propose WebDelta which selectively saves only those that are modified from the initial state. This selective snapshot is saved as a patch file so that after migration, once the original app is launched, the current state can be restored by applying the patch file. We model the relationship between the JavaScript objects as a directed graph to efficiently and completely save the delta of the JavaScript state. We solve the challenging issues related to modified closure variables or modified event handlers attached to the DOM objects. Our framework could successfully migrate five real web apps, and we could speed up the total migration time as much as by 2.7x.",International Conference on Web Engineering,2020,,,,,435-450,2,3,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_29
Structural Profiling of Web Sites in the Wild,Xavier Chamberland-Thibeault & Sylvain Hallé,"Laboratoire d’informatique formelle, Université du Québec à Chicoutimi, Saguenay, Canada",,"The paper reports results of a large-scale survey of 708 websites, in order to measure various features related to their size and structure: DOM tree size, maximum degree, depth, diversity of element types and CSS classes, among others. The goal of this research is to serve as a reference point for studies that include an empirical evaluation on samples of web pages.",International Conference on Web Engineering,2020,,,,,27-34,2,6,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_3
User-Side Service Synchronization in Multiple Devices Environment,"Clay Palmeira da Silva, Nizar Messai, Yacine Sam & Thomas Devogele","Université de Tours, 30 Avenue du Monge, Tours, France",REST; RESTful; Web Services; Multiple-devices; Cloud-based system; Client-side synchronization,"Today, a single user owning multiple devices is a reality. Moreover, with the advent of the concept of Everything-as-a-Service (XaaS), a cloud-based term that allows for a wide variety of services and applications deployed by the user, the multiple devices scenario gain more relevance, mainly due to the lack of interoperability between operating systems and services of these devices. We focus on multiple device’s environments for synchronizing web services at the client-side without continuously depending on a cloud-based system. We discuss a model-based architecture that allows us to fluently migrate services/data and sessions from one device to another regardless of the operating system. The architecture, called The CUBE [12], is based on user-centric principles combined with REST and RESTful concepts. In this extension paper, we present two main contributions. First, with a description of technical and conceptual aspects of the CUBE, and its relation with the devices/applications and web services. Then, a feasibility test for a tight-coupling service such as YouTube streaming. Within a set of ten users, we presented preliminary results that had measured the wasted time to play a given video with and without the CUBE towards five different devices. The results demonstrate that when the users used the CUBE, they spend only 5.821 s to migrate the video, while without the CUBE, they spend 68.101 s to do the same procedure. That means the CUBE is up to \(\approx \)12 times faster than the traditional YouTube cloud-based synchronization procedure.",International Conference on Web Engineering,2020,,,,,451-466,2,5,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_30
An Approach to Build P2P Web Extensions,"Rodolfo Gonzalez, Sergio Firmenich, Alejandro Fernandez, Gustavo Rossi & Darío Velez; Sergio Firmenich & Gustavo Rossi","LIFIA, CIC, Facultad de Informática, Universidad Nacional de La Plata, Buenos Aires, Argentina; CONICET, Buenos Aires, Argentina",Web extensions; Peer to peer,"Web extensions are currently the most frequently used mechanism for end-users to externally adapt and enrich the web. While most functionality offered by extensions runs on the browser, extensions that offer collaboration, complex computation, or massive storage rely on a centralized server. Relying on a server increases the cost of building, deploying, and maintaining web extensions (even small ones). This paper presents a novel P2P approach to build web extensions. It removes the need for a centralized server while hiding behind a framework the complexity of building P2P extensions. It uses a middleware to manage the resources offered by the browser so multiple P2P extensions can coexist, without degrading the browser’s performance. This paper discusses the main challenges of building P2P web extensions, presents the approach, and shows its potential with a proof of concept.",International Conference on Web Engineering,2020,,,,,467-474,2,2,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_31
Blended or Distance Learning?,Erkki Kaila; Henri Kajasilta,"University of Helsinki, Helsinki, Finland; University of Turku, Turku, Finland",Online learning; Open University; CS education; Learning analytics; Blended learning,"Programming and computer science are nowadays taught in various institutions to a very heterogeneous group of people. Open universities are a typical example of non-traditional educational institutes. Online learning and blended learning models are often utilized in open universities because the students rarely study full time. In this paper, we present a study where four programming and computer science courses were taught in the Open University and in the university at the same time. A blended learning methodology was used to teach the courses in the university. The students in the open university could decide freely whether they wanted to take the courses fully online or to participate into classroom sessions as well. Moreover, no lectures were given in the open university. Instead, the students could download lecture handouts and other material online. The results from continuous assessment and the final exam of four shared IT/CS courses were analyzed. We found out that although there are some statistical differences in the results of individual sections, in general the course results are quite similar in both universities. However, the incomplete data of chosen methodologies prevents us from fully answering the research questions.",International Conference on Web Engineering,2020,,,,,477-484,2,6,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_32
On Teaching Web Stream Processing,Emanuele Della Valle & Marco Balduini; Riccardo Tommasini & Sherif Sakr,"DataSystem Group, University of Tartu, Tartu, Estonia; DEIB, Politecnico di Milano, Milan, Italy",Web Stream Processing; Stream Reasoning; RDF Stream Processing; Action Research,"Web Stream Processing (WSP) is a field that studies how to identify, access, represent and process flows of data using Web technologies. One of the barriers that currently limits the adoption of WSP is the paradigm shift from Web data at-rest to Web data in-motion. This barrier is especially high when teaching undergraduate students. To quantify the effort required to learn Web Stream Processing, we run an Action Research audit with master students at Politecnico di Milano. In this paper, we present the results of this inquiry, and we discuss the lesson learned.",International Conference on Web Engineering,2020,,,,,485-493,2,1,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_33
Teaching Container-Based DevOps Practices,"Jami Kousa, Petri Ihantola & Matti Luukkainen; Arto Hellas","University of Helsinki, Helsinki, Finland; Aalto University, Espoo, Finland",DevOps; Education; Lifelong learning,"We present the design of a online course that focuses on container-based virtualization as part of the DevOps toolchain. In addition, we outline the professional background of participants taking the course, and describe how this affects perceived previous knowledge of DevOps. We found out that the self-evaluated conceptual understanding of DevOps topics is nearly equal regardless of the participants professional identity (e.g., student or developer). However, there are significant differences in how much participants have used tools like Docker before. We conclude that there is a clear need for lifelong learning among software engineering professionals as (future) developers often struggle in operations related skills such as command line or networking.",International Conference on Web Engineering,2020,,,,,494-502,2,8,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_34
Predicting the Outbreak of Conflict in Online Discussions Using Emotion-Based Features,Maksymilian Marcinowski & Agnieszka Ławrynowicz; Agnieszka Ławrynowicz,"Faculty of Computing and Telecommunications, Poznan University of Technology, Poznań, Poland; Center for Artificial Intelligence and Machine Learning (CAMIL), Poznan University of Technology, Poznań, Poland",Online discussions; Emotions; Conflict prediction,"Anti-social online behaviour, such as harassment or vulgarity, leading to conflicts aimed at destroying any merit of the discussions, is a serious problem for the Internet community. Recognising the characteristics of conflict discussions and modelling their trajectory might help to predict and prevent derailing. My PhD thesis focuses on using emotion labels as such characteristics and building an explainable prediction model based on them. As a part of the thesis we have proposed a new dataset of discussions containing knowledge about their emotion-based features. It is a set of dialogues from Wikipedia Talk Pages annotated during a crowdsourcing experiment with labels from Plutchik’s model of emotions and described with EmoWordNet lexicon scores.",International Conference on Web Engineering,2020,,,,,505-511,2,2,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_35
An APIfication Approach to Facilitate the Access and Reuse of Open Data,"César González-Mora, Irene Garrigós & Jose Zubcoff","Department of Software and Computing Systems, University of Alicante, Alicante, Spain",Data access; Web accessibility; Open data; Linked data; API,"Nowadays, accessing open data is a difficult task since current Open Data platforms do not generally provide suitable strategies to access their data. Moreover, Linked Open Data requires knowledge in different technologies, which is a challenging task especially for novice developers. In order to manage this open data, Web APIs with accurate documentation are highly recommended features that not all platforms include. Providing these APIs would help developers to easily access data, but this access is still limited for end-users, particularly those with disabilities. Therefore, there is a gap between open data and users in which our APIfication approach can help by creating APIs for available datasets. It consists of a model-based generation of suitable APIs with natural language documentation to access open data, a universal API to access linked open data easily and a Web augmentation framework to improve data accessibility, helping users with disabilities. Accordingly, the aim of this PhD is to provide suitable mechanisms to easily access and reuse open data.",International Conference on Web Engineering,2020,,,,,512-518,2,8,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_36
A Personal Health Trajectory API: Addressing Problems in Health Institution-Oriented Systems,"Javier Rojo, Juan Hernandez & Juan M. Murillo","University of Extremadura, Cáceres, Spain",Personal Health Record; eHealth; Personal Health Trajectory; APIs,"Each person interacts with multiple health institution’s systems along their life. These systems are usually developed to fulfill the specific needs of sanitary organizations or Web of Medical Things manufacturers. However, most of the times these information systems aren’t interconnected, making it very difficult to put in common the information of a patient scattered in various systems. Thus, it’s necessary to develop solutions that allow health information systems developers to consult all the information of an user across the multiple health’s information systems it is scattered and to offer this information organized as the Personal Health Trajectory of the user (a succession of Personal Health Records ordered by time). This paper proposes a solution for the integration of heterogeneous health information systems, the processing of their data and its provisioning in a health trajectory perspective through an API. Thus, software developers of healthcare solutions can leverage this API to develop a new generation of person-oriented solutions.",International Conference on Web Engineering,2020,,,,,519-524,2,10,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_37
Context-Aware Encoding and Delivery in the Web,Benjamin Wollmer & Norbert Ritter; Wolfram Wingerath,"University of Hamburg, Hamburg, Germany; Baqend GmbH, Hamburg, Germany",Web caching; Efficiency; Compression algorithms; Delta encoding; Benchmarking; Runtime optimization; User experience,"While standard HTTP caching has been designed for static resources such as files, different conceptual extensions have made it applicable to frequently changing data like database query results or server-generated HTML content. But even though caching is an indispensable means to accelerate content delivery on the web, whether or not cached resources can be used for acceleration has always been a binary decision: a cached response is either valid and can be used or has been invalidated and must be avoided. In this paper, we present an early-stage PhD project on a novel scheme for content encoding and delivery. Our primary goal is minimizing the payload for client requests in the web by enabling partial usage of cached resources. We discuss related work on the topic and analyze why existing approaches have not been established in practice so far, despite significant gains such as reduced bandwidth usage and loading times for end users. We then present open challenges, derive our research question, and present our research goals and agenda.",International Conference on Web Engineering,2020,,,,,525-530,2,6,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_38
An OpenAPI-Based Testing Framework to Monitor Non-functional Properties of REST APIs,"Steven Bucaille; Javier Luis Cánovas Izquierdo, Hamza Ed-Douibi & Jordi Cabot; Jordi Cabot","Katholieke Universiteit Leuven, Leuven, Belgium; UOC, Barcelona, Spain; ICREA, Barcelona, Spain",,"REST APIs have become key assets for any company willing to have online presence and provide access to its services. Several approaches have been proposed to describe this kind of APIs, being OpenAPI the dominant proposal in the last years. OpenAPI allows any consumer to understand the operations and data elements of a REST API. However, it does not cover any kind of non-functional properties, such as performance and availability. In this paper we present Gadolinium, a framework that leverages the OpenAPI specification to test non-functional properties of REST APIs. Gadolinium automatically tests performance and availability in different geographical locations by means of a master/slave architecture. The results of the test can eventually be injected in the original OpenAPI definition of the REST API.",International Conference on Web Engineering,2020,,,,,533-537,2,10,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_39
Accelerating Web Start-up with Resource Preloading,"JiHwan Yeo, Jae-Hyeon Rim, ChangHyun Shin & Soo-Mook Moon","Seoul National University, Seoul, Korea",Web browser; Resource preloading; Smart device,"Long start-up time of web apps or web pages at the client device may affect the user experience negatively. One bottleneck in reducing the start-up time is resource loading overhead. To reduce the overhead, resource preloading has been proposed, which load resources ahead of time, instead of loading them on time when they are used. For commercial client device such as smart TV, it is reasonable for the browser of the client to do resource preloading. Existing client-only technique remembers the resources accessed in the previous visit and then preloads them in the current visit. However, it preloads the resources in some arbitrary order, thus not dealing well when the preloading order is important, especially for user experience. One solution is employing a resource dependence graph, often used for preloading with proxy servers or web servers, but in client-only environment we need to compute the graph while preloading is in progress, and update the graph incrementally when the resources change. This paper proposes such a dependence graph-based, client-only resource preloading technique. For better user experience, we decide the preloading order based on those factors that affect user perception such as the size or the location of images in the screen. Our experimental results on Chromium browser with real web apps on an embedded board and on a commercial smart TV show that the proposed technique can improve the UX-related app start-up time (above-the-fold time or speed index) tangibly, allowing the user to really feel the difference.",International Conference on Web Engineering,2020,,,,,37-52,2,2,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_4
OpenAPI Bot: A Chatbot to Help You Understand REST APIs,"Hamza Ed-Douibi, Gwendal Daniel & Jordi Cabot; Jordi Cabot","UOC, Barcelona, Spain; ICREA, Barcelona, Spain",,"REST APIs are an essential building block in many Web applications. The lack of a standard machine-readable format to describe these REST APIs triggered the creation of several specification languages to formally define REST APIs, with the OpenAPI specification currently taking the lead. OpenAPI definitions are consumed by a growing ecosystem of tools aimed at automating tasks such as generating server/client SDKs and API documentations. However, current OpenAPI documentation tools mostly provide simple descriptive Web pages enumerating all the API operations and corresponding parameters, but do not offer interactive capabilities to help navigate the API and ask relevant information. Therefore, learning how to use an API and how its different parts are interrelated still requires a considerable time investment. To overcome this situation we present our OpenAPI Bot, a chatbot able to read an OpenAPI definition for you and answer the questions you may have about it.",International Conference on Web Engineering,2020,,,,,538-542,2,25,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_40
A Different Web Analytics Perspective Through Copy to Clipboard Heatmaps,Ilan Kirsh; Mike Joy,"University of Warwick, Coventry, UK; The Academic College of Tel Aviv-Yaffo, Tel Aviv, Israel",Web analytics; Web visualization; Clipboard; Copy; Text analysis; Heatmap; Educational technology; E-Learning,"Heatmaps are widely used in web analytics to visualize certain user activities within web pages, including mouse clicks, mouse moves and page scrolling. We propose Copy to Clipboard Heatmaps (CTCHs), to visualize what users copy from web pages. We present an implementation of CTCHs, demonstrate various types of useful information that CTCHs expose in technical-educational web pages, and discuss several possible uses.",International Conference on Web Engineering,2020,,,,,543-546,2,18,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_41
A Web Augmentation Framework for Accessibility Based on Voice Interaction,César González-Mora & Irene Garrigós; Sven Casteleyn; Sergio Firmenich,"Geospatial Technologies Lab (GEOTEC), Institute of New Imaging Technologies (INIT), University of Jaime I, Castellón de la Plana, Spain; LIFIA, Facultad de Informatica, UNLP and CONICET, La Plata, Argentina; Department of Software and Computing Systems, University of Alicante, Alicante, Spain",Web accessibility; Web augmentation; Voice interaction; Client-side adaptation,"Even nowadays, users with disabilities still experience barriers while accessing information on the Web. In order to facilitate visually-impaired users to access this information, we propose a Web Augmentation Framework for Accessibility (WAFRA). The main focus of our framework are information-rich websites, such as Wikipedia, but it is also applicable to any website. This approach uses client-side Web augmentation techniques, extending the website with new functionality at runtime. With this Web augmentation technique, WAFRA allows users to access Web contents through a voice interface, offering a set of predefined operations to improve Web accessibility: select and read aloud fragments, increase font size, facilitate navigation and show related videos. However, new accessibility operations can be added to the framework by users, considering their own needs. Therefore, by using WAFRA the accessibility of websites is improved: users are able to interact with websites using voice commands or manually through an augmented menu to access easily specific information from the Web.",International Conference on Web Engineering,2020,,,,,547-550,2,16,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_42
Annotated Knowledge Graphs for Teaching in Higher Education,Roy Meissner & Laura Köbis,"Faculty of Education, Leipzig University, Leipzig, Germany",Educational software; T-Mitocar; Semantic data; Knowledge graphs,"Digital systems that enable so-called intelligent, adaptive or personalized learning are thought to bear great potential for the future of education. Research and development towards such innovative learning systems has therefore evolved into an expanding field. Two of the key challenges are (1) to automate the extraction of expert knowledge and (2) the development of an advanced domain model, on which the system can draw. To tackle these challenges, our interdisciplinary contribution is to suggest adopting a novel approach to creating educational knowledge graphs of texts (1), which can then be further annotated and supplemented by instructors and students (2). In particular, we will outline practical use cases for blended learning scenarios in Higher Education.",International Conference on Web Engineering,2020,,,,,551-555,2,11,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_43
A Universal Application Programming Interface to Access and Reuse Linked Open Data,"César González-Mora, Irene Garrigós & Jose Zubcoff","Web and Knowledge Group, University of Alicante, Alicante, 03690, Spain",Linked Open Data; Data reuse; Universal API; Query builder; SPARQL,"In this paper we present a Universal API in order to facilitate the access and reuse of Linked Open Data (LOD). Nowadays, it is difficult to explore heterogeneous data by structured query languages, especially for end users and developers unfamiliar with SPARQL and RDF. Our solution proposes a universal access to the LOD scenario through a common interface, which automatically generates SPARQL queries to access data from any dataset available online. Moreover, the results given by this Universal API are restructured and parsed to well-known formats easily understandable by the majority of developers, such as JSON or CSV. In order to easily use the Web API proposed, there is a Web interface which guides users to get the desired data, providing appropriate documentation to facilitate the search of relevant information. The main innovation of this approach is offering programmatic access to Linked Open Data through the automatic building of SPARQL queries without requiring any prior knowledge of the data and the Semantic Web environment.",International Conference on Web Engineering,2020,,,,,556-560,2,0,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_44
OntoSemStats: An Ontology to Express the Use of Semantics in RDF-Based Knowledge Graphs,"Pierre-Henri Paris, Fayçal Hamdi & Samira Si-Said Cherfi","Conservatoire National des Arts et Métiers, Paris, France",Knowledge graph; Ontology; Semantics; Statistics; OWL; RDFS,"For many users or automated agents, working with knowledge graphs may be a complicated task. Indeed, multiple tools using knowledge graphs rely on semantics to perform at their best. For example, in the context of data integration, some instance matching tools use semantic features such as functional and inverse functional properties or disjoint classes to discover instances that are the same (or not). Hence, in many cases, conducting an exploratory study is required to discover which semantic features are used or defined in a knowledge graph. In this paper, we propose an ontology and a large-scale ontology-based Web service that provides statistics about the use of OWL 2 and RDFS semantic features (e.g. functional properties or subclasses) in knowledge graphs. This will allow a human or automatic agent to choose the most appropriate tool or data for a given task. It also gives the data publishers a clear picture about the semantics they provide to data consumers. These statistics are represented in the form of an RDF graph (with different serialization possibilities), making them easy to use and share.",International Conference on Web Engineering,2020,,,,,561-565,2,0,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_45
An Analysis of Throughput and Latency Behaviours Under Microservice Decomposition,"Malith Jayasinghe, Jayathma Chathurangani, Gayal Kuruppu, Pasindu Tennage & Srinath Perera","WSO2, Colombo, Sri Lanka",Service decomposition; Orchestration; Choreography; Throughput; Latency; Closed system,"Microservice architecture is a widely used architectural style which allows you to design your application using a set of loosely coupled services which can be developed, deployed, and scaled independently. The service decomposition is the act of decomposing (breaking) a coarse-grained service into a set of fine-grained services that collectively perform the functionality of the original service. The service decomposition introduces additional overhead due to inter-service communication of services which impacts the performance. In this paper, we study the effect of service decomposition on the throughput and average latency. We perform an extensive performance analysis using a set of standard microservice benchmarks with different workload characteristics. Our results indicate that when we decompose a service into a set of micro-services the performance of the new application can improve or degrade. The factors which impact the performance behaviours are the number of service calls, the service demand, concurrency (i.e. number of concurrent users) and the decomposition strategy. In addition to the experimental performance evaluation, we analyze the performance impact of service decomposition using queueing theoretic models. We compare the analytical results with experimental results and notice that analytical results match well with the experimental results.",International Conference on Web Engineering,2020,,,,,53-69,2,12,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_5
W-ADE: Timing Performance Benchmarking in Web of Things,Verena Eileen Schlott; Ege Korkan & Sebastian Steinhorst; Sebastian Kaebisch,"Siemens AG, Munich, Germany; Ludwig Maximilian University of Munich, Munich, Germany; Technical University of Munich, Munich, Germany",Web of Things; Thing Description; Timing performance; Performance benchmarking,"As the number of devices participating in the Internet of Things (IoT) rapidly grows, the challenge of interoperability across IoT platforms becomes more apparent. In order to limit fragmentation of IoT development and improve compatibility, web mechanisms and technologies can be applied, forming the Web of Things (WoT). The World Wide Web Consortium (W3C) supports the standardization of WoT by providing a platform-independent specification called Thing Description (TD). It is a machine-readable document that semantically describes metadata, interactions and interfaces of a device, indicating its functionality. However, it does not provide any information about timing performance, which is crucial for the design of optimal system compositions. In this paper, we present W-ADE, a development environment for WoT and TD that facilitates manual timing measurements and automated timing performance benchmarking of Thing interactions, merely with a TD available. Timing performance is guaranteed systematically, hence allowing optimization during the design phase of Thing mashups. Our evaluation shows that with 99.9% confidence W-ADE can predict average interaction timing performance within a range of \({\pm }5\%\), and is able to provide approximate network-independent static timing performance benchmarks for interaction affordances to 99.93%. To enable the design of heterogeneous IoT applications based upon these timing requirements, a proposal on how to annotate a TD based on the measured performance data is made.",International Conference on Web Engineering,2020,,,,,70-86,2,6,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_6
Comparing a Polling and Push-Based Approach for Live Open Data Interfaces,"Brecht Van de Vyvere, Pieter Colpaert & Ruben Verborgh","IDLab, Department of Electronics and Information Systems, Ghent University – imec, Gent, Belgium",Web API engineering; Performance and scalability; Open Data,"There are two mechanisms for publishing live changing resources on the Web: a client can pull the latest state of a resource or the server pushes updates to the client. In the state of the art, it is clear that pushing delivers a lower latency compared to pulling, however, this has not been tested for an Open Data usage scenario where 15 k clients are not an exception. Also, there are no general guidelines when to use a polling or push-based approach for publishing live changing resources on the Web. We performed (i) a field report of live Open datasets on the European and U.S. Open Data portal and (ii) a benchmark between HTTP polling and Server-Sent Events (SSE) under a load of 25 k clients. In this article, we compare the scalability and latency of updates on the client between polling and pushing. For the scenario where users want to receive an update as fast as possible, we found that SSE excels above polling in three aspects: lower CPU usage on the server, lower latency on the client and more than double the number of clients that can be served. However, considering that users can perceive a certain maximum latency on the client (MAL) of an update acceptable, we describe in this article at which MAL point a polling interface can be able to serve a higher number of clients than pushing. Open Data publishers can use these insights to determine which mechanism is the most cost-effective for the usage scenario they foresee of their live updating resources on the Web.",International Conference on Web Engineering,2020,,,,,87-101,2,8,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_7
NuMessage: Providing Scalable and Reliable Messaging Service in Distributed Systems,"Lubin Liu, Xinglang Wang, Tao Xiao, Wei Fang & HongYue Chen; Tong Liu","eBay, Shanghai, 200120, China; Shanghai University, Shanghai, 200444, China",Message oriented middleware; Retry mechanism design; Distributed messaging system,"For e-commerce companies with complex businesses like eBay, messaging oriented middleware has become a critical component of a large-scale distributed system, to support real-time asynchronous communication. In this work, we introduce novel messaging oriented middleware named as NuMessage, which can provide universal messaging service, including supporting push and pull modes and different scenarios. We also propose a retry mechanism to guarantee each message can be delivered and processed at least once. Various interfaces are implemented in NuMessage, making it easy to deploy NuMessage in practice. Experiments are conducted in a real system, and the results show that NuMessage can achieve superior performance when there are message consuming failures happening. Moreover, we have adopted NuMessage in eBay for some time to process 12 billion of messages per day.",International Conference on Web Engineering,2020,,,,,102-110,2,0,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_8
A Credit Scoring Model for SMEs Based on Social Media Data,"Septian Gilang Permana Putra, Bikash Joshi & Judith Redi; Alessandro Bozzon","Exact Software, Delft, Netherlands; Delft University of Technology, Delft, Netherlands",,"Credit scoring is an important tool to assess the solidity of small and medium-sized enterprises (SMEs), and to unlock for them new options for credit and improvement of cash flow. Credit scoring is, in its most common form, used by (potential) creditors to predict the probability of SMEs to default in the future, as an inverse measure of creditworthiness. The majority of existing credit scoring methods for SMEs are solely based on the analysis of SMEs’ financial data. While straightforward, these methods have major limitations: they may rely on very incomplete or outdated data, and fail to capture the very dynamic environment in which the business of SMEs evolves. In this paper, we propose an alternative approach to credit scoring for SMEs by enriching traditionally used financial data with social media data. We carried out our analysis on 25654 SMEs in the Netherlands, using 20 traditional financial indicators and 35 social media features. Experimental results suggest that the use of social media data in addition to traditional data significantly improves the quality of the credit scoring model for SMEs. Furthermore, we analyze the most important factors from social media data influencing the credit scoring.",International Conference on Web Engineering,2020,,,,,113-129,2,15,https://link.springer.com/chapter/10.1007/978-3-030-50578-3_9
Interface to Query and Visualise Definitions from a Knowledge Base,Anelia Kurteva; Hélène De Ribaupierre,"School of Computer Science and Informatics, Cardiff Univeristy, Cardiff, Wales, UK; Semantic Technology Institute, Department of Computer Science, University of Innsbruck, Innsbruck, Austria",Linked data; Knowledge base; User interface; Graphical visualisation; Human-computer interaction; Comprehension,"Linked data is at the core of the Web due to its ability to model real world entities, connect them via relationships and provide context, which could help to transform data into information and information into knowledge. For example, ontologies, which could be stored locally or could be made available to everyone online (e.g. the DBpedia knowledge base). However, both access and usage of Linked Data require individuals to have knowledge in the field of the Semantic Web. Many of the existing solutions are developed for specific use cases such as building and exploring ontologies visually and are aimed at expert users. The solutions that are aimed at non-experts are generic and, in most cases, a data visualisation is not available. In this paper, we present a web application with a user interface (UI), which combines features from applications for both expert and non-experts. The UI allows individuals with no previous knowledge of the Semantic Web to query the DBpedia knowledge base for definitions of a specific word and to view a graphical visualisation of the query results (the search keyword itself and concepts related to it).",International Conference on Web Engineering,2021,,,,,03-Oct,2,9,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_1
Towards Large-Scale Empirical Assessment of Web APIs Evolution,"Fabio Di Lauro, Souhaila Serbout & Cesare Pautasso","Software Institute, USI, Lugano, Switzerland",Web API; API evolution; OpenAPI,"Web Application Programming Interfaces (APIs) decouple the internal implementation of a service from its consumers which can reuse and compose them to rapidly build new applications. Many Web APIs are described with the OpenAPI Specification (OAS). The goal of our research is to check the feasibility of using API descriptions found in public open source repositories to study how APIs evolve over time. To do so, we collected a large dataset of OAS documents by crawling open source repositories, we parsed the corresponding metadata and measured the API size in order to extract a simple model to track the lifecycle of API artifacts and observe common evolution behaviors. Our preliminary results indicate that only a subset of the APIs changes, but as opposed to the expectation that APIs should only grow to maintain backward compatibility we also detected a number of APIs with a more variable history. We also study the stability of API artifacts over time and whether APIs are more or less likely to change as they age.",International Conference on Web Engineering,2021,,,,,124-138,2,13,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_10
Stability Metrics for Continuous Integration of Service-Oriented Systems,Dionysis Athanasopoulos & Daniel Keenan,"School of Electronics, Electrical Engineering, Computer Science Queen’s University Belfast, Northern Ireland, UK",Software stability; Service API; Evolution; Continuous integration,"One of the key principles of the service orientation is the standardised service contract. However, the assumption that the service contract is kept unmodified during the whole life-cycle of a system is not always held. Evolution changes on the service APIs have an impact on the maintainability of their programming clients within the system making difficult the continuous integration of the services. The metrics that have currently been applied for the service maintainability assess the service coupling, cohesion, complexity, and granularity. Software stability can further contribute in assessing the maintainability of systems. However, it is challenging to measure the stability of service APIs without having evolved their programming clients, because it should be measured by considering the types of the evolution changes in APIs that have direct impact on the programming clients. To address this challenge, we define a set of mappings between evolved service APIs based on which the stability changes can be determined. We further specify a generic algorithm that recognises the evolution changes required on the programming clients of the evolved APIs. We finally define an initial version of a suite of metrics that estimate the stability of a service system without assuming the existence of the evolved programming clients.",International Conference on Web Engineering,2021,,,,,139-147,2,0,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_11
Attentive Hybrid Collaborative Filtering for Rating Conversion in Recommender Systems,Phannakan Tengkiattrakul & Atsuhiro Takasu; Saranya Maneeroj; Phannakan Tengkiattrakul & Atsuhiro Takasu,"Department of Mathematics and Computer Science, Faculty of Science, Chulalongkorn University, Bangkok, Thailand; National Institute of Informatics, Tokyo, Japan; The Graduate University for Advanced Studies, SOKENDAI, Tokyo, Japan",Recommender systems; Collaborative filtering; Rating conversion; Neural networks,"Recommendation models that use collaborative filtering consider the influence of friends and neighbors when recommending suitable items for a target user. Most of these neighborhood-based models use the actual ratings from neighbors to predict the ratings of the target user toward target items, which often leads to a low accuracy prediction caused by the improper rating-range problem. Recently, rating conversion methods have been proposed to address this issue. Because each friend/neighbor can have a different level of influence on the target user, we propose a friend module, which converts their ratings to match the target user’s perspective and assigns different weight to each user before modeling latent relations and predictions. In rating conversion, ratings that involve explicit feedback are important. Instead of the traditional approach to user embedding, we propose a novel approach that uses explicit feedback. This can express user features better than traditional methods and can then be used to convert ratings to match the target user’s perspective. For better representation and recommendation, we also learn latent relations between each user and item by adopting knowledge graph ideas, which leads to more accurate results. The FilmTrust and MovieLens datasets are used in experiments comparing the proposed method with existing methods. This evaluation showed that our model is more accurate than existing methods.",International Conference on Web Engineering,2021,,,,,151-165,2,3,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_12
Sentence Dependent-Aware Network for Aspect-Category Sentiment Analysis,"Lianwei Li, Ying Yang, Shimeng Zhan & Bin Wu","Beijing University of Posts and Telecommunications, Beijing, China",Aspect-category sentiment analysis; Multi-task learning; Graph attention networks,"The purpose of Aspect-Category Sentiment Analysis is to predict sentiment polarities of given aspect categories in sentences. Most previous methods used attention-based neural network models to Establish connections between aspect categories and sentiment words and generate aspect-specific sentence representations. However, these models may mismatch sentiment words with aspect categories due to the complexity of sentence structures. To solve this problem, we reconstruct the dependency tree into an ACSA-oriented dependency tree, which builds a direct or indirect semantic connection between sentiment words and corresponding aspect categories, and avoid introducing redundant information from the original dependency tree. On this basis, we propose a Sentence Dependent-Aware Network (SDAN) to encode the tree effectively. The experimental results of applying SDAN to three public datasets demonstrate its effectiveness.",International Conference on Web Engineering,2021,,,,,166-174,2,3,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_13
A Probabilistic Approach to Personalize Type-Based Facet Ranking for POI Suggestion,"Esraa Ali, Séamus Lawless & Owen Conlan; Annalina Caputo","ADAPT Centre, School of Computing, Dublin City University, Dublin, Ireland; ADAPT Centre, School of Computer Science and Statistics, Trinity College Dublin, Dublin, Ireland",Type-based Facets; Faceted search; Personalization,"Faceted Search Systems (FSS) have become one of the main search interfaces used in vertical search systems, offering users meaningful facets to refine their search query and narrow down the results quickly to find the intended search target. This work focuses on the problem of ranking type-based facets. In a structured information space, type-based facets (t-facets) indicate the category to which each object belongs. When they belong to a large multi-level taxonomy, it is desirable to rank them separately before ranking other facet groups. This helps the searcher in filtering the results according to their type first. This also makes it easier to rank the rest of the facets once the type of the intended search target is selected. Existing research employs the same ranking methods for different facet groups. In this research, we propose a two-step approach to personalize t-facet ranking. The first step assigns a relevance score to each individual leaf-node t-facet. The score is generated using probabilistic models and it reflects t-facet relevance to the query and the user profile. In the second step, this score is used to re-order and select the sub-tree to present to the user. We investigate the usefulness of the proposed method to a Point Of Interest (POI) suggestion task. Our evaluation aims at capturing the user effort required to fulfil her search needs by using the ranked facets. The proposed approach achieved better results than other existing personalized baselines.",International Conference on Web Engineering,2021,,,,,175-182,2,5,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_14
Web Table Classification Based on Visual Features,Babette Bühler; Heiko Paulheim,"Hector Research Institute of Education Sciences and Psychology, University of Tübingen, Tübingen, Germany; Data and Web Science Group, University of Mannheim, Mannheim, Germany",Web table; Genuine table; Layout table; Image classification; Convolutional neural network,"Tables on the web constitute a valuable data source for many applications, like factual search and knowledge base augmentation. However, as genuine tables containing relational knowledge only account for a small proportion of tables on the web, reliable genuine web table classification is a crucial first step of table extraction. Previous works usually rely on explicit feature construction from the HTML code. In contrast, we propose an approach for web table classification by exploiting the full visual appearance of a table, which works purely by applying a convolutional neural network on the rendered image of the web table. Since these visual features can be extracted automatically, our approach circumvents the need for explicit feature construction. A new hand labeled gold standard dataset containing HTML source code and images for 13,112 tables was generated for this task. Transfer learning techniques are applied to well known VGG16 and ResNet50 architectures. The evaluation of CNN image classification with fine tuned ResNet50 (F1 93.29%) shows that this approach achieves results comparable to previous solutions using explicitly defined HTML code based features. By combining visual and explicit features, an F-measure of 93.70% can be achieved by Random Forest classification, which beats current state of the art methods.",International Conference on Web Engineering,2021,,,,,185-200,2,2,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_15
Automated Essay Scoring via Example-Based Learning,Yupin Yang & Jiang Zhong,"Chongqing University, Chongqing, 400044, China",Automated essay scoring; Natural language processing; Example-based learning,"Automated essay scoring (AES) is the task of assigning grades to essays. It can be applied for quality assessment as well as pricing on User Generated Content. Previous works mainly consider using the prompt information for scoring. However, some prompts are highly abstract, making it hard to score the essay only based on the relevance between the essay and the prompt. To solve the problem, we design an auxiliary task, where a dynamic semantic matching block is introduced to capture the hidden features with example-based learning. Besides, we provide a hierarchical model that can extract semantic features at both sentence-level and document-level. The weighted combination of the scores is obtained from the features above to get holistic scoring. Experimental results show that our model achieves higher Quadratic Weighted Kappa (QWK) scores on five of the eight prompts compared with previous methods on the ASAP dataset, which demonstrate the effectiveness of our model.",International Conference on Web Engineering,2021,,,,,201-208,2,12,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_16
Conversation and Recommendation: Knowledge-Enhanced Personalized Dialog System,Ming He & Tong Shen; Ruihai Dong,"Beijing University of Technology, Beijing, 100124, China; University College Dublin, Dublin, Ireland",Recommender systems; Dialog systems; Memory network; Knowledge base,"Traditional recommender systems are usually single-shot systems, lacking real-time dialog with customers. Using dialog as an interactive method can more accurately capture user preferences and enhance system transparency. However, building such a goal-oriented dialog system suffered many challenges as the system itself needs to collaborate with various sub-tasks, such as collecting user needs through interaction, recommending appropriate products to users. Most existing work of dialog systems does not comprehensively consider this scenario and the challenges caused. In this paper, we propose a novel memory network framework for conversational recommendation, which harness dialog historical information to endows our model with adaptability in different dialog scenarios, and leverage the knowledge base and user profiles to reweight candidates, to reduce the ambiguity during interactions and improve the quality of conversational recommender systems. Through the experiments on the personalized bAbI dialog dataset and restaurant recommendation application, we demonstrate that the proposed method can achieve state-of-the-art performance in a few classical tasks, such as options display and information provision, etc.",International Conference on Web Engineering,2021,,,,,209-224,2,16,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_17
MPIA: Multiple Preferences with Item Attributes for Graph Convolutional Collaborative Filtering,"Ming He, Zekun Huang & Han Wen","Faculty of Information Technology, Beijing University of Technology, Beijing, China",Recommender systems; Graph convolution networks; Graph neural network; Collaborative filtering,"Personalized recommender systems are playing an increasingly critical role in a variety of online applications. In recent years, advancements in graph-structured deep neural networks have attracted considerable interest and achieved state-of-the-art performance on recommender system benchmarks. However, existing graph-based recommendation methods generally characterize each user with just one representation vector, which is insufficient to convey diverse preferences of users. To address this issue, in this paper, we approach the learning of user representations from a different perspective, by modeling users based on multiple representation embeddings. We propose a Multiple Preferences with Item Attributes for Graph Convolutional Collaborative Filtering (MPIA) framework built upon the message-aggregation concept of graph neural networks, which can generate preference-specific user representations to better model the diverse preferences of users. By taking advantage of graph representation learning techniques, MPIA learns preference-specific embeddings for users and attribute-specific embeddings for items. Moreover, we utilize shared embeddings for user and item representations to obtain the commonalities in multiple networks. Specifically, we construct a user-item bipartite graph for each preference, and enrich the representation of each node with the topological structure and features of its neighbors. We also design a preference-attribute fusion method to acquire more accurate item retrievals for every aspect of interest. Extensive experiments conducted on three real-world datasets demonstrate the effectiveness of the proposed MPIA framework.",International Conference on Web Engineering,2021,,,,,225-239,2,3,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_18
Better Call the Plumber: Orchestrating Dynamic Information Extraction Pipelines,Mohamad Yaser Jaradeh; Kuldeep Singh; Markus Stocker & Sören Auer; Andreas Both,"Anhalt University of Applied Sciences, Bernburg, Germany; Zerotha-Research and Cerence GmbH, Aachen, Germany; L3S Research Center, Leibniz University Hannover, Hanover, Germany; TIB Leibniz Information Centre for Science and Technology, Hanover, Germany",Information extraction; NLP pipelines; Software reusability; Semantic search; Semantic Web,"We propose Plumber, the first framework that brings together the research community’s disjoint information extraction (IE) efforts. The Plumber architecture comprises 33 reusable components for various Knowledge Graphs (KG) information extraction subtasks, such as coreference resolution, entity linking, and relation extraction. Using these components, Plumber dynamically generates suitable information extraction pipelines and offers overall 264 distinct pipelines. We study the optimization problem of choosing suitable pipelines based on input sentences. To do so, we train a transformer-based classification model that extracts contextual embeddings from the input and finds an appropriate pipeline. We study the efficacy of Plumber for extracting the KG triples using standard datasets over two KGs: DBpedia, and Open Research Knowledge Graph (ORKG). Our results demonstrate the effectiveness of Plumber in dynamically generating KG information extraction pipelines, outperforming all baselines agnostics of the underlying KG. Furthermore, we provide an analysis of collective failure cases, study the similarities and synergies among integrated components, and discuss their limitations.",International Conference on Web Engineering,2021,,,,,240-254,2,13,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_19
CARDINAL: Contextualized Adaptive Research Data Description INterface Applying LinkedData,"André Langer, Christoph Göpfert & Martin Gaedke","Chemnitz University of Technology, Chemnitz, Germany",Adaptive user interface; Contextualization; Linked data; Research data management; Data publishing; Ontologies,"In the publishing process for research data, common user interfaces for gathering descriptive structured metadata traditionally rely on static free-text input elements. This constitutes an obstacle for interdisciplinary, unambiguous, fine-grained data descriptions. Reusing already existing domain-specific metadata models based on semantic ontologies are a more promising approach, but the careful selection and presentation of relevant properties is not trivial. In this paper, we present the CARDINAL approach, which takes the current research context into consideration to request additional but only meaningful domain-specific characteristics. It generates and presents an adaptive user input interface to the user that allows the structured input of knowledge-domain specific descriptive metadata based on existing ontologies. We show in a proof-of-concept the feasibility of such a contextualized web form for research metadata and discuss challenges in the selection process for relevant ontologies and properties. A web-based survey experiment with 83 participants of varying research domain and expertise shows, that the CARDINAL approach allows to collect additional relevant metadata in a structured way without overstraining the user.",International Conference on Web Engineering,2021,,,,,Nov-27,2,1,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_2
Preprocessing Techniques for End-To-End Trainable RNN-Based Conversational System,"Hussein Maziad, Julie-Ann Rammouz & Joe Tekli; Boulos El Asmar","Logistics Robotics, BMW Group, 80788, Munich, Germany; E.C.E. Department, Lebanese American University, Byblos, 36, Lebanon",Conversational dialogue systems; Data semantics; Knowledge base; Knowledge integration; Conversational data preprocessing,"Spoken dialogue system interfaces are gaining increasing attention, with examples including Apple’s Siri, Amazon’s Alexa, and numerous other products. Yet most existing solutions remain heavily data-driven, and face limitations in integrating and handling data semantics. They mainly rely on statistical co-occurrences in the training dataset and lack a more profound knowledge integration model with semantically structured information such as knowledge graphs. This paper evaluates the impact of performing knowledge base integration (KBI) to regulate the dialogue output of a deep learning conversational system. More specifically, it evaluates whether integrating dependencies between the data, obtained from the semantic linking of an external knowledge base (KB), would help improve conversational quality. To do so, we compare three approaches of conversation preprocessing methods: i) no KBI: considering conversational data with no external knowledge integration, ii) All Predicates KBI: considering conversational data where all dialogue pairs are augmented with their linked predicates from the domain KB, and iii) Intersecting Predicates KBI: considering conversational data where dialogue pairs are augmented only with their intersecting predicates (to filter-out potentially useless or redundant knowledge). We vary the amount of history considered in the conversational data, ranging from 0% (considering the last dialogue pair only) to 100% (considering all dialogue pairs, from the beginning of the dialogue). To our knowledge, this is the first study to evaluate knowledge integration in the preprocessing phase of conversational systems. Results are promising and show that knowledge integration – with an amount of history ranging between 10% and 75%, generally improves conversational quality.",International Conference on Web Engineering,2021,,,,,255-270,2,5,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_20
Effective Seed-Guided Topic Labeling for Dataless Hierarchical Short Text Classification,"Yi Yang, Hongan Wang, Jiaqi Zhu, Wandong Shi, Wenli Guo & Jiawen Zhang; Jiaqi Zhu; Yi Yang, Hongan Wang, Jiaqi Zhu, Wandong Shi & Jiawen Zhang","Zhejiang Lab, Hangzhou, Zhejiang, China; University of Chinese Academy of Sciences, Beijing, China; SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China",Hierarchical text classification; Topic model; Seed word,"Hierarchical text classification has a wide application prospect on the Internet, which aims to classify texts into a given hierarchy. Supervised methods require a large amount of labeled data and are thus costly. For this purpose, the task of dataless hierarchical text classification has attracted more and more attention of researchers in recent years, which only requires a few relevant seed words for given categories. However, existing approaches mainly focus on long texts without considering the characteristics of short texts, so are not suitable in many scenarios. In this paper, we tackle dataless hierarchical short text classification for the first time, and propose an innovative model named Hierarchical Seeded Biterm Topic Model (HierSeedBTM), which effectively leverages seed words in Biterm Topic Model (BTM) to guide the hierarchical topic labeling. Specifically, our model introduces iterative distribution propagation mechanism among topic models in different levels to incorporate the hierarchical structure information. Experiments on two public datasets show that the proposed model is more effective than the state-of-the-art methods of dataless hierarchical text classification designed for long texts.",International Conference on Web Engineering,2021,,,,,271-285,2,3,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_21
PrivaSeer: A Privacy Policy Search Engine,"Mukund Srinath, Soundarya Nurani Sundareswara, C. Lee Giles & Shomir Wilson","Pennsylvania State University, University Park, State College, PA, USA",Privacy; Search engine; Ranking,"Web privacy policies are used by organisations to disclose their privacy practices to users on the web. However, users often do not read privacy policies because they are too long, time consuming, or too complicated. Attempts to simplify privacy policies using natural language processing have achieved some success, but they face limitations of scalability and generalization. While this puts an onus on researchers and policy regulators to protect users against unfair privacy practices, they often lack a large-scale collection of policies to study the state of internet privacy. To remedy this bottleneck, we present PrivaSeer, the first privacy policy search engine. PrivaSeer has been indexed on 1,400,318 English language website privacy policies and can be used to search privacy policies based on text queries and several search facets. Results can be ranked by PageRank, query-based document relevance, and the probability that a document is a privacy policy. Results also can be filtered by readability, vagueness, industry, and mentions of tracking technology, self-regulatory bodies, or regulations and cross-border agreements in the policy text. PrivaSeer allows legal experts, researchers, and policy regulators to discover privacy trends and policy anomalies in privacy policies at scale. In this paper we present the search interface, ranking technique, and filtering techniques for PrivaSeer. We create two indexes of privacy policies: one including supplementary non-policy content present in privacy policy web pages and one without. We evaluate the functionality of PrivaSeer by comparing ranking techniques on these two indexes.",International Conference on Web Engineering,2021,,,,,286-301,2,13,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_22
Knowledge-Driven Architecture Composition: Assisting the System Integrator to Reuse Integration Knowledge,Fabian Burzlaff & Christian Bartelt,"Institute for Enterprise Systems (InES), University of Mannheim, 68131, Mannheim, Germany",Knowledge-driven architecture composition; Web service integration; Reuse,"Semantic interoperability for web services is still a problem. Although decentralized solutions such as describing the integration context with a formal mapping language or using a web service description language exist, practitioners rely on implementing software adapters manually. For IoT and Web of Things systems, current scientific solutions fall short as changing them, once defined, requires strenuous effort. However, devices and thus, their interfaces change often in this class of system. This paper tackles the barrier of high formalization effort for mappings between required and provided interfaces. Therefore, we apply and evaluate a novel integration method for web service choreography. Our empirical experiment shows that this method lowers the integration time and number of errors by assisting the system integrator to reuse integration knowledge from previous integration cases.",International Conference on Web Engineering,2021,,,,,305-319,2,4,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_23
A-MaGe: Atomic Mashup Generator for the Web of Things,"Ege Korkan, Fady Salama & Sebastian Steinhorst; Sebastian Kaebisch","Siemens AG, Munich, Germany; Technical University of Munich, Munich, Germany",Web of Things; Mashup composition,"Individually, Internet of Things (IoT) devices are often not able to achieve complex functionalities and, therefore, need to be composed together into useful mashups. However, given the current fragmentation of the IoT domain, designing a mashup is still a manual task that is time-consuming and error-prone. The introduction of the Thing Description (TD) from the World Wide Web Consortium (W3C) is meant to facilitate the interoperability between IoT devices and platforms by providing a standardized format to describe the network interfacing of entities, called Things, participating in the Web of Things (WoT). Furthermore, the System Description (SD) extension introduces the notion of Atomic Mashups (AMs), small mashup building blocks that are easier to design. However, designing AMs remains a manual task and, given the rising complexity of IoT devices, manually exploring the resulting design space is infeasible. In this paper, we introduce A-MaGe: a method and its open-source implementation that takes the TDs as an input and uses predefined templates, user-configurable rules, semantic annotation filtering and natural language processing to automatically explore and reduce the design space. SD-compliant UML Sequence Diagrams of the resulting mashups are presented to the human agent for further selection to generate the SD of the mashup as well as implementation code based on the W3C WoT Scripting API. We show that the generation process is fast, allowing multiple iterations by the human agent to increase reduction and we evaluate the filtering power of different filters and constraints. Thus, in combination with the TD standard, our method ensures easy composition of services in heterogeneous environments.",International Conference on Web Engineering,2021,,,,,320-327,2,4,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_24
WebAssembly Modules as Lightweight Containers for Liquid IoT Applications,"Niko Mäkitalo, Tommi Mikkonen, Victor Bankowski, Paulius Daubaris & Risto Mikkola; Cesare Pautasso; Oleg Beletski","University of Lugano, Lugano, Switzerland; Huawei Technologies, Helsinki, Finland; University of Helsinki, Helsinki, Finland",Light-weight containers; Internet of Things; IoT; Liquid software; Containers; WebAssemly; Web of Things; WoT,"Going all the way to IoT with web technologies opens up the door to isomorphic IoT system architectures, which deliver flexible deployment and live migration of code between any device in the overall system. In this vision paper, we propose using WebAssembly to implement lightweight containers and deliver the required portability. Our long-term vision is to use the technology to support developers of liquid IoT applications offering seamless, hassle-free use of multiple devices.",International Conference on Web Engineering,2021,,,,,328-336,2,60,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_25
Leveraging Web of Things W3C Recommendations for Knowledge Graphs Generation,"Dylan Van Assche, Gerald Haesendonck, Gertjan De Mulder, Thomas Delva, Pieter Heyvaert, Ben De Meester & Anastasia Dimou","IDLab, Department of Electronics and Information Systems, Ghent University – imec, Technologiepark-Zwijnaarde 122, 9052, Ghent, Belgium",,"Constructing a knowledge graph with mapping languages, such as RML or SPARQL-Generate, allows seamlessly integrating heterogeneous data by defining access-specific definitions for e.g., databases or files. However, such mapping languages have limited support for describing Web APIs and no support for describing data with varying velocities, as needed for e.g., streams, neither for the input data nor for the output RDF. This hampers the smooth and reproducible generation of knowledge graphs from heterogeneous data and their continuous integration for consumption since each implementation provides its own extensions. Recently, the Web of Things (WoT) Working Group released a set of recommendations to provide a machine-readable description of metadata and network-facing interfaces for Web APIs and streams. In this paper, we investigated (i) how mapping languages can be aligned with the newly specified recommendations to describe and handle heterogeneous data with varying velocities and Web APIs, and (ii) how such descriptions can be used to indicate how the generated knowledge graph should be exported. We extended RML’s Logical Source to support WoT descriptions of Web APIs and streams, and introduced RML’s Logical Target to describe the generated knowledge graph reusing the same descriptions. We implemented these extensions in the RMLMapper and RMLStreamer, and validated our approach in two use cases. Mapping languages are now able to use the same descriptions to define the input data but also the output RDF. This way, our work paves the way towards more reproducible workflows for knowledge graph generation.",International Conference on Web Engineering,2021,,,,,337-352,2,26,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_26
A Standalone WebAssembly Development Environment for the Internet of Things,István Koren,"Chair of Process and Data Science, RWTH Aachen University, Aachen, Germany",WebAssembly; Internet of Things; Industry 4.0,"In Industry 4.0, there is a growing demand to perform high-performance and latency-sensitive computations at the edge. Increasingly, machine data is not only collected but also processed and translated into actionable decisions influencing production parameters in real-time. However, heterogeneous hardware in the Internet of Things prevents the adoption of consistent development and deployment structures as known from service containers. WebAssembly is a recent hardware-agnostic bytecode format that is capable of running not only in the browser, but also on microcontrollers and in cloud environments. In this article, we argue that this web technology can have a real impact by leveraging tools and programming languages that web engineers are familiar with. As a first step, we present a proof-of-concept integrated development and deployment environment to execute WebAssembly modules on microcontrollers. Its key feature is a built-in web server that provides a self-contained browser-based IDE to directly develop, compile and flash AssemblyScript code to a device. In this sense, the Web of Things will unfold a streamlined development and deployment context for the agile and low-latency operationalization of adjustable data streaming and action-oriented process adaptations for industrial devices.",International Conference on Web Engineering,2021,,,,,353-360,2,9,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_27
Full Stack Is Not What It Used to Be,Antero Taivalsaari; Tommi Mikkonen; Cesare Pautasso; Antero Taivalsaari & Kari Systä,"USI, Lugano, Switzerland; Tampere University, Tampere, Finland; University of Helsinki, Helsinki, Finland; Nokia Bell Labs, Tampere, Finland",Education; Software engineering; Web engineering; Software architecture; Cloud; Internet of Things; IoT; Programmable world,"The traditional definition of full stack development refers to a skill set that is required for writing software both for the frontend and backend of a web application or site. In recent years, the scope of full stack development has expanded significantly, though. Today, a full stack software developer is assumed to master various additional areas especially related to cloud infrastructure and deployment, message brokers and data analytics technologies. In addition, the emergence of Internet of Things (IoT) and the rapidly spreading use of AI/ML technologies are introducing additional skill set requirements. In this paper, we discuss the expectations for a modern full stack developer based on our industry observations, and argue that these expectations have significant implications for software and web engineering education.",International Conference on Web Engineering,2021,,,,,363-371,2,23,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_28
An Improving Approach for DOM-Based Web Test Suite Repair,"Wei Chen, Hanyang Cao & Xavier Blanc; Wei Chen & Hanyang Cao","University of Bordeaux, LaBRI, UMR 5800, 33400, Talence, France; Beihang University, Beijing, China",Web test repair; Test suite; Web test evolution; Test case; Automated E2E test,"Developers increasingly rely on end-to-end (E2E) testing to test the web applications they develop and check whether there are no bugs from the end user’s perspective. An E2E test simulates the actions performed by the user using a browser and checks whether the web application returns the expected output. It considers web applications as a black box and only knows what user actions are and what their expected output is. However, once some evolutions are implemented on a web application, user actions may change (a button has been added, deleted, or just moved to another location), which may break the E2E test. Rebuilding new test suites takes a lot of time, especially for large web applications. Therefore, E2E testing needs to evolve with the development of web applications. To help the developers who face this situation, we present an approach, named WebTestSuiteRepair (WTSR), that aims to generate and compare test suite graphs to identify candidates for broken actions, hence helps to automatically and efficiently repair the E2E tests for web applications.",International Conference on Web Engineering,2021,,,,,372-387,2,8,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_29
Publishing Base Registries as Linked Data Event Streams,"Dwight Van Lancker, Pieter Colpaert, Harm Delva, Brecht Van de Vyvere, Julián Rojas Meléndez, Ruben Dedecker, Raf Buyle & Ruben Verborgh; Philippe Michiels; Dwight Van Lancker, Raf Buyle & Annelies De Craene","Flemish Information Agency, Flanders, Belgium; IDLab, Department of Electronics and Information Systems, Ghent University–Imec, Ghent, Belgium; Imec EDiT, Leuven, Belgium",Semantic web; Web Apis; Data reuse; Data versioning,"Fostering interoperability, Public Sector Bodies (PSBs) maintain datasets that should become queryable as an integrated Knowledge Graph (KG). While some PSBs allow to query a part of the KG on their servers, others favor publishing data dumps allowing the querying to happen on third party servers. As the budget of a PSB to publish their dataset on the Web is finite, PSBs need guidance on what interface to offer first. A core API can be designed that covers the core tasks of Base Registries, which is a well-defined term in Flanders for the management of authoritative datasets. This core API should be the basis on which an ecosystem of data services can be built. In this paper, we introduce the concept of a Linked Data Event Stream (LDES) for datasets like air quality sensors and observations or a registry of officially registered addresses. We show that extra ecosystem requirements can be built on top of the LDES using a generic fragmenter. By using hypermedia for describing the LDES as well as the derived datasets, agents can dynamically discover their best way through the KG, and server administrators can dynamically add or remove functionality based on costs and needs. This way, we allow PSBs to prioritize API functionality based on three tiers: (i) the LDES, (ii) intermediary indexes and (iii) querying interfaces. While the ecosystem will never be feature-complete, based on the market needs, PSBs as well as market players can fill in gaps as requirements evolve.",International Conference on Web Engineering,2021,,,,,28-36,2,26,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_3
Communicating Web Vessels: Improving the Responsiveness of Mobile Web Apps with Adaptive Redistribution,Kijin An & Eli Tilevich,"Software Innovations Lab, Virginia Tech, Blacksburg, USA",Mobile web apps; Javascript; Dynamic adaptation; Program analysis & transformation; Web frameworks,"In a mobile web app, a browser-based client communicates with a cloud-based server across the network. An app is statically divided into client and server functionalities, so the resulting division remains fixed at runtime. However, if such static division mismatches the current network conditions and the device’s processing capacities, app responsiveness and energy efficiency can deteriorate rapidly. To address this problem, we present Communicating Web Vessels (CWV), an adaptive redistribution framework that improves the responsiveness of full-stack JavaScript mobile apps. Unlike standard computation offloading, in which client functionalities move to run on the server, CWV’s redistribution is bidirectional. Without any preprocessing, CWV enables apps to move any functionality from the server to the client and vice versa at runtime, thus adapting to the ever-changing execution environment of the web. Having moved to the client, former server functionalities become regular local functions. By monitoring the network, CWV determines if a redistribution would improve app performance, and then analyzes, transforms, sandboxes, and moves functions and program state at runtime. An evaluation with third-party mobile web apps shows that CWV optimizes their performance for dissimilar network conditions and client devices. As compared to their original versions, CWV-powered web apps improve their performance (i.e., latency, energy consumption), particularly when executed over limited networks.",International Conference on Web Engineering,2021,,,,,388-403,2,5,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_30
Snapshot-Based Migration of ES6 JavaScript,Yong-Hwan Yoo & Soo-Mook Moon,"Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul, South Korea",JavaScript; App migration; Serialization; Code generation,"Recently, researches have proposed application (app) migration approaches for JavaScript programs to enable a non-breaking user experience across different devices. To migrate a stateful JavaScript app’s runtime, past studies have proposed snapshot-based techniques in which the app’s runtime state is profiled and serialized into a text form that can be restored back later. A common limitation of existing literature, however, is that they are based on old JavaScript specifications. Since major updates introduced by ECMASCript2015 (a.k.a. ES6), JavaScript supports various features that cannot be migrated correctly with existing methods. Some of these features are in fact heavily used in today’s real-world apps and thus greatly reduces the scope of previous works.",International Conference on Web Engineering,2021,,,,,404-419,2,5,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_31
Automated Repair of Layout Bugs in Web Pages with Linear Programming,"Stéphane Jacquet, Xavier Chamberland-Thibeault & Sylvain Hallé","Laboratoire d’informatique formelle, Université du Québec à Chicoutimi, Chicoutimi, Canada",Layout bugs; Declarative specifications; Linear programming,"The paper addresses the issue of layout bugs, in which elements of a web page may overlap, become misaligned or protrude from their parent container for fortuitous reasons. It proposes a technique to apply corrections to a rendered page by formulating its current state and associated layout constraints into a Mixed Integer Linear Programming problem. An off-the-shelf numerical solver is used to generate a layout that satisfies the constraints, in such a way that disruptions to the original page are minimized. A probe then injects these corrections in the form of a temporary “hotfix”. The approach has been implemented and tested on samples of real-world web pages; using techniques that aim to reduce the size of the optimization problem, a solution can often be computed in a few seconds on commodity hardware.",International Conference on Web Engineering,2021,,,,,423-439,2,7,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_32
A Model-Based Chatbot Generation Approach to Converse with Open Data Sources,"Hamza Ed-douibi, Javier Luis Cánovas Izquierdo, Gwendal Daniel & Jordi Cabot; Jordi Cabot","UOC., Barcelona, Spain; ICREA., Barcelona, Spain",Open data; UML; Chatbots; API; OpenAPI,"The Open Data movement promotes the free distribution of data. More and more companies and governmental organizations are making their data available online following the Open Data philosophy, resulting in a growing market of technologies and services to help publish and consume data. One of the emergent ways to publish such data is via Web APIs, which offer a powerful means to reuse this data and integrate it with other services. Socrata, CKAN or OData are examples of popular specifications for publishing data via Web APIs. Nevertheless, querying and integrating these Web APIs is time-consuming and requires technical skills that limit the benefits of Open Data movement for the regular citizen. In other contexts, chatbot applications are being increasingly adopted as a direct communication channel between companies and end-users. We believe the same could be true for Open Data as a way to bridge the gap between citizens and Open Data sources. This paper describes an approach to automatically derive full-fledged chatbots from API-based Open Data sources. Our process relies on a model-based intermediate representation (via UML class diagrams and profiles) to facilitate the customization of the chatbot to be generated.",International Conference on Web Engineering,2021,,,,,440-455,2,30,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_33
Open Data Accessibility Based on Voice Commands,"César González-Mora, Irene Garrigós & Jose-Norberto Mazón; Sven Casteleyn; Sergio Firmenich","LIFIA, Facultad de Informatica, UNLP and CONICET, La Plata, Argentina; Web And Knowledge Research Group, Department of Software and Computing Systems, University of Alicante, Alicante, Spain; Geospatial Technologies Lab (GEOTEC), Institute of New Imaging Technologies (INIT), University Jaime I, Castellón de la Plana, Spain",Web accessibility; Web augmentation; Open data; Voice interaction,"Nowadays, the accessibility of open data on the Web is problematic, in particular for those data enthusiasts (non-technical users really interested in data) with visual disabilities. They generally experience accessibility barriers when browsing open data portals. Therefore, in order to improve accessibility and facilitate visually impaired users to obtain open data, we propose a Web Augmentation Framework for Accessibility for Open Data (WAFRA4OD). The proposed approach uses Web augmentation techniques and voice interaction to help users in finding relevant open data by offering them various useful comments, including a full fledged voice interaction interface. Thereby, WAFRA4OD enables visually impaired data enthusiasts to explore and interact with open data portals using voice commands, and thus improves the accessibility of open data. To show the feasibility of WAFRA4OD we demonstrate its use in a case study using the European Data Portal.",International Conference on Web Engineering,2021,,,,,456-463,2,5,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_34
PWA vs the Others: A Comparative Study on the UI Energy-Efficiency of Progressive Web Apps,Stefan Huber & Lukas Demetz; Michael Felderer,"Department of Computer Science, University of Innsbruck, Innsbruck, Austria; University of Applied Sciences Kufstein, Kufstein, Austria",Mobile cross-platform development; Mobile web engineering; Mobile app energy efficiency; Progressive web apps,"Developing the same mobile app for multiple platforms is a prominent challenge for practitioners in mobile software development. When starting an app project, practitioners are faced with a plethora of development approaches to choose from. Progressive Web Apps (PWAs) are a novel and promising approach for mobile cross-platform development (MCPD). As mobile devices are limited regarding battery capacity, the energy footprint of a mobile app should be kept as low as possible. Thus, the aim of this study is to analyze the difference in energy consumption of PWAs and other mobile development approaches with a focus on UI rendering and interaction scenarios. For this, we implemented five versions of the same app with different development approaches and examined their energy footprint on two Android devices with four execution scenarios. The results show that the used development approach influences the energy footprint of a mobile app. Native development shows the lowest energy consumption. PWAs, albeit not the lowest energy consuming mobile development approach, are a viable alternative to other MCPD approaches. Moreover, the web-browser engine used to execute the PWA has a significant influence on the energy footprint of the app.",International Conference on Web Engineering,2021,,,,,464-479,2,34,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_35
Static Analysis of Large-Scale JavaScript Front End,Anton Karakochev & Gefei Zhang,"Hochschule für Technik und Wirtschaft Berlin, Berlin, Germany",,"In modern web applications, the elaborate GUI of the front end is often developed with large-scale JavaScript frameworks. In such systems, the behavior of one HTML element is usually defined by code in different JavaScript functions scattered all over the source files, and a piece of code may also have influence on other functions and variables all over the source files. Therefore, the data and control flow of the front end may be hard to follow. We propose an automated approach to integrate the overall data and control flow of the front end into an overview model, which then provides us with an excellent starting point to application of formal methods to prove the correctness of the front end. Our approach is hence helpful for comprehension of the front end code and validation of its correctness.",International Conference on Web Engineering,2021,,,,,483-489,2,1,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_36
Applying Predictive Analytics on Research Information to Enhance Funding Discovery and Strengthen Collaboration in Project Proposals,Dang Vu Nguyen Hai & Martin Gaedke,"Chemnitz University of Technology, Chemnitz, Germany",Research Information Management System (RIMS); Linked data; Predictive analytics; Data driven decision making,"In academic and industrial research, writing a project proposal is one of the essential but time-consuming activities. Nevertheless, most proposals end in rejection. Moreover, research funding is getting more competitive these days. Funding agencies are increasingly looking for more extensive and more interdisciplinary research proposals. To increase the funding success rate, this PhD project focuses on three open challenges: poor data quality, inefficient funding discovery, and ineffective collaborative team building. We envision a Predictive Analytics-based approach that involves analyzing research information and using statistical and machine learning models that can assure data quality, increase funding discovery efficiency and the effectiveness of collaboration building. Accordingly, the goal of this PhD project is to support decision-making process to maximize the funding success rates of universities.",International Conference on Web Engineering,2021,,,,,490-495,2,0,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_37
A Web-Based Co-Creation and User Engagement Method and Platform,"Andrea Tocchetti, Lorenzo Corti & Marco Brambilla; Diletta Di Marco","Dipartimento di Ingegneria Gestionale, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy",Crowdsourcing; Gamification; Co-creation; Policy-making,"In recent years, new methods to engage citizens in deliberative processes of governments and institutions have been studied. Such methodologies have become a necessity to assure the efficacy and longevity of policies. Several tools and solutions have been proposed while trying to achieve such a goal. The dual problem to citizen engagement is how to provide policy-makers with useful and actionable insights stemming from those processes. In this paper, we propose a research featuring a method and implementation of a crowdsourcing and co-creation technique that can provide value to both citizens and policy-makers engaged in the policy-making process. Thanks to our methodology, policy-makers can design challenges for citizens to partake, cooperate and provide their input. We also propose a web-based tool that allow citizens to participate and produce content to support the policy-making processes through a gamified interface that focuses on emotional and vision-oriented content.",International Conference on Web Engineering,2021,,,,,496-501,2,4,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_38
Effectiveness Comparison of Email Addresses Recovery from Gravatars,Przemysław Rodwald,"Department of Computer Science, Polish Naval Academy, Gdynia, Poland",MD5 hash function; Email recovery; Gravatar,"Internet was not designed for anonymity, but most users posting comments with unidentifiable pseudonyms hope to stay anonymous. On many websites, especially those powered by WordPress, the comments system is linked with the Gravatar service. That service uses email address, in obfuscated form (MD5 hash function), to provide users’ avatars. This approach allows to deanonymize real emails of users. Emails, which according to EU law, are considered as a personal information. This article explains all stages and results of the real attacks on a three types on websites: national ones, security oriented national ones and global one. We compare the effectiveness of three types of attacks: brute-force, dictionary and hybrid in relation to the type of attacked website.",International Conference on Web Engineering,2021,,,,,505-508,2,1,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_39
OntoSpect: IoT Ontology Inspection by Concept Extraction and Natural Language Generation,"Mahda Noura, Yichen Wang, Sebastian Heil & Martin Gaedke","Technische Universität Chemnitz, Chemnitz, Germany",Internet of Things; Semantic Web; Ontology; Concept extraction; Model-driven Engineering; Natural Language Generation,"One of the main challenges in the Internet of Things (IoT) is the lack of semantic interoperability between heterogeneous sources. In the Semantic Web domain, ontologies are one way to achieve semantic interoperability by using a common vocabulary that represents heterogeneous sources. However, recent studies have shown that the amount of concept reuse from existing IoT ontologies is low. As the number of IoT ontologies increases, encouraging users to reuse existing ontologies instead of creating new concepts becomes important. Ontology catalogues are a prominent approach to discover and inspect existing ontologies for reuse. However, such catalogues inspect the ontologies using general criteria which is not enough to understand the content of the ontology. In this paper, we propose a method for automatic ontology inspection (OntoSpect) of IoT ontologies from different application domains based on a generic set of content-related concepts. OntoSpect consists of two main steps: first it extracts the set of IoT concepts, and then generates human-understandable descriptions using a Model-driven Engineering (MDE) approach. We evaluate the quality of concept extraction and natural language description generation with 84 ontologies retrieved from the LOV4IoT catalogue and report on quality metrics. In addition, we conduct an empirical study with 28 ontology users to further assess the quality of the generated descriptions. The results demonstrate the capability of OntoSpect to support ontology users inspecting IoT ontologies.",International Conference on Web Engineering,2021,,,,,37-52,2,2,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_4
A Web Tool for XQuery Debugging,Jesús M. Almendros-Jiménez & Antonio Becerra-Terón,"Department of Informatics, University of Almería, 04120, Almería, Spain",Debugging; Database query languages; XQuery,"This system demo shows how to debug XQuery programs using an algorithmic debugger developed for XQuery. The debugging process consists in the building of a debugging tree and the answering of questions Yes/No by the user about the results of Function calls and XPath expressions until a bug is found (or no more questions remain). Using the higher-order capabilities of XQuery several debugging strategies –children selection strategies– can be used, enabling the adaptation of the debugging to the program/query.",International Conference on Web Engineering,2021,,,,,509-512,2,1,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_40
Managing Versioned Web Resources in the File System,Leon Müller & Lars Gleim,"Databases and Information Systems, RWTH Aachen University, Aachen, Germany",Linked data platform; Semantic data management; FUSE; File system; Version management; HTTP memento protocol,"While the WebDAV standard provides a well-established read/write mechanism for Web resources, as well as version management through its Delta-V extension, the complexity of the underlying protocol limits its practical adoption. The W3C Linked Data Platform (LDP) more recently provides an alternative approach for simultaneous resource and semantic metadata management on the Web. In combination with the HTTP Memento protocol, it has recently been successfully employed in the context of interoperable data management. Inspired by file system interfaces for WebDAV, we present factFUSE, the – to our knowledge – first user-space application for the joint management of arbitrary computer files and semantic RDF data & metadata in the file system based on the LDP and HTTP Memento Web standards.",International Conference on Web Engineering,2021,,,,,513-516,2,5,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_41
Visualizing Web Users’ Attention to Text with Selection Heatmaps,Ilan Kirsh,"The Academic College of Tel Aviv-Yaffo, Tel Aviv, Israel",Web analytics; Visualization; Heatmaps; Text selection,"Web analytics tools provide useful information about the interaction of users with websites, and particularly, on what captures the attention of web visitors on websites. User attention to areas of web pages can be visualized using heatmaps. Two types of attention indicators are commonly used in web analytics heatmaps: visibility duration of page sections in the browser’s viewport and mouse activity on areas and elements of web pages. This work introduces a new type of user attention heatmap, which visualizes the frequency of text selection operations on websites. Selection is the first step in the process of copying text to the clipboard, but it is also used to highlight important points while reading, similarly to highlighting words on a notebook with a marker pen. As demonstrated and discussed in this paper, selection heatmaps provide interesting perspectives on user attention to paragraphs, sentences, and words on websites, and this could be useful in web analytics.",International Conference on Web Engineering,2021,,,,,517-520,2,5,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_42
"City-Stories: Combining Entity Linking, Multimedia Retrieval, and Crowdsourcing to Make Historical Data Accessible","Laura Rettig & Philippe Cudré-Mauroux; Shaban Shabani, Loris Sauter & Heiko Schuldt; Shaban Shabani & Maria Sokhn","University of Applied Sciences Western Switzerland (HES-SO), Neuchatel, Switzerland; University of Basel, Basel, Switzerland; University of Fribourg, Fribourg, Switzerland",Multimedia retrieval; Entity linking; Semantic data; Crowdsourcing,"Digitized historical image collections as provided by individuals or memory institutions often suffer from limited or a complete lack of metadata In this paper, we present the City-Stories system that combines entity linking, multimedia retrieval, and crowdsourcing to make historical images searchable even across collections.",International Conference on Web Engineering,2021,,,,,521-524,2,7,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_43
SMOTE: A Tool to Proactively Manage Situations in WoT Environments,"Daniel Flores-Martin, Javier Berrocal, José García-Alonso & Juan M. Murillo","Universidad de Extremadura, Badajoz, Spain",Web of Things; Smart-environments; Proactivity,"The growing number of devices in the Web of Things (WoT) allows larger and more complex smart environments. These environments aim to provide the desired state for the people, adapting the devices to their preferences. The characteristics of the environment, the people and the devices generate a multitude of interconnections and behaviours in specific situations. However, managing these situations is not straightforward because of their changing nature. Tools are needed to identify and automate these interactions according to the desired conditions. In this demo we present SMOTE (Situation Management fOr SmarT Environments), a tool for proactively managing situations in WoT environments, improving the management of different entities and reducing the effort for adapting devices to people’s preferences.",International Conference on Web Engineering,2021,,,,,525-529,2,0,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_44
Voice-Based Virtual Assistants for User Interaction Modeling,Marco Brambilla & Davide Molinelli,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy",,"In this work, we propose a virtual assistant that allows building models by means of voice commands. To demonstrate the generality of the approach, we describe three alternative strategies that apply voice-based support at three levels of detail: a fully-guided strategy; a pattern-based strategy; and an element-based strategy. We describe our implementation experience with the development of a design assistant covering the three strategies described above for OMG’s IFML (Interaction Flow Modeling Language), in the context of user interaction design, including the integration with the Amazon Alexa assistant. We report our results that show how the assistant can bring advantages in terms of productivity.",International Conference on Web Engineering,2021,,,,,530-533,2,3,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_45
"Similarity Search, Recommendation and Explainability over Graphs in Different Domains: Social Media, News, and Health Industry",Panagiotis Symeonidis,"University of the Aegean, Samos, Greece",Recommender systems; Graph-based algorithms,"In this tutorial, we provide a rich blend of theory and practice regarding graph algorithms, to deal with challenging issues such as scalability, data noise, and sparsity in recommender systems. We also demonstrate real-life systems that use the graph algorithms for Social Media (http://delab.csd.auth.gr/moviexplain/), News (http://metarec.inf.unibz.it) and Health (https://drugrec.inf.unibz.it) industry along with user studies which were used to evaluate the acceptance of the users for these systems.",International Conference on Web Engineering,2021,,,,,537-541,2,2,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_46
High-Level Interaction Design with Discourse Models for Automated Web GUI Generation,Hermann Kaindl,"TU Wien, Vienna, Austria",Interaction design; Discourse models; Task models; Automated Web GUI generation; Customization; Low-vision accessibility of Web-pages,"Interaction design is considered important for achieving usable Web user interfaces. Communicative acts as abstractions from speech acts can model basic building blocks (‘atoms’) of communication, like a question or an answer. When, e.g., a question and an answer are glued together as a so-called adjacency pair, a simple ‘molecule’ of a dialogue is modeled. Deliberately complex discourse structures can be modeled using relations from Rhetorical Structure Theory (RST). The content of a communicative act can refer to ontologies of the domain of discourse. Taking all this together, we created a new discourse metamodel that specifies what discourse models may look like. Such discourse models can specify an interaction design. Since manual creation of user interfaces is hard and expensive, automated generation may become more and more important. This tutorial also demonstrates how such an interaction design can be used for automated Web user-interface generation. This is based on model-transformation rules according to the model-driven architecture. Based on AI optimization techniques, the graphical user interfaces (GUIs) are automatically tailored to a device such as a smartphone according to a given device specification. Since the usability of fully-automatically generated GUIs is still not satisfactory, unique customization techniques are employed as well. We also address low-vision accessibility of Web-pages, by combining automated design-time generation of Web-pages with responsive design for improving accessibility.",International Conference on Web Engineering,2021,,,,,542-546,2,0,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_47
Influence Learning and Maximization,George Panagopoulos; Fragkiskos D. Malliaros,"École Polytechnique, Palaiseau, France; Université Paris-Saclay, CentraleSupélec, Inria, Gif-Sur-Yvette, France",Influence maximization; Machine learning; Graph mining; Social network analysis,"The problem of maximizing or minimizing the spreading in a social network has become more timely than ever with the advent of fake news and the coronavirus epidemic. The solution to this problem pertains to influence maximization algorithms that identify the right nodes to lockdown for epidemic containment, hire for viral marketing campaigns, block for online political propaganda etc. Though these algorithms have been developed for many years, the majority of the literature focuses on scalability issues and relaxing the method’s assumptions. In the recent years, the emergence of new complementary data and more advanced machine learning methods for decision have guided part of the literature towards learning-based approaches. These can range from learning how information spreads over a network, to learning how to solve the combinatorial optimization problem itself. In this tutorial, we aim to dissentangle and clearly define the different tasks around learning for influence applications in social networks. More specifically, we start from traditional influence maximization algorithms, describe the need of influence estimation and delineate the state-of-the-art on influence and diffusion learning. Subsequently, we delve into the problem of learning while optimizing the influence spreading which is based on online learning algorithms. Finally, we describe the latest approaches on learning influence maximization with graph neural networks and deep reinforcement learning.",International Conference on Web Engineering,2021,,,,,547-550,2,2,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_48
Correction to: Web Engineering,Marco Brambilla; Richard Chbeir; Flavius Frasincar; Ioana Manolescu,"Dipartimento di Elettronica, Politecnico di Milano, Milan, Italy; Inria Saclay-Île-de-France, Institut Polytechnique de Paris, Palaiseau, France; Econometric Institute, Erasmus University Rotterdam, Rotterdam, The Netherlands; E2S UPPA, LIUPPA, Université de Pau et des Pays de l’Adour, Anglet, France",,,International Conference on Web Engineering,2021,,,,,C1-C1,2,10,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_49
A File-Based Linked Data Fragments Approach to Prefix Search,"Ruben Dedecker, Harm Delva, Pieter Colpaert & Ruben Verborgh","IDLab, Department of Electronics and Information Systems, Ghent University–imec, Technologiepark-Zwijnaarde 122, 9052, Ghent, Belgium",Prefix search; Query evaluation; Linked data fragments; Web APIs,"Text-fields that need to look up specific entities in a dataset can be equipped with autocompletion functionality. When a dataset becomes too large to be embedded in the page, setting up a full-text search API is not the only alternative. Alternate API designs that balance different trade-offs such as archivability, cacheability and privacy, may not require setting up a new back-end architecture. In this paper, we propose to perform prefix search over a fragmentation of the dataset, enabling the client to take part in the query execution by navigating through the fragmented dataset. Our proposal consists of (i) a self-describing fragmentation strategy, (ii) a client search algorithm, and (iii) an evaluation of the proposed solution, based on a small dataset of 73k entities and a large dataset of 3.87 m entities. We found that the server cache hit ratio is three times higher compared to a server-side prefix search API, at the cost of a higher bandwidth consumption. Nevertheless, an acceptable user-perceived performance has been measured: assuming 150 ms as an acceptable waiting time between keystrokes, this approach allows 15 entities per prefix to be retrieved in this interval. We conclude that an alternate set of trade-offs has been established for specific prefix search use cases: having added more choice to the spectrum of Web APIs for autocompletion, a file-based approach enables more datasets to afford prefix search.",International Conference on Web Engineering,2021,,,,,53-67,2,2,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_5
Correction to: A Web-Based Co-Creation and User Engagement Method and Platform,"Andrea Tocchetti, Lorenzo Corti & Marco Brambilla; Diletta Di Marco","Dipartimento di Ingegneria Gestionale, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy",,,International Conference on Web Engineering,2022,,,,,C2-C2,2,0,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_50
Assessing the Quality of Online Reviews Using Formal Argumentation Theory,Davide Ceolin & Jan Wielemaker; Giuseppe Primiero; Michael Soprano,"Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; University of Milan, Milan, Italy; University of Udine, Udine, Italy",Formal argumentation theory; Online reviews; Information quality,"Review scores collect users’ opinions in a simple and intuitive manner. However, review scores are also easily manipulable, hence they are often accompanied by explanations. A substantial amount of research has been devoted to ascertaining the quality of reviews, to identify the most useful and authentic scores through explanation analysis. In this paper, we advance the state of the art in review quality analysis. We introduce a rating system to identify review arguments and to define an appropriate weighted semantics through formal argumentation theory. We introduce an algorithm to construct a corresponding graph, based on a selection of weighted arguments, their semantic similarity, and the supported ratings. We provide an algorithm to identify the model of such an argumentation graph, maximizing the overall weight of the admitted nodes and edges. We evaluate these contributions on the Amazon review dataset by McAuley et al. [15], by comparing the results of our argumentation assessment with the upvotes received by the reviews. Also, we deepen the evaluation by crowdsourcing a multidimensional assessment of reviews and comparing it to the argumentation assessment. Lastly, we perform a user study to evaluate the explainability of our method. Our method achieves two goals: (1) it identifies reviews that are considered useful, comprehensible, truthful by online users and does so in an unsupervised manner, and (2) it provides an explanation of quality assessments.",International Conference on Web Engineering,2021,,,,,71-87,2,11,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_6
Web User Interface as a Message,Sebastian Heil & Martin Gaedke; Maxim Bakaev,"Novosibirsk State Technical University, Novosibirsk, Russia; Technische Universität Chemnitz, Chemnitz, Germany",Data quality; Distribution functions; Crowdsourcing; Amazon Mechanical Turk; Image labeling,"Web Engineering becomes increasingly hungry for training data, as the application of machine learning (ML) methods in the field intensifies. Human-labeled datasets are particularly indispensable for ML-based validation and design of user interfaces (UIs). The production of such datasets is often outsourced to crowdworkers, who typically have lower motivation and payment compared to in-house staff, so the quality of their work becomes the paramount concern. In our paper, we explore the applicability of the trending fraud detection approach based on fit to power law in crowdsourced web UI labeling. On Amazon Mechanical Turk, 298 crowdworkers labeled over 30,000 UI elements in about 500 university homepage screenshots. We found a significant correlation between workers’ precisions and Kolmogorov-Smirnov statistics-based goodness-of-fit between the frequencies of UI elements in a worker’s output and power law. The obtained R2 = 0.504 was higher than the R2 = 0.432 baseline for the popular time-on-task parameter. Moreover, the distribution of UI elements’ frequencies is much less prone to manipulation by malicious crowdworkers, which is advantageous as a crowdsourced data quality control measure. The findings of our study suggest a certain resemblance between web UIs and natural language texts, in which word frequencies are known to comply with Zipf’s law.",International Conference on Web Engineering,2021,,,,,88-96,2,2,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_7
Conversation Graphs in Online Social Media,"Marco Brambilla, Alireza Javadian & Amin Endah Sulistiawati","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Via Giuseppe Ponzio, 34, 20133, Milano, Italy",Network analysis; Conversation graph; Intent analysis; Social media; Instagram; Discourse analysis; Online conversation,"In online social media platforms, users can express their ideas by posting original content or by adding comments and responses to existing posts, thus generating virtual discussions and conversations. Studying these conversations is essential for understanding the online communication behavior of users. This study proposes a novel approach to retrieve popular patterns on online conversations using network-based analysis. The analysis consists of two main stages: intent analysis and network generation. Users’ intention is detected using keyword-based categorization of posts and comments, integrated with classification through Naïve Bayes and Support Vector Machine algorithms for uncategorized comments. A continuous human-in-the-loop approach further improves the keyword-based classification. To build and understand communication patterns among the users, we build conversation graphs starting from the hierarchical structure of posts and comments, using a directed multigraph network. The experiments categorize 90% comments with 98% accuracy on a real social media dataset. The model then identifies relevant patterns in terms of shape and content; and finally determines the relevance and frequency of the patterns. Results show that the most popular online discussion patterns obtained from conversation graphs resemble real-life interactions and communication.",International Conference on Web Engineering,2021,,,,,97-112,2,14,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_8
WTA: Towards a Web-Based Testbed Architecture,Valentin Siegert & Martin Gaedke,"Distributed and Self-organizing Systems Group, Technische Universität Chemnitz, Straße der Nationen 62, 09111, Chemnitz, Germany",Web; Testbeds; Software architecture,"Tests, evaluations, and solution comparisons in complex use cases are often realized by creating a testbed for a domain of use cases and solutions. Web-based testbeds add key advantages like results sharing, remote test execution, and collaboration. Focusing on their research objectives, creators see their testbeds as a means to that end. The resulting web-based testbeds are similar in structure and functionality, but there is no common architecture supporting their creation, introducing redundant design efforts. Therefore, we determine structural similarities based on insights into the architecture of current web-based testbeds, from which we derive a generic web-based testbed architecture. This framework of reference will help to develop future testbeds focusing on the testbed domain instead of reinventing general testbed functionality.",International Conference on Web Engineering,2021,,,,,115-123,2,1,https://link.springer.com/chapter/10.1007/978-3-030-74296-6_9
MARF: User-Item Mutual Aware Representation with Feedback,"Qinqin Wang, Khalil Muhammad, Diarmuid O’ Reilly-Morgan, Barry Smyth, Elias Tragos, Aonghus Lawlor, Neil Hurley & Ruihai Dong","Insight Centre for Data Analytics, University College Dublin, Dublin, Ireland",Click-through rate prediction; Deep learning; Cross domain recommendation,"As deep learning (DL) technologies have developed rapidly, many new techniques have become available for recommender systems. Yet, there is very little research addressing how users’ feedback for particular items (such as ratings) can affect recommendations. This feedback can assist in building more fine-grained user profiles, as not all raw clicks will truly reflect a user’s preference. The challenge of encoding such records, which are typically prohibitively long, also prevents research from considering using the whole click history to learn representations. To address these challenges, we propose MARF, a novel model for click prediction. Specifically, we construct fine-grained user representations (by considering both the multiple items browsed, and user’s feedback on them) and item representations (by considering browsing histories from multiple users, and their feedback). Moreover, the flexible up-down strategy is designed to avoid loading incomplete or overloaded historical information by selecting representative users/items based on their feedback records. A comprehensive evaluation on three large scale real-world benchmark datasets, showing that MARF significantly outperforms a variety of state-of-the-art solutions. Furthermore, MARF model is evaluated through an ablation study that validates the contribution of each component. As a final demonstration, we show how MARF can be used for cross-domain recommendation.",International Conference on Web Engineering,2022,,,,,Mar-15,2,0,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_1
Enriching Scholarly Knowledge with Context,Muhammad Haris & Sören Auer; Markus Stocker & Sören Auer,"TIB—Leibniz Information Centre for Science and Technology, Hannover, Germany; L3S Research Center, Leibniz University Hannover, 30167, Hannover, Germany",Information enrichment; Scholarly knowledge; Scholarly communication infrastructures; Federated querying; Knowledge graphs,"Leveraging a GraphQL-based federated query service that integrates multiple scholarly communication infrastructures (specifically, DataCite, ORCID, ROR, OpenAIRE, Semantic Scholar, Wikidata and Altmetric), we develop a novel web widget based approach for the presentation of scholarly knowledge with rich contextual information. We implement the proposed approach in the Open Research Knowledge Graph (ORKG) and showcase it on three kinds of widgets. First, we devise a widget for the ORKG paper view that presents contextual information about related datasets, software, project information, topics, and metrics. Second, we extend the ORKG contributor profile view with contextual information including authored articles, developed software, linked projects, and research interests. Third, we advance ORKG comparison faceted search by introducing contextual facets (e.g. citations). As a result, the devised approach enables presenting ORKG scholarly knowledge flexibly enriched with contextual information sourced in a federated manner from numerous technologically heterogeneous scholarly communication infrastructures.",International Conference on Web Engineering,2022,,,,,148-161,2,4,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_10
FAIRification of Citizen Science Data Through Metadata-Driven Web API Development,"Reynaldo Alvarez & Hector Raúl González Diez; César González-Mora, José Zubcoff, Irene Garrigós & Jose-Norberto Mazón","University of Informatics Sciences, Havana, Cuba; Department of Languages and Computing Systems, University of Alicante, Alicante, Spain",Citizen science; FAIR; DCAT metadata; Web APIs; Open data,"Citizen Science (CS) implies a collaborative process to encourage citizens to collect data in CS projects and platforms. Unfortunately, these CS initiatives do not follow metadata nor data-sharing standards, which hampers their discoverability and reusability. To improve this scenario in CS is crucial to consider FAIR (Findability, Accessibility, Interoperability and Reusability) guidelines. Therefore, this paper defines a FAIRification process (i.e. make CS initiatives more FAIR compliant) which maps metadata of CS platforms’ catalogues to DCAT and generates Web Application Programming Interfaces (APIs) for improving CS data discoverability and reusability in an integrated approach. An experiment in a CS platform with different CS projects shows the performance and suitability of our FAIRification process. Specifically, the validation of the DCAT metadata generated by our FAIRification process was conducted through a SHACL standard validator, which emphasises how the process could boost CS projects to become more FAIR compliant.",International Conference on Web Engineering,2022,,,,,162-176,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_11
The Case for Cross-Entity Delta Encoding in Web Compression,"Benjamin Wollmer, Fabian Panse & Norbert Ritter; Wolfram Wingerath; Benjamin Wollmer, Wolfram Wingerath, Sophie Ferrlein & Felix Gessert","University of Oldenburg, Oldenburg, Germany; Baqend, Hamburg, Germany; University of Hamburg, Hamburg, Germany",Delta encoding; Caching; Dictionary compression,"Delta encoding and shared dictionary compression (SDC) for accelerating Web content have been studied extensively in research over the last two decades, but have only found limited adoption in the industry so far: Compression approaches that use a custom-tailored dictionary per website have all failed in practice due to lacking browser support and high overall complexity. General-purpose SDC approaches such as Brotli reduce complexity by shipping the same dictionary for all use cases, while most delta encoding approaches just consider similarities between versions of the same entity (but not between different entities). In this study, we investigate how much of the potential benefits of SDC and delta encoding are left on the table by these two simplifications. As our first contribution, we describe the idea of cross-entity delta encoding that uses cached assets from the immediate browser history for content encoding instead of a precompiled shared dictionary: This avoids the need to create a custom dictionary, but enables highly customized and efficient compression. Second, we present an experimental evaluation of compression efficiency to hold cross-entity delta encoding against state-of-the-art Web compression algorithms. We consciously compare algorithms some of which are not yet available in browsers to understand their potential value before investing resources to build them. Our results indicate that cross-entity delta encoding is over 50% more efficient for text-based resources than compression industry standards. We hope our findings motivate further research and development on this topic.",International Conference on Web Engineering,2022,,,,,177-185,2,5,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_12
Dynamic Network Embedding in Hyperbolic Space via Self-attention,"Dingyang Duan, Daren Zha, Nan Mu & Jiahui Shen; Dingyang Duan, Daren Zha, Nan Mu & Jiahui Shen; Xiao Yang; Xiao Yang","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Aerospace Internet of Things Technology Co., Ltd., Beijing, China; China Aerospace Times Electronics Co., Ltd., Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",Dynamic graphs; Hyperbolic space; Self-attention; Representation learning,"Graph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn node representations in complex graphs. Existing graph representation learning methods primarily target static graphs in Euclidean space, while many graphs in practical applications are dynamic and evolve constantly over time. Besides, most of these methods underestimate the inherent complex and hierarchical properties in real-world graphs, leading to sub-optimal embeddings. In this work, we propose a Dynamic Network in Hyperbolic space via Self-Attention, referred to as DynHAT, a novel neural architecture that computes node representations through joint two dimensions of hyperbolic structural graph and temporal attention graph. More specifically, DynHAT maps the structural graph into hyperbolic space to capture the hierarchical information, then temporal graph captures time-varying dynamic evolution over multiple time steps by flexibly weighting historical representations. Experimental results on three real-world datasets demonstrate the superiority of DynHAT for dynamic graph embedding, as it consistently outperforms competing methods in link prediction tasks.",International Conference on Web Engineering,2022,,,,,189-203,2,4,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_13
Engineering Annotations to Support Analytical Provenance in Visual Exploration Processes,"Maroua Tikat, Aline Menin, Michel Buffa & Marco Winckler","University Côte d’Azur, SPARKS/wimmics team, Inria, CNRS, I3S, Nice, France",Annotations; Provenance analysis; Visual exploration; Information visualization; Data quality,"This paper focuses on the fundamental role played by annotations to support provenance analysis in visual exploration processes of large datasets. Particularly, we investigate the use of annotations during the visual exploration of semantic datasets assisted by chained visualization techniques. In this paper, we identify three potential uses of annotations: (i) documenting findings (including errors in the dataset), (ii) supporting collaborative reasoning among teammates, and (iii) analysing provenance during the exploratory process. To demonstrate the feasibility of our approach, we implemented it as a tool support, while illustrating its usage and effectiveness through a series of use case scenarios. We identify the attributes and meta-data that describe the dependencies between annotations and visual representations, and we illustrate these dependencies through a domain-specific model.",International Conference on Web Engineering,2022,,,,,204-218,2,2,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_14
Lunatory: A Real-Time Distributed Trajectory Clustering Framework for Web Big Data,"Yang Wu, Zhicheng Pan, Pingfu Chao, Junhua Fang, Wei Chen & Lei Zhao","Department of Computer Science and Technology, Soochow University, Suzhou, China",Spatio-temporal data; Real-time trajectory clustering; Distributed stream processing; Trajectory analysis,"Web big data contains a wealth of valuable information, which can be extracted through web mining and knowledge extraction. Among them, the real-time location information of web can provide a richer calculation basis for existing applications, such as real-time monitoring systems and recommendation systems based on real-time trajectory clustering. However, as a trajectory is a sequence of user positions in the time dimension, the correlation calculation of the trajectories will inevitably incur a massive computational cost. In addition, such trajectory data is usually time-sensitive, that is, once the trajectory data has been generated and changed, the corresponding clustering results need to be output with low latency. Although the offline trajectory clustering has been well studied, extending such work to an online environment directly tends to incur (1) expensive network cost, (2) high processing latency, and (3) low accuracy results. To enable a real-time clustering on trajectory stream, we propose a distributed cLustering framework for hexagonal-based streaming trajectory (Lunatory). Lunatory covers three key components, that are: (1) Simplifier: to solve the problem of extensive network transmission in a distributed trajectory streaming system, a pivot trajectory data structure is introduced to simplify trajectories by reducing the number of samples and extracting key features; (2) Partitioner: to enhance the local computational efficiency of subsequent clustering, a hexagonal-based indexing strategy is proposed to index the pivot trajectories; (3) Executor extends DBSCAN to pivot trajectories and implements real-time trajectory clustering based on Flink. Empirical studies on real-world data validate the usefulness of our proposal and prove the huge advantage of our approach over available solutions in the literature.",International Conference on Web Engineering,2022,,,,,219-234,2,2,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_15
Building Knowledge Subgraphs in Question Answering over Knowledge Graphs,"Sareh Aghaei, Kevin Angele & Anna Fensel; Anna Fensel","Wageningen Data Competence Center and Chair Group Consumption and Healthy Lifestyles, Wageningen University and Research, Wageningen, The Netherlands; Department of Computer Science, Semantic Technology Institute (STI), University of Innsbruck, Innsbruck, Austria",Knowledge graphs; Question answering systems; Knowledge subgraph; Personal Page Rank,"Question answering over knowledge graphs targets to leverage facts in knowledge graphs to answer natural language questions. The presence of large number of facts, particularly in huge and well-known knowledge graphs such as DBpedia, makes it difficult to access the knowledge graph for each given question. This paper describes a generic solution based on Personal Page Rank for extracting a small subset from the knowledge graph as a knowledge subgraph which is likely to capture the answer of the question. Given a natural language question, relevant facts are determined by a bi-directed propagation process based on Personal Page Rank. Experiments are conducted over FreeBase, DBPedia and WikiMovie to demonstrate the effectiveness of the approach in terms of recall and size of the extracted knowledge subgraphs.",International Conference on Web Engineering,2022,,,,,237-251,2,7,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_16
Dual-Attention Based Joint Aspect Sentiment Classification Model,Ping Gu & Zhipeng Zhang,"Chongqing University, Chongqing, China",Aspect-Category Sentiment Analysis; Multi-task learning; Dual-attention; Graph Convolutional Network,"Aspect-Category based Sentiment Analysis (ACSA) aims to predict the aspect category and the sentiment polarity mentioned in a sentence. Most works treat it as two individual tasks: aspect category detection (ACD) and aspect category sentiment classification (ACSC), thus resulting in category missing and mismatch between sentiment words and aspect categories. This paper proposes a dual-attention based joint aspect sentiment classification model (AS-DATJM), which jointly predicts aspect category and sentiment polarity in one framework. Given a sentence, AS-DATJM firstly employs aspect aware attention in ACD to obtain the hidden aspect terms. With these terms as guidance, ACSC module aggregates relevant sentiment context over the Graph Convolutional Network. As a result, the inter-relations between aspect categories and sentiments can be captured and employed to predict both categories simultaneously. Extensive evaluations demonstrate the effctiveness of our model and results show that it outperforms the state-of-the-art methods on four benchmark datasets.",International Conference on Web Engineering,2022,,,,,252-267,2,6,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_17
Explaining a Deep Neural Model with Hierarchical Attention for Aspect-Based Sentiment Classification Using Diagnostic Classifiers,Kunal Geed & Flavius Frasincar; Maria Mihaela Truşcǎ,"Bucharest University of Economic Studies, 010374, Bucharest, Romania; Erasmus University Rotterdam, Burgemeester Oudlaan 50, 3062 PA, Rotterdam, The Netherlands",Aspect-based sentiment classification; Neural rotatory attention model; Diagnostic classification,"LCR-Rot-hop++ is a state-of-art model for Aspect-Based Sentiment Classification. However, it is also a black-box model where the information encoded in each layer is not understood by the user. This study uses diagnostic classifiers, single layer neural networks, to evaluate the information encoded in each layer of the LCR-Rot-hop++ model. This is done by using various hypotheses designed to test for information deemed useful for sentiment analysis. We conclude that the model did not focus on identifying the aspect mentions associated with a word and the structure of the sentence. However, the model excelled in encoding information to identify which words are related to the target. Lastly, the model was able to encode to some extent information about the word sentiment and sentiments of the words related to the target.",International Conference on Web Engineering,2022,,,,,268-282,2,4,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_18
A Model for Meteorological Knowledge Graphs: Application to Météo-France Data,"Nadia Yacoubi Ayadi, Catherine Faron, Franck Michel, Fabien Gandon & Olivier Corby","University Côte d’Azur, Inria, CNRS, I3S (UMR 7271), Sophia-Antipolis, France",Knowledge graph; Semantic modelling; Observational data; Linked Data; Meteorology,"To study and predict meteorological phenomenons and to include them in broader studies, the ability to represent and exchange meteorological data is of paramount importance. A typical approach in integrating and publishing such data now is to formalize a knowledge graph relying on Linked Data and semantic Web standard models and practices. In this paper, we first discuss the semantic modelling issues related to spatio-temporal data such as meteorological observational data. We motivate the reuse of a network of existing ontologies to define a semantic model in which meteorological parameters are semantically defined, described and integrated. The model is generic enough to be adopted and extended by meteorological data providers to publish and integrate their sources while complying with Linked Data principles. Finally, we present a meteorological knowledge graph of weather observations based on our proposed model, published in the form of an RDF dataset, that we produced by transforming observation records made by Météo-France weather stations. It covers a large number of meteorological variables described through spatial and temporal dimensions and thus has the potential to serve several scientific case studies from different domains including agriculture, agronomy, environment, climate change and natural disasters.",International Conference on Web Engineering,2022,,,,,283-299,2,9,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_19
MRVAE: Variational Autoencoder with Multiple Relationships for Collaborative Filtering,"Zhou Pan, Wei Liu & Jian Yin; Zhou Pan, Wei Liu & Jian Yin","Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, 510006, People’s Republic of China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",Recommendation; Variational Autoencoders; Collaborative filtering,"Variational Autoencoder (VAE)-based collaborative filtering (VAE-based CF) methods have shown their effectiveness in top-N recommendation. Mult-VAE is one of them that achieves state-of-the-art performance. Multinomial likelihood and additional hyperparameter \(\beta \) on the KL divergence term controlling the strength of regularization make Mult-VAE a strong baseline. However, Mult-VAE uses non-linear MLPs as its encoder and decoder, which will boost the performance on the dense datasets but degrade the performance on the sparse datasets in our experiments. While recent studies shed light on the non-linearity for modeling the relationships between users and items, they ignore the importance of linearity between users and items, especially on the sparse datasets. To bridge the gap and consider both the linearity and non-linearity user-item relationships, we design a hybrid encoder that incorporates both linearity and non-linearity, and use a linear decoder for VAE-based CF, which can achieve competitive performance on both sparse and dense datasets. Moreover, most VAE-based CF methods only consider the relationships between users and items but ignore the relationships between items for improving the performance in collaborative filtering. To overcome this limitation, we try to incorporate item-item relationships into VAE-based CF with the help of cosine similarity between items. Unifying these relationships into VAE-based CF forms our proposed method, Variational Autoencoder with Multiple Relationships (MRVAE) for collaborative filtering. Extensive experiments on several dense and sparse datasets show the effectiveness of MRVAE.",International Conference on Web Engineering,2022,,,,,16-30,2,1,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_2
An Ontological Approach for Recommending a Feature Selection Algorithm,"Aparna Nayak, Bojan Božić & Luca Longo","SFI Centre for Research Training in Machine Learning, School of Computer Science, Technological University Dublin, Dublin, Republic of Ireland",Feature selection algorithms; Meta-features; Ontology,"Feature selection plays an important role in machine learning or data mining problems. Removing irrelevant features increases model accuracy and reduces the computational cost. However, selecting important features is not a simple task as one feature selection algorithm does not perform well on all the datasets that are of interest. This paper tries to address the recommendation of a feature selection algorithm based on dataset characteristics and quality. The research uses three types of dataset characteristics along with data quality metrics. The main contribution of the work is the utilization of Semantic Web techniques to develop a novel system that can aid in robust feature selection algorithm recommendations. The system’s strength lies in assisting users of machine learning algorithms by providing more relevant feature selection algorithms for the dataset using an ontology called Feature Selection algorithm recommendation based on Data Characteristics and Quality (FSDCQ). Results are generated using six different feature selection algorithms and four types of classifiers on ten datasets from UCI repository. Recommendations take the form of “Feature selection algorithm X is recommended for dataset i, as it performed better on dataset j, similar to dataset i in terms of class overlap 0.3, label noise 0.2, completeness 0.9, conciseness 0.8 units"". While the domain-specific ontology FSDCQ was created to aid in the task of algorithm recommendation for feature selection, it is easily applicable to other meta-learning scenarios.",International Conference on Web Engineering,2022,,,,,300-314,2,4,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_20
Towards Bridging the Gap Between Knowledge Graphs and Chatbots,Annemarie Wittig & Aleksandr Perevalov; Aleksandr Perevalov & Andreas Both; Andreas Both,"Leipzig University of Applied Sciences, Leipzig, Germany; Anhalt University of Applied Sciences, Köthen, Germany; DATEV eG, Nuremberg, Germany",Dialog systems; Chatbots; Knowledge graphs; Synthetic data generation; Natural-language interfaces; Software generator; Human-computer interactions,"Chatbots are nowadays being applied widely in different life domains. One major reason for this trend is the mature development process that is supported by large companies and sophisticated conversational platforms. However, the required development steps are mostly done manually while transforming existing knowledge bases into interaction configurations, s.t., algorithms integrated into the conversational platforms are enabled to learn the intended interaction patterns. However, already existing domain knowledge may get vanished while transforming a structured knowledge base into a “flat” text representation without references backwards. In this paper, we aim for an automatic process dedicated to generating interaction configurations for a conversational platform (Google Dialogflow) from an existing domain-specific knowledge base. Our ultimate goal is to generate chatbot configurations automatically, s.t., the quality and efficiency are increased.",International Conference on Web Engineering,2022,,,,,315-322,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_21
Configurable Per-Query Data Minimization for Privacy-Compliant Web APIs,"Frank Pallas, David Hartmann, Paul Heinrich, Josefine Kipke & Elias Grünewald","Information Systems Engineering, TU Berlin, Berlin, Germany",Privacy; Data protection; Data minimization; Anonymization; Web APIs; GraphQL; Privacy Engineering,"The purpose of regulatory data minimization obligations is to limit personal data to the absolute minimum necessary for a given context. Beyond the initial data collection, storage, and processing, data minimization is also required for subsequent data releases, as it is the case when data are provided using query-capable Web APIs. Data-providing Web APIs, however, typically lack sophisticated data minimization features, leaving the task open to manual and all too often missing implementations. In this paper, we address the problem of data minimization for data-providing, query-capable Web APIs. Based on a careful analysis of functional and non-functional requirements, we introduce Janus, an easy-to-use, highly configurable solution for implementing legally compliant data minimization in GraphQL Web APIs. Janus provides a rich set of information reduction functionalities that can be configured for different client roles accessing the API. We present a technical proof-of-concept along with experimental measurements that indicate reasonable overheads. Janus is thus a practical solution for implementing GraphQL APIs in line with the regulatory principle of data minimization.",International Conference on Web Engineering,2022,,,,,325-340,2,0,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_22
Effective Malicious URL Detection by Using Generative Adversarial Networks,"Jinbu Geng, Shuhao Li, Zhicheng Liu, Zhenyu Cheng & Li Fan; Jinbu Geng & Shuhao Li; Zhicheng Liu","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; National Computer Network Emergency Response Technical Team/Coordination Center of China, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",Web security; Deep learning; Malicious URL Detection; Hierarchical semantics features; Concept drift,"Malicious URL, a.k.a. malicious website, pose a great threat to Web security. In particular, concept drift caused by variants of malicious URL degrades the performance of existing detection methods based on the available attack patterns. In this paper, We conduct an extensive measurement study of the realistic URL and find that the hierarchical semantics feature is suitable for identifying malicious URL. Therefore, we propose URLGAN, a deep neural network model equipped with the hierarchical semantics features, to detect distinguish between malicious and normal URL. Firstly, we embed the entire URL into a hierarchical semantics structure. Secondly, hierarchical semantics features are extracted from the hierarchical semantics structure through BERT. Then, the extracted features are combined with features generated by the generator, similar but slightly different, to enable the condition discriminator to extract the essential difference between normal and malicious URL. Notably, with the features generated by the generator, we enhance the robustness of the system to detect malicious URL variants. Extensive experiments on the public dataset and our data collected from specific targets demonstrate that our method achieves superior performance to other methods and protects specific targets from the susceptibility of malicious URL.",International Conference on Web Engineering,2022,,,,,341-356,2,4,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_23
MEMTD: Encrypted Malware Traffic Detection Using Multimodal Deep Learning,"Xiaotian Zhang, Jintian Lu, Jiakun Sun, Ruizhi Xiao & Shuyuan Jin","School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",Malware traffic detection; Encrypted traffic; Multimodal deep learning; Intermediate fusion mechanism,"Malware that generates encrypted traffic presents a great threat to Internet security. The existing state-of-the-art malware traffic detection techniques based on deep learning (DL) ignore the heterogeneity of encrypted traffic, resulting in their inability to further improve detection performance. This paper applies multimodal DL to detect encrypted malware traffic, proposing a multimodal encrypted malware traffic detection (MEMTD) approach. MEMTD extracts features from three types of modal data—the transport layer security (TLS) handshake payload bytes (encryption behavior modal data), packet length sequence (spatial modal data), and packet arrival-time interval sequence (time modal data) of encrypted traffic. Moreover, an intermediate fusion mechanism is adopted in the MEMTD approach to mine the dependencies among modalities and fuse the discriminative traffic features, improving detection performance. The experimental results on datasets containing 8 malware families and normal traffic show that the MEMTD approach achieves 0.9996 macro-F1 and outperforms other single-modal DL detection methods.",International Conference on Web Engineering,2022,,,,,357-372,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_24
A Web Crowdsourcing Platform for Territorial Control in Smart Cities,"Andrea Pazienza, Domenico Lofù, Giampaolo Flace, Marco Salzedo, Pietro Noviello & Felice Vitulano; Domenico Lofù & Eugenio Di Sciascio","Innovation Lab, Exprivia S.p.A., Via A. Olivetti 11, 70056, Molfetta, Italy; Polytechnic University of Bari, Via E. Orabona 4, 70125, Bari, Italy",Web crowdsourcing; COP; Smart city,"Nowadays citizens engage with smart city ecosystems in several ways using smartphones, mobile devices, connected cars, and drones. Pairing devices and data with a city’s infrastructure and services can improve sustainability and achieve an improvement in awareness and territorial control. Communities can improve energy distribution and decrease traffic congestion with the help of IoT technologies. To support and streamline such a process, in this paper we introduce a Web crowdsourcing platform as a Common Operational Picture dashboard to interoperate with smart devices, collect urban data from them, and monitor the city in real-time. Its application to the Metropolitan City of Bari is presented and discussed.",International Conference on Web Engineering,2022,,,,,375-382,2,0,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_25
Supporting Natural Language Interaction with the Web,"Marcos Baez, Cinzia Cappiello, Claudia M. Cutrupi, Maristella Matera, Isabella Possaghi, Emanuele Pucci, Gianluca Spadone & Antonella Pasquale","Politecnico di Milano, Piazza L. Da Vinci 32, 20133, Milano, Italy",Conversational AI; Conversational Web; Conversational design patterns,"Conversational AI is disrupting the way information is accessed. However, there is still a lack of conversational technologies leveraging the Web. This paper introduces an approach to support the notion of Conversational Web Browsing. It illustrates design patterns for navigating websites through conversation and shows how such patterns are sustained by a Web architecture that integrates NLP technologies.",International Conference on Web Engineering,2022,,,,,383-390,2,7,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_26
User Acceptance of Modified Web Page Loading Based on Progressive Streaming,Lucas Vogel & Thomas Springer,"TU Dresden, 01069, Dresden, Germany",Progressive page loading; Initial page load; Page streaming; User experience; User acceptance,"In times of the pandemic, it becomes more evident that our modern society relies heavily on the internet for most areas of life. As websites become more complex and their size increases, the amount of code slows down their loading speed, especially on mobile devices with poor network connectivity. Various improvements exist to optimize the code before and after delivering a web page to a client. However, the delivery and rendering itself was rarely examined. In this paper, we evaluate two new methods of loading and displaying websites faster, namely Text-First and Layout-First. Layout-First reduced the time until first contentful paint (FCP) on average from 281.75 s down to 6.43 s at 32 KB/s, a difference of more than 4.5 min. Text-First reached the FCP on average in 2.15 s at the same network speed. However, our user study revealed that not every technological improvement is well accepted by users. Results showed that users will wait longer if the layout is stable while loading the page. More than 85% of participants preferred the Layout-First method introduced in this paper.",International Conference on Web Engineering,2022,,,,,391-405,2,4,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_27
We Don’t Need No Real Users?! Surveying the Adoption of User-less Automation Tools by UI Design Practitioners,Maxim Bakaev; Maximilian Speicher & Johanna Jagow; Sebastian Heil & Martin Gaedke,"Technische Universität Chemnitz, Chemnitz, Germany; Jagow Speicher, Barcelona, Spain; Novosibirsk State Technical University, Novosibirsk, Russia",AI/ML; Design tools; Online survey; Ui design; User interfaces,"The main principles for designing successful UIs in a perfect world have long been known—considering many possible solutions for a problem and involving representative users in the process. In practice, however, reasons for violating those principles can be plentiful: the infamous tight budgets and schedules, lack of management buy-in, restrictions for face-to-face meetings, etc. Yet, design tools that do not require real users, such as AI-/ML-powered solutions, which could mitigate these issues seem to experience a rather low adoption rate in industry. In this paper, we present a survey with 34 professional digital designers and user researchers intended to investigate the above hypotheses. We inquire into awareness and usage of 61 such tools and platforms, as well as participants’ design and research processes and general design tool adoption in industry. From the results we identify three particular challenges and three opportunities. Finding and recruiting relevant participants for user studies seems to be indeed problematic, and professional designers and researchers often lack the time and resources to follow a textbook process. They are, however, open to novel tools addressing these shortcomings—particular for ideation and evaluation—but at the same time seem to be largely unfamiliar with AI-/ML-based approaches or do not (yet) see added value in them. With these findings as a starting point, the Web Engineering community can work towards a deeper understanding of designers’ and researchers’ needs that could be met with AI-/ML-based support tools.",International Conference on Web Engineering,2022,,,,,406-414,2,8,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_28
Achieving Corruption-Transparency in Service Governance Processes with Blockchain-Technology Based e-Participation,Mohammad Mustafa Ibrahimy & Peeter Normak; Alex Norta,"Dymaxion, Tallinn, Estonia; School of Digital Technologies, Tallinn University, Tallinn, Estonia",Corruption; Transparency; Blockchain; Smart-contract; Token economy; e-Participation,"Corruption takes place in public procurement by public servants through intermediaries due to the use of centralized systems and complicated processes. Blockchain and Web3 has the potential to remove these intermediaries, instead allowing institutions to build trust among public servants and citizens through a decentralized web. It is feasible to positively reinforce the transparency in tackling corruption in public procurement by establishing an e-participatory governance infrastructure using token economics from smart-contract blockchain technology. The overall success of public procurement in terms of service delivery to citizens is associated with citizen e-participation. Thus, increased e-participation through automated processes makes the government accountable and transparent in the provision of services that lead to the progress and economic growth of a country. In this paper, we investigate the potential of blockchain and smart-contracts to improve the efficiency, trust, and transparency of public procurement in the case of Afghanistan. Moreover, we identify the existing barriers namely lack of trust, transparency, the complexity of procurement documents, and inappropriate record-keeping system. To address these issues, we propose a blockchain-based e-participatory infrastructure to boost transparency by curbing public procurement corruption.",International Conference on Web Engineering,2022,,,,,417-425,2,5,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_29
Multilevel Feature Interaction Learning for Session-Based Recommendation via Graph Neural Networks,"Ming He, Tianshuo Han & Tianyu Ding","Beijing University of Technology, Beijing, China",Graph neural networks; Recommender systems; Session-based recommendation,"Predicting users’ actions based on anonymous sessions is a challenging problem due to the uncertainty of user behavior and limited information. Recent advances in graph neural networks (GNN) have led to a promising approach for addressing this problem. However, existing methods have three major issues. First, they are incapable of modeling the transitions between inconsecutive items. Second, they are infeasible for learning the cross-feature interactions when learning the item relationships. Third, very few models can adapt to the improvement of embedding quality to help improve recommendation performance. Therefore, to address these issues, we propose a novel model named M ultilevel F eature I nteractions L earning (MFIL) that effectively learns item and session representation using GNN. By leveraging item side information, e.g., brands and categories, MFIL can model transitions between inconsecutive items in the session graph (session-level). We further design hierarchical structures to learn the feature interactions, which is effective to estimate the importance weights of different neighboring items in the global graph (global-level). In addition, an effective learning strategy is employed to enhance MFIL’s capability, and it performs better than the classic regularization methods. Extensive experiments conducted on real-world datasets demonstrate that MFIL, significantly outperforms existing state-of-the-art graph-based methods.",International Conference on Web Engineering,2022,,,,,31-46,2,2,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_3
Applying a Healthcare Web of Things Framework for Infertility Treatments,Anastasiia Gorelova & Santiago Meliá,"Department of Computer Languages and Systems, Universidad de Alicante, Carretera de San Vicente s/n, 03690, San Vicente del Raspeig, Alicante, Spain",Infertility treatment; Web of Things (WoT); Internet of Things (IoT) devices; Healthcare Monitoring System (HMS); Simulator; Digital twin,"According to doctors and researchers, fertility problems are becoming epidemic proportions. Meanwhile, the demand for infertility treatment is increasing by 5–10% per year. To support the growing demand, physicians need to define personalized remote monitoring treatments supported by devices that send real-time information on hormones levels, heart-rate, temperature, etc. To this end, Healthcare Monitoring Systems (HMS) have recently appeared, based on increasingly advanced devices that help to manage this task. However, current solutions are expensive and not very customizable by physicians themselves. In this paper, we propose a framework called MoSTHealth, based on digital twins and Model-Driven Engineering (MDE), allows healthcare experts to model a personalized Web of Things (WoT) HMS scenario per treatment and per patient. Thanks to MDE, the simulated scenario allows us to generate a Service-Oriented enterprise cloud architecture that integrates a prediction module based on machine learning and data analysis. In this paper, a WoT HMS scenario for infertility treatment is presented as a case study. In this scenario, a specific care plan is defined, associated with a set of devices, including the use of a biosensing device that sends hormones levels in real-time.",International Conference on Web Engineering,2022,,,,,426-431,2,5,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_30
Blockchain and AI to Build an Alzheimer’s Risk Calculator,Paolo Sorino,"Politecnico di Bari, Bari, Italy",Blockchain; Artificial Intelligence; Recommander system; Alzheimer’s disease; E-Health,"The problems affecting healthcare databases and medical records are numerous, although the potential of the data stored in them is high. However, medical records are hidden across hospitals, and data sharing processes fail to provide accountable data control. Blockchain technology has been successfully applied in various fields to support distributed data management and data quality. This article evidences how Blockchain is expected to be leveraged to better organize and sharing of healthcare’s big data with mixed EHR (Electronic Health Records) and imaging (CAT, RX, etc.) sources. The aim is to exploit these data through Artificial Intelligence methods in order to build an Alzheimer’s risk calculator based on neuro-images.",International Conference on Web Engineering,2022,,,,,432-436,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_31
Bridging Static Site Generation with the Dynamic Web,Juho Vepsäläinen & Petri Vuorimaa,"Aalto University, Espoo, Finland",Static site generation; JSON; Software architecture,"Historically web sites have been developed using HTML for their markup either by authoring it directly or through abstraction to generate it. The currently available tools exist in a continuum of static, developer-oriented tools and dynamic services that cater to non-technical users. In this paper, we propose an approach that sits in the middle by using JSON for site definitions. The definition is leveraged on the client-side for editing, bridging the continuum’s ends.",International Conference on Web Engineering,2022,,,,,437-442,2,5,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_32
Enhance Web-Components in Order to Increase Security and Maintainability,Tobias Münch & Rainer Roosmann,"University of Applied Sciences Osnabrück, Albrechtstraße 30, 49076, Osnabrück, Germany",Web application modelling and engineering; Developer efficiency; Concepts and patterns; Standards,"Today’s development of client-side web applications is based on one of the JavaScript-frameworks, such as Angular or React. The excessive dependencies that arise in the ecosystem from the Node-Package-Manager increase the security risk and the dependency of your own web application on third-party packages. Moreover, the frameworkless approach proposes a renaissance of classic web development, because it strives to avoid external dependencies as far as possible and to fall back on the standards. Whether the implementation achieves maintainability and security of frameworks is questionable. Therefore, it makes sense to research which core concepts of the frameworks meet the requirements for maintainability and security and how these are implemented. The novelty is that the concepts to be explored are moved to a standard in order to ensure the developer efficiency, security, performance and maintainability in the long term. This allows existing approaches to focus on other essential features.",International Conference on Web Engineering,2022,,,,,443-449,2,1,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_33
FAIRification of Citizen Science Data,Reynaldo Alvarez Luna & Hector Gonz; José Zubcoff & Irene Garrigós,"University of Informatics Sciences, Havana, Cuba; Department of Languages and Computing Systems, University of Alicante, Alicante, Spain",Citizen science; Data sharing; FAIR guidelines; Open data,"Citizen Science (CS) initiatives encourage citizens to collect local data, contributing to knowledge creation and scientific development. However, these CS initiatives do not follow metadata nor data-sharing standards, which hampers their discoverability and reusability out of the scope of them. To improve this scenario in CS is crucial to consider Findable, Accessible, Interoperable and Reusable (FAIR) guidelines for research data sharing. This work proposes a FAIRification process (i.e. making CS initiatives more FAIR compliant), enhancing data sharing capacities in the CS context. It will be considered the adoption of Web standards, Web application programming interfaces (APIs) and Web augmentation. This approach contributes to the production of FAIR data in CS for data consumers. As preliminary results this paper explains the FAIRification process. The research objectives and plan are also presented.",International Conference on Web Engineering,2022,,,,,450-454,2,2,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_34
Towards Differentially Private Machine Learning Models and Their Robustness to Adversaries,Alberto Carlo Maria Mancino & Tommaso Di Noia,"Politecnico di Bari, Bari, Italy",Differential privacy; Adversarial training; Recommender systems; Privacy preservation; System robustness,"The pervasiveness of modern machine learning algorithms exposes users to new vulnerabilities: violation of sensitive information stored in the training data and wrong model behaviors caused by adversaries. State-of-the-art approaches to prevent such behaviors are usually based on Differential Privacy (DP) and Adversarial Training (AT). DP is a rigorous formulation of privacy in probabilist terms to prevent information leakages that could reveal private information about the users, while AT algorithms empirically increase the system’s robustness, injecting adversarial examples during the training process. Both techniques involve achieving their goal by modeling noise introduced into the system. We propose analyzing the relationship between these two techniques, studying how one affects the other. Our objective is to design a mechanism that guarantees DP and robustness against adversarial attacks, injecting modeled noise into the system. We propose Recommender Systems as an application scenario because of the severe risks to user privacy and system sensitivity to adversaries.",International Conference on Web Engineering,2022,,,,,455-461,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_35
A Metadata-Driven Tool for FAIR Data Production in Citizen Science Platforms,"Reynaldo Alvarez; César González-Mora, Irene Garrigós & Jose Zubcoff","University of Informatics Sciences, Havana, Cuba; Department of Languages and Computing Systems, University of Alicante, Alicante, Spain",Citizen Science; DCAT; FAIR; Web APIs,"Citizen Science (CS) platforms include a large number of projects that manage data from citizen observations. However, data and metadata are not easily available and do not generally comply with standards. This makes it difficult to share data through the mechanisms commonly used in the scientific community, affecting the reuse of data outside the context of CS platforms. The adoption of Web standards could improve the FAIR (Findable, Accessible, Interoperable and Reusable) quality of shared data. Adopting standards is not enough; it is also important to provide the technologies that make it possible to find the data, access it, share it and be able to interoperate with the data. For this purpose, this paper presents a tool for the production of FAIR data from PPSR (Public Participation in Scientific Research) Core metadata model based platforms. The tool allows (i) transforming metadata from CS platforms to the DCAT (Data Catalogue Vocabulary) standard, (ii) generating Web APIs from the available data, and (iii) building a DCAT-validated data catalogue. This approach improves the FAIR compliance of CS data, empowering data consumers and developers.",International Conference on Web Engineering,2022,,,,,465-468,2,0,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_36
A New Compatibility Measure for Harmonic EDM Mixing,Gabriel Bibbó Frau & Angel Faraldo,"Universitat Pompeu Fabra, Barcelona, 08018, Spain",DJ; Harmonic compatibility; Harmonic mixing; Tonal Interval Vector (TIV); Pitch transposition; Interface,"DJ track selection can benefit from software-generated recommendations that optimise harmonic transitions. Emerging techniques (such as Tonal Interval Vectors) enable the definition of new metrics for harmonic compatibility (HC) estimation that improve the performance of existing applications. Thus, the aim of this study is to provide the DJ with a new tool to improve his/her musical selections. We present a software package that can estimate the HC between digital music recordings, with a particular focus on modern dance music and the workflow of the DJ. The user must define a target track for which the calculation is to be made, and obtains the HC values expressed as a percentage with respect to each track in the music collection. The system also calculates a pitch transposition interval for each candidate track that, if applied, maximizes the HC with respect to the target track. Its graphical user interface allows the user to easily run it simultaneously with the DJ software of choice during live performances. The system, tested with musically experienced users, generates pitch transposition suggestions that improve mixes in 73.7% of cases.",International Conference on Web Engineering,2022,,,,,469-472,2,0,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_37
Compaz: Exploring the Potentials of Shared Dictionary Compression on the Web,"Benjamin Wollmer & Norbert Ritter; Wolfram Wingerath; Benjamin Wollmer, Wolfram Wingerath, Sophie Ferrlein & Felix Gessert","University of Oldenburg, Oldenburg, Germany; Baqend, Hamburg, Germany; University of Hamburg, Hamburg, Germany",Delta encoding; Caching; Dictionary compression,"In this demonstration, we present Compaz, an extensible benchmarking tool for web compression that enables evaluating approach-es before they have been fully implemented and deployed. Compaz makes this possible by collecting all relevant data from user journeys on live websites first and then performing the benchmark analysis as a subsequent step with global knowledge of all transmitted resources. In our demonstration scenario, the audience can witness how current websites could improve their compression ratio and save bandwidth. They can choose from standard and widespread approaches such as Brotli or gzip and advanced approaches like shared dictionary compression that are currently not even supported by any browser.",International Conference on Web Engineering,2022,,,,,473-476,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_38
Social Events Analyzer (SEA): A Toolkit for Mining Social Workflows by Means of Federated Process Mining,"Javier Rojo, José García-Alonso, Javier Berrocal, Juan Hernández & Juan M. Murillo; Carlos Canal","Universidad de Málaga, Málaga, Spain; University of Extremadura, Caceres, Spain",Process mining; Pattern discovery; Social workflows; Federated process mining,"Users’ smartphones collect information about the different interactions they perform in their daily life, including web interactions. Mining this information to discover user’s processes provides information about them as individuals and as part of a social group. However, analyzing events produced by human behavior, where indeterminism and variability prevail, is a complex task. Techniques such as process mining focus on analyzing customary event logs produced by a system where all the possible interactions are predefined. The analysis become even harder when it involves a group of people whose joint activity is considered part of a Social Workflow. In this demo we present Social Events Analyzer (SEA), a toolkit for easy Social Workflow analysis using a technique called Federated Process Mining. The tool offers models more faithful to the behavior of the users that make up a Social Workflow and opens the door to the use of process mining as a basis for the creation of new automatic procedures adapted to the user behavior.",International Conference on Web Engineering,2022,,,,,477-480,2,1,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_39
A Real-Time System for Detecting Landslide Reports on Social Media Using Artificial Intelligence,"Ferda Ofli, Umair Qazi & Muhammad Imran; Julien Roch & Remy Bossu; Catherine Pennington & Vanessa Banks; Remy Bossu","CEA, DAM, DIF, 91297, Arpajon, France; Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar; British Geological Survey, Keyworth, Nottinghamshire, UK; European-Mediterranean Seismological Centre, Arpajon, France",Landslide detection; Social media; Online system; Real time; Image classification; Computer vision; Artificial intelligence,"This paper presents an online system that leverages social media data in real time to identify landslide-related information automatically using state-of-the-art artificial intelligence techniques. The designed system can (i) reduce the information overload by eliminating duplicate and irrelevant content, (ii) identify landslide images, (iii) infer geolocation of the images, and (iv) categorize the user type (organization or person) of the account sharing the information. The system was deployed in February 2020 online at https://landslide-aidr.qcri.org/landslide_system.php to monitor live Twitter data stream and has been running continuously since then to provide time-critical information to partners such as British Geological Survey and European Mediterranean Seismological Centre. We trust this system can both contribute to harvesting of global landslide data for further research and support global landslide maps to facilitate emergency response and decision making.",International Conference on Web Engineering,2022,,,,,49-65,2,13,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_4
Solid Web Monetization,"Merlijn Sebrechts, Tom Goethals, Thomas Dupont, Wannes Kerckhove, Ruben Taelman, Filip De Turck & Bruno Volckaert","IDLab, Department of Information Technology (intec), Ghent University - imec, Ghent, Belgium",Web Monetization; Solid; Micropayments; Payment processing; Interledger; Open payments,"The Solid decentralization effort decouples data from services, so that users are in full control over their personal data. In this light, Web Monetization has been proposed as an alternative business model for web services that does not depend on data collection anymore. Integrating Web Monetization with Solid, however, remains difficult because of the heterogeneity of Interledger wallet implementations, lack of mechanisms for securely paying on behalf of a user, and an inherent issue of trusting content providers to handle payments. We propose the Web Monetization Provider as a solution to these challenges. The WMP acts as a third party, hiding the underlying complexity of transactions and acting as a source of trust in Web Monetization interactions. This demo shows a working end-to-end example including a website providing monetized content, a WMP, and a dashboard for configuring WMP into a Solid identity.",International Conference on Web Engineering,2022,,,,,481-486,2,1,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_40
Web Push Notifications from Solid Pods,Christoph H.-J. Braun & Tobias Käfer,"Institute AIFB, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",,"Our demo showcases how a Solid Pod, i.e. a web server that adheres to the Solid Protocol, can be extended to support Web Push Notifications for Progressive Web Applications (PWAs). For a user’s perspective, we present a PWA where a user can choose to receive Web Push Notifications when a message is posted to her Solid Pod’s inbox.",International Conference on Web Engineering,2022,,,,,487-490,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_41
A Guide for Quantum Web Services Deployment,"Jaime Alvarado-Valiente, Javier Romero-Álvarez, Jose Garcia-Alonso & Juan M. Murillo","Escuela Politécnica, Quercus Software Engineering Group, University of Extremadura, Av. de la Universidad, S/N, 10003, Cáceres, Spain",Quantum software development; Quantum web services; Quantum programming,"Quantum computing is a new paradigm for solving problems that classical computers cannot reach. To the point that it is already generating interest in the scientific and industrial communities. Currently, quantum computers and technology are being developed to support the execution of quantum software. Several large computer companies have already built functional quantum computers, and developed several programming languages and quantum simulators that can be used by the general public. All this infrastructure for quantum computing is offered to quantum developers through the cloud, following a model similar to the familiar Infrastructure as a Service. However, due to the early stages of quantum computing taking advantage of the capabilities of these computers requires a very in depth knowledge of quantum programming and quantum hardware that is far from what cloud developers are used to in classical cloud offerings. Although the future of quantum computing is still unknown, it is highly certain that there must be a time when quantum computing coexists with classical computing. At the same time, one of the most well-known and tested solutions for the communication of heterogeneous computing systems are web services. In this tutorial we will offer an introductory view on how quantum algorithms can be converted into web services, how this web services can be deployed, using the Amazon Braket platform for quantum computing, and invoked through classical web services endpoints. Finally, we will propose a way in which a disadvantage of current quantum computers in terms of web services can be transformed into an advantage for web services through the use of a Quantum API Gateway.",International Conference on Web Engineering,2022,,,,,493-496,2,9,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_42
About Lightweight Code Generation,Andreas Schmidt; Andreas Schmidt,"University of Applied Sciences, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",Code generator; Lightweight-code-generation-approach; Software-development process,"There is often something mystical about code generation [1]. This is partly due to tools, that are able to achieve a high degree of generation thanks to their flexibility and universality, but this also makes the tools extremely complex and restricts their use to suitably trained persons. This also applies to the OMG’s “Model Driven Architecture” approach, which has tried to establish a standard in this field and to enable the exchange between different tools through additional technologies. A “code generation light” approach, which would often be sufficient in many cases, is difficult to implement with these tools.",International Conference on Web Engineering,2022,,,,,497-500,2,0,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_43
SPARQL Endpoints and Web API (SWApi),Pasquale Lisena; Albert Meroño-Peñuela,"King’s College London, London, UK; EURECOM, Sophia Antipolis, France",API; Semantic Web; Web Development,"The success of Semantic Web technology has boosted the publication of Knowledge Graphs in the Web of Data, and several technologies to access them have become available covering different spots in the spectrum of expressivity: from the highly expressive SPARQL to the controlled access of Linked Data APIs, with GraphQL in between. Many of these technologies have reached industry-grade maturity. Finding the trade-offs between them is often difficult in the daily work of developers, interested in quick API deployment and easy data ingestion. This tutorial covers this in-between technology space, with the main goal of providing strategies and tools for publishing Web APIs that ensure the easy consumption of data coming from SPARQL endpoints. Together with an overview of state-of-the-art technologies, the tutorial focuses on two novel technologies: SPARQL Transformer, which allows to get a more compact JSON structure for SPARQL results, decreasing the effort required by developers in interfacing JavaScript and Python applications; and grlc, an automatic way of building APIs on top of SPARQL endpoints by sharing queries on collaborative platforms. Moreover, recent developments are presented to combine the two, offering a complete resource for developers and researchers. Hands-on sessions are proposed to internalise those concepts with practical exercises.",International Conference on Web Engineering,2022,,,,,501-504,2,1,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_44
Web Engineering with Human-in-the-Loop,"Dmitry Ustalov, Nikita Pavlichenko, Boris Tseytlin, Daria Baidakova & Alexey Drutsa","Toloka, Lucerne, Switzerland",,"Modern Web applications employ sophisticated Machine Learning models to rank news, posts, products, and other items presented to the users or contributed by them. To keep these models useful, one has to constantly train, evaluate, and monitor these models using freshly annotated data, which can be done using crowdsourcing. In this tutorial we will present a portion of our six-year experience in solving real-world tasks with human-in-the-loop pipelines that combine efforts made by humans and machines. We will introduce data labeling via public crowdsourcing marketplaces and present the critical components of efficient data labeling. Then, we will run a practical session, where participants address a challenging real-world Information Retrieval for e-Commerce task, experiment with selecting settings for the labeling process, and launch their label collection project on real crowds within the tutorial session. We will present useful quality control techniques and provide the attendees with an opportunity to discuss their annotation ideas. Methods and techniques described in this tutorial can be applied to any crowdsourced data and are not bound to any specific crowdsourcing platform.",International Conference on Web Engineering,2022,,,,,505-508,2,0,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_45
Online Social Event Detection via Filtering Strategy Graph Neural Network,"Lifu Chen, Junhua Fang, Pingfu Chao, An Liu & Pengpeng Zhao","School of Computer Science and Technology, Soochow University, Suzhou, China",Social event detection; Online clustering; Graph neural network,"Nowadays, as a strongly time-dependent data type, the ubiquity of social media messages enables the detection and analysis of real-time events. Through the clustering of online posts concerning their topics, existing methods can quickly identify the current trends on social media, which helps discover marketing opportunities, prevent potential crises, etc. However, due to the diversity of social network users, the performance of current approaches is significantly affected by the long tail of random topics, which should be regarded as outliers in a clustering problem. Besides, current models are weak in detecting events that last for multiple days, which is common in real-world scenarios. Therefore, we propose the FS-GNN, a graph neural network based on a filtering strategy, for incremental social event detection in data streams. Our method uses heterogeneous information networks (HINs) to construct a social message graph, and we propose a centrality-based scoring mechanism to grade and filter noisy data before clustering. In addition, a message complement window is introduced to connect the same topic mentioned across multiple days for better clustering accuracy. Extensive experimental results demonstrate the superiority of FS-GNN over multiple baselines in both offline and online scenarios.",International Conference on Web Engineering,2022,,,,,66-81,2,1,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_5
Similarity Search with Graph Index on Directed Social Network Embedding,"Zhiwei Qi, Kun Yue & Liang Duan; Zhiwei Qi, Kun Yue & Liang Duan; Zhihong Liang","School of Big Data and Intelligence Engineering, Southwest Forestry University, Kunming, China; Key Lab of Intelligent Systems and Computing of Yunnan Province, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China",Social network; Similarity search; Graph index; Network embedding,"Similarity search on directed social networks (DSNs) could help users find the K nearest neighbors (KNNs). The graph index based similarity search does not have to compare query node against every node in DSNs, since the neighbor relationship of the nodes is captured by the edges. Nevertheless, the performance of similarity search is still unsatisfactory, such as not supporting the end-to-end search or taking unnecessary detours, etc. In this paper, we propose the method of Graph Index on Directed Social Network Embedding (GI-DSNE) to facilitate the approximate KNN search on DSNs. First, the DSNE is proposed to embed the DSN into a low-dimensional vector space to achieve the embeddings for efficient calculation of similarities on the search path. Then, the nearest neighbor descent algorithm is adopted to calculate the KNN graph. Subsequently, to construct the graph index efficiently, the direction guided strategy for edge selection, maximum out-degree of GI-DSNE and the depth-first-search tree for guaranteeing the connectivity of GI-DSNE are proposed. Experimental results show that our proposed method outperforms the state-of-the-art competitors on both execution time and precision.",International Conference on Web Engineering,2022,,,,,82-97,2,3,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_6
An In-Depth Analysis of Web Page Structure and Efficiency with Focus on Optimization Potential for Initial Page Load,Lucas Vogel & Thomas Springer,"TU Dresden, 01069, Dresden, Germany",Progressive page loading; Initial page load; Page streaming; User experience; User acceptance,"Web pages are nowadays usually built with a variety of different tools, frameworks, and generated code. The structure and size of the resulting HTML, CSS, and JavaScript code highly influence the time for page load, and related energy consumption. However, no large-scale baseline data exists about the efficiency of the resulting page code, e.g., what amount of the code is actually used, or if code parts must be render-blocking. Furthermore, existing examinations analyze page code structure but do not investigate the potential impact on code efficiency if parts of the code would be optimized. In this paper, the top 10,000 web pages worldwide using the Tranco list were analyzed in-depth. Aspects with the highest impact on structure or performance are evaluated in detail and set into context regarding used techniques, frameworks, code efficiency, and differences in the delivered desktop- and mobile versions. The results showed that the vast majority (over 70% for JavaScript and \(\approx \)90% CSS) of externally loaded resources (both JavaScript and CSS) are loaded as render-blocking code. On average, only \(\approx \)40% of render-blocking JavaScript and \(\approx \)15% of CSS are used until page render, which unveils a significant potential for performance improvements for most analyzed websites.",International Conference on Web Engineering,2022,,,,,101-116,2,10,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_7
Automatic Web Data API Creation via Cross-Lingual Neural Pagination Recognition,"Chia-Hui Chang, Cheng-Ju Wu & Tzu-Ping Lin","National Central University, Taoyuan, Taiwan",Web Data ETL scalability; Pagination recognition; Neural sequence labeling; Announcement extraction,"Information extraction, transformation and loading (abbreviated as ETL) tools are important for big data analysis and value-added applications on the Web. Typical Web scraping systems such as “Dexi.io” or “Import.io” allow users to specify where to fetch the page and what information or data to be extracted from the page. Although these commercial services already provide a graphical user interface to guide the system to the target pages for each data source, such systems are not scalable because users have to create crawlers one by one. In this paper we consider the problem of pagination recognition, which aims to automate the process of finding similar pages by locating the next page link and the list of page links from any starting URL. We propose a neural sequence model that will label each clickable link in a page as either “NEXT”, “PAGE” or “Other”, where the first two could guide the system to find similar pages of the seed URL. To have multilingual support, we have exploited the attribute contents in the links as well as Language-Agnostic SEntence Representations (LASER) for anchor text embedding. The experimental results show that the proposed model, achieves an average of micro 0.834 and macro 0.818 F1 score on pagination recognition. In terms of practical deployment, we are able to automatically create 1,060 (MDR) and 153 (DCADE) data APIs from 392 event source pages within 62 min.",International Conference on Web Engineering,2022,,,,,117-131,2,1,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_8
Disclosure: Efficient Instrumentation-Based Web App Migration for Liquid Computing,Jae-Yun Kim & Soo-Mook Moon,"Seoul National University, Seoul, Republic of Korea",Web app migration; Closure; Code instrumentation; Liquid computing; Multiple migration,"Web App migration means capturing a snapshot of the execution state of an web app on a device, and restoring it on another device to continue its execution, for cross-device liquid computing. Although web apps are relatively easy to migrate due to its high portability, there is a JavaScript language feature called closure, which complicates migration since it requires migrating the variable states of already-finished outer functions. One approach of web app migration is to instrument the source code to trace the closure variables, yet it often suffers from performance slowdown, especially for multiple migrations. In this paper, we propose a new instrumentation-based technique called Disclosure, which moves the declarations of closure variables to a managed data structure and replaces closure variables by the corresponding references to the data structure. This can improve the runtime performance while enhancing security. We evaluated our work with eight Octane benchmarks and four real web apps. The runtime performance penalty due to Disclosure is 0%–15%, which is much better than the result of the latest instrumentation-based work that supports deep closures and multiple migrations, as Disclosure. Real web apps are also shown to migrate seamlessly, even multiple times.",International Conference on Web Engineering,2022,,,,,132-147,2,7,https://link.springer.com/chapter/10.1007/978-3-031-09917-5_9
DCM: Dynamic Client-Server Code Migration,Sebastian Heil & Martin Gaedke,"Technische Universität Chemnitz, Chemnitz, Germany",Web Infrastructure; Software Architecture; Code Mobility; WebAssembly; WebSockets,"The underlying Client/Server architecture of the Web inherently raises the question of the distribution of application logic between client and server. Currently, this distribution is static and fixed at design time, inhibiting dynamic and individual load distribution between clients and server at runtime. The benefits of dynamic migration allow balancing the needs of users, through increased responsiveness, and software providers, through better resource usage and cost reductions. Recent additions to the Web environment like WebAssembly provide a technological basis to move units of code at runtime. However, making use of them to extend a web application with dynamic code migration capabilities is challenging for web engineers. To that end, we devise a novel distributed Client/Server software architecture for web applications that supports dynamic migration of code at runtime, addressing the technical challenges of dependency management, distribution of control and data flow, and the required communication and interfaces. Our novel software architecture aims at providing a point of reference to web engineers seeking to extend their web applications with dynamic code migration capabilities and to contribute to the current re-consideration of the Web environment in the light of the standardization and wide-spread support of WebAssembly in all major browsers. Our experiments with 3 scenarios show that implementing such architecture is not only feasible but also that the impact on performance is negligible.",International Conference on Web Engineering,2023,,,,,Mar-18,2,6,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_1
In2P-Med: Toward the Individual Privacy Preferences Identity in the Medical Web Apps,"Ha Xuan Son; Khoi N. H. Tuan & Loc C. P. Van; Phuc T. Nguyen, Khanh H. Vo, Huong H. Huong, Khiem G. Huynh, Khoa D. Tran, Anh T. Nguyen, Nghia H. Huynh, Duy T. Q. Nguyen & Bang K. Nguyen; Ngan T. K. Nguyen; Nghia Duong-Trung","VinCSS Internet Security Services JSC, Long Bien, Ha Noi, Vietnam; German Research Center for Artificial Intelligence (DFKI), Alt-Moabit 91C, 10559, Berlin, Germany; RMIT University (SGS), 702 Nguyen Van Linh, 7th District, Ho Chi Minh City, Vietnam; FPT Polytechnic, 22nd street, Cai Rang District, Can Tho City, Vietnam; FPT University, Nguyen Van Cu street, Ninh Kieu District, Can Tho City, Vietnam",Privacy preferences; Medical data; Medical web applications; Semi-supervised Learning,"With the advancement of technology, people are now able to monitor their health more efficiently. Mobile phones and smartwatches are equipped with sensors that can measure real-time changes in blood pressure, SPO2, and other attributes and public them to service providers via web applications (called web apps) for health improvement suggestions. Moreover, users can share the collected health data with other people, such as doctors, relatives, or friends. However, using technology-based approaches has raised the issue of privacy. Some health web apps, by default, intrusively gather and share data. Additionally, smartwatches may monitor people’s health status 24/7. This can be cumbersome as they would have to configure each device manually. To this end, we have developed a privacy-preference prediction mechanism in the web apps called In2P-Med: the individual privacy preferences identity for the medical data. To capture individual privacy preferences in the web apps, our model learns users’ privacy behavior based on their responses in different medical scenarios. In practice, we exploited several machine learning algorithms: SVM, Gradient Boosting Classifier, Ada Boost Classifier, and Gradient Boosting Regressor. To prove its effectiveness, we set up several scenarios to measure the accuracy and the satisfaction level in the two participant groups (i.e., expert and normal users). One key point in this research’s selection of participants is its focus on those living in developing countries, where privacy violation issues are not a common topic.",International Conference on Web Engineering,2023,,,,,126-140,2,12,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_10
Hierarchical Transformers for User Semantic Similarity,Marco Di Giovanni & Marco Brambilla,"Politecnico di Milano, Milan, Italy",,"The investigation of users’ behaviour on Web and Social Media platforms usually requires to analyze many heterogeneous features, such as shared textual content, social connections, demographic traits, and temporal attributes. This work aims to compute accurate user similarities on Twitter just using the textual content shared by users, a feature known to be easy and quick to collect. We design and train a 2-stages hierarchical Transformer-based model, whose first stage independently elaborates single tweets, and its second stage combines the embeddings of the tweets to obtain user-level representations. To evaluate our model we design a ranking task involving many accounts, automatically collected and labeled without the need for human annotators. We extensively investigate hyper-parameters to obtain the best model configuration. Finally, we check whether the obtained embeddings reflect our idea of similarity by testing them on further tasks, including community visualization, outlier detection, and polarization quantification.",International Conference on Web Engineering,2023,,,,,143-157,2,1,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_11
User Identity Linkage via Graph Convolutional Network Across Location-Based Social Networks,"Qian Li, Qian Zhou, Wei Chen & Lei Zhao","School of Computer Science and Technology, Soochow University, Suzhou, China",User identity linkage; Graph convolutional network; Location data; Spatial features,"In the past few decades, we have witnessed the flourishing of location-based social networks (LBSNs), where many users tend to create different accounts on multiple platforms to enjoy various services. Benefiting from the large-scale check-in data generated on LBSNs, the task of location-based user identity linkage (UIL) has attracted increasing attention recently. Despite the great contributions made by existing work on location-based UIL, they usually investigate the task with data mining methods, which are hard to extract and utilize the latent features contained by check-in records for more precise user identity linkage. In view of the deficiencies of existing studies, we propose a graph convolutional network (GCN) based model namely GCNUL that consists of a GCN-based encoder, an interaction layer, and a classifier, to fully exploit the spatial features hidden in check-in records. Specifically, the GCN-based encoder aims to exploit the spatial proximity of check-in records and mine user mobility patterns. The interaction layer is developed to capture deep correlations between users’ behaviors explicitly. The extensive experiments conducted on two real-world datasets demonstrate that our proposed model GCNUL outperforms the state-of-the-art methods.",International Conference on Web Engineering,2023,,,,,158-173,2,3,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_12
Emotions Intensity Prediction in Online Discussions Using Time Series Forecasting,Maksymilian Marcinowski,"Poznan Supercomputing and Networking Center, Poznań, Poland",online discussion; emotions intensity; dialogue modeling,"Toxic behaviors such as aggression, harassment, and insults are the scourge of social media and online discussion sites. Conflictual interactions of this type finally lead dialogues off the rails and as a result the dialogue loses its essence. Preventing a discussion from such incidents requires the ability to predict such situation. This, in turn, presents the challenge of modeling and understanding the dynamics of dialogues and thus predefining the factors that may change throughout their course.",International Conference on Web Engineering,2023,,,,,174-188,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_13
Speed Up the Web with Universal CSS Rendering,Lucas Vogel & Thomas Springer,"Technical University Dresden, 01069, Dresden, Germany",universal rendering; CSS rendering; render-critical; Above-the-Fold; improved loading times; render pipeline; web page optimization,"Achieving fast page load and upholding conversion rates requires continuous effort for web applications ever-growing in size and complexity. Consequently, developing new methods for optimizing and speeding up page load is a constant effort of the web community. Existing methods aim to reduce the amount of render-blocking code in the render pipeline to improve the time until render. However, a recent study revealed a tremendous optimization potential remaining, especially for CSS, since only \(\approx \) 15% of render-blocking CSS code is used until render [12]. In this paper, we present Essential, an improved serverside CSS renderer. It is based on the popular Critical package [10], which increases the code efficiency and prepares websites by extracting render-critical elements “Above-the-Fold"" and delaying the remaining code asynchronously. Essential renders the CSS of the whole page, as well as eliminates code duplicates to optimize the rendered result. Our evaluation results show that Essential  more than triples code efficiency and decreases the transferred render-critical CSS by 65.9% compared to the original while maintaining a high visual similarity and matching or surpassing the performance of Critical.",International Conference on Web Engineering,2023,,,,,191-205,2,4,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_14
Collaborative Web Accessibility Evaluation: An EARL-Based Workflow Approach,"Juan-Miguel López-Gil, Oscar Díaz & Mikel Iturria","ONEKIN Research Group, University of the Basque Country (UPV/EHU), 20018, Donostia-San Sebastián, Spain",Web engineering; Web accessibility; Web accessibility evaluation; Browser extension; Aggregation,"The Web Accessibility Guidelines are designed to help developers ensure that web content is accessible to all users. These guidelines provide the foundation for evaluation tools that automate inspection processes. However, due to the heterogeneity of these guidelines and the subjectivity involved in their evaluation, humans are still necessary for the process. As a result, evaluating accessibility becomes a collaborative endeavor wherein different human experts and tools interact. Despite quickly being noticed by the W3C, it has largely been overlooked in the existing literature. Tool vendors often focus on providing a thorough evaluation rather than importing, integrating, and combining results from diverse sources. This paper examines an EARL-based document-centric workflow. It introduces a dedicated editor for EARL documents that accounts for the life-cycle of EARL documents where evaluation episodes feedback on each other. Expert evaluations were conducted (n = 5 experts), not so much about the tool itself but its ability to facilitate a collaborative approach.",International Conference on Web Engineering,2023,,,,,206-220,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_15
In a Hurry: How Time Constraints and the Presentation of Web Search Results Affect User Behaviour and Experience,"Garrett Allen, Mike Beijen, David Maxwell & Ujwal Gadiraju","TU Delft, Delft, The Netherlands",web search; time constraints; user interfaces; search behaviour analysis; task performance; user experience,"Time constraints are commonplace in our daily lives. While literature in recent years from the Information Retrieval (IR) community has increased our understanding of the effects of time constraints on search, practical effects on search outcomes have rarely been evaluated. Little is known about how different search interfaces influence search outcomes and experiences in time-constrained search. This constitutes a knowledge gap that we aim to address in our work. Through a pre-registered 4 \(\times \) 4 between-subjects crowdsourced user study, we investigate the influence of four different interfaces (list view, grid-based view, absence of result snippets, and linear scanning pattern view) on search outcomes and experiences under imposed time constraints (no constraint and constraints at two, five, and eight minutes). Results from our study indicate that user task performance is considerably affected by time constraints. In addition, as time constraints are tightened, a trade-off between querying rates and click depths arises. While no interaction effects between SERP interfaces and time constraints were ultimately found, findings from this study form an essential foundation for future work on how search result presentation may assist those searchers under strict time constraints.",International Conference on Web Engineering,2023,,,,,221-235,2,1,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_16
A Taxonomy of User Behavior Model (UBM) Tools for UI Design and User Research,Maxim Bakaev; Sebastian Heil & Martin Gaedke; Johanna Jagow & Maximilian Speicher; Kevin Bauer,"University of Mannheim, 68161, Mannheim, Germany; Jagow Speicher Consulting, 08037, Barcelona, Spain; Independent UX Consultant, 630132, Novosibirsk, Russia; Technische Universität Chemnitz, 09111, Chemnitz, Germany",Software Classification; User-Centered Design; Human-Computer Interaction; Machine Learning,"The engineering of user interfaces (UIs) increasingly relies on software tools that aid in ideation, design, evaluation, etc., but involve no real users. Particularly, user behavior models (UBMs) bear the potential to improve human-centered design processes, but their adoption in practice remains low. In this paper, we present a taxonomy for UBM tools that organizes and structures them along 7 dimensions – supported job, degree of automation, focus, interface data input, user data input, output of tool, and target interface platform. We also conduct an initial evaluation with 61 existing tools, providing insights into the current state of the field. Notably, none of the investigated tools work with user characteristics or reference interfaces as input, although this would appear very practical for real projects. Our results could support UI/UX researchers and digital design practitioners in searching for the tools and further enhancing them. Ultimately, our work represents a step toward understanding and overcoming the low adoption rate of ML-based UBM tools in the industry.",International Conference on Web Engineering,2023,,,,,236-244,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_17
On the Energy-Efficiency of Hybrid UI Components for Mobile Cross-Platform Development,Stefan Huber & Michael Felderer; Mario Döller; Michael Felderer; Michael Felderer,"German Aerospace Center (DLR), 51147, Cologne, Germany; University of Cologne, 50923, Cologne, Germany; University of Applied Sciences Kufstein, 6330, Kufstein, Austria; University of Innsbruck, 6020, Innsbruck, Austria",Energy-efficiency; Mobile cross-platform development; Empirical Study,"The increasing use of mobile apps in everyday life has led to an increased demand for efficient and cost-effective mobile development methods. One such method is mobile cross-platform development (MCPD), which enables the creation of apps from a single codebase for multiple platforms. However, previous research has shown that MCPD approaches can have higher energy consumption than native development approaches. In order to address this issue, this paper proposes the use of Hybrid UI components, which are a combination of native and web technologies, as a means to improve the energy efficiency of cross-platform UI components. Four selected Hybrid UI components were implemented and evaluated regarding their energy-efficiency against native and hybrid mobile development. Results indicate that for two UI components, a substantial increase in energy-efficiency was achieved. However, for the other two UI components, no improvement, and in one case, even a degradation in energy consumption was observed. The study concludes that Hybrid UI components are a promising approach, but further research is needed to ensure their energy-efficiency in all cases.",International Conference on Web Engineering,2023,,,,,247-261,2,3,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_18
Human-Friendly RDF Graph Construction: Which One Do You Chose?,"Ana Iglesias-Molina & David Chaves-Fraga; David Chaves-Fraga, Ioannis Dasoulas & Anastasia Dimou","Ontology Engineering Group, Universidad Politécnica de Madrid, Madrid, Spain; KULeuven – Flanders Make@KULeuven – Leuven.AI, Leuven, Belgium",Knowledge Graphs; Mapping Languages; YARRRML,"Knowledge Graphs (KGs) are a powerful mechanism to structure and organize data on the Web. RDF KGs are usually constructed by declaring a set of mapping rules, specified according to the grammar of a mapping language (e.g., RML), that relates the input data sources to a domain vocabulary. However, the verbosity and (manual) definition of these rules affect their global adoption. Several user-friendly serializations for different mapping languages were proposed to facilitate users with the definition of such rules, e.g., YARRRML, SMS2, XRM, or ShExML. Still, most of them do not cover all features of the mapping languages for RDF graph construction (e.g., constructing RDF-star), or they lack tooling support. In this paper, (i) we present a set of updates over the YARRRML serialisation to empower it with the latest necessities for constructing RDF graphs; (ii) we implement these new features in a new open-source translator, Yatter, currently used in different real-use cases and international projects; and (iii) we qualitatively compare our proposal against similar state-of-the-art serialisations, and their associated translators over a set of conformance test cases. Our proposal advances the declarative construction of RDF graphs and supports users in choosing an appropriate serialisation and translator for their use cases.",International Conference on Web Engineering,2023,,,,,262-277,2,12,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_19
Code Vectorization and Sequence of Accesses Strategies for Monolith Microservices Identification,Vasco Faria & António Rito Silva,"INESC-ID, Instituto Superior Técnico, University of Lisbon, Lisbon, Portugal",Monolith; Microservices; Microservices Identification; Static Analysis; Machine Learning; Architecture Migration,"Migrating a monolithic application to a microservice architecture can benefit from automated methods that accelerate migration and improve the results of decomposition. One of the current approaches that guide software architects on the migration is to group monolith domain entities into microservices, using the sequences of accesses of the monolith functionalities to the domain entities. In this paper, we enrich the sequence of accesses solution by applying code vectorization to the monolith, using the Code2Vec neural network model. We apply Code2Vec to vectorize the monolith functionalities. We propose two strategies to represent a functionality, one by aggregating its call graph method vectors and the other by extending the sequence of accesses approach with vectorization of the accessed entities. To evaluate these strategies, we compare the proposed strategies with the sequence of accesses strategy and an existing approach that uses class vectorization. We run all these strategies over a large set of codebases and then compare the results of their decompositions in terms of cohesion, coupling, and complexity.",International Conference on Web Engineering,2023,,,,,19-33,2,8,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_2
"Waiter and AUTRATAC: Don’t Throw It Away, Just Delay!",Lucas Vogel & Thomas Springer,"Technical University Dresden, 01069, Dresden, Germany",asynchronous JavaScript; code delay; code splitting; faster loading times; JavaScript framework,"The modern web is built with a mixture of HTML, CSS, and an increasing amount of JavaScript. Since JavaScript determines \(\approx \)70% of the overall data of websites on average, JavaScript code efficiency significantly influences their loading performance. A recent study revealed that the average JavaScript code usage until render is \(\approx \)40%. For economical and convenience reasons, a significant amount of research already focuses on optimizing the delivered data to reduce loading times. For example, a large area of research focuses on eliminating dead code, where unused functions are deleted. Code in this context is classified as “dead” when the results of the code or the whole code itself are never executed or used. Since code elimination is based on heuristics/code classification, there is always a trade-off between code elimination and missing JavaScript code that harms the correct functioning of the website. As a result, some pages do not load correctly after elimination. Even the most advanced attempts with user input emulation do not achieve 100% accuracy. In this paper, we introduce two new open-source frameworks called Waiter, which waits until a resource is available, and AUTRATAC, an automatic transpiler to awaitable code. Both can be used separately or in combination to robustly delay pieces of JavaScript code without breaking it. For example, it allows code to be executed without loading all called functions beforehand. Therefore, when eliminating dead code optimized with AUTRATAC, the loading of unused functions can be delayed in a non-render-blocking way. This also opens up multiple new opportunities, as future code-splitting techniques might be significantly stricter without breaking a page. Our results show that delaying render-blocking JavaScript reduces loading times until First Contentful Paint (FCP) significantly, especially at slower network speeds. In one instance, an 85% drop in loading time was measured. Furthermore, it was visible that deferring the code with the developed frameworks still matches the total code execution time of the original render-blocking JavaScript.",International Conference on Web Engineering,2023,,,,,278-292,2,8,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_20
Scraping Data from Web Pages Using SPARQL Queries,Radek Burget,"Faculty of Information Technology, Brno University of Technology, Bozetechova 2, 61266, Brno, Czechia",Web scraping; Page rendering; Data extraction; RDF; SPARQL,"Despite the increasing use of semantic data, plain old HTML web pages often provide a unique interface for accessing data from many domains. To use this data in computer applications or to integrate it with other data sources, it must be extracted from the HTML code. Currently, this is typically done by single-purpose programs called scrapers. For each data source, specific scrapers must be created, which requires a thorough analysis of the source page’s implementation in HTML. This makes writing and maintaining a set of scrapers a complex and time-consuming task. In this paper, we present an alternative approach that allows defining scrapers based on visual properties of the presented content instead of the HTML code structure. First, we render the source page and create an RDF graph that describes the visual properties of every piece of the displayed content. Next, we use SPARQL to query the model and extract the data. As we demonstrate with real-world examples, this approach allows us to easily define more robust scrapers that can be used across multiple web sites and that better cope with changes in the source documents.",International Conference on Web Engineering,2023,,,,,293-300,2,1,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_21
An Empirical Study of Web API Versioning Practices,Souhaila Serbout & Cesare Pautasso,"Software Institute (USI), Lugano, Switzerland",API; Web API; OpenAPI; Empirical Study; Versioning,"As Web APIs evolve, developers assign them version identifiers to reflect the amount and the nature of changes that the API clients should expect. In this work we focus on identifying versioning practices adopted by Web API developers by extracting and classifying version identifiers found in a large collection of OpenAPI descriptions. In particular, we observe how frequently different versioning schemes have been adopted for identifying both stable and preview releases (e.g., simple version counters, semantic versioning, or release timestamps). We further study the stability of versioning schemes during APIs evolution. We also detect APIs which offer dynamic access to versioning metadata through dedicated endpoints as well as APIs which support clients expecting to reach up to 14 different versions of the same API at the same time. Overall the results offer a detailed view over current Web API versioning practices and can serve as the basis for future discussions on how to standardize critical API versioning metadata.",International Conference on Web Engineering,2023,,,,,303-318,2,13,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_22
The Rise of Disappearing Frameworks in Web Development,"Juho Vepsäläinen, Arto Hellas & Petri Vuorimaa","Aalto University, Espoo, Finland",web; web development; multi-page applications; JavaScript; front-end frameworks; single-page applications; islands architecture; disappearing frameworks; Astro; Marko.js; Qwik,"The evolution of the web can be characterized as an emergence of frameworks paving the way from static websites to dynamic web applications. As the scope of web applications has grown, new technical challenges have emerged, leading to the need for new solutions. The latest of these developments is the rise of so-called disappearing web frameworks that question the axioms of earlier generations of web frameworks, providing benefits of the early web and simple static sites.",International Conference on Web Engineering,2023,,,,,319-326,2,15,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_23
On the Popularity of Classical Music Composers on Community-Driven Platforms,"Ioannis Petros Samiotis, Chirstoph Lofi & Alessandro Bozzon; Andrea Mauri","Université Claude Bernard Lyon 1, Lyon, France; TU Delft, Delft, The Netherlands",social media; user-generated content; music; popularity; web crawling,"Traditionally, the popularity of classical music composers is approximated through commercial figures like album releases, record sales, or live performances. However, commercial factors only provide one piece of the overall picture. The success of community-driven platforms has profoundly changed how people consume and interact with music, and, consequently, our understanding of what popularity is. People discuss their favourite artists, archive knowledge regarding them and share their work through multimedia platforms. In this paper, we investigate how data from these platforms can provide a more comprehensive view on popularity and engagement regarding the long-tail of classical music composers. We combine album release data provided by MusicBrainz, the commitment of people in maintaining the composers’ Wikipedia pages and user engagement in classical music videos on YouTube. Our analysis provides a complementary multi-faceted view on community engagement and urges future research to expand on user-generated content for a more diverse expression of popularity in the music domain.",International Conference on Web Engineering,2023,,,,,327-335,2,1,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_24
Topio: An Open-Source Web Platform for Trading Geospatial Data,"Andra Ionescu, Kyriakos Psarakis & Asterios Katsifodimos; Kostas Patroumpas, Georgios Chatzigeorgakidis, Dimitrios Skoutas & Spiros Athanasiou; Diego Collarana; Kai Barenscher","Fraunhofer IAIS, Sankt Augustin, Germany; WIGeoGIS, Vienna, Austria; Delft University of Technology, Delft, The Netherlands; Athena Research Center, Athens, Greece",Web platform; Data trading; Data marketplace; Open-source,"The increasing need for data trading across businesses nowadays has created a demand for data marketplaces. However, despite the intentions of both data providers and consumers, today’s data marketplaces remain mere data catalogs. We believe that marketplaces of the future require a set of value-added services, such as advanced search and discovery, that have been proposed in the database research community for years, but are not yet put to practice. With this paper, we report on the effort to engineer and develop an open-source modular data market platform to enable both entrepreneurs and researchers to setup and experiment with data marketplaces. To this end, we implemented and extended existing methods for data profiling, dataset search & discovery, and data recommendation. These methods are available as open-source libraries. In this paper we report on how those tools were assembled together to build topio.market, a real-world web platform for trading geospatial data, that is currently in a beta phase.",International Conference on Web Engineering,2023,,,,,336-351,2,1,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_25
Creating Searchable Web Page Snapshots Using Semantic Technologies,Radek Burget & Hamza Salem,"Brno University of Technology, Faculty of Information Technology, Bozetechova 2, 61266, Brno, Czechia",Web page snapshot; Page rendering; Web data extraction; RDF; SPARQL,"For many applications, it is necessary to create snapshots of web pages that accurately describe how the page appeared in a browser at a given point in time. Storing the original code (even if all referenced resources are included) and creating bitmap screenshots have many drawbacks when it comes to searching, viewing, and manipulating such snapshots. In this paper, we demonstrate a different approach that uses a remotely controlled web browser to render web pages. We capture the complete information about the rendered page and all of its content, transform it into an explicit RDF-based model representation, and store it in a repository. The stored page models can then be explored using interactive web-based tools, exported in various formats, linked to other data sources, and queried using SPARQL. We also include several application scenarios that demonstrate the benefits of the proposed approach.",International Conference on Web Engineering,2023,,,,,355-358,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_26
Choose your Preferred Life Cycle and SofIA will do the Rest,"María-José Escalona, Julían García-García & Nora Parcus de Koch; Laura García-Borgoñon & Guillermo López-Nicolás","Universidad de Sevilla, Seville, Spain; Instituto Tecnológico de Aragón, Zaragoza, Spain",Requirements modeling; Mockups; Early testing; Model verification; Bidirectional traceability,"The importance of requirements engineering for software quality is well-understood in industry. It is also clear that requirements engineers need tools that do not prescribe only one type of development process. This paper presents an overview of SofIA, a CASE tool that provides maximum flexibility when modeling functionality, data or prototypes because it can use any given model to generate other models. SofIA is built on the experience acquired from having used the previous NDT-Suite in industrial projects for more than two decades. It achieves its objectives by supporting bidirectional transformations and guaranteeing traceability between all models. Initial evaluations performed in the academic environment have shown that students require less training and feel more comfortable when following their own modeling process.",International Conference on Web Engineering,2023,,,,,359-362,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_27
SLA4OAI-Analyzer: Automated Validation of RESTful API Pricing Plans,"Rafael Fresno-Aranda, Pablo Fernández & Antonio Ruiz-Cortés","SCORE Lab, I3US Institute, Universidad de Sevilla, Seville, Spain",Automation; Validity; REST; API; Pricing,"Nowadays, public web APIs are considered as business assets by many organizations. They provide data and functionality which other developers can integrate within their own services. These APIs are commercialized through pricings, which include a series of plans. Each plan contains features and limitations, coupled with a price. Developers who wish to use the API need to choose which plan better suits their needs. The formal description of pricings is not standardized, which hinders the ability to automate their analysis. The SLA4OAI specification aims to provide an extension for OpenAPI that allows pricings to be described. This specification paves the way for an ecosystem of tools that leverage the information of a pricing.",International Conference on Web Engineering,2023,,,,,363-366,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_28
Towards a Model-Driven Development of Environmental-Aware Web Augmenters Based on Open Data,"Paula González-Martínez, César González-Mora, Irene Garrigós & Jose-Norberto Mazón; José M. Cecilia","Department of Software and Computing Systems (DLSI), Universidad de Alicante, Alicante, Spain; Department of Computing Engineering (DISCA), Universitat Politècnica de València, València, Spain",Web Augmentation; Open data; Environment; Sustainable Development Goals; Model-driven development,"In order to achieve the SDGs (Sustainable Development Goals), society must be able to consume open data to be aware of environmental situations. However, the existence of many related heterogeneous open data sets hampers citizens to use them to rise environmental awareness. In order to overcome this scenario, in this paper, we introduce a model-driven approach to automatically generate Web Augmenters that (i) homogeneously access environmental open data, and (ii) visualize this data while users are surfing the Web. In order to show the feasibility of our approach a case study is defined, based on generating a Web Augmenter that uses open data and Wikipedia related to “Mar Menor” coastal lagoon; a highly anthropized ecosystem located in South-East Spain.",International Conference on Web Engineering,2023,,,,,367-370,2,1,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_29
HYAS: Hybrid Autoscaler Agent for Apache Flink,Alexandros Nikolaos Zafeirakopoulos & Euripides G. M. Petrakis,"School of Electrical and Computer Engineering, Technical University of Crete (TUC), Chania, Crete, Greece",Stream Processing; Autoscaling; Kubernetes; Apache Flink,"Apache Flink is a distributed processing engine for stateful computations over unbounded and bounded data streams. Despite its versatility, Apache Flink cannot automatically and optimally adjust its computing resources to match the requirements of the incoming workload. HYAS agent monitors and models Flink’s responsiveness based on changes in operator idleness, backpressure and input record lag. The decision process instructs Flink to adjust its parallelism to keep up with the workload. The performance of HYAS has been assessed experimentally on an Apache Flink deployment on Kubernetes on the Google Cloud Platform using synthetic and real-life workloads. HYAS successfully maintains application performance and provides a better performance-to-cost ratio than existing methods.",International Conference on Web Engineering,2023,,,,,34-48,2,3,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_3
Enhancing Web Applications with Dynamic Code Migration Capabilities,"Sebastian Heil, Jan-Ingo Haas & Martin Gaedke","Technische Universität Chemnitz, Chemnitz, Germany",Web Infrastructure; Software Architecture; Code Mobility; WebAssembly; WebSockets,"Dynamic migration of code between client and server of a web application allows to balance the needs of users for smooth and responsive user interactions with the interests of software providers to reduce costs and use resources efficiently. The ability to change the execution location of parts of the application logic at runtime means that depending on client capabilities, network speed and the current load of client and server, the code distribution can be optimized. In this demonstration, we showcase dynamic code migration for a sample e-commerce web application. The demonstrator is designed according to our novel DCM architecture and uses its infrastructure to automate compilation of code fragments and manage the migration at runtime, leveraging standardized Web technologies like WebAssembly and WebSockets. Demo participants will be able to interactively control the distribution of code fragments via a control user interface in the browser and interact with the e-commerce web application which was extended so that execution locations of application logic can be observed life. This demo provides a running prototypical implementation of the DCM architecture and aims at inspiring discussions about new possibilities for the Web platform from the widespread support of WebAssembly in all major browsers.",International Conference on Web Engineering,2023,,,,,371-375,2,2,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_30
Macaroni: Crawling and Enriching Metadata from Public Model Zoos,"Ziyu Li, Henk Kant, Rihan Hai, Asterios Katsifodimos & Alessandro Bozzon","Delft University of Technology, Delft, The Netherlands",Machine Learning; Model Zoo; Metadata Representation,"Machine learning (ML) researchers and practitioners are building repositories of pre-trained models, called model zoos. These model zoos contain metadata that detail various properties of the ML models and datasets, which are useful for reporting, auditing, reproducibility, and interpretability. Unfortunately, the existing metadata representations come with limited expressivity and lack of standardization. Meanwhile, an interoperable method to store and query model zoo metadata is missing. These two gaps hinder model search, reuse, comparison, and composition. In this demo paper, we advocate for standardized ML model metadata representation, proposing Macaroni, a metadata search engine with toolkits that support practitioners to obtain and enrich that metadata.",International Conference on Web Engineering,2023,,,,,376-380,2,5,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_31
WS3H: Webified Self-Sovereign Smart Home,"Valentin Siegert, Clemens Albrecht, Mahda Noura & Martin Gaedke","Distributed and Self-organizing Systems, Chemnitz University of Technology, Chemnitz, Germany",Self-Sovereign Identity; Smart Home; Web of Things,"The Web of Things (WoT) concept proposes to integrate the existing Web ecosystem with Things to provide an interoperable infrastructure which goes beyond basic network connectivity. Existing approaches unify the process to integrate the devices into the Web by automatically generating Web APIs based on semantic device descriptions. However, they are either limited to specific protocols or do not address transport security and authorization. In this paper, we demonstrate our approach on a Webified Self-Sovereign Smart Home that uses self-sovereign identity to establish transport security and authorization in a webified smart home. Our solution provides end user support with easy deployment and addresses the local scope of a smart home due to its self-sovereignty.",International Conference on Web Engineering,2023,,,,,381-385,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_32
Quantum Web Services Orchestration and Management Using DevOps Techniques,"Jaime Alvarado-Valiente, Javier Romero-Álvarez & José García-Alonso; Enrique Moguel","CénitS–COMPUTAEX (Extremadura Supercomputing, Technological Innovation and Research Center), Carretera Nacional 521, Km 41.8, 10071, Cáceres, Spain; University of Extremadura, Escuela Politécnica, Quercus Software Engineering Group, Av. de la Universidad, S/N, 10003, Cáceres, Spain",Quantum computing; Quantum web services; Quantum software; DevOps,"Quantum computing is a new approach to computing based on quantum mechanics. It holds great promise for solving problems that classical computers cannot reach in a reasonable time, up to the point that it is already attracting the interest of the scientific and industrial communities. As quantum technology continues to advance and quantum computers become more prevalent, the need for hybrid systems that can integrate quantum software with classical information systems is becoming increasingly pressing. One of the most promising solutions for this integration is web engineering, which provides artifacts that are already well consolidated in classical computing and that can be integrated into quantum systems. Therefore, web engineering can provide a leap forward in the advancement of quantum computing. This thesis aims to design an orchestration method to coordinate and integrate quantum services into classic software systems and propose DevOps techniques for managing the life cycle of these systems.",International Conference on Web Engineering,2023,,,,,389-394,2,6,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_33
Using Emotions and Topics to Understand Online Misinformation,"Yuwei Chuai, Arianna Rossi & Gabriele Lenzini","SnT, University of Luxembourg, Luxembourg, Luxembourg",Misinformation; Social Networks; Emotions; Topics; Echo Chambers,"Misinformation has become one of the most pressing social issues in the twenty-first century. How the combinations of emotions and topics trigger the spread of misinformation, however, still remains to be revealed. This study comprehensively examines misinformation and its diffusion by correlating emotions and topics. First, we examine how specific emotions and topics are combined in misinformation. Second, we identify the effects of emotions and topics on the virality of misinformation. Finally, we further explore how to employ users’ topic preferences and emotion reactions to detect and analyze echo chambers in misinformation cascades. The findings can help construct a detailed and consistent understanding on misinformation diffusion in terms of emotions and topics. Potential practical implications are also provided to prevent the spread of misinformation online.",International Conference on Web Engineering,2023,,,,,395-400,2,2,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_34
Learning-Based Quality of Experience Prediction for Selecting Web of Things Services in Public Spaces,KyeongDeok Baek & In-Young Ko,"School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Public WoT service selection; Learning-based QoE prediction; Attention-based multi-agent reinforcement learning,"In the age of the Web of Things (WoT), an increasing number of WoT devices will be deployed over public spaces and provide various services to users. Therefore, discovering and selecting public WoT services by predicting the expected Quality of Experience (QoE) become critical to satisfying users. However, because of the uncertain and dynamic nature of public WoT environments, accurately predicting and continuously maintaining the QoE of the services is challenging. We investigated the limitations of the traditional model-based QoE prediction in WoT environments and the potential of the learning-based approaches to deal with the challenges. In this work, we propose a distributed algorithm powered by learning-based QoE prediction for selecting public WoT services. Service agents predict the long-term QoE for the corresponding service based on attention mechanism and multi-agent reinforcement learning. Service agents learn the influence of hard-to-observe influencing factors in the environment, such as physical obstacles and interference from other services.",International Conference on Web Engineering,2023,,,,,401-406,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_35
A Practical Introduction for Developing and Operating Hybrid Quantum Applications,"Martin Beisel, Marie Salm & Benjamin Weder; Felix Gemeinhardt","Institute of Architecture of Application Systems, University of Stuttgart, Stuttgart, Germany; Johannes Kepler University Linz, Linz, Austria",Quantum Computing; Quantum Software Engineering; Hybrid Quantum Applications; SoC; Workflow Technology,"With the increasing number of quantum computers available via the cloud, the research area of quantum software engineering is emerging. Its goal is the investigation of concepts and guidelines to develop and operate hybrid quantum applications, ensuring engineering principles such as modularity, reuse, and maintainability. In this tutorial, we provide an overview of state-of-the-art concepts and techniques in quantum computing, as well as quantum software engineering. It includes an introduction of selected essential quantum algorithms, limitations of current quantum computers, and a lifecycle for hybrid quantum applications. Furthermore, we show how the service-oriented development of hybrid quantum applications increases their modularity and reusability. Finally, we demonstrate the orchestration of the required classical and quantum programs using workflows and their automated deployment.",International Conference on Web Engineering,2023,,,,,409-412,2,3,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_36
Automated Web GUI Generation from High-Level Interaction Design with Discourse Models,Hermann Kaindl,"TU Wien, Vienna, Austria",Interaction design; Discourse models; Task models; Automated Web GUI generation; Customization; Low-vision accessibility of Web-pages,"Interaction design is considered important for achieving usable Web user interfaces. Communicative acts as abstractions from speech acts can model basic building blocks (‘atoms’) of communication, like a question or an answer. When, e.g., a question and an answer are glued together as a so-called adjacency pair, a simple ‘molecule’ of a dialogue is modeled. Deliberately complex discourse structures can be modeled using relations from Rhetorical Structure Theory (RST). The content of a communicative act can refer to ontologies of the domain of discourse. Taking all this together, we created a new discourse metamodel that specifies what discourse models may look like. Such discourse models can specify an interaction design. Since manual creation of user interfaces is hard and expensive, automated generation may become more and more important. This tutorial also demonstrates how such an interaction design can be used for automated Web GUI generation. This is based on model-transformation rules according to the model-driven architecture. Based on AI optimization techniques, the graphical user interfaces (GUIs) are automatically tailored to a device such as a smartphone according to a given device specification. Since the usability of fully-automatically generated GUIs is still not satisfactory, unique customization techniques are employed as well. We also address low-vision accessibility of Web-pages, by combining automated design-time generation of Web-pages with responsive design for improving accessibility.",International Conference on Web Engineering,2023,,,,,413-417,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_37
Developing Distributed WoT Applications for the Cloud-to-thing Continuum,Sergio Laso; Javier Berrocal,"Escuela Politécnica, Quercus Software Engineering Group, University of Extremadura, Avda. de la Universidad s/n, Cáceres, 10003, Spain; Global Process and Product Improvement S.L., Calle Las Ocas 2, Cáceres, 10004, Spain",Cloud-to-thing continuum; End devices; WoT applications; Internet of Things,"The great popularity and acceptance of smart devices have encouraged the development of applications focused on the Internet of Things (IoT) and Web of Things (WoT) paradigms. These applications are normally based on cloud-centric architectures. However, the increasing amount of information exchanged and the need of IoT devices capable of adapting on real-time their behavior to the user context pose a challenge to these architectural assumptions. Recently, paradigms such as Fog, Edge, and Mist computing have been proposed along the Cloud-to-thing continuum to exploit the computational and storage capabilities of end devices (IoT devices, smartphones, etc.) in order to distribute some tasks on them, reducing the overhead both in the cloud and in the network, and increasing the response time. Currently, the implementation of these paradigms requires developers to be qualified and trained to create ad-hoc systems, as there is a lack of standards and tools to facilitate the development of these highly distributed applications. This tutorial delves into the deployment of WoT applications along the Cloud-to-thing continuum. It presents a framework based on existing standards to shorten the learning curve, the development time, and improve the software quality.",International Conference on Web Engineering,2023,,,,,418-420,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_38
Quantum Web Services: Development and Deployment,"Javier Romero-Álvarez, Jaime Alvarado-Valiente & Jose Garcia-Alonso; Enrique Moguel","CénitS-COMPUTAEX (Extremadura Supercomputing, Technological Innovation and Research Center), Carretera Nacional 521, Km 41.8, 10071, Cáceres, Spain; University of Extremadura, Escuela Politécnica, Quercus Software Engineering Group, Av. de la Universidad, S/N, 10003, Cáceres, Spain",Quantum computing; Quantum web services; Quantum programming; OpenAPI,"Quantum computing has gained attention from the scientific community and industry, resulting in the development of increasingly powerful quantum computers and supporting technology. Major computer companies have created functional quantum computers, programming languages, and simulators that can be used by developers. This infrastructure is available through the cloud, similar to Infrastructure as a Service. However, utilizing these computers requires a deep understanding of quantum programming and hardware, which is different from traditional cloud computing. To enable a coexistence between quantum and classical computing, we believe that a transition period is necessary. One solution for coexistence is through web services. This tutorial will provide an overview of how quantum algorithms can be converted into web services, and how they can be deployed using the Amazon Braket platform for quantum computing and invoked through classical web service endpoints. Finally, we will propose a process for creating and deploying quantum services using an extension of OpenAPI and GitHub Actions. This extension allows developers to use the same methodology that they are used to for classical services.",International Conference on Web Engineering,2023,,,,,421-423,2,9,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_39
Optimizing ML Inference Queries Under Constraints,"Ziyu Li, Mariette Schönfeld, Wenbo Sun, Rihan Hai, Alessandro Bozzon & Asterios Katsifodimos; Marios Fragkoulis","Delivery Hero SE, Berlin, Germany; TU Delft, Delft, The Netherlands",Machine learning inference query; Constrained-based query optimization; Predicate ordering,"The proliferation of pre-trained ML models in public Web-based model zoos facilitates the engineering of ML pipelines to address complex inference queries over datasets and streams of unstructured content. Constructing optimal plan for a query is hard, especially when constraints (e.g. accuracy or execution time) must be taken into consideration, and the complexity of the inference query increases. To address this issue, we propose a method for optimizing ML inference queries that selects the most suitable ML models to use, as well as the order in which those models are executed. We formally define the constraint-based ML inference query optimization problem, formulate it as a Mixed Integer Programming (MIP) problem, and develop an optimizer that maximizes accuracy given constraints. This optimizer is capable of navigating a large search space to identify optimal query plans on various model zoos.",International Conference on Web Engineering,2023,,,,,51-66,2,4,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_4
LiquidAI: Towards an Isomorphic AI/ML System Architecture for the Cloud-Edge Continuum,Kari Systä & Antero Taivalsaari; Cesare Pautasso; Antero Taivalsaari; Tommi Mikkonen,"Nokia Bell Labs, Tampere, Finland; USI, Lugano, Switzerland; Tampere University, Tampere, Finland; University of Jyväskylä, Jyväskylä, Finland",Isomorphic Software; Software Architecture; Internet of Things; IoT; Web of Things; WoT; Artificial Intelligence; AI; Machine Learning; ML; Software Deployment; Deployment in the Large; Programmable World,"A typical Internet of Things (IoT) system consists of a large number of different subsystems and devices, including sensors and actuators, gateways that connect them to the Internet, cloud services, end-user applications and analytics. Today, these subsystems are implemented with a broad variety of programming technologies and tools, making it difficult to migrate functionality from one subsystem to another. In our earlier papers, we have predicted the rise of isomorphic IoT system architectures in which all the subsystems can be developed with a consistent set of technologies. In this paper we expand the same research theme to machine learning technologies, highlighting the need to use ML in a consistent and uniform fashion across the entire Cloud-Edge continuum.",International Conference on Web Engineering,2023,,,,,67-74,2,6,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_5
Predicting Crowd Workers Performance: An Information Quality Case,Davide Ceolin; Kevin Roitero; Furong Guo,"University of Udine, Udine, Italy; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Vrije Universiteit Amsterdam, Amsterdam, The Netherlands",Crowdsourcing; Behavioral Analysis; Worker performance,"Supervised machine learning tasks require human-labeled data. Crowdsourcing allows scaling up the labeling process, but the quality of the labels obtained can vary. To address this limitation, we propose methods for predicting label quality based on worker trajectories, i.e., on the sequence of documents workers explore during their crowdsourcing tasks. Trajectories represent a lightweight and non-intrusive form of worker behavior signal. We base our analysis on previously collected datasets composed of thousands of assessment data records including information such as workers’ trajectories, workers’ assessments, and experts’ assessments. We model such behavior sequences as embeddings, to facilitate their management. Then, we: (1) use supervised methods to predict worker performance using a given ground truth; (2) perform an unsupervised analysis to provide insight into crowdsourcing quality when no gold standard is available. We test several supervised approaches which all beat the baseline we propose. Also, we identify significant differences between trajectory clusters in terms of assessments and worker performance. The trajectory-based analysis is a promising direction for non-intrusive worker performance evaluation.",International Conference on Web Engineering,2023,,,,,75-90,2,0,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_6
WebAssembly in IoT: Beyond Toy Examples,"Pyry Kotilainen, Viljami Järvinen, Juho Tarkkanen, Teemu Autto, Teerath Das, Muhammad Waseem & Tommi Mikkonen","University of Jyväskylä, Jyväskylä, Finland",WebAssembly; Web of Things; Internet of Things; IoT,"WebAssembly enables running the same application code in a range of devices in headless mode outside the browser. Furthermore, it has been proposed that WebAssembly applications can be made isomorphic so that they can be liberally allocated to a set of computers that comprise the runtime environment. In this paper, we explore if WebAssembly truly enables the development of comprehensive IoT applications with the same ease as more traditional techniques would enable.",International Conference on Web Engineering,2023,,,,,93-100,2,10,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_7
Applying Discrete Event Simulation on Patient Flow Scenarios with Health Monitoring Systems,"Anastasiia Gorelova, Santiago Meliá & Diana Gadzhimusieva; Alexandra Parichenko","Universidad de Alicante, Carretera de San Vicente S/N, 03690, San Vicente del Raspeig, Alicante, Spain; Institute for Materials Science and Max Bergmann Center of Biomaterials, Dresden University of Technology, Budapester Str. 27, 01069, Dresden, Germany",Web of things (WoT); MATLAB; Simulink; SimEvents; infertility treatment; simulation; biosensor; Model Driven Engineering (MDE); Digital Twin; Discrete-Event Simulation (DES),"Despite technological advances, today there are still many treatments that have not been addressed by remote monitoring due to the absence of reliable monitoring devices and/or Health Monitoring Systems (HMS). In addition, there are situations where the deficiency of data due to the lack of a real scenario or device makes it impossible to use artificial intelligence (AI) techniques. However, this problem could be solved with simulation, being a fundamental mechanism for predicting and forecasting not-existing scenarios. In this paper, we proposed the use of Discrete-Event Simulation (DES) to model complex HMS scenarios. We have integrated a simulation module based on Matlab Simulink, into the MoSTHealth framework, so that the digital twins (DTs) modelled by the framework are elements of the DES scenario that the medical expert can easily parameterize through a mobile interface. A case study has been defined on the use of a wearable device (under development) that collects relevant hormone levels in real time, during infertility treatment. The DES simulation demonstrates an increase in the number of patients seen by one physician by 88,8%. In addition, the average waiting time for consultation decreased by 36.5%.",International Conference on Web Engineering,2023,,,,,101-108,2,1,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_8
Streamlining Personal Data Access Requests: From Obstructive Procedures to Automated Web Workflows,"Nicola Leschke, Florian Kirsten, Frank Pallas & Elias Grünewald","TU Berlin, Information Systems Engineering, Berlin, Germany",Data Subject Access Request; Process Automation; Web Automation; Privacy; Privacy Engineering; Data Access; Data Portability; GDPR,"Transparency and data portability are two core principles of modern privacy legislations such as the GDPR. From the regulatory perspective, providing individuals (data subjects) with access to their data is a main building block for implementing these. Different from other privacy principles and respective regulatory provisions, however, this right to data access has so far only seen marginal technical reflection. Processes related to performing data subject access requests (DSARs) are thus still to be executed manually, hindering the concept of data access from unfolding its full potential.",International Conference on Web Engineering,2023,,,,,111-125,2,6,https://link.springer.com/chapter/10.1007/978-3-031-34444-2_9
Language Models as SPARQL Query Filtering for Improving the Quality of Multilingual Question Answering over Knowledge Graphs,"Aleksandr Perevalov, Aleksandr Gashkov & Andreas Both; Andreas Both; Maria Eltsova","CBZ München GmbH, Heilbronn, Germany; Leipzig University of Applied Sciences, Leipzig, Germany; DATEV eG, Nuremberg, Germany",,"Question Answering systems working over Knowledge Graphs (KGQA) generate a ranked list of SPARQL query candidates for a given natural-language question. In this paper, we follow our long-term research agenda of providing trustworthy KGQA systems – here – by presenting a query filtering approach that utilizes (large) language models (LMs/LLMs), s.t., correct and incorrect queries can be distinguished. In contrast to the previous work, we address here multilingual questions represented in major languages (English, German, French, Spanish, and Russian), and confirm the generalizability of our approach by also evaluating it on low-resource languages (Ukrainian, Armenian, Lithuanian, Belarusian, and Bashkir). For our experiments, we used the following LMs: BERT, DistilBERT, Mistral, Zephyr, GPT-3.5, and GPT-4. The LMs were applied to the KGQA systems – QAnswer and MemQA – as SPARQL query filters. The approach was evaluated on the multilingual Wikidata-based dataset QALD-9-plus. The experimental results suggest that the KGQA systems achieve quality improvements for all languages when using our query-filtering approach.",International Conference on Web Engineering,2024,,,,,Mar-18,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_1
The Open V2X Management Platform,"Christos Dalamagkas, Angelos Georgakis, Kostas Hrissagis-Chrysagis & George Papadakis","EU Programs Coordination Department, Public Power Corporation, Athens, Greece",,"In this paper, we present an open-source web-based system, called Open V2X Management Platform (O-V2X-MP), which facilitates the management of charging points for electric vehicles with the goal of realizing Vehicle-to-Everything (V2X) scenarios. We describe its backend, which is composed of numerous components through a microservices architecture leveraging Docker containers. Using the C4 model methodology, we present the system context diagram with the main actors that interact with O-V2X-MP, the container diagram with the main communication flows between its components and the component diagram with the modules comprising the core of the platform. We also delve into the value-added services of O-V2X-MP, namely the billing engine, the REST APIs that enable interconnections and integration with external systems, the data analytics capabilities and the cyber-security module. We conclude with our future plans for the platform’s frontend.",International Conference on Web Engineering,2024,,,,,133-146,2,2,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_10
DyST: Dynamic Specification Mining for Heterogenous IoT Systems with WoT,Ege Korkan; Silvia Oliva Ramirez & Sebastian Steinhorst,"Technical University of Munich, Munich, Bavaria, Germany; Siemens, Munich, Bavaria, Germany",,"The comprehension of a distributed system and its verification is one of the most challenging problems in today’s software engineering, commonly referred to as observability. The complexity increases when one cannot control all the components, like in IoT systems composed of third-party devices. The Web of Things standards by the W3C help with this by describing what one can do with an IoT device via network messages. However, no work has leveraged these standards to offer an observability solution that works with any set of IoT devices. This work addresses this gap by proposing a method to verify the correctness of the system by mining its specification from device interactions. Our approach can reverse engineer complex application logic in the form of UML Sequence Diagrams from the analysis of network messages of any protocol between the devices during system runtime, which can be used to programmatically assert the correctness of the mined specification. We have evaluated our approach with three case studies to assess our mining technique, the performance of our algorithms, and the applicability of our contributions to system verification in the IoT. Our results show that our approach can produce accurate Sequence Diagrams that help understand and verify the behavior of IoT systems.",International Conference on Web Engineering,2024,,,,,147-162,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_11
SeamlessMDD: Framework for Seamless Integration of Generated and Hand-Written Code,"Bojana Dragaš, Nenad Todorović & Gordana Milosavljević; Tijana Rajačić","Faculty of Technical Sciences, University of Novi Sad, Trg Dositeja Obradovića 6, Novi Sad, Serbia; Schneider Electric, Industrijska 3G, Novi Sad, Serbia",,"This paper presents SeamlessMDD - our open-source framework for a gradual and effortless transition from traditional development to MDD (Model-Driven Development) that allows maintaining hand-written and generated code intertwined without the need to adjust the web application architecture or the established way of work. We propose a novel workflow that is based on the following: (1) Incremental and iterative transformations derived from model versions comparison so that only code for affected model elements is generated or modified; (2) Integration of generated and hand-written code using API-based code generators, which operate on syntax trees of target programming languages; (3) Case-specific support for change propagation and conflict resolution (contrary to the VCS-based systems operating on the single line).",International Conference on Web Engineering,2024,,,,,163-177,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_12
EdgER: Entity Resolution at the Edge for Next Generation Web Systems,"Cristian Martella, Angelo Martella & Antonella Longo","Department of Engineering for Innovation, University of Salento, Lecce, Italy",,"Thanks to the advances of emerging technologies like Edge and Cloud Computing and microservice development, web architectures are evolving to support Big Data platforms fully. The decentralization of the traditional cloud-centric approach pushes microservices towards the edge of the Internet when constraints exist regarding response time, security, and proximity services availability. This work proposes an approach for detecting anomalies at the edge called EdgER based on entity resolution techniques. Such an approach can be adopted for any application providing proximity-added-value service, even in near real-time. In this sense, a case study is provided in the photovoltaics domain. By implementing EdgER’s building blocks at the edge, it is possible to reconcile the received IoT data streams early against a predefined data model and identify near real-time anomalies in energy production and/or in smart photovoltaic panel operations. In general, EdgeER can also significantly contribute to improving the quality of the data managed by the overall Big Data platform and facilitating the implementation of privacy-preserving proximity-added-value services.",International Conference on Web Engineering,2024,,,,,178-196,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_13
"AuthApp – Portable, Reusable Solid App for GDPR-Compliant Access Granting","Andreas Both, Thorsten Kastner & Dustin Yeboah; Andreas Both; Christoph Braun & Tobias Käfer; Daniel Schraudner, Sebastian Schmid & Andreas Harth","Leipzig University of Applied Sciences, Leipzig, Germany; DATEV eG, Nuremberg, Germany; Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",,"The Solid (Social Linked Data) technology family was developed to provide the foundation for Data Sovereignty in the context of web applications. The advantage of this innovative approach is the opportunity to dynamically bind an identity to a Solid application and a user-specific Solid data store (Solid Pod). These three basic components can be combined dynamically, allowing users to share their data with an application while retaining full control of the data in self-managed Solid Pods. This paper presents a prototype of a web-based user interface to grant access to data in a Solid Pod. To enable a dynamic binding into Solid-driven environments, we made the implementation available as a Solid application – AuthApp – with a specific focus on allowing users to configure the data access granting efficiently. To comply with data protection regulations, in particular Europe’s GDPR, we extended the standard to include the validation of the purpose of data sharing. Unlike previous work, we also make full use of robust technologies to avoid the need to copy or store data outside the personal context, meaning all data remains under the user’s control and so does the AuthApp.",International Conference on Web Engineering,2024,,,,,199-214,2,3,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_14
Hook-in Privacy Techniques for gRPC-Based Microservice Communication,"Louis Loechel, Siar-Remzi Akbayin, Elias Grünewald, Jannis Kiesel, Inga Strelnikova, Thomas Janke & Frank Pallas","Information Systems Engineering, Technische Universität Berlin, Berlin, Germany",,"gRPC is at the heart of modern distributed system architectures. Based on HTTP/2 and Protocol Buffers, it provides highly performant, standardized, and polyglot communication across loosely coupled microservices and is increasingly preferred over REST- or GraphQL-based service APIs in practice. Despite its widespread adoption, gRPC lacks any advanced privacy techniques beyond transport encryption and basic token-based authentication. Such advanced techniques are, however, increasingly important for fulfilling regulatory requirements. For instance, anonymizing or otherwise minimizing (personal) data before responding to requests, or pre-processing data based on the purpose of the access may be crucial in certain usecases. In this paper, we therefore propose a novel approach for integrating such advanced privacy techniques into the gRPC framework in a practically viable way. Specifically, we present a general approach along with a working prototype that implements privacy techniques, such as data minimization and purpose limitation, in a configurable, extensible, and gRPC-native way utilizing a gRPC interceptor. We also showcase how to integrate this contribution into a realistic example of a food delivery use case. Alongside these implementations, a preliminary performance evaluation shows practical applicability with reasonable overheads. Altogether, we present a viable solution for integrating advanced privacy techniques into real-world gRPC-based microservice architectures, thereby facilitating regulatory compliance “by design”.",International Conference on Web Engineering,2024,,,,,215-229,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_15
Trusting Decentralized Web Data in a Solid-Based Social Network,"Valentin Siegert, Dirk Leichsenring & Martin Gaedke","Distributed and Self-organizing Systems, Chemnitz University of Technology, Chemnitz, Germany",,"In our current data-centric society, there is a rising concern among individuals regarding their privacy and the degree of control they have over their personal data. In response to this growing demand for transparency and control, a recent initiative for web re-decentralization has emerged, wherein web applications no longer store data centrally. One of the prominent approaches aimed at re-decentralizing the web is Solid. Solid facilitates data storage in decentralized pods secured with web access control, enabling seamless connectivity of diverse data. However, the integration of decentralized data from various third-party pods in web applications poses a significant challenge, as the data’s trustworthiness may be compromised, potentially leading to malicious or harmful outcomes. Therefore, data integration necessitates a trust-aware decision, i.e., the extent to which the data is trustworthy enough to use despite its high heterogeneity. To enable such trust awareness for web applications utilizing decentralized data, we propose a trust-aware framework called TrADS for decentralized social networks. TrADS leverages the MVC pattern of web applications to integrate external data from Solid pods trust aware. The potentially malicious and harmful status of external data is an end-user concern. A web application must therefore be trust aware to provide a better user experience. Therefore, we evaluate the proposed trust-aware decentralized social network in terms of usability and transparency with 53 end users through an empirical study. The results demonstrate that the trust awareness component in TrADS can support end users in their trustworthy user experience.",International Conference on Web Engineering,2024,,,,,230-245,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_16
Combining Anti-typosquatting Techniques,"Francesco Blefari, Angelo Furfaro, Giovambattista Ianni & Alessandro Viscomi; Francesco Blefari","IMT Schools for Advanced Studies, Lucca, LU, Italy; University of Calabria, Rende, CS, Italy",,"Typosquatting constitutes a widely used malpractice of domain exploitation that leverages users’ typographical errors when entering URLs. Different techniques have been devised to mitigate this threat and some tools have been developed. However, currently there are almost no tools available to web users. We propose a comprehensive open-source software solution which combines state-of-the-art typosquatting detection techniques and it is freely available as a dedicated extension for the web browser Chrome, named TypoAlert. TypoAlert is designed to automatically detect in real-time when a user visits a typosquatted domain and alerts the user accordingly. An assessment done through the analysis of a significant number of domains shows the effectiveness of the approach.",International Conference on Web Engineering,2024,,,,,246-254,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_17
The Programmable World and Its Emerging Privacy Nightmare,"Pyry Kotilainen, Tommi Mikkonen & Niko Mäkitalo; Ali Mehraj","University of Jyväskylä, Jyväskylä, Finland; Tampere University, Tampere, Finland",,"So-called programmable world refers to a paradigm where we are surrounded by intelligent, programmable devices that communicate with each other to support us in our daily activities. Furthermore, these systems are intimately addressing data that we produce and consume, both as such as well as via machine learning (ML) and artificial intelligence (AI). The fashion the data is treated in the network is a subject to regulatory, ethical and privacy concerns, however. In this paper, we study data and ML/AI related privacy concerns that emerge in the context of such programmable world, and how to take them into account when realizing the programmable world vision. In particular, we wish to enable composing systems so that constraints emerging from privacy concerns can be satisfied, but without risking the flexibility when composing complex networked systems, where data related operations are essential.",International Conference on Web Engineering,2024,,,,,255-262,2,3,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_18
Weakly-Supervised Left-Center-Right Context-Aware Aspect Category and Sentiment Classification,"Gonem Lau, Flavius Frasincar & Finn van der Knaap","Erasmus University Rotterdam, Burgemeester Oudlaan 50, 3062 PA, Rotterdam, The Netherlands",,"Aspect-Based Sentiment Analysis (ABSA) aims to extract all aspects mentioned in a Web review and classify the aspect category and sentiment for each aspect. Most existing methods rely on single-task supervised approaches. However, ABSA tasks are not independent. Furthermore, obtaining labeled data might be difficult or expensive. The Context-aware Aspect category and Sentiment Classification (CASC) model addresses this issue by classifying categories and sentiments simultaneously using a weakly-supervised approach. However, CASC uses a simple neural network on the input text that does not exploit any other information. This paper proposes an extension named Left-Center-Right+CASC (LCR+CASC), where we implement a sophisticated neural model that exploits the location of explicit aspect expressions. Besides aspect categorization and sentiment classification, LCR+CASC also extracts target expressions from a sentence, which goes beyond CASC’s abilities. This paper conducts two experiments on restaurant reviews: extracting target expressions and using annotated data that provide targets to evaluate the proposed model. Results show that LCR+CASC outperforms CASC when targets are given, and is able to extract target expressions to some extent.",International Conference on Web Engineering,2024,,,,,265-280,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_19
TraQuLA: Transparent Question Answering Over RDF Through Linguistic Analysis,"Elizaveta Zimina, Kalervo Järvelin, Jaakko Peltonen & Jyrki Nummenmaa; Aarne Ranta","Tampere University, Tampere, Finland; University of Gothenburg, Gothenburg, Sweden",,"Answering complex questions over knowledge graphs has gained popularity recently. Systems based on large language models seem to achieve top performance. However, these models may generate content that looks reasonable but is incorrect. They also lack transparency, making it impossible to exactly explain why a particular answer was generated. To tackle these problems we present the TraQuLA (Transparent QUestion-answering through Linguistic Analysis) system – a rule-based system developed through linguistic analysis of datasets of complex questions over DBpedia and Wikidata. TraQuLA defines a question’s type and extracts its semantic component candidates (named entities, properties and class names). For the extraction of properties, whose natural language verbalisations are most diverse, we built an extensive database which matches DBpedia/Wikidata properties to natural language expressions, allowing linguistic variation. TraQuLA generates semantic parses for the components and ranks them by each question’s structure and morphological features. The ranked parses are then analysed top down according to their patterns, also noting linguistic aspects, until a solution is found and a SPARQL query is produced. TraQuLA outperforms the existing baseline systems on the LC-QuAD 1.0 and competes with ChatGPT-based systems on LC-QuAD 2.0. For the LC-QuAD 1.0 test set, we developed an evaluation approach that accepts multiple ways to answer the questions (some ignored by the dataset) and curated some errors. TraQuLa contains no “black boxes” of neural networks or machine learning and makes its answer construction traceable. Users can therefore better rely on them and assess their correctness.",International Conference on Web Engineering,2024,,,,,19-33,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_2
"Subjectivity, Polarity and the Aspect of Time in the Evolution of Crowd-Sourced Biographies","Constantinos Romantzis, Evangelos Mathioudis, Ioannis Katakis & Pantelis Agathangelou; Alexandros Karakasidis; Jahna Otterbacher","Department of Computer Science, School of Sciences and Engineering, University of Nicosia, 2417, Nicosia, Cyprus; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Faculty of Pure and Applied Sciences, Open University of Cyprus, Nicosia, Cyprus",,"This study examines the use of subjective and sentimentally charged language in crowd-sourced articles by focusing on time and how articles in environments like Wikipedia tend to evolve as edits are made by multiple contributors. More specifically, we measure linguistic subjectivity (the systematic, asymmetrical use of language) using Mean Abstraction Level, an established subjectivity measure, and polarity (the use of positively or negatively sentimentally charged words) through time. For the latest case, we introduce a new measure called Polarity Density. We focus on Wikipedia biographies and their evolution over time and we perform a detailed analysis per gender and per personality category. Our empirical evaluation provides evidence of increased subjectivity in female biographies as per personality category and per gender, while the same also occurs when considering sentimental charge over time.",International Conference on Web Engineering,2024,,,,,281-295,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_20
Investigating the Usefulness of Product Reviews Through Bipolar Argumentation Frameworks,Atefeh Keshavarzi Zafarghandi; Ji Qi & Erik Tjong Kim Sang; Laura Hollink & Davide Ceolin,"Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Vrije Universiteit Amsterdam, Amsterdam, The Netherlands; Netherlands eScience Center, Amsterdam, The Netherlands",,"The importance of useful product reviews cannot be overstated, as they not only provide crucial information to potential buyers but also offer valuable feedback to the businesses or individuals under review. Providing useful reviews to consumers has gained significant attention as an effective market analysis tool for companies. Numerous studies have delved into the facets that contribute to predicting the usefulness of reviews, encompassing a spectrum from philosophical insights to advancements in artificial intelligence. In this work, we study how to use the argument structure of reviews to identify the most useful reviews in a set of annotated product reviews. In particular, we use quantitative bipolar argumentation frameworks (QBAFs) to construct a model of review arguments and topics, and we apply reasoning to such a model to identify useful reviews. Our results show that indeed argument reasoning, and QBAFs in particular, provide an insightful and well-performing means to analyze the usefulness of reviews.",International Conference on Web Engineering,2024,,,,,296-308,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_21
Interaction Design Patterns of Web Chatbots,Verena Traubinger & Martin Gaedke,"Faculty of Computer Science, Chemnitz University of Technology, Chemnitz, Germany",,"Chatbots are often used in the web as an additional user interface which offers different modalities for users. Still, there is not yet an established catalogue of interaction patterns across different chatbot implementations, while this is the case for graphical user interfaces. Such a catalogue will give web engineers an orientation in developing chatbots, which will in turn lead to users more easily recognizing common functionalities of chatbots. This short paper is mapping known chatbot functionalities to already established interaction design patterns from graphical user interfaces. For this, these frameworks were assessed on their relevance towards web interfaces before systematically mapping them onto each other by regarding their similarities in the categories Situation, Intention and Implementation. From the result, we discuss similarities and differences which are influencing the specific use of interaction design patterns in web chatbots and formulate the ensuing 12 chatbot interaction patterns in a catalogue for web engineers.",International Conference on Web Engineering,2024,,,,,309-317,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_22
Estimating Diffusion Degree on Graph Stream Generated from Social and Web Networks,"Vinit Ramesh Gore, Suman Kundu & Anggy Eka Pratiwi","Department of Computer Science and Engineering, IIT Jodhpur, Jodhpur, India",,"Data stream generated from different Web 2.0 applications may contains data which is best described by graphs. Graph streams thus generated show big data characters, including volume and velocity. The challenges of graph stream algorithms are twofold; each edge needs to be processed only once (due to velocity), and it needs to work on highly constrained memory (due to volume). Diffusion degree, a measure of node centrality, can be calculated for static graphs using a single Breadth-First Search (BFS). However, tracking Diffusion Degree in a graph stream is nontrivial. This paper proposes an estimator for diffusion degree for graph streams, which can be used to extract top-k influencing nodes for viral marketing in social networks. Comparative experiments show that the proposed graph stream algorithm is equivalent to or better than the exact diffusion degree-based algorithm.",International Conference on Web Engineering,2024,,,,,318-326,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_23
Task Manager of Quantum Web Services Through a Load Balancing Solution,"Jaime Alvarado-Valiente, Javier Romero-Álvarez, Enrique Moguel, José Garcia-Alonso & Juan M. Murillo","Quercus Software Engineering Group, Universidad de Extremadura, Cáceres, Spain",,"In the dynamic field of quantum computing, characterized by constant innovation and continuous advancement of hardware and software capabilities, it is clear that this emerging technology holds immense potential in fields such as medicine and security. However, as the quantum computing ecosystem expands, it introduces a unique set of challenges for developers and researchers. One of the main challenges facing developers in the quantum field is the great diversity of quantum service providers. Each of these service providers has different ways of managing the execution tasks and returning the results, which is a problem when trying to execute the same circuit in different providers. In response to this, we present an approach to the management of quantum web services in the cloud, following web engineering techniques. This solution uses load balancing and resource allocation techniques to improve the execution of quantum tasks across multiple providers. The proposal is based on a Quantum Load Balancer that dynamically allocates tasks to the most suitable provider based on availability, performance, and cost. In addition, a Task Manager is introduced that integrates the balancer with a resource manager and a quantum task scheduler to provide a seamless and efficient user experience. The proposal is evaluated through a set of experiments on real quantum hardware and simulators from different quantum service providers, such as Amazon Braket and IBM Quantum. The evaluation results demonstrate a significant average reduction in response times, with an average reduction of 31.6% when the load balancer is employed.",International Conference on Web Engineering,2024,,,,,329-343,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_24
How Many Web APIs Evolve Following Semantic Versioning?,Souhaila Serbout & Cesare Pautasso,"Software Institute (USI), Lugano, Switzerland",,"More and more Web APIs use semantic versioning to represent the impact of changes on clients depending on previous versions. Our goal is to provide insights about the extent to which evolving Web APIs align with semantic versioning rules. In this paper we present the results of an empirical study on the descriptions of 3 075 Web APIs, which released at least one new version throughout their history. The APIs descriptions were mined by retrieving 132 909 commits from 2 028 different open source GitHub repositories. We systematically collected and examined 506 273 changes of 195 different types released within 16 053 new API versions. We classified whether each change is likely to break clients or not, and checked whether the corresponding version identifier has been updated following semantic versioning rules. The results indicate that in the best case, only 517 APIs consistently release major upgrades when introducing breaking changes, while 1 970 APIs will not always correctly inform their clients about breaking changes released as part of minor or patch-level upgrades. We also detected 927 APIs which use a backwards-compatible evolution strategy, as they never introduce any breaking change throughout their history.",International Conference on Web Engineering,2024,,,,,344-359,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_25
GitHub-Sourced Web API Evolution: A Large-Scale OpenAPI Dataset,Fabio Di Lauro,"Università della Svizzera Italiana (USI), Lugano, Switzerland",,"This study presents a dataset curated using a software tool called the crawler, which gathers OpenAPI Specifications (OAS) from GitHub. The crawler efficiently collects versioned OAS files and metadata, reflecting API development evolution. It incorporates functionalities for updating, validating, parsing OAS files, ensuring dataset accuracy and relevance. With over three years of data, including 660,000 artifacts from 2.8 million commits, the dataset offers insights into OpenAPI standards adoption and its impact on API development. This paper discusses the dataset and crawler’s application in research and API development, highlighting their role in understanding API practices.",International Conference on Web Engineering,2024,,,,,360-368,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_26
MatchCom: Stable Matching-Based Software Services Composition in Cloud Computing Environments,Satish Kumar; Renyu Yang; Rajiv Ranjan Singh; Rami Bahsoon; Jie Xu; Rajkumar Buyya,"School of Built Environment, Engineering and Computing, Leeds Beckett University, Leeds, UK; School of Software, Beihang University, Beijing, China; School of Computer Science, University of Birmingham, Birmingham, UK; School of Computing and Information Systems, University of Melbourne, Melbourne, Australia; School of Computing, University of Leeds, Leeds, UK; Department of Cyber Security and Networks, Glasgow Caledonian University, Glasgow, UK",,"User preferences on throughput, latency, cost, service location, etc. indicate specific requirements when choosing a web service from the cloud marketplace. Service providers can also adopt preferences to prioritize a set of end-users based on their Service Level Agreement and service usage history. An effective matching between preferences from both parties enables fair service marketing in the cloud marketplace. The existing approaches are insufficient in capturing both parties’ preferences in the service composition process. To address this limitation, we propose MatchCom, a novel service composition approach driven by diverse preferences and formulate it as the stable marriage problem. Particularly, we present a novel fair preference ordering mechanism – in the context of a cloud marketplace, for enabling users to specify services provider ranking based on the capability they can provision, and for helping providers select the most suitable users to be served given users’ profile. MatchCom extends the Gale-Shapely Algorithm with a service composer algorithm for optimising the stable service composition. We evaluate MatchCom on a service-oriented system with 10 abstract services, each of which has 100 candidate web services. We establish through the experimental results that MatchCom outperforms other baseline approaches and can maximize end-user satisfaction in the composition process.",International Conference on Web Engineering,2024,,,,,369-377,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_27
Demonstrating Liquid Software in IoT Using WebAssembly,"Pyry Kotilainen, Viljami Järvinen, Teemu Autto & Tommi Mikkonen; Lakshan Rathnayaka","Faculty of Computing, Tampere University, Tampere, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland",,"In this paper we introduce a demonstration of our prototype orchestration system utilising WebAssembly to achieve isomorphism for a liquid software IoT system. The demonstration hardware consists of two Raspberry Pi IoT devices and a computer acting as the orchestrator. The audience can interact with the orchestrator through a web interface to deploy different software configurations to the devices, and observe the deployment process as well as the deployed application in action.",International Conference on Web Engineering,2024,,,,,381-384,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_28
KITspotlight: A System for Spotlighting Researchers in the Media,"Michael Färber, Benjamin Zagoruiko & Markus Wambach","Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",,"Academic institutions, such as universities, heavily rely on public relations and are thus interested in media monitoring. However, tracking mentions of their researchers in news articles presents challenges such as identifying affiliated personnel and their departments, and aggregating the extracted information. In this paper, we introduce KITspotlight, a novel system that automatically identifies researchers of the Karlsruhe Institute of Technology (KIT) in newspaper articles, associates these individuals with their departments, and presents this information visually. KITspotlight is tailored for both department heads, administrative staff, and individual researchers, focussing on the institution’s overall public visibility or individual researcher’s public appearance. Analyzing data from 2,280 articles over 12 months, our system offers a model for monitoring academic personnel at any research institution.",International Conference on Web Engineering,2024,,,,,385-388,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_29
Inclusive Counterfactual Generation: Leveraging LLMs in Identifying Online Hate,M. Atif Qureshi; Arjumand Younus; Simon Caton,"School of Computer Science, University College Dublin, Dublin, Ireland; ADAPT Centre, eXplainable Analytics Group, Faculty of Business, Technological University Dublin, Dublin, Ireland; School of Information and Communication Studies, University College Dublin, Dublin, Ireland",,"Counterfactually augmented data has recently been proposed as a successful solution for socially situated NLP tasks such as hate speech detection. The chief component within the existing counterfactual data augmentation pipeline, however, involves manually flipping labels and making minimal content edits to training data. In a hate speech context, these forms of editing have been shown to still retain offensive hate speech content. Inspired by the recent success of large language models (LLMs), especially the development of ChatGPT, which have demonstrated improved language comprehension abilities, we propose an inclusivity-oriented approach to automatically generate counterfactually augmented data using LLMs. We show that hate speech detection models trained with LLM-produced counterfactually augmented data can outperform both state-of-the-art and human-based methods.",International Conference on Web Engineering,2024,,,,,34-48,2,3,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_3
Towards Pricing4SaaS: A Framework for Pricing-Driven Feature Toggling in SaaS,"Alejandro García-Fernández, José Antonio Parejo, Pablo Trinidad & Antonio Ruiz-Cortés","SCORE Lab, I3US Institute, Universidad de Sevilla, Seville, Spain",,"In a rapidly evolving digital marketplace, the ability to enable features and services dynamically on SaaS products in alignment with market conditions and pricing strategies is essential for sustaining competitiveness and improving the user experience. This demo paper presents Pricing4SaaS, a reference architecture designed to enhance the integration and management of pricing-driven feature toggles in SaaS systems. It centralizes the configuration of the pricing structure, spreading its changes across the whole application every time it is modified, while securing state synchronization between both the client and server. Additionally, a case study integrating a reference implementation of Pricing4SaaS inside a Spring+React PetClinic project demonstrates how such approach can be leveraged to optimize developer productivity, reducing technical debt, and improving operational efficiency.",International Conference on Web Engineering,2024,,,,,389-392,2,4,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_30
Utilizing DNS and VirusTotal for Automated Ad-Malware Detection,Florian Nettersheim & Stephan Arlt; Michael Rademacher,"University of Applied Sciences Bonn-Rhein-Sieg, Sankt Augustin, Germany; Federal Office for Information Security, Bonn, Germany",,"In this paper, we present a novel approach to the automated detection of ad-malware. We efficiently crawl a vast set of websites and extensively fetch all HTTP requests embedded in these websites.Then we query these requests both against filtered DNS resolvers and VirusTotal. The idea is to evaluate, how much content is labeled as a potential threat. The results show that up to 8.8% of the domains found in our approach are labeled as suspicious. Moreover, up to 3.2% of these domains are categorized as ad-malware. However, the overall responses from the used services paint a divergent picture: Both DNS resolvers and VirusTotal have different understandings to the definition of suspicious content.",International Conference on Web Engineering,2024,,,,,393-396,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_31
A User Interface Design for Collaborations Between Humans and Intelligent Vehicles,"Yong Zhao, Yatai Ji, Sihang Qiu, Zhengqiu Zhu & Rusheng Ju","National University of Defense Technology, Changsha, China",,"Intelligent vehicles have been widely applied in the industry, academia, and our daily lives, to complete various tasks. However, existing AI that drives intelligent vehicles sometimes falls short as they may not ensure completeness or optimality, leading to issues like local optima or infinite loops. In response to these limitations, we proposed a user interface design for online crowdsourcing tasks, which enables collaborations between crowd workers and intelligent vehicles. This design aims to bolster existing intelligent vehicles’ AI with human intelligence as external support, while also leveraging AI predictions to minimize human effort. This research provides significant insights into the design of collaborative systems that effectively integrate human and artificial intelligence.",International Conference on Web Engineering,2024,,,,,397-400,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_32
Utilizing a Standards-Based Toolchain to Model and Execute Quantum Workflows,"Martin Beisel, Johanna Barzen, Frank Leymann, Lavinia Stiliadou & Benjamin Weder; Jaime Alvarado-Valiente & Javier Romero-Álvarez","University of Extremadura, Quercus Software Engineering Group, Badajoz, Spain; University of Stuttgart, Institute of Architecture of Application Systems, Stuttgart, Germany",,"The increasing availability of quantum devices via the cloud led to a multitude of commercial and scientific tools for developing quantum applications. However, since quantum applications are typically hybrid, comprising both quantum and classical parts, these tools are very heterogeneous. Therefore, combining them within a single application is complicated by incompatible programming languages, data formats, and interfaces. Hence, to enable the development of portable and interoperable quantum applications a standards-based toolchain is required. In this demonstration, we present a holistic toolchain for developing quantum applications utilizing well-established standards for defining workflows, deployment topologies, application interfaces, and provenance data. To demonstrate the practical feasibility of our toolchain, we showcase it for two use cases from the cryptography and machine learning domains.",International Conference on Web Engineering,2024,,,,,401-405,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_33
A Prototype Design of LLM-Based Autonomous Web Crowdsensing,"Zhengqiu Zhu, Yatai Ji, Sihang Qiu, Yong Zhao, Kai Xu, Rusheng Ju & Bin Chen","National University of Defense Technology, Changsha, China",,"The expanded demands of complex sensing campaigns involving Cyber-Physical-Social spaces have brought forth a multitude of challenges for web crowdsensing applications, such as substantial human efforts, potential user privacy breaches, and interest diminishes of users. Significant advancements have occurred in the application of Large Language Models (LLMs) for various tasks, such as conversational engagement, social simulation, and decision-making. Despite this, their potential to empower web crowdsensing activities is under-explored. To bridge this gap, we explore the design of a LLM-based autonomous web crowdsensing framework for flood-related data collection to mitigate the workload and professional demands on individuals in this poster.",International Conference on Web Engineering,2024,,,,,406-409,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_34
Web Crowdsourcing for Coastal Flood Prevention and Management,"Sihang Qiu, Yatai Ji, Zhengqiu Zhu, Yong Zhao, Rusheng Ju & Xiaohui Wang","National University of Defense Technology, Changsha, China",,"Coastal floods have been causing massive casualties and economic loss to human societies. To better understand and manage coastal floods, existing research has comprehensively studied their physical processes, but we still face the challenges of inaccurate predictions, insufficient information, and imprecise management. Web crowdsourcing has emerged as an effective tool to collect and leverage crowd intelligence. However, there is a research gap in terms of using web crowdsourcing to aid flood disaster prevention and management. Therefore, in this poster, we present a crowdsourcing design that uses various web applications and technologies, to improve flood prediction, collect necessary information, and help in management optimization.",International Conference on Web Engineering,2024,,,,,410-413,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_35
Unveiling Human-AI Interaction and Subjective Perceptions About Artificial Intelligent Agents,"Mathyas Giudici, Federica Liguori, Andrea Tocchetti & Marco Brambilla","Politecnico di Milano, DEIB, 20133, Milano, Italy",,"This work focuses on human-AI interactions, employing a crowd-based methodology to collect and assess the reactions and perceptions of a human audience to a dialogue between a human and an artificial intelligent agent. The study is conducted through a live streaming platform where human streamers broadcast interviews to a custom-made GPT voice interface. The questions extracted from the dialogues were categorized based on emotional and cognitive criteria. Our method covers thematic, emotional, and sentiment analyses of the comments platform users shared during the interview. This work aims to contribute to Human-Computer Interaction (HCI) and Human-Centered AI, emphasizing the need for a paradigm shift in AI research from focusing on technological development to considering its impact on human beings.",International Conference on Web Engineering,2024,,,,,414-418,2,3,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_36
EMiGRe: Unveiling Why Your Recommendations are Not What You Expect,"Herve-Madelein Attolou, Katerina Tzompanaki & Dimitris Kotzinos; Kostas Stefanidis","ETIS, CY Cergy Paris University, ENSEA, CNRS UMR8051, Paris, France; Tampere University, Tampere, Finland",,"This demonstration showcases EMiGRe, a system tailored for computing explanations for missing recommendations in a graph-based recommendation system. The users can interact with the system through our intuitive visualization interface to navigate the graph, select their missing recommendations, choose their preferred explanation mode (add or remove user actions), and finally consume the explanations in textual or graphical form. n. Throughout, they are guided through important steps of EMiGRe (The source code for this demonstration is available here https://git.cyu.fr/hattolou/emigre_icwe2024) and useful statistics that clarify the scenario.",International Conference on Web Engineering,2024,,,,,419-423,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_37
Handling Data Transformations in Virtual Knowledge Graphs with RML View Unfolding,Julián Arenas-Guerrero,"Universidad Politécnica de Madrid, Madrid, Spain",,"Although declarative data transformation functions defined in RML-FNML were implemented in KG materialization systems, they have not yet been studied or implemented in virtual knowledge graph systems. In this work we propose to translate RML-FNML mapping to RML Views, which can be transparently used by virtual knowledge graph systems without modifying them. We implemented a research prototype of RML-FNML to RML Views unfolding and applied it to GTFS data to show the feasibility of the approach.",International Conference on Web Engineering,2024,,,,,424-427,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_38
MyLearningTalk: An LLM-Based Intelligent Tutoring System,"Ludovica Piro, Tommaso Bianchi, Luca Alessandrelli, Andrea Chizzola, Daniela Casiraghi, Susanna Sancassani & Nicola Gatti","Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, 20133, Milan, Italy",,"Thanks to recent advancements in natural language interaction, dialogue-based online Intelligent Tutoring Systems (ITS) employing Large Language Models (LLMs) have begun to emerge. However, the effective design of LLM-based ITS interfaces to support learning still requires attention. In this demo, we present the initial implementation of MyLearningTalk (MLT), a web-based ITS powered by LLMs. MLT exploits state-of-the-art techniques such as retrieval augmented generation to offer interactive features to provide users with grounded answers and a tailored experience to enhance and facilitate the learning process.",International Conference on Web Engineering,2024,,,,,428-431,2,4,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_39
Decentralized Search over Personal Online Datastores: Architecture and Performance Evaluation,"Mohamed Ragab, Yury Savateev, Thanassis Tiropanis & Adriane Chapman; Helen Oliver, Alexandra Poulovassilis & George Roussos; Ruben Taelman","School of Computing and Mathematical Sciences, Birkbeck, University of London, London, UK; School of Electronics and Computer Science, University of Southampton, Southampton, UK; IDLab, Department of Electronics and Information Systems, Ghent University - imec, Ghent, Belgium",,"Data privacy and sovereignty are open challenges in today’s Web, which the Solid (https://solidproject.org) ecosystem aims to meet by providing personal online datastores (pods) where individuals can control access to their data. Solid allows developers to deploy applications with access to data stored in pods, subject to users’ permission. For the decentralised Web to succeed, the problem of search over pods with varying access permissions must be solved. The ESPRESSO framework takes the first step in exploring such a search architecture, enabling large-scale keyword search across Solid pods with varying access rights. This paper provides a comprehensive experimental evaluation of the performance and scalability of decentralised keyword search across pods on the current ESPRESSO prototype. The experiments specifically investigate how controllable experimental parameters influence search performance across a range of decentralised settings. This includes examining the impact of different text dataset sizes (0.5 MB to 50 MB per pod, divided into 1 to 10,000 files), different access control levels (10%, 25%, 50%, or 100% file access), and a range of configurations for Solid servers and pods (from 1 to 100 pods across 1 to 50 servers). The experimental results confirm the feasibility of deploying a decentralised search system to conduct keyword search at scale in a decentralised environment.",International Conference on Web Engineering,2024,,,,,49-64,2,2,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_4
Dynamic Hybrid Recommendation System for E-Commerce: Overcoming Challenges of Sparse Data and Anonymity,Kailash Chowdary Bodduluri & Arianit Kurti; Francis Palma; Ilir Jusufi; Henrik Löwenadler,"Blekinge Institute of Technology, 37179, Karlskrona, Sweden; Linnaeus University, Universitetsplatsen 1, 35252, Växjö, Sweden; SE+AI Lab, Faculty of Computer Science, University of New Brunswick, Fredericton, Canada; Enode, 35230, Växjö, Sweden",,"In the evolving landscape of e-commerce, personalizing user experience through recommendation systems has become a way to boost user satisfaction and engagement. However, small-scale e-commerce platforms struggle with significant challenges, including data sparsity and user anonymity. These issues make it hard to effectively implement recommendation systems, resulting in difficulty in recommending the right products to users. This study introduces an innovative Hybrid Recommendation System (HRS) to address challenges in e-commerce personalization caused by data sparsity and user anonymity. By blending multiple dimensions of the data into one unified system for producing recommendations, this system represents a notable advancement in web engineering for achieving personalized user experiences in the context of limited data. This research emphasizes the significance of innovative and tech-driven solutions in transforming small-scale e-commerce platforms, providing direction for future research and development in the field.",International Conference on Web Engineering,2024,,,,,435-440,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_40
Model-Driven Development of Single Page Applications,Alexander Müller-Lobeck & Gefei Zhang,"Hochschule für Technik und Wirtschaft, Berlin, Germany",,"Prevalent approaches to Model-Driven Web Engineering focus on traditional, hypertext-based web applications, but do not scale well for modern, single page applications (SPAs), where the functionalities are rather reflected by changes of their HTML elements’ properties and dependencies between them than hypertext structures and navigation paths. In the realm of SPAs, modeling, formal model validation, and code generation need better support. We propose an approach to the model-driven development of SPAs. We model the behavior of SPAs with UML state machines and translate these to JavaScript as well as a formal specification, which can be formally verified. Our approach thus provides an intuitive and easy-to-use means, which is backed by formal methods, to model-driven development of SPAs.",International Conference on Web Engineering,2024,,,,,441-447,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_41
Sequential Group Recommendations with Responsibility Constraints,Maria Stratigi,"University of Tampere, Tampere, Finland",,"This paper addresses the aspects of fairness and transparency in Group Recommender Systems (GRS), crucial for fostering user trust and system reliability. With Recommender Systems (RS) being pivotal in modern applications, ensuring responsible recommendation techniques is paramount. We focus on two key responsibility constraints: fairness and transparency. Fairness in group recommendations poses challenges, particularly in the context of sequential recommendation rounds. We introduce the concept of sequential group recommendations, emphasizing the need to consider multiple rounds to prevent bias against any group member and ensure overall satisfaction. Additionally, we explore transparency in recommendations, proposing explanations for why certain items are excluded from recommendation lists. Our work enhances the ethical and user-centric aspects of web engineering, which are essential for the success of web applications.",International Conference on Web Engineering,2024,,,,,448-452,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_42
Overview of Serendipity in Recommender Systems,Denis Kotkov,"Department of Computer Science, University of Helsinki, Yliopistonkatu 4, 00100, Helsinki, Finland",,"Has it ever happened to you that services like Spotify, Netflix or YouTube showed you recommendations on the same topic over and over again? This might be caused by the lack of serendipity in recommender systems of these services. Recommender systems are software tools that suggest items, such as audio recordings or videos, of interest to users. Meanwhile, serendipity is the property of these systems, which indicates the degree, to which they suggest items that pleasantly surprise users. In this talk, I will provide an overview of serendipity in recommender systems. In particular, I will talk about how the concept of serendipity has been defined and measured in recommender systems, and what experiments have been conducted to investigate this concept. I will also touch on recommendation algorithms designed to suggest serendipitous items and discuss future directions of the topic.",International Conference on Web Engineering,2024,,,,,453-457,2,3,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_43
Vanilla JS - Design and Implementation of a Progressive Web Application from Scratch,Tobias Münch,"Münch Ges. für IT Solutions mbH, Gewerbering 1, 49393, Lohne, Germany",,"Nowadays, web applications are developed using different kind of web frameworks. The usage of them is always a trade-off between comfort, resource efficiency, and long-term dependency. This dependency can have a negative effect on maintainability. The Vanilla JS approach avoids the use of frameworks and consequently relies on the strict use of W3C standards. In this tutorial, an offline-ready progressive web application (PWA) build, according to the frameworkless approach without increasing the development effort compared to development with respective frameworks. To solve this complex tasks, components of the web standard “Web Components"" are introduced and used. Additionally, patterns for state management and offline capability as well as routing between different pages are discussed. Finally, the sample application is extended by a responsive design. The sample application is build in an iterative way, so the participants will learn theoretical concepts as well as practical implementation.",International Conference on Web Engineering,2024,,,,,461-464,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_44
Quantum Service-Oriented Computing: A Practical Introduction to Quantum Web Services and Quantum Workflows,Martin Beisel & Benjamin Weder; Jose Garcia-Alonso & Juan M. Murillo,"Institute of Architecture of Application Systems, University of Stuttgart, Stuttgart, Germany; Quercus Software Engineering Group, University of Extremadura, Badajoz, Spain",,"Quantum applications are hybrid and require quantum and classical programs. Similar to classical applications, they can benefit from modularity, maintainability, and reusability. This can be achieved by implementing the different functionalities of quantum applications as independent web services. In this tutorial, we provide an overview of concepts to develop and execute quantum applications based on the paradigm of service-oriented computing. This includes the development of quantum web services and corresponding OpenAPI specifications. Further, these services are orchestrated using quantum workflows to achieve robustness, scalability, and reliability. Thereby, concepts and tools for their modeling, execution, and monitoring are introduced and practically applied.",International Conference on Web Engineering,2024,,,,,465-468,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_45
The Five Generations of Entity Resolution on Web Data,Konstantinos Nikoletos & George Papadakis; Ekaterini Ioannou,"University of Athens, Athens, Greece; Tilburg University, Tilburg, The Netherlands",,"Entity Resolution constitutes a core data integration task that has attracted a bulk of works on improving its effectiveness and time efficiency. This tutorial provides a comprehensive overview of the field, distinguishing relevant methods into five main generations. The first one targets Veracity in the context of structured data with a clean schema. The second generation extends its focus to cover Volume, as well, leveraging multi-core or massive parallelization to process large-scale datasets. The third generation addresses the additional challenge of Variety, targeting voluminous, noisy, semi-structured, and highly heterogeneous data from the Semantic Web. The fourth generation also tackles Velocity so as to process data collections of a continuously increasing volume. The latest works, though, belong to the fifth generation, involving pre-trained (large) language models which heavily rely on external knowledge to address all four Vs with high effectiveness.",International Conference on Web Engineering,2024,,,,,469-473,2,6,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_46
Tag-Aware Recommendation Based on Attention Mechanism and Disentangled Graph Neural Network,"Haojiang Yao, Dongjin Yu, Dongjing Wang, Haiping Zhang, Shiyu Song & Jiaming Li; Haojiang Yao & Dongjin Yu; Haiping Zhang","School of Information Engineering, Hangzhou Dianzi University, Hangzhou, 310005, China; Hangzhou Dianzi University Binjiang Institute Co., Ltd., Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China",,"Tag-aware recommender system leverages user-annotated historical data to enhance the understanding of user preferences and web service/item features, attracting widespread attention in academia and industry. However, most existing tag-aware recommender systems cannot effectively model the relationships among users, items, and tags, disrupting their comprehension of user preferences, item attributes, and tag semantics, thereby affecting recommendation performance. Therefore, we propose a tag-aware recommendation model based on attention mechanism and disentangled graph neural network (AM-DGNN). Specifically, we first construct three bipartite graphs describing user-tag, item-tag, and user-item relationships based on user-annotated historical data. Then, we utilize the multi-head attention mechanism on the first two relational graphs to integrate semantic information from tags into user and item representations, aiming to enhance the model’s understanding of user preferences and item features. Subsequently, on the user-item relational graph, we refine user and item feature representations to form intention subgraphs, describing the relationships between users and items under different intentions. Ultimately, we obtain intention-disentangled user and item representations to achieve the recommendation objective. Extensive experiments on two datasets demonstrate that the proposed model outperforms the baselines in tag-aware recommendation tasks.",International Conference on Web Engineering,2024,,,,,67-81,2,3,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_5
AutoMaster: Differentiable Graph Neural Network Architecture Search for Collaborative Filtering Recommendation,"Caihong Mu, Haikun Yu, Keyang Zhang & Qiang Tian; Yi Liu","School of Electronic Engineering, Xidian University, Xi’an, 710071, China; Xidian University, Xi’an, 710071, China",,"Graph Neural Networks (GNNs) have been widely applied in Collaborative Filtering (CF) and have demonstrated powerful capabilities in recommender systems (RSs). In recent years, there has been a heated debate on whether the non-linear propagation mechanism in Graph Convolutional Networks (GCNs) is suitable for CF tasks, and the performance of linear propagation is believed to be superior to non-linear propagation mainly in the field of RSs. Therefore, it is necessary to reexamine this issue: (1) whether linear propagation generally outperforms non-linear propagation, and (2) whether a combination of linear and non-linear propagation can be applied to CF tasks to achieve better accuracy. Furthermore, most existing studies design a single model architecture tailored to specific data or scenarios, and there remains a challenging and worthwhile problem to obtain the best-performing model in new recommendation data. To address the above issues, we propose a model called AutoMaster, which implements differentiable graph neural network architecture search for CF recommendation and automatically designs GNN architectures specific to different datasets. We design a compact and representative search space that includes various linear and non-linear graph convolutional layers, and employ a differentiable search strategy to search for the best-performing hybrid architecture in different recommendation datasets. Experimental results on five real-world datasets demonstrate that the GNN automatically achieved by the proposed AutoMaster contains both linear and nonlinear propagation, and outperforms several advanced GNN based CF models designed by the experienced human designers.",International Conference on Web Engineering,2024,,,,,82-98,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_6
A Multi-model Recurrent Knowledge Graph Embedding for Contextual Recommendations,Dionisis Kotzaitsis & Georgia Koloniari,"University of Macedonia, Thessaloniki, Greece",,"Recommenders can be improved by exploiting the huge disposal of multi-context data that is now available. Knowledge Graphs (KGs) offer an intuitive way to incorporate this kind of assorted data. This paper introduces a context-aware recommender, based on deriving graph embeddings by learning the representations of appropriate meta-paths mined from a graph database. Our system uses several LSTMs to model the meta-path semantics between a user-item pair, based on the length of the mined path, a Multi-head Attention module as an attention mechanism, along with a pooling and a recommendation layer. Our evaluation shows that our system is on par with state-of-the-art recommenders, while also supporting contextual modeling.",International Conference on Web Engineering,2024,,,,,99-114,2,1,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_7
Data Augmentation Using BERT-Based Models for Aspect-Based Sentiment Analysis,"Bron Hollander, Flavius Frasincar & Finn van der Knaap","Erasmus University Rotterdam, Burgemeester Oudlaan 50, 3062 PA, Rotterdam, The Netherlands",,"In today’s digital world, there is an overwhelming amount of opinionated data on the Web. However, effectively analyzing all available data proves to be a resource-intensive endeavor, requiring substantial time and financial investments to curate high-quality training datasets. To mitigate such problems, this paper compares data augmentation models for aspect-based sentiment analysis. Specifically, we analyze the effect of several BERT-based data augmentation methods on the performance of the state-of-the-art HAABSA++ model. We consider the following data augmentation models: EDA-adjusted (baseline), BERT, Conditional-BERT, BERT\(_{\textrm{prepend}}\), and BERT\(_{\textrm{expand}}\). Our findings show that incorporating data augmentation techniques can significantly improve the out-of-sample accuracy of the HAABSA++ model. Specifically, our results highlight the effectiveness of BERT\(_{\textrm{prepend}}\) and BERT\(_{\textrm{expand}}\), increasing the test accuracy from 78.56% to 79.23% and from 82.62% to 84.47% for the SemEval 2015 and SemEval 2016 datasets, respectively.",International Conference on Web Engineering,2024,,,,,115-122,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_8
Streamlining Vocabulary Conversion to SKOS: A YAML-Based Approach to Facilitate Participation in the Semantic Web,"Christoph Göpfert, Jan Ingo Haas, Lucas Schröder & Martin Gaedke","Technische Universität Chemnitz, 09111, Chemnitz, Germany",,"Controlled vocabularies, such as classification schemes, glossaries, taxonomies, or thesauri, play an important role in many Web services. One of the main areas of application of controlled vocabularies is the domain of information retrieval systems, as they can be used to improve the findability of resources. For instance, concepts described in a vocabulary may be used to uniquely classify resources, to tag them with relevant keywords, or to annotate them with domain-specific attributes. The Simple Knowledge Organization System (SKOS) is an established data model of the Semantic Web domain that can be used to describe vocabularies in a semantically structured format. However, modelling a vocabulary is oftentimes highly time demanding, labor-intensive, and requires both familiarity with basic Semantic Web technologies and expertise in the application domain. This complicates both the development of new vocabularies and the conversion of existing vocabularies into the RDF data model. We propose an intermediate, YAML-based format to express concepts and their relationships hierarchically. The intermediate format can be converted automatically into a SKOS vocabulary using a command-line conversion program. To demonstrate the feasibility of our approach, we selected 26 vocabularies of highly diverse formats, expressed them in the proposed intermediate format, which was subsequently converted in an automated manner into the corresponding SKOS vocabulary using our yaml2skos program. Our approach enables users with little to no familiarity with the Semantic Web to develop SKOS vocabularies, thereby lowering the barrier to participation in the Semantic Web landscape.",International Conference on Web Engineering,2024,,,,,123-130,2,0,https://link.springer.com/chapter/10.1007/978-3-031-62362-2_9
Special Issue on Advanced Practices in Web Engineering,J. G. Enríquez - | F. J. Domínguez-Mayo | M. J. Escalona,"Computer Languages and Systems, University of Seville, Avenida Reina Mercedes, Sevilla | Computer Languages and Systems, University of Seville, Avenida Reina Mercedes, Sevilla | Computer Languages and Systems, University of Seville, Avenida Reina Mercedes, Sevilla",,"Technological disruption is causing great changes and impact in our society in the way we live, work and how we relate to each other. This is due to the fact that Internet is a great communication tool as a means of influence is reflected in the advances and the continuous adaptation of users, practitioners and researchers to it. As soon as we implement intelligent technologies in our homes, factories or workplaces, the machinery and systems connected to the Internet are interacting, processing information and making decisions autonomously. Increasing new technologies and paradigms such as Artificial Intelligence or the Internet of Things and System of Systems, together with technologies such as Cloud Computing or Big Data, make the Fourth Industrial Revolution that we are living developing towards the optimization of processes and resources through the collection, use, and an intelligent analysis of processing of data.",JWE,2019,,18,04-Jun,,01-Apr,2,0,https://ieeexplore.ieee.org/document/10251818/
Discovery and Analysis About the Evolution of Service Composition Patterns,Zhenfeng Gao | Yushun Fan | Xiu Li | Liang Gu | Cheng Wu | Jia Zhang,"Graduate School at Shenzhen, Tsinghua University, Shenzhen, China | Tsinghua National Laboratory for Information Science and Technology, Beijing, China | Graduate School at Shenzhen, Tsinghua University, Shenzhen, China | Sangfor Technologies Inc., Shenzhen, China | Tsinghua National Laboratory for Information Science and Technology, Beijing, China | Department of Electrical and Computer Engineering, Carnegie Mellon University, Silicon Valley, California, USA",Topic evolution graph | service composition recommendation | topic model,"Service ecosystems, consisting of various kinds of services and mashups, usually keep evolving over time. Existing works on the evolution of service ecosystems focus on either evaluating the impacts of single services' changes on the usage of services and the stability of the whole ecosystem, or discovering co-occurrence relationship between services, but fail to disclose any knowledge from the aspect of the evolution of service composition patterns. Based on our previous work, this paper moves one step further, revealing the latent service composition trends in a service ecosystem and providing more distinct explanation of different topic evolution patterns. A novel methodology, named Extended Dependency-Compensated Service Co-occurrence LDA (EDC-SeCo-LDA), is developed to calculate the directed dependencies between different topics and build topic evolution graph. The evolution trend of service composition could be disclosed by the graph intuitively. What's more, EDC-SeCo-LDA proposes five different ways to adopt dependency compensation to improve the performance when making service recommendation. Experiments on ProgrammableWeb.com show that EDC-SeCo-LDA can reveal significant topic dependencies, and recommend service compo-sition more effectively, i.e., 6% better in terms of Mean Average Precision compared with baseline approaches.",JWE,2019,,18,7,,579-625,2,9,https://ieeexplore.ieee.org/document/10251866/
Model Driven Development of Gamified Applications,Piero Fraternali | Sergio Luis Herrera Gonzalez,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy | Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy",Model Driven Engineering | gamification | rapid prototyping | code generation | IFML,"Gamification is defined as the injection of game elements in applications with non-gaming purposes. This technique has shown outstanding results in promoting the engagement and activity on communities of users, in both business and non-for-profits fields. Often, gamification features are added late in the application life-cycle and must be weaved into the existing functions. In this paper, we present a model-driven approach to the design of gamified applications, which accelerates the introduction of gamification elements in pre-existing or new applications. The approach relies on a data model of gamification features and on design patterns for the front-end, which encode the essential elements of gamification in a platform independent way.",JWE,2019,,18,7,,655-694,2,8,https://ieeexplore.ieee.org/document/10251861/
Privacy-Preserving Reengineering of Model-View-Controller Application Architectures Using Linked Data,Juan Manuel Dodero | Mercedes Rodriguez-Garcia | Iván Ruiz-Rube | Manuel Palomo-Duarte,"School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain | School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain | School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain | School of Engineering, University of Cadiz, Puerto Real, Cádiz, Spain",Privacy by design | Web of data | Software architecture | Model View-Controller,"When a legacy system's software architecture cannot be redesigned, implementing additional privacy requirements is often complex, unreliable and costly to maintain. This paper presents a privacy-by-design approach to reengineer web applications as linked data-enabled and implement access control and privacy preservation properties. The method is based on the knowledge of the application architecture, which for the Web of data is commonly designed on the basis of a model-view-controller pattern. Whereas wrapping techniques commonly used to link data of web applications duplicate the security source code, the new approach allows for the controlled disclosure of an application's data, while preserving non-functional properties such as privacy preservation. The solution has been implemented and compared with existing linked data frameworks in terms of reliability, maintainability and complexity.",JWE,2019,,18,7,,695-727,2,0,https://ieeexplore.ieee.org/document/10251874/
A Semantic Web Approach to Enable a Smart Route to Historical Archives,Annamaria Goy | Diego Magro | Alessandro Baldo,"Dipartimento di Informatica, Università di Torino, Turin, Italy | Dipartimento di Informatica, Università di Torino, Turin, Italy | Dipartimento di Informatica, Università di Torino, Turin, Italy",Semantic Web | Intelligent Web applications | Ontology-driven Web applications | Digital Humanities | Web-based access to historical archives,"In this paper we show that an ontology-based approach can be beneficial for enhancing the access to cultural resources, and in particular historical documents. The paper starts with an overview of our approach, aimed at providing online archival systems with a semantic layer based on Semantic Web standards (OWL 2 and RDF). Two projects are introduced, namely Harlock900 and PRiSMHA, carried out in collaboration with local cultural institutions owning rich historical archives. In particular, the paper describes the computational ontologies supporting the approach, and then focuses on two case studies showing that our framework provides better results if compared with standard access systems. The case studies show the enhancement provided by a semantically rich representation of time intervals and a detailed formal description of events and their participants.",JWE,2019,,18,04-Jun,,287-318,2,5,https://ieeexplore.ieee.org/document/10251822/
A Boxology of Design Patterns for Hybrid Learning and Reasoning Systems,Frank van Harmelen | Annette ten Teije,"Department of Computer Science, Vrije Universiteit, Amsterdam, Netherlands | Department of Computer Science, Vrije Universiteit, Amsterdam, Netherlands",Hybrid systems | neurosymbolic systems | knowledge representation | machine learning | design patters,"We propose a set of compositional design patterns to describe a large variety of systems that combine statistical techniques from machine learning with symbolic techniques from knowledge representation. As in other areas of computer science (knowledge engineering, software engineering, ontology engineering, process mining and others), such design patterns help to systematize the literature, clarify which combinations of techniques serve which purposes, and encourage re-use of software components. We have validated our set of compositional design patterns against a large body of recent literature.",JWE,2019,,18,01-Mar,,97-123,2,112,https://ieeexplore.ieee.org/document/10247288/
Towards Improving Productivity in NMap Security Audits,Jose Manuel Redondo | Daniel Cuesta,"Department of Computer Science, Computational Reflection Research Group, University of Oviedo, Science Faculty, Oviedo, Spain | Computer Network Attack (CNA), S2Grupo, Valencia, Spain",nmap | web GUI | advanced features | productivity | Domain Specific Language | static type checking,"Maintaining an adequate security level in computer infrastructures, like Internet-facing web servers, requires periodic assessment of their vulnerabilities with specialized security tools. nmap is arguably the most popular one, due to its versatility, powerful features, and low resource usage. However, this versatility can turn its usage difficult and error-prone, as it implements a lot of features and reports errors at runtime. This can lead to suboptimal results while designing auditing tasks. This research aims to decrease this complexity by developing a web GUI that favors experimentation, on-demand scans, and provides solutions to several shortcomings detected in the official one. We complemented it with a Domain Specific Language that implements early detection and reporting of syntax, type, and semantic errors when creating audit tasks. Both expand nmap possibilities, creating robust, schedulable, distributable, and portable auditing tasks able to find anomalies analyzing their output. Our initial release shows that the web GUI has been well received by several security related media and professionals. The language can detect and report a wide range of potential errors, substantially increasing the robustness of the created tasks. Therefore, Domain Specific Languages with early detection of type errors turned to be suitable to lower the complexity and expand the usage possibilities of complex tools like nmap.",JWE,2019,,18,7,,539-577,2,12,https://ieeexplore.ieee.org/document/10251826/
On Twitter Bots Behaving Badly: A Manual and Automated Analysis of Python Code Patterns on GitHub,Andrea Millimaggi | Florian Daniel,"Politecnico di Milano, Milan, Italy | Politecnico di Milano, Milan, Italy",Bots | Harm | Abuse | Code patterns | Pattern recognition | GitHub | Twitter | Python,"Bots, i.e., algorithmically driven entities that behave like humans in online communications, are increasingly infiltrating social conversations on the Web. If not properly prevented, this presence of bots may cause harm to the humans they interact with. This article aims to understand which types of abuse may lead to harm and whether these can be considered intentional or not. We manually review a dataset of 60 Twitter bot code repositories on GitHub, derive a set of potentially abusive actions, characterize them using a taxonomy of abstract code patterns, and assess the potential abusiveness of the patterns. The article then describes the design and implementation of a code pattern recognizer and uses the pattern recognizer to automatically analyze a dataset of 786 Python bot code repositories. The study does not only reveal the existence of 28 communication-specific code patterns - which could be used to assess the harmfulness of bot code - but also their consistent presence throughout all studied repositories.",JWE,2019,,18,8,,801-835,2,11,https://ieeexplore.ieee.org/document/10247296/
Citation Count Prediction Using Abstracts,Takahiro Baba | Kensuke Baba | Daisuke Ikeda,"Kyushu University, Fukuoka, Japan | Fujitsu Laboratories, Kawasaki, Japan | Kyushu University, Fukuoka, Japan",Citation count prediction | Document classification | Text analysis | Machine learning,"Researchers are expected to find previous literature that is related to their research and potentially has a scientific impact from among a large number of publications. This paper addresses the problem of predicting the citation count of each research paper, that is, the number of citations from other papers to that paper. Previous literature related to the problem claims that the textual data of papers do not deeply affect the prediction compared with data about the authors and venues of publication. In contrast, the authors of this paper detected the citation counts of papers using only the paper abstracts. Additionally, they investigated the effect of technical terms used in the abstracts on the detection. They classified abstracts of papers with high and low citation counts and applied the classification to the abstracts modified by hiding the technical terms used in them. The results of their experiments indicate that the high and low of citation counts of research papers can be detected using their abstracts, and the effective features used in the prediction are related to the trend of research topics.",JWE,2019,,18,01-Mar,,207-228,2,8,https://ieeexplore.ieee.org/document/10247226/
Multi-Device Complementary View Adaptation with Liquid Media Queries,Andrea Gallidabino | Cesare Pautasso,"Faculty of Informatics, Software Institute, Università della Svizzera italiana, Lugano, Switzerland | Faculty of Informatics, Software Institute, Università della Svizzera italiana, Lugano, Switzerland",Liquid software | CSS media queries | multi-device adaptation | responsive user interface | complementary view adaptation,"Responsive Web applications assume that they run on a single device at a time. Developers use CSS3 media queries to declare how the Web application user interface adapts to specific capabilities (e.g., screen size or resolution) of individual devices. As users own and use multiple devices across which they attempt to run the same Web application at the same time, we propose to extend CSS media queries so that developers can also use them to dynamically adapt so-called liquid Web applications as they are seamlessly deployed across multiple devices. In this paper we present the concept of liquid media queries. They support features to detect the number of connected devices, the number of users running the application, or the role played by each device during the application execution. The liquid media query types and features defined in this paper are designed for component-based Web applications, and they enable developers to control the deployment and dynamic migration and cloning of individual Web components across multiple browsers. Furthermore we present the design of how liquid media queries are implemented within the Liquid.js for Polymer framework and the corresponding distributed adaptation algorithms. We discuss the implications of multi-device adaptation from the perspective of the developers and also the users of a liquid Web application. Finally we showcase the expressiveness of the liquid media queries to support real-world examples and evaluate the algorithmic complexity of our approach.",JWE,2019,,18,8,,761-800,2,4,https://ieeexplore.ieee.org/document/10247305/
Design Guidelines for Web Interfaces of Home Automation Systems Accessible via Screen Reader,Marina Buzzi | Barbara Leporini | Clara Meattini,"IIT-CNR, Pisa, Italy | ISTI-CNR, Pisa, Italy | ISTI-CNR, Pisa, Italy",Smart homes | home automation | accessible interfaces | blind users,"Home Automation Systems (HAS) - also referred to as smart homes - exploit multiple components such as sensors, RFID readers, wireless devices, and remote control systems to enable easy interaction with smart appliances and devices, and to automate performing sequences of tasks to make human-device interaction simpler and life more comfortable. For people with vision impairment, especially those who are unable to see at all, smart homes can be a powerful tool for enhancing personal autonomy, provided that the system offers suitable device integration and accessible interfaces with a simple interaction via keyboard, assistive technology and other modalities such as voice and gestures. This paper investigates the accessibility of web interfaces when interacting with HAS components via screen reader assistive technology, in order to propose potential suggestions to developers. Web interfaces are particularly considered in this study in order to support screen reader users who are not yet skilled in using touch-screen devices. Specifically, based on collected accessibility and usability issues, as well as users' expectations and preferences, a Web-based prototype has been designed and optimized especially for interaction via screen reader. After describing an evaluation conducted with a small group of skilled screen reader users, several guidelines are suggested for designers of HAS interfaces.",JWE,2019,,18,04-Jun,,477-511,2,20,https://ieeexplore.ieee.org/document/10251852/
"Applying Feature-Oriented Software Development in SaaS Systems: Real Experience, Measurements, and Findings",Oscar Pedreira | Fernando Silva-Coira | Ángeles Saavedra Places | Miguel R. Luaces | Leticia González Folgueira,"Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Facultade de Informática, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain | Enxenio S.L., A Coruña, Spain",feature oriented software development | feature oriented domain analysis | variability management | software as a service | feature model metrics,"Distributing software as a service (SaaS) has become a major trend for web-based systems. However, this software distribution model poses many challenges. One of them is feature variability, that is, some features of the system may be required by some users, but not by all of them. In addition, variability is more complex than just including or excluding a feature, since different types of relationships may exist between features. The implementation of this variability, and the parametrization and configuration of the system can be complex in this context, so the development process of a SaaS system must adequately address variability management. In this paper we present an experience applying feature oriented software development (FOSD) in the context of SaaS web-based systems development. We present a real experience in the development of a web-based system for managing home care services for dependent people. The article describes the problem of variability management in this domain, and the feature model of the system. Finally, we present an empirical evaluation of the feature model of the system based on data obtained from its real deployment after two years of use. The empirical evaluation was based on state-of-the-art measures for variability management, and revealed relevant insights for software development in this context.",JWE,2019,,18,04-Jun,,447-475,2,2,https://ieeexplore.ieee.org/document/10251854/
Traceability Management of Systems of Systems: A Systematic Review in the Assisted Reproduction Domain,Leticia Morales Trujillo | Julián Alberto García | David Lizcano | Manuel Mejías,"Web Engineering and Early Testing (IWT2) group, University of Seville, Escuela Té cnica Superior de Ingenierí a Informá tica, Sevilla, Spain | Web Engineering and Early Testing (IWT2) group, University of Seville, Escuela Té cnica Superior de Ingenierí a Informá tica, Sevilla, Spain | Universidad a Distancia de Madrid (UDIMA), Madrid, Spain | Web Engineering and Early Testing (IWT2) group, University of Seville, Escuela Té cnica Superior de Ingenierí a Informá tica, Sevilla, Spain",Systematic Literature Review | Systems of Systems | Biological Sample Management | Assisted Reproductive Treatment,"Over last decade, Assisted Reproductive Treatment (ART) has become a very used health service by more and more people around the world because of problems such as the delay in the maternity age, singleparent couples, etc. In this context, health agencies have performed innovations to improve healthcare processes of ARTs, to optimize the performance of health professionals who work in fertilization laboratories and to improve Biological Sample Management (BSM) and sample traceability in ART. However, there are important handicaps in ART processes from the point of view of quality, safety and management. On the one hand, these processes are mainly based on manual execution tasks and manual control tasks. This excess of manual tasks could lead to fatal traceability and safety errors during BSM. On the other hand, ART processes require real, interoperable and traceable communications between different software systems that have to collaborate together (health information systems, biological sample management systems, patient management systems, etc.), but, at present, it is possible to identify some limitations in this domain, that is, the domain of systems of systems (SoS). This paper aims to conduct an exhaustive study was carried out both in the research community and in the commercial field to identify and analyze SoS solutions and theoretical proposals for BSM in ART processes. We have applied the Systematic Literature Review (SLR) methodology to carry out our study and we conclude it is a very young research line that shows a growing trend and that in the actuality there are very few technologies that deal with the problem of the BSM in ART.After analyzing the results, this paper presents as future work an initial Model-Driven conceptual solution to improve BSM in ART.",JWE,2019,,18,04-Jun,,409-445,2,5,https://ieeexplore.ieee.org/document/10251823/
Automatic Detection and Analysis of the “Game Hack” Scam,Emad Badawi | Guy-Vincent Jourdan | Gregor Bochmann | Iosif-Viorel Onut,"Faculty of Engineering, University of Ottawa, Ottawa, Canada | Faculty of Engineering, University of Ottawa, Ottawa, Canada | Faculty of Engineering, University of Ottawa, Ottawa, Canada | IBM Centre for Advanced Studies, Ottawa, Canada",Game Hack scam | scam analysis | fraud detection | cyberattack,"The “Game Hack” Scam (GHS) is a mostly unreported cyberattack in which attackers attempt to convince victims that they will be provided with free, unlimited “resources” or other advantages for their favorite game. The endgame of the scammers ranges from monetizing for themselves the victims time and resources by having them click through endless “surveys”, filing out “market research” forms, etc., to collecting personal information, getting the victims to subscribe to questionable services, up to installing questionable executable files on their machines. Other scams such as the “Technical Support Scam”, the “Survey Scam”, and the “Romance Scam” have been analyzed before but to the best of our knowledge, GHS has not been well studied so far and is indeed mostly unknown. In this paper, our aim is to investigate and gain more knowledge on this type of scam by following a data-driven approach; we formulate GHS-related search queries, and used multiple search engines to collect data about the websites to which GHS victims are directed when they search online for various game hacks and tricks. We analyze the collected data to provide new insight into GHS and research the extent of this scam. We show that despite its low profile, the click traffic generated by the scam is in the hundreds of millions. We also show that GHS attackers use social media, streaming sites, blogs, and even unrelated sites such as change.org or jeuxvideo.com to carry out their attacks and reach a large number of victims. Our data collection spans a year; in that time, we uncovered 65,905 different GHS URLs, mapped onto over 5,900 unique domains. We were able to link attacks to attackers and found that they routinely target a vast array of games. Furthermore, we find that GHS instances are on the rise, and so is the number of victims. Our low-end estimation is that these attacks have been clicked at least 150 million times in the last five years. Finally, in keeping with similar large-scale scam studies, we find that the current public blacklists are inadequate and suggest that our method is more effective at detecting these attacks.",JWE,2019,,18,8,,729-760,2,8,https://ieeexplore.ieee.org/document/10247291/
OPT+: A Monotonic Alternative to OPTIONAL in SPARQL,Sijin Cheng | Olaf Hartig,"Department of Computer and Information Science (IDA), Linköping University, Sweden | Department of Computer and Information Science (IDA), Linköping University, Sweden",Semantic web | linked data | query language | optimization,"Due to the OPTIONAL operator, the core fragment of the SPARQL query language is non-monotonic. That is, some solutions of a query result can be returned to the user only after having consulted all relevant parts of the queried dataset(s). This property presents an obstacle when developing query execution approaches that aim to reduce responses times rather than the overall query execution times. Reducing the response times-i.e., returning as many solutions as early as possible-is important in particular in Web-based client-server query processing scenarios in which network latencies dominate query execution times. Such scenarios are typical in the context of integration of Web data sources where a data integration component executes queries over a decentralized federation of such data sources. In this paper we introduce an alternative operator that is similar in spirit to OPTIONAL but without causing non-monotonicity. We show fundamental properties of this operator and observe that the downside of achieving the desired monotonicity property is a potentially significant increase in query result sizes. We study the extend of this trade-off in practice. Thereafter, we introduce different algorithms to implement the new operator and evaluate them regarding their potential to reduce response times.",JWE,2019,,18,01-Mar,,169-206,2,8,https://ieeexplore.ieee.org/document/10247308/
A Brief Overview on the Strategies to Fight Back the Spread of False Information,Álvaro Figueira | Nuno Guimaraes | Luis Torgo,"CRACS-INESCTEC and University of Porto, Porto, Portugal | CRACS-INESCTEC and University of Porto, Porto, Portugal | Faculty of Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada",false information | social networks,"The proliferation of false information on social networks is one of the hardest challenges in today's society, with implications capable of changing users perception on what is a fact or rumor. Due to its complexity, there has been an overwhelming number of contributions from the research community like the analysis of specific events where rumors are spread, analysis of the propagation of false content on the network, or machine learning algorithms to distinguish what is a fact and what is “fake news”. In this paper, we identify and summarize some of the most prevalent works on the different categories studied. Finally, we also discuss the methods applied to deceive users and what are the next main challenges of this area.",JWE,2019,,18,04-Jun,,319-352,2,9,https://ieeexplore.ieee.org/document/10251847/
Model-Driven Skills Assessment in Knowledge Management Systems,Antonio Balderas | Juan Antonio Caballero-Hernández | Juan Manuel Dodero | Manuel Palomo-Duarte | Iván Ruiz-Rube,"Department of Computer Science, University of Cadiz, Puerto Real, Spain | EVAL for Research Group, University of Cadiz, Puerto Real, Spain | Department of Computer Science, University of Cadiz, Puerto Real, Spain | Department of Computer Science, University of Cadiz, Puerto Real, Spain | Department of Computer Science, University of Cadiz, Puerto Real, Spain",knowledge management system | generic skills assessment | organizational learning | Model-Driven engineering,"Organizations need employees who perform satisfactorily in generic skills, such as teamwork, leadership, problem solving or interpersonal abilities, among others. In organizational environments, employees perform work that is not always visible for supervisors and, thus, they can hardly assess their performance in generic skills. By using a knowledge management system, the users are able to leave a trace of their activity in the system's records. This research aims to address a computer supported assessment of the user's generic skills from the perspective of Model-Driven engineering. First, a systematic mapping study is carried out to understand the state of the art. Second, a proposal based on Model-Driven engineering is presented and is then validated through an organizational learning process model. Our results are promising and we are able to conduct a scalable assessment based on objective indicators of the employee's planning, time management and problem solving skills.",JWE,2019,,18,04-Jun,,353-379,2,8,https://ieeexplore.ieee.org/document/10251851/
Model-Driven Integration Testing of Hypermedia Systems,Henry Vu | Tobias Fertig | Peter Braun,"PENTASYS AG, Munich, Germany | PENTASYS AG, Munich, Germany | PENTASYS AG, Munich, Germany",REST | Integration Testing | RESTful API | Hypermedia Testing | MDSD | MDE | MDT | Model-Driven Testing,"The proper design of Representational State Transfer (REST) APIs is not trivial because developers have to deal with a flood of recommendations and best practices, especially the proper application of the hypermedia constraint requires some decent experience. Furthermore, testing RESTful APIs is a missing topic within literature. Especially hypermedia testing is not mentioned at all. Manual hypermedia testing is time-consuming and hard to maintain. Testing a hypermedia API requires many test cases that have similar structure, especially when different user roles and error cases are considered. In order to tackle this problem, we proposed a Model-Driven Testing (MDT) approach for hypermedia systems using the metamodel within our existing Model Driven Software Development (MDSD) approach. This work discusses challenges and results of hypermedia testing for RESTful APIs using MDT techniques that were discovered within our research. MDT allows white-box testing, hence covering complete program structure and behavior of the generated application. By doing this, we are able to achieve a high automated test coverage. Moreover, any runtime behavior deviated from the metamodel reveals bugs within the generators.",JWE,2019,,18,04-Jun,,381-407,2,2,https://ieeexplore.ieee.org/document/10251853/
LOD Construction Through Supervised Web Relation Extraction and Crowd Validation,Goran Rumin | Igor Mekterović,"Infobip, Zagreb, Croatia | University of Zagreb Faculty of Electrical Engineering and Computing, Croatia",Relation Extraction | Machine Learning | RDF | Linked Open Data | Crowd validation | Semantic Web | Web Application,"Free, unstructured text is the dominant format in which information is stored and published. To interpret such vast amount of data one must employ a programmatic approach. In this paper, we describe a novel approach - a pipeline in which interesting relations are extracted from web portals news texts, stored as RDF triplets, and finally validated by end user via browser extension. In the process, different machine learning algorithms were tested on relation extraction, enhanced with our own set of features and thoroughly evaluated, with excellent precision and recall results compared to models used for semantic knowledge expansion. Building on those results, we implement and describe the component to resolve discovered entities to existing semantic entities from three major online repositories. Finally, we implement and describe the validation process in which RDF triplets are presented to the web portal reader for validation via Chrome extension.",JWE,2019,,18,01-Mar,,229-255,2,1,https://ieeexplore.ieee.org/document/10247224/
Ontology-Driven News Classification with Aethalides,Wouter Rijvordt | Frederik Hogenboom | Flavius Frasincar,"Econometric Institute, Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands | Econometric Institute, Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands | Econometric Institute, Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands",News personalization | word sense disambiguation | ontology learning | semantic web,"The ever-increasing amount of Web information offered to news readers (e.g., news analysts) stimulates the need for news selection, so that informed decisions can be made with up-to-date knowledge. Hermes is an ontologybased framework for building news personalization services. It uses an ontology crafted from available news sources, allowing users to select and filter interesting concepts from a domain ontology. The Aethalides framework enhances the Hermes framework by enabling news classification through lexicographic and semantic properties. For this, Aethalides applies word sense disambiguation and ontology learning methods to news items. When tested on a set of news items on finance and politics, the Aethalides implementation yields a precision and recall of 74.4% and 49.4%, respectively, yielding an F0.5-measure of 67.6% when valuing precision more than recall.",JWE,2019,,18,7,,627-654,2,4,https://ieeexplore.ieee.org/document/10251873/
Integrating Semantic Run-Time Models for Adaptive Software Systems,Francesco Poggi | Davide Rossi | Paolo Ciancarini,"Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, Italy | Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, Italy | University of Bologna, Italy",Autonomic systems | adaptive software | MAPE-K | Semantic Web | ontology,"Software-intensive systems work in ever-changing environments requiring expensive technical efforts to manage their evolution. In order to mitigate their risks and costs they should dynamically self-adapt to any modification of their environment. MAPE-K (Monitor, Analyze, Plan, Execute - Knowledge) is the basic architectural pattern for building software-intensive self-adaptable systems. In this paper we propose an approach in which all the information about a system and its environment is unified by using Semantic Web technologies into a set of semantic run-time models which enhance the Knowledge in MAPE-K. Ontologies are used to manage the interaction and integration of these models with disparate data sources. The resulting knowledge base is then used to drive adaptation activities exploiting well known languages and notations. We discuss how MAPE-K can be exploited in order to take advantage of ontological representations, along with Semantic Web languages and tools, by studying a real-word case study: a legacy system that was not designed to perform automatic adaptation. We discuss merits and limits of our approach based on semantic run-time models both in the context of this specific case study and in a broader scope.",JWE,2019,,18,01-Mar,,Jan-41,2,9,https://ieeexplore.ieee.org/document/10247311/
Leveraging Conceptual Data Models to Ensure the Integrity of Cassandra Databases,Pablo Suárez-Otero | María José Suárez-Cabal | Javier Tuya,"Computer Science Department, University of Oviedo, Gijón, Spain | Computer Science Department, University of Oviedo, Gijón, Spain | Computer Science Department, University of Oviedo, Gijón, Spain",NoSQL | Cloud | Conceptual Model | Logical Model | Cassandra | Logical Data Integrity,"The use of NoSQL databases for cloud environments has been increasing due to their performance advantages when working with big data. One of the most popular NoSQL databases used for cloud services is Cassandra, in which each table is created to satisfy one query. This means that as the same data could be retrieved by several queries, these data may be repeated in several different tables. The integrity of these data must be maintained in the application that works with the database, instead of in the database itself as in relational databases. In this paper, we propose a method to ensure the data integrity when there is a modification of data by using a conceptual model that is directly connected to the logical model that represents the Cassandra tables. This method identifies which tables are affected by the modification of the data and also proposes how the data integrity of the database may be ensured. We detail the process of this method along with two examples where we apply it in two insertions of tuples in a conceptual model. We also apply this method to a case study where we insert several tuples in the conceptual model, and then we discuss the results. We have observed how in most cases several insertions are needed to ensure the data integrity as well as needing to look for values in the database in order to do it.",JWE,2019,,18,04-Jun,,257-286,2,7,https://ieeexplore.ieee.org/document/10251850/
Temporal Extensions to RDF,Hsien-Tseng Wang | Abdullah Uz Tansel,"Department of Computer Science, The Graduate Center, The City University of New York, USA | Department of Computer Science, The Graduate Center, The City University of New York, USA",The Semantic Web | Resource Description Framework | Taxonomy | Temporal Data | Temporal Knowledge,"The Semantic Web aims at building a foundation of semantic-based data models and languages for not only manipulating data and knowledge, but also in decision making by machines. Naturally, time-varying data and knowledge are required in Semantic Web applications to incorporate time and further reason about it. However, the original specifications of RDF and OWL do not include constructs for handling time-varying data and knowledge. For simplicity, RDF model is confined to binary predicates, hence some form of reification is needed to represent higher-arity predicates. To this date, there are many proposals extending RDF and OWL for handling temporal data and knowledge. They all focus on the valid time. In this paper, we examine each of these proposals and develop a taxonomy to classify them according to the form of reification employed: explicit reification or implicit reification. The implicit reification proposals are further divided into three sub-categories according to semantic constructs they use. Some of these proposals stay compliant to the RDF and OWL standards whereas others add new constructs to RDF model and SPARQL query language. Additionally, we compare these proposed models with respect to characteristics, such as their syntax and semantics, their compliance to RDF and OWL specifications, their need for additional objects, etc. The comparison provides a useful guideline for the researchers and practitioners of the Semantic Web in managing temporal data and knowledge.",JWE,2019,,18,01-Mar,,125-168,2,17,https://ieeexplore.ieee.org/document/10247309/
"PLEC, A Participative Process for GUI Prototyping",Javier J. Gutiérrez | Carlos Arévalo | David Lizcano,"Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | School of Computer Science, Universidad a Distancia de Madrid, UDIMA, Madrid, Spain",GUI | prototyping | team work,"GUI is one of the key aspect of an information system from the point of view of customers and users. This paper introduces PLEC, a participative process for designing GUI interfaces with the collaboration of the final users and stakeholders. Participants do not need technical knowledge of GUI prototype. A case study has been developed and carried out to verify if PLEC process is feasible.",JWE,2019,,18,04-Jun,,513-538,2,1,https://ieeexplore.ieee.org/document/10251821/
RiAiR: A Framework for Sensitive RDF Protection,M. Irvin Dongo | Richard Chbeir,"Univ. Pau & Pays Adour, UPPA / E2S, LIUPPA, Anglet, France | Univ. Pau & Pays Adour, UPPA / E2S, LIUPPA, Anglet, France",RDF protection | Sensitive information | Semantic Web | Disclosure source,"The Semantic Web and the Linked Open Data (LOD) initiatives promote the integration and combination of RDF data on the Web. In some cases, data need to be analyzed and protected before publication in order to avoid the disclosure of sensitive information. However, existing RDF techniques do not ensure that sensitive information cannot be discovered since all RDF resources are linked in the Semantic Web and the combination of different datasets could produce or disclose unexpected sensitive information. In this context, we propose a framework, called RiAiR, which reduces the complexity of the RDF structure in order to decrease the interaction of the expert user for the classification of RDF data into identifiers, quasi-identifiers, etc. An intersection process suggests disclosure sources that can compromise the data. Moreover, by a generalization method, we decrease the connections among resources to comply with the main objectives of integration and combination of the Semantic Web. Results show a viability and high performance for a scenario where heterogeneous and linked datasets are present.",JWE,2019,,18,01-Mar,,43-95,2,1,https://ieeexplore.ieee.org/document/10247289/
DotCHA: An Interactive 3D Text-based CAPTCHA,Suzi Kim | Sunghee Choi,"School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",CAPTCHA | 3D CAPTCHA | text-based CAPTCHA | 3D typography | mental rotation | security | usability,"We introduce a new type of 3D text-based CAPTCHA, called DotCHA, which relies on human interaction and overcomes the limitations of existing 2D and 3D CAPTCHAs. DotCHA asks users to rotate a 3D text model to identify the correct letters. The 3D text model is a twisted form of sequential 3D letters around a center pivot axis, and it shows different letters depending on the rotation angle. Because each model consists of many small spheres instead of a solid letter model, DotCHA is classified as a scatter-type CAPTCHA and resists character segmentation attacks. Moreover, DotCHA is resistant to machine learning attacks because each letter is only identified in a particular direction. We demonstrate that DotCHA is resistant to existing types of attacks while maintaining usability.",JWE,2019,,18,8,,837-863,2,1,https://ieeexplore.ieee.org/document/10247295/
Sentimental Analysis Using Capsule Network with Gravitational Search Algorithm,V. Diviya Prabha | R. Rathipriya,"Department of Computer Science Periyar University, Salem, India | Department of Computer Science Periyar University, Salem, India",Deep learning | capsule network | machine learning | sentimental classification,"Day by day the recent development of communication and the data on the web is increasing tremendously. Moreover, the use of social media among people to express their opinion has greatly increased. Therefore, analyzing this textual data using sentimental analysis techniques can be very helpful in capturing and categorizing people's opinions. This work aims to propose an algorithm which is combination of Capsule Network (CN) with Gravitational Search Algorithm (GSA) to analyze people's sentiments from twitter data. In text data mining, CN works to an excessive extent for sentiment analysis compared with other models. The performance of the proposed approach is studied using existing benchmark datasets and COVID-19 twitter posts. The results showed that the proposed approach could automatically classify the sentiments with high performance. It works better compared to other algorithms and results also encourage further research.",JWE,2020,,19,05-Jun,,775-794,2,14,https://ieeexplore.ieee.org/document/10247282/
An Optimized Algorithm to Construct QC-LDPC Matrix in Compressed Sensing,Xiaoqi Yin | Jiansheng Qian | Xingge Guo | Guohua Lin,"School of Informatiom and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu, China | School of Informatiom and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu, China | School of Informatiom and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu, China | Huaiyin Institute of Technology, Jiangsu Laboratory of Lake Environment Remote Sensing Technologies, Huaian, Jiangsu, China",Measurement matrix | LDPC | quasi-cyclic | finite geometry | short girth | compressed sensing,"Aiming at the problems such as the large amount of data in transmission and difficulties in hardware implementation, an optimized algorithm is put forward to generate QC-LDPC measurement matrix based on limited geometry in compressed sensing, which can eliminate the short girth of 4 in Tanner graph through the design of basis matrix. Because of the quasicyclic characteristics, it can be realized by shift register so as to reduce the complexity of coding. The simulation results indicate that QC-LDPC matrix is superior to traditional measurement matrices by using the same OMP algorithm, and there are good improvements in the aspects of PSNR, SSIM, NMSE and runtime, which are conductive to the application of compressed sensing theory in real-time data transmission.",JWE,2020,,19,07-Aug,,99-116,2,1,https://ieeexplore.ieee.org/document/10251837/
A Method of Stereoscopic Display for Dynamic 3D Graphics on Android Platform,Shihong Chen | Zi Jiu,"Applied Arts and Science College, Beijing Union University, Beijing, China | School of Digital Art and Animation, Communication University of China, Beijing, China",Stereoscopic display | dynamic 3D graphic | parallax,"With the widespread use of smart terminals, the convenient use of stereoscopic video display on mobile platforms is urgently needed by more and more people. This study presents a method to rapidly convert 3D dynamic graphics produced by 3D animation software into stereoscopic display suitable for the Android platform, with details of an algorithm to generate double-viewpoint image sequences from single-viewpoint 3D dynamic graphics, and a method for compositing stereoscopic display from double-viewpoint image sequences. It developes a program on the basis of popular animation software to implement this method for realizing automatic generation of dynamic 3D graphics and for outputting composite images that conforms to the binocular characteristics of stereoscopic displays. As shown by experiments, the methods presented by this study, produce better results at a faster speed and provide stronger support for the production of high-quality stereo videos.",JWE,2020,,19,05-Jun,,849-863,2,9,https://ieeexplore.ieee.org/document/10247328/
Fault-tolerant and Congestion Balanced Routing Algorithm for 2D Mesh NoCs,Jiao Guan | Jueping Cai | Yequn Wang | Jian Liu,"State Key Discipline Laboratory of Wide Band Gap Semiconductor Technology, School of Microelectronics, Xidian University, Xi'an, China | State Key Discipline Laboratory of Wide Band Gap Semiconductor Technology, School of Microelectronics, Xidian University, Xi'an, China | Institute of Information and Navigation, Air Force Engineering University, Xi'an, China | Institute of Information and Navigation, Air Force Engineering University, Xi'an, China",Network-on-Chip (NoC) | fault-tolerant routing algorithm | path channels | free buffer length,"With the number of cores and nodes in networks-on-chips (NoCs) growing, the node fault occurrence probability is increasing. Although the existing turn model can route packets around the fault area and avoid deadlocks, a large traffic load is generated in the non-rightmost column of the fault region. This paper presents a novel fault-tolerant and congestion balanced (FTCB) routing algorithm that chooses a lower load area as the optimal router path by calculating the maximum path channels to balance traffic load and avoid network congestion. Two methods are proposed to calculate path channels for the fault-free mesh and the fault mesh. The improved odd-even turn rule is introduced to calculate path channels for the fault-free mesh. To balance the network load, free buffer length information is added to path channel calculations, which reflects the global perception. For the non-fault region, we update path channels by using the back formulas from the destination node to the source node. In a fault region, the modified calculation rules of path channels and fault-location odd-even turn rules are given. Compared to the other two related works, the throughput of the FTCB algorithm is improved by 6.92% and 10.7%. Meanwhile, the traffic load of FTCB is decreased to some degree in whole mesh, which shows the FTCB routing algorithm can obviously improve network load balanced, saturation throughput and network latency.",JWE,2020,,19,07-Aug,,1049-1066,2,3,https://ieeexplore.ieee.org/document/10251840/
A Metrics Framework for Evaluating Microservices Architecture Designs,O. Al-Debagy | P. Martinek,"Department of Electronics Technology, Budapest University of Technology and Economics, Hungary | Department of Electronics Technology, Budapest University of Technology and Economics, Hungary",Microservices | software metrics | lack of cohesion | service granularity | service complexity,"Microservices are becoming a more popular software architecture among companies and developers. Therefore, there is a need to develop methods for quantifying the process of measuring the quality of microservices design. This paper has created a novel set of metrics for microservices architecture applications. The proposed metrics are the Service Granularity Metric “SGM”, the Lack of Cohesion Metric “LCOM”, and the Number of Operations “NOO”. The proposed metrics measure the granularity, cohesion, and complexity of individual microservices through analyzing the application programming interface “API”. Using these metrics, it is possible to evaluate the overall quality of the design of microservices applications. The proposed metrics were measured on 5 applications with different sizes and business cases. This research found that the value for the SGM metric needs to be between 0.2 and 0.6. Besides, the value of LCOM metric for a microservice needs to be between 0 and 0.8 with less than ten operations per microservice. These findings can be applied in the decomposition process of monolithic applications as well.",JWE,2020,,19,03-Apr,,341-370,2,25,https://ieeexplore.ieee.org/document/10251860/
FlakyLoc: Flakiness Localization for Reliable Test Suites in Web Applications,Jesús Morán | Cristian Augusto | Antonia Bertolino | Claudio De La Riva | Javier Tuya,"Computer Science Department, University of Oviedo, Gijón, Spain | Computer Science Department, University of Oviedo, Gijón, Spain | ISTI-CNR, Consiglio Nazionale delle Ricerche, Pisa, Italy | Computer Science Department, University of Oviedo, Gijón, Spain | Computer Science Department, University of Oviedo, Gijón, Spain",Software testing and debugging | spectrum-based localization | web applications | test flakiness,"Web application testing is a great challenge due to the management of complex asynchronous communications, the concurrency between the clients-servers, and the heterogeneity of resources employed. It is difficult to ensure that a test case is re-running in the same conditions because it can be executed in undesirable ways according to several environmental factors that are not easy to fine-grain control such as network bottlenecks, memory issues or screen resolution. These environmental factors can cause flakiness, which occurs when the same test case sometimes obtains one test outcome and other times another outcome in the same application due to the execution of environmental factors. The tester usually stops relying on flaky test cases because their outcome varies during the re-executions. To fix and reduce the flakiness it is very important to locate and understand which environmental factors cause the flakiness. This paper is focused on the localization of the root cause of flakiness in web applications based on the characterization of the different environmental factors that are not controlled during testing. The root cause of flakiness is located by means of spectrum-based localization techniques that analyse the test execution under different combinations of the environmental factors that can trigger the flakiness. This technique is evaluated with an educational web platform called FullTeaching. As a result, our technique was able to locate automatically the root cause of flakiness and provide enough information to both understand it and fix it.",JWE,2020,,19,2,,267-296,2,26,https://ieeexplore.ieee.org/document/10247298/
Research on Network Security Situation Assessment and Forecasting Technology,Hongbin Wang | Dongmei Zhao | Xixi Li,"College of Computer and Cyber Security, Hebei Normal University, Shijiazhuang, China | College of Computer and Cyber Security, Hebei Normal University, Shijiazhuang, China | Hebei Key Laboratory of Network and Information Security, Shijiazhuang, China",Network security situation | particle swarm optimization | D-S evidence theory | RBF neural network,"In recent years, the network security issues have become more prominent, and traditional network security protection technologies have been unable to meet the needs. To solve this problem, this paper improves and optimizes the existing methods, and proposed a set of network security situation assessment and prediction methods. First, the cross-layer particle swarm optimization with adaptive mutation (AMCPSO) algorithm proposed in this paper is combined with the traditional D-S evidence theory to evaluate the current network security situation; Then, the parameters and structure of traditional RBF neural network are optimized by introducing FCM (fuzzy c-means), HHGA (hybrid hierarchy genetic algorithm) and least square method. According to the optimized RBF neural network and situation assessment results, the next stage of network security situation is predicted. Finally, the effectiveness of the network security situation assessment and prediction method proposed in this paper is verified by simulation experiments. The algorithm in this paper improves the accuracy of situation assessment and prediction, and has certain reference significance for the research of network security.",JWE,2020,,19,07-Aug,,1239-1266,2,26,https://ieeexplore.ieee.org/document/10251838/
Eye Tracking and ROI Detection within a Computer Screen Using a Monocular Camera,Guangmin Sun | 06jie Zhang | Kun Zheng | Xiaohui Fu,"Beijing University of Technology, Beijing, China | Beijing University of Technology, Beijing, China | Beijing University of Technology, Beijing, China | Beijing University of Technology, Beijing, China",Iris detection | gaze tracking | monocular camera | ROI detection,"The region of interest will change according to the task, even in the same situation. In the study, a method for region of interest detection within a computer screen using a monocular camera is proposed. In contrast to gaze tracking techniques that require particular devices (e.g., an eye tracker and RGB-D device) meanwhile complex calibration, a cheap and more convenient monocular camera is used in this study to solves the eye gaze tracking problem. Firstly, Human face is detected in a real-time video sequence using HoG features. Then, the landmarks around the eyes, which reflect the gaze position, are extracted. Next, the iris centers are detected in the eye region. In order to reduce the gaze error caused by head movement, a three-dimensional head model is proposed to estimate head pose. Finally, the eye region is tracked by calculating the eye vectors and head movement. Experiments were performed to evaluate the face detection, landmarks, iris detection, eye movement estimation, and head pose estimation on databases such as the Hong Kong, BioID, and Boston University head pose databases. Besides, experiments for gaze tracking were performed for a real-time video sequence. Deviation is calculated using Euclidean distance between the real and estimated points. The results show that the method achieves an average error of 1.85° with head fixed and 3.58° with head movement in the range of -45° and 45°. The requirement is detecting the user's attention in the screen area. Our method can reach the same level to the other methods, even though the accuracy is not state-of-the-art. Meanwhile, as we all know not only a specific point is concerned but also a region area according to the characteristics of human eye imaging, thus the proposed method can meet the requirements of demand.",JWE,2020,,19,07-Aug,,1117-1146,2,11,https://ieeexplore.ieee.org/document/10251887/
Benchmarking Web API Quality - Revisited,David Bermbach | Erik Wittern,"Mobile Cloud Computing Research Group, TU Berlin & Einstein Center Digital Future, Berlin, Germany | Hybrid Cloud Integration, IBM, Hamburg, Germany",Web APIs | Benchmarking | Quality of Service,"Modern applications increasingly interact with web APIs - reusable components, deployed and operated outside the application, and accessed over the network. Their existence, arguably, spurs application innovations, making it easy to integrate data or functionalities. While previous work has analyzed the ecosystem of web APIs and their design, little is known about web API quality at runtime. This gap is critical, as qualities including availability, latency, or provider security preferences can severely impact applications and user experience. In this paper, we revisit a 3-month, geo-distributed benchmark of popular web APIs, originally performed in 2015. We repeat this benchmark in 2018 and compare results from these two benchmarks regarding availability and latency. We furthermore introduce new results from assessing provider security preferences, collected both in 2015 and 2018, and results from our attempts to reach out to API providers with the results from our 2015 experiments. Our extensive experiments show that web API qualities vary 1.) based on the geo-distribution of clients, 2.) during our individual experiments, and 3.) between the two experiments. Our findings provide evidence to foster the discussion around web API quality, and can act as a basis for the creation of tools and approaches to mitigate quality issues.",JWE,2020,,19,05-Jun,,603-646,2,23,https://ieeexplore.ieee.org/document/10247284/
On Modelling for Bias-Aware Sentiment Analysis and Its Impact in Twitter,Ahsan Mahmood | Hikmat Ullah Khan | Muhammad Ramzan,"Department of Computer Science, COMSATS University, Islamabad, Attock Campus, Pakistan | Department of Computer Science, COMSATS University, Islamabad, Wah Campus, Pakistan | Department of Computer Science and IT, University of Sargodha, Sargodha, Pakistan",Social media | Twitter | sentiment analysis | bias | data mining | opinion mining,"Sentiment Analysis (SA) is an active research area for the last ten years. SA is the computational treatment of opinions, sentiments, and subjectivity of text. Twitter is one of the most widely used micro-blog and considered as an important source for computation of sentiment and of data analysis. Therefore, companies all over the world analyze Twitter data using SA and extract knowledge which has potential applications in diverse areas. Although SA is the successful way of finding the people's opinion, the bias in the tweets affects the results of the SA and reflects inaccurate analysis that may mislead users to take erroneous decisions. The biased tweets are shared by valid, but biased human users as well as the social bots to propagate the biased opinions on certain topics. To counter this, this research study proposes a statistical model to identify such users and social bots who share the biased content in the form of tweets in the Twitter social media. For experiment purpose, we use annotated twitter dataset and argue the results of SA with and without the biased tweets and explored the effects of biased users at micro-level and macro level. The empirical results show that the proposed approach is effective and properly identifies the biased users and bots from other authentic users using sentiment analysis.",JWE,2020,,19,1,,Jan-27,2,15,https://ieeexplore.ieee.org/document/10251863/
Research on Indoor Wireless Positioning Precision Optimization Based on UWB,Hua Guo | Mengqi Li | Xuejing Zhang | Qian Liu | Xiaotian Gao,"College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China | College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China | College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China | College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China | College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China",UWB | positioning | neutral network | clustering | Kalman filtering,"The ultra-wide band (UWB) indoor positioning precision often has large deviations due to environmental influences. To reduce noise error and improve the UWB indoor positioning precision, this paper divides the indoor positioning into static positioning and mobile positioning, and proposes different optimization algorithms for the two positioning modes. An improved self-organizing feature mapping neural network clustering algorithm is used for static positioning. After training, the layout of the neural network is established, and each weight vector is located at the center of the input vector cluster. Experiments indicate that the fully trained neural network can effectively filter noise, and reduce the mean square error significantly within 3.0 × 10-3. The positioning precision is 32.39% and 17.24% higher than those of the K-mean filtering algorithm and the Kalman filtering algorithm. For mobile positioning, the optimized neural network clustering algorithm is integrated with the unscented Kalman filter (UKF) to smooth the positioning data and reduce non-line-of-sight (NLOS) error. Experiments prove that this method can effectively reduce the errors caused by the NLOS state change, and estimate the distance with a high precision for ultra-wide band positioning and tracking.",JWE,2020,,19,07-Aug,,1017-1048,2,9,https://ieeexplore.ieee.org/document/10251836/
Malware Analysis Through Random Forest Approach,Ajay Kumar | Kumar Abhishek | Shishir Kumar Shandilya | Muhammad Rukunuddin Ghalib,"Department of Computer Science & Engineering, NIT Patna, Bihar, India | Department of Computer Science & Engineering, NIT Patna, Bihar, India | Division Head, Cyber Security and Digital Forensics, Vellore Institute of Technology, VIT Bhopal University, India | School of Computer Science and Engineering, Vellore Institute of Technology (VIT), Vellore, India",Machine intelligence | deep learning | signature-centric discovery | behavioral-based detection,"This paper gives precise and comprehensive detail along with a proposed system for malware detection using ML and Deep Learning techniques by integrating both behavior-based detection methods and signature-based methods. The primary purpose of this paper is (A) Outline difficulty identified with malware detection. (B) Represent detail and categorized ML technique for malware detection. (C) Investigating the structure of basic strategies in malware discovery. (D) Inspecting the essential deep learning approach for malware detection using a grouping of malware inside the data mining. The point of interest and downside of various malware detection approaches were analyzed based on evaluation strategy and their capability. The proposed model uses random forest for making an end-to-end pipeline for malware detection. During comparative study with five other state of the art models, the proposed model obtained accuracy of 99.7% on the dataset. The experimental results show the proposed model outperformed other five state of the art techniques. This research paper encourages the researcher to think about the best approach for malware detection.",JWE,2020,,19,05-Jun,,795-818,2,3,https://ieeexplore.ieee.org/document/10247307/
A Context-Aware Personalized Hybrid Book Recommender System,Hossein Arabi | Vimala Balakrishnan | Nor Liyana Mohd Shuib,"Bookurve Sdn. Bhd., Malaysia | Department of Information Systems, University of Malaya, Kuala Lumpur, Malaysia | Department of Information Systems, University of Malaya, Kuala Lumpur, Malaysia",Recommendation system | context - aware | personality | demographic | location | review sentiment | purchase reason,"Contextual information such as emotion, location and time can effectively improve product or service recommendations, however, studies incorporating them are lacking. This paper presents a context-aware recommender system, personalized based on several user characteristics and product features. The recommender system which was customized to recommend books, was aptly named as a Context-Aware Personalized Hybrid Book Recommender System, which utilized users' personality traits, demographic details, location, review sentiments and purchase reasons to generate personalized recommendations. Users' personality traits were determined using the Ten Item Personality Inventory. The results show an improved recommendation accuracy compared to the existing algorithms, and thus indicating that the integration of several filtering techniques along with specific contextual information greatly improves recommendations.",JWE,2020,,19,03-Apr,,405-427,2,8,https://ieeexplore.ieee.org/document/10251864/
Machine Learning and Semantic Orientation Ensemble Methods for Egyptian Telecom Tweets Sentiment Analysis,Amira Shoukry | Ahmed Rafea,"Department of Computer Science and Engineering, The American University in Cairo (AUC), Cairo, Egypt | Department of Computer Science and Engineering, The American University in Cairo (AUC), Cairo, Egypt",Arabic sentiment analysis | lexicon based sentiment analysis | egyptian dialect | arabic opinion mining | ensemble learning,"The vast amount of data currently available online attracted many parties to analyze sentiments expressed in these data extracting valuable knowledge. Many approaches have been proposed to classify the posted content utilizing a single classifier. However, it has been proven that ensemble learning and combining multiple classifiers may enhance classification performance. The aim of this study is to improve the Egyptian sentiment classification by combining different classification algorithms. First, we investigated the benefit of combining multiple SO classifiers using different subsets from SATALex Egyptian lexicon. Second, we investigated the benefit of combining three classification algorithms; Naïve Bayes, Maximum Entropy and Support Vector Machines, adopted as base-classifiers. The experimental results show that combining classifiers can effectively improve the accuracy of Egyptian dataset sentiment classification. However, building these ensembles require more time for processing than the individual classifiers. The time needed depends on the number of classifiers used and the combination method used to combine these classifiers. Thus, the more classifiers used, the more time needed.",JWE,2020,,19,2,,195-214,2,7,https://ieeexplore.ieee.org/document/10247310/
An Application of CHNN for FANETs Routing Optimization,Xing Wei | Hua Yang,"School of Computer Science and Information Technology, Guangxi Normal University, Guilin, China | Guilin University of Aerospace Technology, Guilin, China",Flying ad hoc network | routing algorithm | neural network | Hopfiled neural network,"Routing algorithm has a decisive influence on routing quality, and routing quality has a direct impact on network performance. For FANETs, the highly dynamically changing topology poses a challenge to the design of routing algorithms. The paper studies the characteristics of FANETs, and uses a CHNN to search for FANETs routing to form CHNNR. Using NS3 as a simulation tool, a highly dynamic simulation scheme in the background of the network topology of the air flight platform was designed, making the simulation scene closer to the dynamic performance of the FANETs highly dynamic mobile node. By comparing parameters such as network delay, normalized network throughput, routing load and data transmission success rate, the performance of CHNNR and passive routing algorithms is analyzed and compared. The simulation results show that the comprehensive performance of CHNNR is better than other passive routing algorithms, and it is more suitable for FANETs networks where nodes move at a high speed and the network topology changes frequently, and lay the foundation for the next research.",JWE,2020,,19,05-Jun,,865-882,2,7,https://ieeexplore.ieee.org/document/10247278/
Compound Attack Prediction Method Based on Improved Algorithm of Hidden Markov Model,Dongmei Zhao | Hongbin Wang | Shixun Geng,"College of Computer and Cyber Security, Hebei Normal University, Shijiazhuang, China | College of Computer and Cyber Security, Hebei Normal University, Shijiazhuang, China | College of Computer and Cyber Security, Hebei Normal University, Shijiazhuang, China",Network security | hidden Markov model | compound attack prediction | attack intention | Baum-Welch algorithm | forward algorithm | Viterbi algorithm,"Network attacks are developing in the direction of concealment, complexity, multi-step, etc., making it difficult to identify and predict. In order to solve the problems such as the difficulty of determining the matching degree of the network attack, the difficulty of predicting the attack intention, and the incorrect calculation of the alarm intent sequence due to the incorrect alarm information, a hidden Markov model based on improved algorithm composite attack prediction is proposed. Firstly, in order to improve the learning ability and adaptability of the algorithm, an improved Baum-Welch algorithm is proposed to train the hidden Markov model (HMM) and generate new HMMs. Then use the Forward algorithm to calculate the HMM with the maximum probability of generating a pre-processed alarm message sequence. When the alarm message sequence is misreported, the attack intent sequence obtained by the classic Viterbi algorithm may be biased. This paper improves the Viterbi algorithm to make the extracted attack intention sequence more accurate. Finally, simulation results show that the model can effectively extract attack intention sequence and improve the accuracy of compound attack prediction.",JWE,2020,,19,07-Aug,,1213-1238,2,8,https://ieeexplore.ieee.org/document/10251865/
The Importance of Testing in the Early Stages of Smart Contract Development Life Cycle,N. Sánchez-Gómez | L. Morales-Trujillo | J. J. Gutiérrez | J. Torres-Valderrama,"University of Seville, Escuela Técnica Superior de Ingeniería Informática. Web Engineering and Early Testing (IWT2) Group, Sevilla, Spain | University of Seville, Escuela Técnica Superior de Ingeniería Informática. Web Engineering and Early Testing (IWT2) Group, Sevilla, Spain | University of Seville, Escuela Técnica Superior de Ingeniería Informática. Web Engineering and Early Testing (IWT2) Group, Sevilla, Spain | University of Seville, Escuela Técnica Superior de Ingeniería Informática. Web Engineering and Early Testing (IWT2) Group, Sevilla, Spain",Blockchain | Smart contract | Model-based software development | Early testing,"The use of smart contract augurs a world without intermediaries because the code and the agreements contained therein exist across a distributed, decentralized blockchain network. In software engineering, this collaboration is usually represented by using business process models and smart contracts can be used to implement business collaborations in general and inter-organizational business processes. The validation of this contract and the assurance of its quality are critical for its right application. Early testing in smart contract definition is the fact of this paper. The paper discusses the possibility to use transformation protocols to obtain derived artefacts like test case definitions and smart contract code scaffolds. Generation of derived artefacts significantly reduces the number of defects before deploying the smart contract code in the blockchain network. Transformations protocols are created using model-based software development and modelling techniques. This approach allows to simplify and improve the management and execution of collaborative business processes. This would allow, in addition, the application of systematic mechanisms to evaluate and validate the smart contract and, particularly, the application of early testing techniques which would help to reduce the number of defects and, ultimately, the cost of the final review.",JWE,2020,,19,2,,215-242,2,9,https://ieeexplore.ieee.org/document/10247301/
Mobile Notification System for Blood Pressure and Heartbeat Anomaly Detection,Saswat Raj Pandey | David Hicks | Ayush Goyal | Devottam Gaurav | Sanju Mishra Tiwari,"Department of Electrical Engineering and Computer Science, Texas A&M University, Kingsville, United States | Department of Electrical Engineering and Computer Science, Texas A&M University, Kingsville, United States | Department of Electrical Engineering and Computer Science, Texas A&M University, Kingsville, United States | Department of Computer Science and Engineering, IIT Delhi, India | Universidad Autonoma de Tamaulipas, Mexico",Anomaly detection | Pan-Tompkins algorithm | Firebase cloud messaging service | diastolic blood pressure | systolic blood pressure | ECG,"In today's fast-paced world where patients may need to be remotely monitored while they are away or out of hospitals, there is a need for mobile applications that can gather the biometric and biomedical signals from any number of devices and sensors, collecting biometric or biomedical data from a patient. This effort boons the improvement of a circulatory strain and heartbeat anomaly detection and notice apparatus as an Android application that permits quick discovery of any variations from the norm in a patient's fundamental dependent on the Pan-Tompkins algorithm and reports it to the pertinent emergency clinic or clinical staff. The blood ECG information can be gotten from the health tracker sensors by means of a Bluetooth association and the patient can enter their Blood pressure esteems. In this case, the information gathered from a set of reproduced data, which is identified with a triggering notice from Firebase Cloud function. This notification is further acknowledged by the enrolled specialist. The system's security part is represented by the fine-grained consent procedure which directs that solitary significant authorizations are required for the best possible working of the application which ought to be given to the application. An encryption method using the Blowfish algorithm is included as a feature of the developed mobile Android application to provide secure data transfer of the patient's vital signals.",JWE,2020,,19,05-Jun,,747-773,2,11,https://ieeexplore.ieee.org/document/10247281/
Artificial Neural Network Controller for Automatic Ship Berthing Using Separate Route,Li Qiang | Hong Bi-Guang,"Navigation College, Dalian Maritime University, Dalian, China | Navigation College, Dalian Maritime University, Dalian, China",Ships | automatic berthing | artificial intelligence | route segmentation | tug assistance,"The operation of ships in the port area requires not only the assistance of in-vessel equipment such as main engines and rudder, but also the assistance of external equipment such as tugboats. The complexity in the operation of ships in the port, requires control algorithm with multiple input and output for the automatic berthing control of the ship. The entering and leaving data of the ship can help the algorithm to efficiently control the berthing and unberthing process of ships. This is based on the artificial intelligence which has been continuously approaching the operating habits of the pilot. The advances in artificial intelligence can control the entering, turning, and berthing in the port by artificial intelligence. In this study, the artificial neural network algorithm has been used to establish an automatic berthing model, based on the scheduled route. With the help of training data of one port, this model can be applied to the ship's berthing with different berth layouts. Furthermore, it can also be applied to complex systems such as direct or turning-berthing of a ship. Finally, the automatic berthing model has been used for the simulation of direct berthing and turning-berthing in different berth.",JWE,2020,,19,07-Aug,,1089-1116,2,13,https://ieeexplore.ieee.org/document/10251841/
Developing Web-Based Geographic Information Systems with a DSL: Proposal and Case Study,Suilen H. Alvarado | Alejandro Cortiñas | Miguel R. Luaces | Oscar Pedreira | Ángeles S. Places,"Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain | Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain | Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain | Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain | Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain",Domain specific language | geographic information systems,"In this paper, we present a declarative domain-specific language (DSL) for the development of Geographic Information Systems (GIS). GIS applications manage information with a spatial component, usually in the form of points, lines, polygons, or variants of these basic data types, in domains where the spatial information plays a central role. They provide the user with different functionalities on different application domains, but they are usually developed according to a common architecture and using a common set of technologies. Hence, they share a significant number of elements that make some aspects of their development quite repetitive. Our DSL allows developers to specify the entities, geographic layers, and maps of the applications using a declarative language. Then, the specification is transformed into a working GIS application. We present the language, its implementation, and a case study on two sample projects that allowed us to evaluate the resulting software, paying special attention to the savings in the development effort.",JWE,2020,,19,2,,167-193,2,13,https://ieeexplore.ieee.org/document/10247304/
Scheduling Algorithm Based on Heterogeneity and Confidence for Mimic Defense,Wenjian Zhang | Shuai Wei | Le Tian | Ke Song | Zhengbin Zhu,"Information Engineering University, Zhengzhou, China | Information Engineering University, Zhengzhou, China | Information Engineering University, Zhengzhou, China | Information Engineering University, Zhengzhou, China | Information Engineering University, Zhengzhou, China",Mimic defense | security | heterogeneity | confidence | TOPSIS | operating efficiency,"As a defense technology with endogenous security, mimic defense plays an important role in network security research. The scheduling of executors is one of the severe problems to take into account for mimic defense, and current research lacks comprehensive consideration of the influence of system architecture and attack behavior on scheduling algorithm. Based on previous research, this paper first introduces concept of heterogeneity and confidence according to vulnerability attributes and attack distribution characteristics to characterize the executors. Moreover, the TOPSIS (Technique for Order Preference by Similarity to an Ideal Solution) algorithm is brought in to optimize the system security and improve operating efficiency. Experimental results showed that,compared with the existing algorithms, Random, MD, RSMS, it improves the security of the system in non-uniform distributed attack scenario and the operating efficiency in each attack scenario.",JWE,2020,,19,07-Aug,,971-998,2,8,https://ieeexplore.ieee.org/document/10251839/
GitHubNet: Understanding the Characteristics of GitHub Network,Abdullah Talha Kabakus,"Department of Computer Engineering, Faculty of Engineering, Duzce University, Turkey",GitHub | social coding | social network analysis | link analysis | graph database,"Web 2.0 technologies have not only raised microblogs, but also social software development and collaboration platforms. GitHub is the most popular software development platform that provides social collaboration. Within the scope of this study, a novel graph-based analysis model is proposed which targets to reveal (1) the characteristics of the GitHub in order to shed light on social software development in general, and (2) the most popular programming languages, repositories, and developers in order to shed light on the trending software development technologies. To this end, a subset of the GitHub network, which contains 84, 737 developers and 209, 100 repositories, was collected through the GitHub API and stored on a graph database namely neo4j to be later analyzed. The result of the analysis shows that (1) the connections in GitHub are not mutually linked, (2) JavaScript, Python, and Java are currently the most popular three programming languages, (3) You-Dont-Know-JS, oh-my-zsh, and public-apis are the most popular three repositories, and (4) TarrySingh (Tarry Singh), indrajithbandara (Indrajith Bandara), and rootsongjc (Jimmy Song) are the most popular three developers. Furthermore, the proposed novel analysis model can be easily applied to other social networks.",JWE,2020,,19,05-Jun,,557-574,2,2,https://ieeexplore.ieee.org/document/10251061/
Applying Importance-Performance Analysis (IPA) to Interpret the Results of the User Experience Questionnaire (UEQ),Andreas Hinderks | Anna-Lena Meiners | Francisco José Domínguez-Mayo | Jörg Thomaschewski,"Department of Computer Languages and Systems, University of Seville, Seville, Spain | University of Applied Sciences, Emden/Leer, Germany | Department of Computer Languages and Systems, University of Seville, Seville, Spain | University of Applied Sciences, Emden/Leer, Germany",Importance-performance analysis | IPA | user experience | UX factors | User Experience Questionnaire | UEQ,"In recent years, user experience questionnaires have established themselves to measure various aspects of User Experience (UX). In addition to these questionnaires, an evaluation tool is usually offered so that the results of a study can be evaluated in the light of the questionnaire. As a rule, the evaluation consists of preparing the data and comparing it with a benchmark. Often this interpretation of the data is not sufficient as it only evaluates the current User Experience. However, it is desirable to determine exactly where there is a need for action. The User Experience Questionnaire (UEQ) is a common and valid questionnaire with an evaluation tool to measure and analyse the User Experience for a product or service. In our article we present an approach that evaluates the results from the User Experience Questionnaire using the importance-performance analysis (IPA). The aim is to create another possibility to interpret the results of the UEQ and to derive recommendations for action from them. In a study with 467 participants, we validated the approach presented with YouTube, WhatsApp, and Facebook. The results show that the IPA provides additional insights from which further recommendations for action can be derived.",JWE,2020,,19,2,,243-266,2,17,https://ieeexplore.ieee.org/document/10247292/
Model-based Generation of Web Application Programming Interfaces to Access Open Data,César González-Mora | Irene Garrigós | Jose Zubcoff | Jose-Norberto Mazón,"Department of Languages and Informatics Systems, University of Alicante, Spain | Department of Languages and Informatics Systems, University of Alicante, Spain | Department of Languages and Informatics Systems, University of Alicante, Spain | Department of Languages and Informatics Systems, University of Alicante, Spain",Web APIs | open data | data access | data reuse,"In order to facilitate the reusing of open data from open data platforms' catalogs, Web Application Programming Interfaces (APIs) are an important mechanism for reusers. However, there is a lack of suitable Web APIs to access data from open data platforms. Moreover, in most cases, the currently available APIs only allow to access catalog's metadata or to download entire data resources (i.e. coarse-grain access to data), hampering the reuse of data. Therefore, we propose a model-based approach to automatically generate Web APIs from open data. Our generated Web APIs facilitate the access and reuse of specific data (i.e., providing fine-grain or query-level access to data), which will result in many societal and economic benefits such as transparency and innovation. With this approach we address open data publishers which will be able to include a Web API within their data, but also open data reusers in case of missing APIs. This APIfication process, which means the creation of APIs for every available dataset, is based on automatic, generic and standardised generation mechanisms. The performance and functioning of this approach is validated with different datasets, which successfully generates Web APIs that facilitate the reuse of data.",JWE,2020,,19,07-Aug,,1147-1172,2,11,https://ieeexplore.ieee.org/document/10251871/
The Optimal Resource Self-configuration Method of Cognitive Network for Survivability Enhancement,Jian Wang | Guosheng Zhao | Zhongnan Zhao | Zhixin Li,"School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China | School of Computer Science and Information Engineering, Harbin Normal University, Harbin, China | School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China | School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China",Survivability enhancement | cognitive network | self-configuration | utility function,"In view of that general lack of intelligence and flexibility of the existing network resource allocation methods in the case of time-varying environments and diversified requirements, an efficient self-configuration method is put forward to optimize the allocation of resources and improve the survivability of system. First of all, the utility function of consumption domain is introduced as an indicator to pre-arrange the priority of user's QoS, as a result, the utility maximization of the system under resource constraint is obtained. Then, based on this definition, a multidimensional dynamic programming framework is proposed to define and describe the self-configuration process, and the problem model is constructed under certain constraints. Furthermore, the adaptive adjustment and configuration of resources are implemented by determining the priority sequence of user services, finding the optimal resource configuration scheme, and optimizing the time configuration window. Finally, The simulation results show that the proposed method is superior to the traditional resource allocation scheme in terms of system reliability, connectivity, broadband utilization, average response time and transmission rate, which improves the system's ability to adapt to the environment intelligently and survivability effectively.",JWE,2020,,19,03-Apr,,503-520,2,1,https://ieeexplore.ieee.org/document/10251875/
Lightweight Messaging for Efficient Service Discovery in Mobile loT Environments Using Hierarchical Bloom Filters,Hyeon-06 Jo | 06g-Hyun Kwon | MinHyeop Kim | In-Young Ko,"School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Yuseong-gu, Daejeon, South Korea | School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Yuseong-gu, Daejeon, South Korea | School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Yuseong-gu, Daejeon, South Korea | School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Yuseong-gu, Daejeon, South Korea",Service discovery | service registry | Bloom filter | mobile IoT environments | service-oriented architecture,"In highly dynamic IoT environments, the connection statuses of IoT resources and the availability of IoT-based services change frequently. Therefore, to successfully build distributed service registries for managing and finding the information about available services in an effective manner, it is crucial to minimize the overhead of message exchanges between registries and to reduce the time overhead for identifying the capabilities of available IoT resources and the services that can be provided by utilizing these capabilities. In this paper, we propose a lightweight messaging approach that uses hierarchical Bloom filters to efficiently represent service information to be exchanged and managed by distributed service registries for IoT environments with high mobility. We also propose a method for serializing the dimensions of a Bloom-filter-encoded search space. We conducted experiments to demonstrate the improvement in the service discovery performance, the reduction in message traffic among service registries, and the decrease in the latency when synchronizing distributed service registries.",JWE,2020,,19,1,,29-61,2,1,https://ieeexplore.ieee.org/document/10251885/
Design of a Hybrid Digital Watermarking Algorithm with High Robustness,Yi Xie | Yulin Wang | Maode Ma,"School of Computer Science, Wuhan University, Wuhan, China | School of Computer Science, Wuhan University, Wuhan, China | School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore",Digital watermarking | digital multimedia security | hybrid algorithm | information security | high robustness,"With the development of the Internet, storage and transmission technologies such as printers and scanners, digital multimedia products are rapidly transmitted through the Internet broadcasting, multimedia works becoming easy to obtain and illegally tampering and copying. The copyright of media works urgently needs to be protected. As an important information security scheme, digital watermarking technology provides a powerful solution to the protection of multimedia works. In this paper, we propose an image digital watermarking algorithm combining discrete wavelet transform, discrete cosine transform and matrix singular value decomposition and new scrambling technique. Furthermore, to improve the robustness of the algorithm, grayscale scrambling and pseudo magic square transform are used. To evaluate our proposed algorithm, we realize the simulation based on Python 3.7. All the simulation results show that our proposed algorithm has strong imperceptibility and robustness.",JWE,2020,,19,05-Jun,,725-746,2,10,https://ieeexplore.ieee.org/document/10247283/
Chinese Shallow Semantic Parsing Based on Multi-Method of Machine Learning,Fucheng Wan | Xiangzhen He | Dongjiao Zhang | Guo Qi | Ao Zhu | Zhang Lei | Ning Zenan | Wang Yicheng,"Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China | Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China | Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China | Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China | Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China | Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China | Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China | Key Laboratory of China's Ethnic Languages, Information Technology of Ministry of Education Northwest Minzu University, Lanzhou, China",Semantic role labelling | multi-method | linear sequence | hierarchical tree | deep learning | modularization,"With the rapid development of 5G+ information intelligence, higher requirements are put forward for accurate and efficient semantic annotation methods. Semantic role annotation for any single method at present has its obvious and complementary advantages and disadvantages. Therefore, this paper attempts to introduce the above three mainstream and stable annotation methods into each task of semantic role annotation, and designs a Chinese semantic role annotation that integrates multi-method. This method integrates the statistical-based linear sequence method, the rule-based hierarchical tree method and the most advanced deep learning in the four processing modules of semantic role annotation. Multi-level linguistic features are introduced into the feature arrangement of the model to realize the mutual combination of multiple modules. Experiments show that the modular fusion of steps and methods effectively improves the annotation performance of each step of annotation.",JWE,2020,,19,05-Jun,,685-706,2,2,https://ieeexplore.ieee.org/document/10247285/
Human Behavior Feature Representation and Recognition Based on Depth Video,Miao He | Guangming Song | Zhong Wei,"School of Instrument Science and Engineering, Southeast University, Nanjing, China | School of Instrument Science and Engineering, Southeast University, Nanjing, China | School of Automation, Nanjing University of Information Science and Technology, Nanjing, China",Artificial intelligence | composite features of video images | motion recognition | feature extraction algorithm,"With the continuous development of computer artificial intelligence technology, various applications based on artificial intelligence emerge in an endless stream, among which video image recognition technology is the most widely used in life. This article starts from the process of image recognition, based on the composite characteristics of artificial intelligence and video images, to discuss human gesture recognition technology. This article uses the feature extraction algorithm for image composite feature extraction as a method, and conducts human body movement collection experiments, analyzes the database and The gesture recognition step. This paper mainly introduces the extraction method of image composite features and the basic requirements of gesture recognition, and through the algorithm calculation of feature extraction, the function of human gesture recognition video and image composite features is completed, and the human action collection experiment is carried out to confirm. The results of images and data show the advantages of the algorithm support used in this article. We will Dmti. MsHOG is compared with other methods in the three subsets. In terms of the accuracy of all tests, our method performs better than other methods. The results show that the MSHOG (Multi-scale Histogram of Oriented Gradients) descriptor can represent the unique characteristics of human behavior, reflecting the effectiveness of our proposed method. In particular, this method achieved 100% recognition accuracy in Test, with an average recognition accuracy of 94.91%, which is significantly better than existing methods.",JWE,2020,,19,05-Jun,,883-902,2,5,https://ieeexplore.ieee.org/document/10247327/
GenDE: A CRF-Based Data Extractor,Mohammed Kayed | Khaled Shaalan,"Faculty of Computers and Artificial Intelligence, Beni-Suef University, Beni-suef, Egypt | Faculty of Engineering and IT, The British University in Dubai, Dubai, UAE",Wrapper induction | data extractor | wrapper verifier | sequence labeling | CRFs model | JSON data extraction,"Web site schema detection and data extraction from the Deep Web have been studied a lot. Although, few researches have focused on the more challenging jobs: wrapper verification or extractor generation. A wrapper verifier would check whether a new page from a site complies with the detected schema, and so the extractor will use the wrapper to get instances of the schema types. If the wrapper failed to work with the new page, a new wrapper/schema would be re-generated by calling an unsupervised wrapper induction system. In this paper, a new data extractor called GenDE is proposed. It verifies the site schema and extracts data from the Web pages using Conditional Random Fields (CRFs). The problem is solved by breaking down an observation sequence (a Web page) into simpler subsequences that will be labeled using CRF. Moreover, the system solves the problem of automatic data extraction from modern JavaScript sites in which data/schema are attached (on the client side) in a JSON format. The experiments show an encouraging result as it outperforms the CSP-based extractor algorithm (95% and 96% of recall and precision, respectively). Moreover, it gives a high performance result when tested on the SWDE benchmark dataset (84.91%).",JWE,2020,,19,03-Apr,,371-404,2,2,https://ieeexplore.ieee.org/document/10251872/
A Unified Model Representation of Machine Learning Knowledge,J. G. Enríquez | A. Martínez-Rojas | D. Lizcano | A. Jiménez-Ramírez,"Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Universidad a distancia de Madrid. Carretera de La Coruña, Collado Villalba, Madrid, Spain | Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain",Machine Learning | Automated Machine Learning | Knowledge Representation | Model-Driven Engineering,"Nowadays, Machine Learning (ML) algorithms are being widely applied in virtually all possible scenarios. However, developing a ML project entails the effort of many ML experts who have to select and configure the appropriate algorithm to process the data to learn from, between other things. Since there exist thousands of algorithms, it becomes a time-consuming and challenging task. To this end, recently, AutoML emerged to provide mechanisms to automate parts of this process. However, most of the efforts focus on applying brute force procedures to try different algorithms or configuration and select the one which gives better results. To make a smarter and more efficient selection, a repository of knowledge is necessary. To this end, this paper proposes (1) an approach towards a common language to consolidate the current distributed knowledge sources related the algorithm selection in ML, and (2) a method to join the knowledge gathered through this language in a unified store that can be exploited later on, and (3) a traceability links maintenance. The preliminary evaluations of this approach allow to create a unified store collecting the knowledge of 13 different sources and to identify a bunch of research lines to conduct.",JWE,2020,,19,2,,319-340,2,4,https://ieeexplore.ieee.org/document/10247225/
The Strength of Considering Tie Strength in Social Interest Profiling,Asma Chader | Hamid Haddadou | Leila Hamdad | Walid-Khaled Hidouci,"Laboratoire de la Communication dans les Systèmes Informatiques (LCSI), Ecole Nationale Supérieure d'Informatique (ESI), Oued-Smar, Algiers, Algeria | Laboratoire de la Communication dans les Systèmes Informatiques (LCSI), Ecole Nationale Supérieure d'Informatique (ESI), Oued-Smar, Algiers, Algeria | Laboratoire de la Communication dans les Systèmes Informatiques (LCSI), Ecole Nationale Supérieure d'Informatique (ESI), Oued-Smar, Algiers, Algeria | Laboratoire de la Communication dans les Systèmes Informatiques (LCSI), Ecole Nationale Supérieure d'Informatique (ESI), Oued-Smar, Algiers, Algeria",Social profiling | user profile | relationship strength | weighted social networks | egocentric networks,"With the emergence of social networking platforms and great amount of generated content, analyzing people interactions and behaviour raises new opportunities for several applications such as user interest profiling. In this context, this paper highlights the importance of considering relationship strength to infer more refined and relevant interests from user's direct neighbourhood. We propose WeiCoBSP, a Weight-aware Community-Based Social Profiling approach that leverages strength of ego-friend and friend-friend relationships. The former, describing connections with the profiled user, allows to identify most relevant people from whom to infer worthwhile interests. The latter qualifies connections among user's neighbourhood and enables depicting the most realistic community structure of the network. We present an empirical evaluation performed on real world co-authorship networks, validating our approach. Experimental results demonstrate the ability of WeiCoBSP to infer user's interest accurately, improving greatly the unweighted CoBSP process but also results of experiments assessing separately ego-friend and friend-friend relationships strength.",JWE,2020,,19,03-Apr,,457-501,2,3,https://ieeexplore.ieee.org/document/10251884/
LiveSankey: Advanced Web Visualization in Data Intelligence Multi Domain Contexts,José M. Conejero | Juan Carlos Preciado | Alvaro E. Prieto | Roberto Rodriguez-Echeverria | Fernando Sánchez-Figueroa,"Quercus Software Engineering Group. School of Technology, University of Extremadura, Spain | Quercus Software Engineering Group. School of Technology, University of Extremadura, Spain | Quercus Software Engineering Group. School of Technology, University of Extremadura, Spain | Quercus Software Engineering Group. School of Technology, University of Extremadura, Spain | Quercus Software Engineering Group. School of Technology, University of Extremadura, Spain",visualization | data intelligence | sankey | multi domain,"In the last years, the growing volumes and sources of data has made Big Data technologies to become mainstream. In that sense, techniques like Data Visualization are being used more and more to group large amounts of data in order to transform them into useful information. Nevertheless, these techniques are currently included in Business Intelligence approaches to provide companies and public organizations with helpful tools for making decisions based on evidences instead of intuition. The Sankey diagram is an example of those complex visualization tools allowing the user to graphically trace meaningful relationships in large volumes of data. However, this type of diagram is usually static so they must be continuously and manually rebuilt on top of massive multivariable environments whenever decision makers need to evaluate different options and they do not allow to establish conditions over the data shown. This paper presents LiveSankey, an approach to automatically generate dynamic Sankey Diagrams allowing users to filter the data shown. As a result, multiple conditions may be established over the data used and the corresponding diagram can be dynamically rebuilt.",JWE,2020,,19,2,,109-137,2,0,https://ieeexplore.ieee.org/document/10247312/
Validating Structural Metrics for BPEL Process Models,Geoffrey Muchiri Muketha | Abdul Azim Abd Ghani | Rodziah Atan,"Murang'a University of Technology, Kenya | Universiti Putra Malaysia, Malaysia | Universiti Putra Malaysia, Malaysia",BPEL processes | business process models | web services | metrics validation | structural complexity | modifiability | understandability,"Business process models tend to get more and more complex with age, which hurts the ease with which designers can understand and modify them. Few metrics have been proposed to measure this complexity, and even fewer have been tested in the Business Process Execution Language (BPEL) context. In this paper, we present three related experimental studies whose aim was to analyse the ability of four selected structural metrics to predict BPEL process model understandability and modifiability. We used Spearman's rho and regression analysis in all three experiments. All metrics passed the correlation tests meaning that they can serve as understandability and modifiability indicators. Further, four of the metrics passed the regression test for understanding time implying that they can serve as understandability predictors. Finally, only one metric passed the regression test for modification time implying that it can serve as a modifiability predictor.",JWE,2020,,19,05-Jun,,707-723,2,1,https://ieeexplore.ieee.org/document/10247280/
A Checklist for the Evaluation of Web Accessibility and Usability for Brazilian Older Adults,Sandra Souza Rodrigues | Renata Pontin de Mattos Fortes,"ICMC, University of São Paulo, São Carlos, SP, Brazil | ICMC, University of São Paulo, São Carlos, SP, Brazil",Web accessibility | usability | older adults | evaluation methods,"The constant evolution of the Web has covered various segments of society and, as it evolves, its content must be accessible to different users' profiles. Older adults (60+) are the fastest growing population of users who face difficulties in interacting with websites, due to limitations in their abilities caused by the aging process. Despite the legislation and guidelines estab-lished for the development of accessible and usable web contents, several problems of accessibility and usability still must be solved. In particular, most website designers do not take into account the older adult's profile. This paper introduces Sene-check checklist, a support to web accessibility and usability evaluations for the Brazilian older profile developed according to scientific procedures, including the following three perspectives: (1) literature review, (2) point of view of experts and developers and (3) point of view of Brazilian older adults. The results enabled an investigation into the main problems encountered by older adults regarding web interaction and reinforced the relevance of a support for the evaluation of web accessibility and usability.",JWE,2020,,19,1,,63-108,2,7,https://ieeexplore.ieee.org/document/10251886/
Enhancing Performance of Distributed Transactions in Microservices via Buffered Serialization,Kindson Munonye | P. Martinek,"Budapest University of Technology and Economics, Budapest, Hungary | Budapest University of Technology and Economics, Budapest, Hungary",Distributed Transactions | Microservices | Transaction Management | Serialization | Protocol Buffer | Buffered Serialization | Appointment transaction processing,"Although the Microservices Architecture comes with a number of benefits, it is a challenge to design an efficient transaction management for multi-agent transactions that span across multiple services. Since microservices design require a loose coupling between service logic and resources, data used by a distributed transaction is spread across different nodes, there is need to an effective way to ensure data portability, speed consistency for transaction in microservices. Therefore this research addresses both the issue of improving transaction performance and maintaining data portability for distributed transactions in microservices. A novel approach to transaction management termed ‘buffered serialization’ is proposed in this research as a way to improve transaction management by the use serialization libraries. This work has a three-part objective which are (1) to highlight the challenges of distributed transaction management in microservices, (2) to propose an enhanced approach to transaction management through the use of buffered serialization between services (3) to provide a proof of concept for this novel approach. Obtained result indicate a 60% improvement in transaction failure recovery time, 10% higher success rate for load tests but an insignificantly higher resource utilization values.",JWE,2020,,19,05-Jun,,647-684,2,0,https://ieeexplore.ieee.org/document/10247286/
Dynamic Query Processing for Hidden Web Data Extraction From Academic Domain,Babita Ahuja | Anuradha Pillai | Deepika Punj | Jyoti Verma,"MRCE, Faridabad, India | YMCA, J.C. Bose University of Science and Technology, Faridabad, India | YMCA, J.C. Bose University of Science and Technology, Faridabad, India | YMCA, J.C. Bose University of Science and Technology, Faridabad, India",Surface web | hidden web | dynamic query processing | text summarization | semantic fuzzy rules,"The web documents lying on WWW can be classified as hidden web and surface web. The web documents from surface web are indexable as well as crawlable by the search engines and hence they can be displayed to users as per their input query. In contrast to this, hidden web documents are neither indexable nor crawlable by the traditional search engines due to disconnected URL's, no-index tag, user authentication, web form processing. Also, since the information is scattered across multiple web pages, users find it difficult to hop between multiple pages to find the desired information. Hence, there is dire need of hidden web crawlers which could extract the data from hidden web databases and uncover this big part of WWW. In this research, a novel framework “Dynamic Query Processing for Hidden Web Data Extraction (DQPHDE)” has been proposed to extract such hidden web data and integrate it with the data from surface web to meet user's requirements. DQPHDE makes use of clustering, semantic based text mining and fuzzy rule based system to carry out the desired task. The results of the proposed work were compared with the existing academic search engines like ‘Microsoft Academic’ and ‘Academia.edu’ etc, and our proposed work outperforms them in fetching the information and then integrating the related information for other pages.",JWE,2020,,19,07-Aug,,931-970,2,0,https://ieeexplore.ieee.org/document/10251928/
A Mixed Deep Learning Based Model to Early Detection of Depression,Boumahdi Fatima | Madani Amina | Rezoug Nachida | Hentabli Hamza,"Laboratoire LRDSI, Faculté des Sciences, Université Blida 1, Blida, Algerie | Laboratoire LRDSI, Faculté des Sciences, Université Blida 1, Blida, Algerie | Laboratoire LRDSI, Faculté des Sciences, Université Blida 1, Blida, Algerie | Faculty of Computing, Universiti Teknologi Malaysia, Johor, Malaysia",Sentiment analysis | early risk detection | deep learning | mental health | depression identification | text classification,"Mental health is considered as one of today's world's most prominent plagues. Therefore, our work aims to use the potential of social media platforms to solve one of mental health's biggest issues, which is depression identification. We propose a new deep learning model that we train on a depression-dedicated dataset in order to detect such mental illness from an individual's posts. Our main contributions lie in the three following points: (1) We trained our own word embeddings using a depression-dedicated dataset. (2) We combined a Convolutional Neural Networks model with the Message-level Sentiment Analysis model in order to improve the feature extraction process and enhance the model's performance. (3) We analyzed through different experiments the performance of three deep learning models in order to provide more perspectives and insights for depression researches. A total of four classifier models were deployed with the same dataset. Those implementing CNN-BiLSTM with Attention model attained greater overall Accuracy, Recall, Precision and F1 macro scores of 0.97, 0.95, 0.84 and 0.92 on the final assessment test set, respectively.",JWE,2020,,19,03-Apr,,429-455,2,15,https://ieeexplore.ieee.org/document/10251867/
Verification of the Instantiation and Integration of Security Patterns,Tu Peng | Shuliang Wang | Jing Geng | Qinsi Wang | Yun Yang | Kang Zhang,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China | School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China | School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China | Department of Computer Science, Carnegie Mellon University, Pittsburgh, USA | School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia | Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA",Software engineering | software safety | software verification,"As software applications suffer from increasing malicious attacks, security becomes a critically important issue for software development. To avoid security problems and increase efficiency, a large software system design may reuse good security solutions for existing security patterns. While security patterns document expert solutions to common security problems and capture well-examined practices on secure software design, implementing them in a particular context (pattern instantiation) and composing them with other related patterns (pattern integration) are prone to flaws and may break expected security properties. In this paper, we present an approach to verify security patterns instantiation and integration automatically. We offer formal definitions for security pattern instantiation and integration, and establish rules to transform sequence diagrams (representing the behaviors of security patterns) to expressions in Milner's Calculus of Communicating Systems (CCS). We prove the correctness of the proposed transformation, and propose an algorithm to carry out this transformation automatically. In particular, we formally specify the alternative flows of UML sequence diagrams guarded by constraint conditions, which allows us to model choice making behaviors of security patterns precisely. The properties of the instantiation and integration can be verified by model checking against their CCS expressions. Flaws of instantiation and integration can, therefore, be discovered early in the design stage. We use two case studies to illustrate our approach and show the capability to prove security in integration and detect design errors in instantiation respectively.",JWE,2020,,19,03-Apr,,521-555,2,1,https://ieeexplore.ieee.org/document/10251869/
Abstract Concept Instantiation with Context Relevance Measurement,Shengwei Gu | Xiangfeng Luo | Hao Wang | Jing Huang | Subin Huang,"School of Computer Engineering and Science, Shanghai University, Shanghai, China | School of Computer Engineering and Science, Shanghai University, Shanghai, China | School of Computer Engineering and Science, Shanghai University, Shanghai, China | Ant Financial Services Group, Hangzhou, China | School of Computer Engineering and Science, Shanghai University, Shanghai, China",Abstract concept instantiation | contextual constraint | instance ranking,"In different contexts, one abstract concept (e.g., fruit) may be mapped into different concrete instance sets, which is called abstract concept instantiation. It has been widely applied in many applications, such as web search, intelligent recommendation, etc. However, in most abstract concept instantiation models have the following problems: (1) the neglect of incorrect label and label incompleteness in the category structure on which instance selection relies; (2) the subjective design of instance profile for calculating the relevance between instance and contextual constraint. The above problems lead to false prediction in terms of abstract concept instantiation. To tackle these problems, we proposed a novel model to instantiate the abstract concept. Firstly, to alleviate the incorrect label and remedy label incompleteness in the category structure, an improved random-walk algorithm is proposed, called InstanceRank, which not only utilize the category information, but it also exploits the association information to infer the right instances of an abstract concept. Secondly, for better measuring the relevance between instances and contextual constraint, we learn the proper instance profile from different granularity ones. They are designed based on the surrounding text of the instance. Finally, noise reduction and instance filtering are introduced to further enhance the model performance. Experiments on Chinese food abstract concept set show that the proposed model can effectively reduce false positive and false negative of instantiation results.",JWE,2020,,19,05-Jun,,575-602,2,0,https://ieeexplore.ieee.org/document/10247279/
Robust Optimization of Best-worst Multi-criteria Decision-making Method,Deqiang Qu | Zhong Wu | Shaojian Qu | Fan Zhang | Ping Li,"Business School, University of Shanghai for Science and Technology, Shanghai, P.R. China | Business School, University of Shanghai for Science and Technology, Shanghai, P.R. China | Business School, University of Shanghai for Science and Technology, Shanghai, P.R. China | Business School, University of Shanghai for Science and Technology, Shanghai, P.R. China | Business School, University of Shanghai for Science and Technology, Shanghai, P.R. China",Parameter uncertainty | robust counterpart | weight interval | quantile,The Best-worst multi-criteria decision-making method can determine optimal weight value of each criteria. It uses two vectors for pairwise comparisons in multi-criteria decision-making problem. This paper improves the original method from the perspective of robust optimization. Four robust counterpart constraints instead of two linear constraints in original optimization model are proposed. The decision-making problem can divide into full consistent and non-full consistent problems by classifying parameter value. We can achieve a unique set of interval solution in full consistent decision-making problem. Non-full consistent problem can result in multiple sets of optimal interval solution. The result which we get from this method is more effective than the original method. Each criterion can achieve optimal weight interval value. Then we take quantile value of each interval as optimal weight. This is effectively illustrated in the numerical test at the end of the paper.,JWE,2020,,19,07-Aug,,1067-1088,2,1,https://ieeexplore.ieee.org/document/10251889/
Heterogeneous Identity Expression and Association Method Based on Attribute Aggregation,Wenye Zhu | Chengxiang Tan | Qian Xu | Ya Xiao,"Department of Computer Science and Technology, Tongji University, Shanghai, China | Department of Computer Science and Technology, Tongji University, Shanghai, China | China Telecom Bestpay Co.Ltd,, Blockchain Research Institute, Shanghai, China | Department of Computer Science and Technology, Tongji University, Shanghai, China",Heterogeneous identity alliance | attribute aggregation | network identity management | identity expression | trust management,"Existing identity expression methods are often limited in a single security domain, and this is inadequate to meet the cross-domain access requirements of heterogeneous networks. In view of this problem, we propose an index system for the ubiquitous expression of heterogeneous identities, and introduce the concept pair matching based attribute aggregation method by combining the characteristics of heterogeneous identity alliances. The selection of concept pairs considers the original meaning of attribute characteristics, including the lexical level, i.e., class, ontology, label, description, the structural level, i.e., position, distance between nodes, and the semantic level, i.e., formal concept analysis. As for the attribute aggregation, if multiple attributes from a heterogeneous network contain the same or similar concepts, they are considered the same attribute for the user identity in a heterogeneous network. Relevant domain knowledge or heuristic knowledge will adjust the result of attribute aggregation, and the constraint relationship between conceptual structures are used to adjust and optimize the attribute aggregation set. Based on the identity attribute index system of the heterogeneous identity alliance, the identity similarity evaluation results based on each attribute are generated. When the comprehensively considered identity similarity evaluation result is higher than the empirical threshold, the heterogeneous identity alliance has different trusts for the same user. The experimental results show that our scheme has a better overall aggregation effect on identity attribute aggregation.",JWE,2020,,19,07-Aug,,1267-1290,2,0,https://ieeexplore.ieee.org/document/10251927/
Information Flow Control with Decentralized Labeling Model in Information Security,Veli Hakkoymaz | Cigdem Bakir,"Computer Engineering Department, Yildiz Technical University, Istanbul, Turkey | Computer Engineering Department, Yildiz Technical University, Istanbul, Turkey",Label model | data confidentiality | path compression | distributed databases | data privacy,"Data security aims to prevent the use, modification, and spread of data by unauthorized people. In this study, our purpose was to provide data privacy and confidentiality with information flow control in distributed databases. In particular, a decentralized label model was developed that maintained confidentiality, including privacy, with data flow control. This model consists of an actor, an object, and a label. The owners of the objects are actors, and they need to share their data objects with others. Actors label the data objects and then send them out. A label contains the policy statements of data security issued by each of the owners. Each owner sets its own security and privacy policy independently of the other owners. The confidentiality of data in unsecured transport channels is ensured for all the actors in the system by means of labels while the data are in flow. Data objects are spread and shared securely among actors within unsecured environments. In addition, with the path compression, the long node chain that is formed while the data objects are passing between the source node and the destination is broken, so that the objects are retrieved fast, and the cost of access is reduced. This result was shown experimentally by modeling the distributed environment.",JWE,2020,,19,07-Aug,,903-930,2,1,https://ieeexplore.ieee.org/document/10251858/
A Human-Centric and Environment-Aware Testing Framework for Providing Safe and Reliable Cyber-Physical System Services,In-Young Ko | KyeongDeok Baek | 06g-Hyun Kwon | Hernan Lira | HyeongCheol Moon,"School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Service-oriented systems | Cyber-physical systems | Environment-aware testing | Service effects | Human cognitive resources,"The functions, capabilities, and effects produced by the application services of cyber physical systems (CPS) are usually consumed by users performing their daily activities in a variety of environmental conditions. Thus, it is critical to ensure that those systems neither interfere with human activities nor harm the users involved. In this paper, we propose a framework for testing and verifying the safety and reliability of CPS services from the perspectives of CPS environments and users. The framework provides an environment-aware testing method by which the efficiency of testing CPS services can be improved by prioritizing CPS environments and by applying machine-learning techniques. The framework also includes a metric by which we can automate the test of the most effective services that deliver effects from physical devices to users. Additionally, the framework provides a computational model that assesses mental workloads to test whether a CPS service can cause cognitive depletion or contention problems for users. We conducted a series of experiments to show the effectiveness of the proposed approaches for ensuring the safety and reliability of CPS application services during the development and operation phases.",JWE,2020,,19,2,,139-165,2,0,https://ieeexplore.ieee.org/document/10247287/
An Efficient Authentication Protocol for Wireless Mesh Networks,Peng Zhai | Jingsha He | Nafei Zhu | Peng He | Yao Liang,"Faculty of Information Technology, Beijing University of Technology, Beijing, China | Faculty of Information Technology, Beijing University of Technology, Beijing, China | Faculty of Information Technology, Beijing University of Technology, Beijing, China | College of Computer and Information Science, China Three Gorges University, Yichang, Hubei, China | Department of Computer and Information Science, Indiana University-Purdue University Indianapolis, Indianapolis, IN, USA",Wireless mesh network | trusted authentication | network security | key cryptography,"In a wireless mesh network (WMN), how to guarantee safe access to sensitive information has been an issue under research partly because of various hidden attacks and attack vectors. As a network with no need to depend on a fixed infrastructure, WMN is operated over an open and wireless medium. Every user accessing to radio wave may access to the network. Hence, as the first line of defense, authentication for network access can stop illegal users from visiting the network. As an essential mechanism, an authentication program ensures safe access. A reliable handoff protocol on basis of some technologies is put forward in this paper, examples include classical hierarchical network model, Elliptic Curve Cryptography, Strategy evaluation and trust evaluation. The authentication protocol is on basis of Trusted Platform Module (TPM) where the validity of users and terminal devices are verified. Therefore, only reliable terminals applied by legal users can access to a WMN. According to numerical analysis and simulation outcomes, the switchoff authentication protocol proposed greatly overcomes other authentication protocols with regard to the ratio of authentication success and authentication delay.",JWE,2020,,19,07-Aug,,1193-1212,2,0,https://ieeexplore.ieee.org/document/10251870/
Dynamic Evaluation of Recommendation Trust in Open Networks,Yu Zhang | Guangmin Sun | Peng He | Peng Zhai | Yuge Sun,"Faculty of Information Technology, Beijing University of Technology, Beijing, China | Faculty of Information Technology, Beijing University of Technology, Beijing, China | College of Computer and Information Technology, China Three Gorges University, Yichang, China | Faculty of Information Technology, Beijing University of Technology, Beijing, China | School of Electrical and Electronic Engineering, the University of Manchester, Manchester, United Kingdom",Open networks | recommendation trust | dynamic | evaluation,"Trust evaluation is a key issue in the interaction between network entities in open networks. The attacks of malicious entities have become a major obstacle to the development of open networks. Few traditional trust models have considered incorporating incentive mechanisms to reduce the influence of recommendation values from malicious entities in trust evaluation. This paper proposed a dynamic evaluation of recommendation trust model, considering the interaction procedure between entities, introducing reward-punishment factor and evaluation reliability factor. The function of reward-punishment factor is to reward honest interactions between entities while punishing fraudulent interactions. The evaluation reliability factor is used to decide whether to accept the recommendations from the recommending entities. Simulation results show that the model could effectively reduce the influence of malicious entities in trust evaluation. The proposed model could accurately and reliably identify the access behaviour of malicious entities, and adopt appropriate processing countermeasure to ensure the accuracy and fault tolerance of calculation.",JWE,2020,,19,07-Aug,,1173-1192,2,0,https://ieeexplore.ieee.org/document/10251868/
A Testability and Observability Framework to Assure Traceability Requirements on System of Systems,Leticia Morales Trujillo | Miguel Ángel Olivero González | Francisco José Domínguez Mayo | Julián Alberto García García | Manuel Mejías Risoto,"Department of Languages and Computer Systems, Web Engineering and Early Testing (IWT2) group, University of Seville, Spain | Department of Languages and Computer Systems, Web Engineering and Early Testing (IWT2) group, University of Seville, Spain | Department of Languages and Computer Systems, Web Engineering and Early Testing (IWT2) group, University of Seville, Spain | Department of Languages and Computer Systems, Web Engineering and Early Testing (IWT2) group, University of Seville, Spain | Department of Languages and Computer Systems, Web Engineering and Early Testing (IWT2) group, University of Seville, Spain",System of Systems (SoS) | traceability | framework,"The advance in the digital world has caused a growth of complexity in innovation. Traditional approaches to innovation, based on reductionism, face greater difficulties. That is why we have witnessed the growth of those known as System of Systems (SoS). There is a wide variety of methodologies and domains of application in the literature to form framed solutions in the context of SoS, but there is no unified consensus for its use and even less when it comes to agile environments of continuous integration and deployment in which traceability requirements are critical. In recent years, the need to have traceability software that continuously records and monitors the trace of the entities that interact with it has become an essential feature. In addition, over the years there has been evidence of errors caused by poor traceability control. Therefore, this document presents an agile framework that aims to guarantee the traceability of a SoS from the early stages. This framework unifies the discovery, development and operations, providing full coverage in the conformation of the solution. Finally, we present a case study as future work, which is based on the application of our framework on smart laboratories for assisted reproduction.",JWE,2020,,19,2,,297-318,2,2,https://ieeexplore.ieee.org/document/10247297/
"Unveiling Usability and UX Relationships for Different Gender, Users Habits and Contexts of Use",Deller James Ferreira | Tatiane F. N. Melo | Tiago do Carmo Nogueira,"Instituto de Informática, Universidade Federal de Goiás, Goiânia, Goiás, Brazil | Instituto de Matemática e Estatística, Universidade Federal de Goiás, Goiânia, Goiás, Brazil | Núcleo de Informática Acessível, Instituto Federal Baiano, Guanambi, Bahia, Brazil",Usability | UX | gender | computer usage time | context of use,"Despite the abundance of research into usability and user experience (UX), there are few works approaching how the context influences the relationships between these two concepts. The actual experience of a user highly depends on personal characteristics, like the social and cultural background. In this work, we address user-related and contextual factors for a better comprehension of usability UX correlations. We conducted a study with 160 participants in entertainment, e-bank, education and e-commerce websites. As a result, for both sex and usage time user classes, a good usability was positively correlated to positive emotions. Despite the correlations between usability and female users negative and positive emotional reactions are greater than for male users, no significant difference was observed. Also, there was no significant difference involving correlations between usability and emotional reactions, when comparing less and more frequent users. As another result, there are differences of the degree of the correlations between perceived usability and emotional responses in different contexts of use, when dividing the users on sex and usage time classes, but the correlations between usability and positive emotions remained positive. In spite of the particularities of user classes, similarities on the usability for different user classes and the agreement of patterns of correlations with previous literature, our results reinforces the usability as a determinant aspect for UX.",JWE,2020,,19,05-Jun,,819-847,2,6,https://ieeexplore.ieee.org/document/10247300/
Special Issue on Advanced Practices in Web Engineering 2020,J. G. Enríquez | A. Jiménez-Ramírez | S. Meliá,"Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Computer Languages and Systems Department, Universidad de Alicante, San Vicente del Raspeig, Alicante, Spain",,"Web engineering is aligned with the undergoing evolution of modern web applications which have higher user expectations and demands than ever before. Thus, the ability of developers to adopt new advanced practices could be the difference between success and failure.",JWE,2020,,19,2,,v-viii,2,0,https://ieeexplore.ieee.org/document/10247275/
Dynamic Resource Allocation Method for Load Balance Scheduling Over Cloud Data Center Networks,Sakshi Chhabra | Ashutosh Kumar Singh,"National Institute of Technology Kurukshetra, Haryana, India | National Institute of Technology Kurukshetra, Haryana, India",Cloud computing | resource configuration | dynamic allocation | optimization,"The cloud datacenter has numerous hosts as well as application requests where resources are dynamic. The demands placed on the resource allocation are diverse. These factors could lead to load imbalances, which affect scheduling efficiency and resource utilization. A scheduling method called Dynamic Resource Allocation for Load Balancing (DRALB) is proposed. The proposed solution constitutes two steps: First, the load manager analyzes the resource requirements such as CPU, Memory, Energy and Bandwidth usage and allocates an appropriate number of VMs for each application. Second, the resource information is collected and updated where resources are sorted into four queues according to the loads of resources i.e. CPU intensive, Memory intensive, Energy intensive and Bandwidth intensive. We demonstarate that SLA-aware scheduling not only facilitates the cloud consumers by resources availability and improves throughput, response time etc. but also maximizes the cloud profits with less resource utilization and SLA (Service Level Agreement) violation penalties. This method is based on diversity of client's applications and searching the optimal resources for the particular deployment. Experiments were carried out based on following parameters i.e. average response time; resource utilization, SLA violation rate and load balancing. The experimental results demonstrate that this method can reduce the wastage of resources and reduces the traffic upto 44.89% and 58.49% in the network.",JWE,2021,,20,8,,2269-2284,2,47,https://ieeexplore.ieee.org/document/10246901/
News Recommendation Systems in the Era of Information Overload,Shuaishuai Feng | 06yan Meng | Jiaxing Zhang,"School of Sociology, Wuhan University, Wuhan, Hubei, China | School of Sociology, Wuhan University, Wuhan, Hubei, China | The Institute of Social Development Studies, Wuhan University, China",Information overload | internet news | recommendation systems | User-CF | Item-CF | reflection on technology,"The internet has reconstructed information boundaries in the modern world, and along with mobile internet has become the most important source of information for the public. Simultaneously, the internet has brought humanity into an era of information overload. In response to this information overload, recommendation systems backed by big data and smart algorithms have become highly popular on information platforms on the internet. There have already been many studies that attempted to improve and upgrade recommendation algorithms from a technical perspective, but the field lacks a comprehensive reflection on news recommendation systems. In our study, we summarize the principles and characteristics of current news recommendation systems and discuss “unexpected consequences” that might arise from these algorithms. In particular, technical bottlenecks include cold starts and data sparsity, and moral bottlenecks are presented in the form of information imbalance and manipulation. These problems may cause new recommendation systems to become a “warped mirror”.",JWE,2021,,20,2,,459-470,2,24,https://ieeexplore.ieee.org/document/10247326/
Suspicious Action Detection in Intelligent Surveillance System Using Action Attribute Modelling,Manisha Mudgal | Deepika Punj | Anuradha Pillai,"Department of Computer Engineering, JC BOSE UST YMCA, Faridabad, Haryana, India | Department of Computer Engineering, JC BOSE UST YMCA, Faridabad, Haryana, India | Department of Computer Engineering, JC BOSE UST YMCA, Faridabad, Haryana, India",Action recognition | surveillance systems | gaussian mixture model | violence action,"Research in the field of image processing and computer vision for recognition of suspicious activity is growing actively. Surveillance systems play a key role in monitoring of sensitive places such as airports, railway stations, shopping complexes, roads, parking areas, roads, banks. For a human it is very difficult to monitor surveillance videos continually, therefore a smart and intelligent system is required that can do real time monitoring of all activities and can categories between usual and some abnormal activities. In this paper many different abnormal activities has been discussed. More focuses is given to violence activity like hitting, slapping, punching etc. For this large human action dataset like UCF101, Kaggel is required. This paper proposes a method to model violence actions using Gaussian Mixture Model with Universal Attribute Model. Super action vector is calculated using UMA. To represent every SAV in few significant attributes, factor analysis is performed and result gives a low dimensional relevant action vectors.",JWE,2021,,20,1,,129-146,2,23,https://ieeexplore.ieee.org/document/10246862/
Research on End-to-end Voiceprint Recognition Model Based on Convolutional Neural Network,Hong Zhao | Lupeng Yue | Weijie Wang | Xiangyan Zeng,"School of Computer Science, Lanzhou University of Technology, Gansu, Lanzhou, China | School of Computer Science, Lanzhou University of Technology, Gansu, Lanzhou, China | School of Computer Science, Lanzhou University of Technology, Gansu, Lanzhou, China | Department of Mathematics and Computer Science, Fort Valley State University, Fort Valley, GA, Georgia",Convolutional neural network | end-to-end voiceprint recognition | voiceprint recognition model | speech signal | Res-FD-CNN network structure,"Speech signal is a time-varying signal, which is greatly affected by individual and environment. In order to improve the end-to-end voice print recognition rate, it is necessary to preprocess the original speech signal to some extent. An end-to-end voiceprint recognition algorithm based on convolutional neural network is proposed. In this algorithm, the convolution and down-sampling of convolutional neural network are used to preprocess the speech signals in end-to-end voiceprint recognition. The one-dimensional and two-dimensional convolution operations were established to extract the characteristic parameters of Meier frequency cepstrum coefficient from the preprocessed signals, and the classical universal background model was used to model the recognition model of voice print. In this study, the principle of end-to-end voiceprint recognition was firstly analyzed, and the process of end-to-end voice print recognition, end-to-end voice print recognition features and Res-FD-CNN network structure were studied. Then the convolutional neural network recognition model was constructed, and the data were preprocessed to form the convolutional layer in frequency domain and the algorithm was tested.",JWE,2021,,20,5,,1573-1586,2,10,https://ieeexplore.ieee.org/document/10246874/
Trajectory Data Restoring: A Way of Visual Analysis of Vessel Identity Base on OPTICS,Jinyu Lei | Xiumin Chu | Wei He,"National Engineering Research Center for Water Transport Safety, Wuhan University of Technology, Wuhan, China | Fujian Engineering Research Center of Safety Control for Ship Intelligent Navigation, Minjiang University, Fuzhou, China | Fujian Engineering Research Center of Safety Control for Ship Intelligent Navigation, Minjiang University, Fuzhou, China",Automatic identification system | waterway transportation | visual analysis | OPTICS clustering,"Automatic identification system (AIS) data is a significant analysis and decision-making basis for maritime situational awareness. Because of particular navigation environment and the vulnerability of AIS equipment onboard, results in the phenomenon that numerous vessels share the same Maritime Mobile Service Identity (MMSI) in the AIS data collected in ocean and inland waterway. This kind of mixed trajectory information dramatically affects the judgement of the maritime manager and supervisors. In this paper, the visual analytics combined with the algorithm named Ordering Points to Identify the Clustering Structure (OPTICS) is adopted to realize the separation of vessels sharing same MMSI, which can help analysts to recognize the vessel trajectory information and assess the risk of marine traffic correctly. Firstly, this paper illustrates the application of OPTICS clustering method based on space-time distance in AIS trajectory separation. Secondly, the display and interaction of trajectory information of Vessels sharing the same MMSI in OpenStreetMap map were introduced. Then visual analysis method is applied to optimize the parameters of the algorithm and display the trajectory separation effect corresponding to different settings. In final, various practical situations are discussed, and the empirical test shows that it is feasible in AIS chaos trajectory separation.",JWE,2021,,20,2,,413-430,2,11,https://ieeexplore.ieee.org/document/10247333/
Research on Web Data Mining Based on Topic Crawler,Hongjian Guo,"Nanjing Audit University, Jiangsu, China",Topic network | crawler | data mining | web information search,"This paper analyzes the method of Web information data mining based on topic crawler. This paper puts forward the architecture of Web information search and data mining, and introduces the key technology and operation principle of the architecture. After analyzing the functions and shortcomings of ordinary crawler, this paper focuses on the working principle, implementation method and performance analysis of this crawler, as well as the functions of this crawler different from other crawlers and its application in Web information search and data mining system. The experimental results show that the crawler can get all kinds of information resources on the world wide web, which is helpful to the monitoring and management of network cultural content.",JWE,2021,,20,4,,1193-1206,2,13,https://ieeexplore.ieee.org/document/10246783/
Analysis and Mining of Internet Public Opinion Based on LDA Subject Classification,Mei Zhang | Huihui Su | Jinghua Wen,"Information Institute, Guizhou University of Financial and Economics, Guiyang, Guizhou, China | Information Institute, Guizhou University of Financial and Economics, Guiyang, Guizhou, China | Information Institute, Guizhou University of Financial and Economics, Guiyang, Guizhou, China",Online public opinion | LDA | co-occurrence knowledge graphs | visualization,"This paper uses Python, R language, Gephi and other software to crawl and classify the comment content of Weibo hot search events. Using word cloud, co-occurrence social network graphs, LDA topic classification visualization methods, this paper regularizes and integrates public opinions of hot events. Through this research, we can get the influence of public opinion mediators, public opinion objects, and government forces on the network public opinion and put forward corresponding improvement suggestions. We hope to contribute to the government's governance and prevention of online public opinion during the spread of COVID-19 and other public hot events.",JWE,2021,,20,8,,2457-2472,2,19,https://ieeexplore.ieee.org/document/10246839/
A K-means Text Clustering Algorithm Based on Subject Feature Vector,Ji Duo | Peng Zhang | Liu Hao,"Criminal Investigation Police University of China, China | Chinese Academy of Sciences, Institute of Information Engineering, China | Criminal Investigation Police University of China, China",k-means | initial points | decision graph | iterative class center | subject feature vector,"As one of the most popular clustering algorithms, k-means is easily influenced by initial points and the number of clusters, besides, the iterative class center calculated by the mean of all points in a cluster is one of the reasons influencing clustering performance. Representational initial points are selected in this paper according to the decision graph composed by local density and distance of each point. Then we propose an improved k-means text clustering algorithm, the iterative class center of the improved algorithm is composed by subject feature vector which can avoid the influence caused by noises. Experiments show that the initial points are selected successfully and the clustering results improve 3%, 5%, 2% and 7% respectively than traditional k-means clustering algorithm on four experimental corpuses of Fudan and Sougou.",JWE,2021,,20,6,,1935-1946,2,7,https://ieeexplore.ieee.org/document/10246892/
Theoretical and Empirical Analysis of Crime Data,Manisha Mudgal | Deepika Punj | Anuradha Pillai,"Department of Computer Engineering, JC BOSE UST YMCA, Faridabad, Haryana, India | Department of Computer Engineering, JC BOSE UST YMCA, Faridabad, Haryana, India | Department of Computer Engineering, JC BOSE UST YMCA, Faridabad, Haryana, India",Crime | data mining | deep learning | KNN | RNN | Gaussian | Naïve Bayes | clustering | classification | decision tree,"Crime is one of the biggest and dominating problems in today's world and it is not only harmful to the person involved but also to the community and government. Due to escalation in crime frequency, there is a need for a system that can detect and predict crimes. This paper describes the summary of the different methods and techniques used to identify, analyze and predict upcoming and present crimes. This paper shows, how data mining techniques can be used to detect and predict crime using association mining rule, k-means clustering, decision tree, artificial neural networks and deep learning methods are also explained. Most of the researches are currently working on forecasting the occurrence of future crime. There is a need for approaches that can work on real-time crime prediction at high speed and accuracy. In this paper, a model has been proposed that can work on real-time crime prediction by recognizing human actions.",JWE,2021,,20,1,,113-128,2,5,https://ieeexplore.ieee.org/document/10246869/
Research on Data Fusion Method of Multi-source Complex System,Yuxiang Cai,"Shanghai Jiao Tong University, Shanghai, China",Artificial neural network | fuzzy neural network | Data fusion algorithm | Multi-platform sensor,"Multi source fusion of data collected by various sensors to realize accurate perception is the key basic technology of the Internet of things. At present, there are many problems in the fusion of various kinds of data collected by sensors, such as more noise and more null values. In this paper, the fuzzy neural network algorithm is proposed to establish the model, combined with the Delphi method and the null value estimation method based on the prediction value to construct the data fusion system. This method has rich application scenarios in the construction of IOT system in the field of power and energy.",JWE,2021,,20,5,,1553-1572,2,5,https://ieeexplore.ieee.org/document/10246872/
Research on Outlier Detection for High-Dimensional Data Based on PPCLOF,Chen Chen | Kaiwen Luo | Lan Min | Shenglin Li,"Department of Military logistics, Army Logistics University of PLA, Chongqing, China | Department of Military logistics, Army Logistics University of PLA, Chongqing, China | College of Management Science, Chengdu University of Technology, Chengdu, China | College of Artificial Intelligence, Southwest University, Chongqing, China",Outlier detection | high-dimensional data | PPC | LOF,"Aiming at the “dimension disaster” problem encountered in the outlier detection of high-dimensional data, this paper uses the projection pursuit algorithm to perform non-linear dimensionality reduction on high-dimensional data by calculating the phase relationship between dimensions. According to the sample points obtained by dimensionality reduction, the LOF (Local Outlier Factor) algorithm is applied to calculate the outlier factor to obtain the relevant outlier data. In order to improve the calculation accuracy and efficiency of the LOF algorithm, clustering method is used to cut the outlier calculation data to reduce the amount of calculation. Experiments on real-world and artificial datasets, compared with the existing algorithms, demonstrated the effectiveness and efficiency of the proposed algorithm.",JWE,2021,,20,3,,743-758,2,2,https://ieeexplore.ieee.org/document/10246196/
Multi-image Reorganization Encryption Based on S-L-F Cascade Chaos and Bit Scrambling,Xiaoming Song | Daihan Xu | Guodong Li | Wenxia Xu,"School of Mathematics and Computing Science, Guilin University of Electronic Technology, Guilin, Guangxi, China | School of computer science, Beijing University of Technology, Beijing, China | School of Mathematics and Computing Science, Guilin University of Electronic Technology, Guilin, Guangxi, China | School of Mathematics and Computing Science, Guilin University of Electronic Technology, Guilin, Guangxi, China",S-L-F Cascade Chaos | bit-level scrambling | Multi-image Encryption | Logistic chaos | Sine-Sine mapping,"Aiming at the problems of small value range of a single chaotic parameter, low sequence chaos, and transient effects, a composite chaotic system of cascaded Sine-Sine mapping, Logistic chaos and generalized third-order Fibonacci is proposed (S-L-F). The new system is highly sensitive to initial values, the maximum spectral entropy of the generated sequence can reach 0.95, and the value range of the parameter x is expanded to [0,4] compared with the traditional Logistic, indicating that the new system is suitable for generating pseudo-random sequences for image encryption. For the problem that the traditional multi-image encryption scheme can only encrypt images of the same type and size, the practicability is poor, and a multi-image encryption scheme based on image reorganization and biting is proposed. The algorithm recombines any number, different sizes and different types of images into a three-dimensional matrix, converts it into a binary matrix, performs bit-level scrambling and surface cyclic scrambling, and then restores the scrambling matrix to decimal, and the chaotic sequence performs exclusive-or diffusion, and completes simultaneous encryption at one time, which greatly improves the encryption efficiency and scope of application. The NPCR of the ciphertext image is 0.9961, and the UACI is 0.3345, which proves that the ciphertext image can effectively resist the difference attack. The information entropy is greater than 7.999, which can effectively resist attacks. It has certain application value in image information security. Experimental analysis shows that the algorithm has high security and strong practicability.",JWE,2021,,20,4,,1177-1192,2,19,https://ieeexplore.ieee.org/document/10246198/
Lossless Compression Algorithm and Architecture for Reduced Memory Bandwidth Requirement with Improved Prediction Based on the Multiple DPCM Golomb-Rice Algorithm,Imjae Hwang | Juwon Yun | Woonam Chung | Jaeshin Lee | Cheong-Ghil Kim | Youngsik Kim | Woo-Chan Park,"Sejong University, Seoul, Korea | Sejong University, Seoul, Korea | Sejong University, Seoul, Korea | Sejong University, Seoul, Korea | Namseoul University, Cheonan, South Korea | Korea Polytechnic University, Gyeonggi Province, South Korea | Sejong University, Seoul, Korea",Lossless image compression | hardware architecture | memory bandwidth reduction,"In a computing environment, higher resolutions generally require more memory bandwidth, which inevitably leads to the consumption more power. This may become critical for the overall performance of mobile devices and graphic processor units with increased amounts of memory access and memory bandwidth. This paper proposes a lossless compression algorithm with a multiple differential pulse-code modulation variable sign code Golomb-Rice to reduce the memory bandwidth requirement. The efficiency of the proposed multiple differential pulse-code modulation is enhanced by selecting the optimal differential pulse code modulation mode. The experimental results show compression ratio of 1.99 for high-efficiency video coding image sequences and that the proposed lossless compression hardware can reduce the bus bandwidth requirement.",JWE,2021,,20,6,,1813-1828,2,1,https://ieeexplore.ieee.org/document/10246890/
The Application of Artificial Intelligence Technology in Cloud Computing Environment Resources,Xiangbin Wen | Yuan Zheng,"Information Center, GuangZhou University of Chinese Medicine, Guangzhou, Guangdong, China | Information Center, GuangZhou University of Chinese Medicine, Guangzhou, Guangdong, China",Artificial intelligence technology | cloud computing environment | cloud computing resources | IaaS,"With the continuous innovation and development of modern computer science and mobile Internet and other information technologies, artificial intelligence (AI) is not a new thing. It has been widely studied and applied in many fields, and it is very important for people in modern society. The research fields of artificial intelligence mainly include: deep learning, natural language processing, computer vision, intelligent robot, automatic programming, data mining and so on. All kinds of industrial production and daily life will bring a very important practical significance and far-reaching influence. The rapid development and improvement of AI have effectively changed the daily life of modern people and improved work efficiency, and promoted the vigorous and healthy development of human economic and social civilization and the progress of information technology. When widely used, traditional network information and big data processing technologies are difficult to adapt to its development needs. Only by closely combining cloud computing technology with other technologies can it play a better role and give full play to AI technology and its development. The enthusiasm and promotion of related application technologies have promoted the smooth progress of AI technology and related undertakings. With the development and improvement of cloud computing technology, more and more users tend to use the cloud to work. However, a large number of cloud service failures occurred, causing huge losses for enterprises and individuals. In order to prevent damage to the interests of enterprises and individuals, cloud service providers will provide high-quality services as much as possible. This paper aims to study the application of AI technology in cloud computing environment resources, research on the indicator of reliability, and propose a cloud service reliability verification method for the infrastructure-as-a-service layer. Experimental research shows that through the reliability detection method in this paper, users can easily and quickly obtain the reliability of the purchased cloud service, and can intuitively feel whether the performance of each server meets the promised situation in the cloud service provider's SLA.",JWE,2021,,20,6,,1853-1866,2,12,https://ieeexplore.ieee.org/document/10247157/
Integration of “Offline + Online” Teaching Method of College English Based on Web Search Technology,Li06 Bian,"Henan Finance University, Zhengzhou, Henan, China",Web technology | college english | learning platform | big data,"The change of social demand for English application-oriented talents has affected the transformation of the way of cultivating talents in College English. The traditional training mode of indoctrination has exposed more and more disadvantages, and the demand of new teaching mode is imminent. This paper first analyzes the current situation of College English learning platform in China. Then, it discusses the design and implementation of “Online + offline” College English learning platform based on Web. The overall structure and function of the database are designed in detail. The teaching platform provides students with learning tools, learning resources, communication platform, testing and evaluation functions, and can evaluate students' learning behavior, learning process and learning effect. This paper traces and collects a large amount of data left by learners in learning college English courses, and analyzes learners' learning habits, learning progress and learning effect. Finally, according to the learning big data, this paper customized a reasonable personalized learning platform and improved the online teaching personalized service system.",JWE,2021,,20,4,,1207-1218,2,13,https://ieeexplore.ieee.org/document/10246200/
A Deep Convolutional Neural Network to Limit Virus Spread Using Facial Mask Segmentation,D. Lefloch | J. M. Wang,"Software Engineering Department, Tiangong University, Tianjin, China | Software Engineering Department, Tiangong University, Tianjin, China",Mask segmentation | face detection | convolutional neural networks | deep learning,"Due to the recent COVID-19 outbreak the world has experienced many challenges. Limit and control the virus spread rate is one of them. This letter focuses on limiting the speed of virus spreading by monitoring the use of facial mask in crowded public environments such as tourism places, commercial centres, etc. The proposed method first accurately localizes faces using a state-of-the-art approach and, segments facial mask in a second step. The facial mask segmentation allows to distinguish whether the current subject is wearing a facial mask or not but also if it is properly covering the human face. Indeed, most recent face detection algorithms provide as output a set of facial features such as nose tip and mouth corners. By combining these facial features with facial mask segmentation, the proposed method detects real-time subjects that indirectly encourage virus spread in crowded environments. The proposed facial mask segmentation model is trained with pairs of RGB images and its corresponding alpha image created by extending the publicly available real-world masked face dataset. Further, the proposed model is pruned and optimized using the TensorRt library to be usable for real-world applications.",JWE,2021,,20,4,,1239-1250,2,2,https://ieeexplore.ieee.org/document/10246202/
Patterns for Migration of SOA Based Applications to Microservices Architecture,Vinay Raj | Ravichandra Sadam,"National Institute of Technology Warangal, Telangana, India | National Institute of Technology Warangal, Telangana, India",Distributed systems | service oriented architecture | microservices | migration | migration patterns,"Service oriented architecture (SOA) has been widely used in the design of enterprise applications over the last two decades. Though SOA has become popular in the integration of multiple applications using the enterprise service bus, there are few challenges related to delivery, deployment, governance, and interoperability of services. To overcome the design and maintenance challenges in SOA, a new architecture of microservices has emerged with loose coupling, independent deployment, and scalability as its key features. With the advent of microservices, software architects have started to migrate legacy systems to microservice architecture. However, many challenges arise during the migration of SOA to microservices, including the decomposition of SOA to microservice, the testing of microservices designed using different programming languages, and the monitoring the microservices. In this paper, we aim to provide patterns for the most recurring problems highlighted in the literature i.e, the decomposition of SOA services, the size of each microservice, and the detection of anomalies in microservices. The suggested patterns are combined with our experience in the migration of SOA-based applications to the microservices architecture, and we have also used these patterns in the migration of other SOA applications. We evaluated these patterns with the help of a standard web-based application.",JWE,2021,,20,5,,1291-1307,2,16,https://ieeexplore.ieee.org/document/10246860/
Research on the Design of Mass Recommendation System Based on Lambda Architecture,Bowen Chen | Li Zhu | Da Wang | 06Hua Cheng,"School of Electronics and Electrical Engineering, Hubei University of Technology, Hubei, Wuhan, China | Hubei Key Laboratory for High-efficiency Utilization of Solar Energy and Operation Control of Energy Storage System, Hubei University of technology, Wuhan, P. R. China | School of Electronics and Electrical Engineering, Hubei University of Technology, Hubei, Wuhan, China | Manager of No. 11 branch of China Communications Construction Third Engineering Bureau Co., Ltd, P. R. China",Lambda architecture | mass | recommender system | cascading | hybrid algorithm,"In the era of big data, in order to increasing the information data for conforms to the personalized needs of content, research scholars put forward based on the Lambda mass recommendation system architecture design, it can not only to the recessive and dominant behavior of users of the system data collection storage and research analysis, can also be based on the analysis of cascading hybrid algorithm to explore how to carry out real-time recommendation. Therefore, on the basis of understanding the research and development achievements of recommender systems at home and abroad in recent years, and based on the understanding and analysis of Lambda architecture and cascading hybrid algorithm, this paper aims at how to design a massive recommender system in line with users' behavior, and makes clear the recommendation effect by combining with system testing.",JWE,2021,,20,6,,1971-1990,2,1,https://ieeexplore.ieee.org/document/10246895/
Development of Converged Device-Based Exercise Program for Preventing Fall and Increasing Physical Activity for the Elderly,Sunyoung Kang,"Department of Physical Education, Korea University, Seoul, Korea",Converged device-based | the frail elderly | fall | interface,"As the effects of COVID-19, many changes are occurring in the daily life. Breaking away from the temporal and spatial restrictions, the exercise method utilizing converged device in non-contact fashion is emerging. In the present study, home training with utilization of the converged device for fall prevention and improvement of daily life in behalf of the frail elderly has been composed, and execution process designed. Converged device-based exercise program extracted through Delphi analysis is composed of essential 8 types of motion reflecting the performance capability of the frail elderly as the subject, though easy, have been selected. Converged device-based exercise program configured the system in a structure of subject, interface, and administrator for the purpose of utilizing this exercise program. Overall execution process is composed 3 stages, and implemented with the elderly and the trainer being converged via medium. For the overall implementation, the elderly performs the exercise program under leading of the trainer as the administrator. Depending on the condition of the elderly as the subject, the trainer selects the difficulty of exercise, which the elderly performs and implements the exercise program while communicating with the trainer. The converged device-based exercise program that is applicable to the elderly as a digitally vulnerable class is expected to bring about not only fall prevention and increased physical activities but also subsidiary effects of producing digital device-friendly environments for the elderly as a digitally vulnerable class.",JWE,2021,,20,1,,103-112,2,0,https://ieeexplore.ieee.org/document/10246858/
Data Analysis for Thermal Disease Wearable Devices,Jinkook Kim | Soohyun Kim,"Department of Sport and Healthcare, Namseoul University, Korea | Department of Sport and Healthcare, Namseoul University, Korea",Thermal disease | wearable device | service platform | application,"This study was conducted as a planning stage for development of wearable devices capable of managing the thermal diseases by applying the ICT (Information Communication Technology) in an endeavor to meet the urgent needs for countermeasures amid rapid increase in the number of patients with the thermal diseases caused as a result of global warming. The purpose of this study was to provide the basic data for development of wearable devices allowing the patients to be transported expeditiously to hospitals based on synchronization with medical institutions or enabling the prevention of diseases through the response system for each stage according to the reference values based on the data reflecting physical characteristics of individuals by applying the ICT, so that the thermal diseases can be managed effectively. For that, basic study will be conducted on expanding the role of the devices capable of protecting human lives from various thermal diseases caused by the scorching heat waves, which are affecting countries worldwide and expected to persist in the period ahead, by setting the goals of each stage for the thermal disease management platform and collecting necessary information. Based on the accumulated data, the functions of precise diagnosis and treatment can be expected through more accurate evidences pertaining to the thermal diseases.",JWE,2021,,20,1,,89-102,2,3,https://ieeexplore.ieee.org/document/10246857/
Deep Learning-Based Encrypted Network Traffic Classification and Resource Allocation in SDN,Hao Wu | Xi Zhang | Jufeng Yang,"School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China | School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China | Signal and Communication Research Institute, China Academy of Railway Science Corporation, Beijing, China",Deep learning | encrypted traffic | Fourier transform | convolutional neural network | DFR architecture | one-dimensional CNN encrypted traffic classification mode,"In the rapid development of network technology, with the improvement of the quality and quantity of network users' demands, more and more network information technology and excessive network traffic also raise people's attention to the internal network security. Especially for the classification and resource allocation of encrypted network traffic, the research of related technologies has become the main research direction of the development of network technology. The extensive application of deep learning provides a new idea for the study of traffic classification. Therefore, on the basis of understanding the current situation, the improved convolutional neural network is selected to conduct an in-depth discussion on traffic classification and resource allocation of encrypted networks based on deep learning. The performance of the system is verified from the perspective of practical application.",JWE,2021,,20,8,,2319-2334,2,10,https://ieeexplore.ieee.org/document/10246898/
A High Autonomous Sea Front Detection Algorithm Based on SAR Data,Su-qin Xu | Hao Jiang | Ting-ting Li | Li-ming Yuan | Lu Yu | Jie Chen | Biao Chen | Bao-qiang Zhang,"Navy Submarine Academy, Qingdao, China | Navy Submarine Academy, Qingdao, China | Navy Submarine Academy, Qingdao, China | Navy Submarine Academy, Qingdao, China | Navy Submarine Academy, Qingdao, China | Navy Submarine Academy, Qingdao, China | Navy Submarine Academy, Qingdao, China | Navy Submarine Academy, Qingdao, China",Sea front | SAR | high autonomy | graphic detection,"This paper has proposed a high autonomous sea front detection algorithm based on SAR data. Through the innovative introduction of empirical mode decomposition method, a good image de-trend and de-stripe effect is achieved. By introducing the calculation of the maximum interclass variance, the automatic conversion of binary images is realized; through the use of polynomial fitting method, the independent screening of front information is realized, and the continuity of front detection results is improved. After comparison, it is found that the new algorithm proposed in this paper has greatly improved detection accuracy and autonomy compared with the old algorithm. Finally, a SAR data of the GF-3 satellite on the west side of Taiwan Island is used to test the new algorithm proposed in this paper. The results show that the detection results are highly consistent with the original image in morphology, and the changes in frontal intensity are also very detailed, verifying the accuracy and autonomy of the new method.",JWE,2021,,20,2,,471-490,2,2,https://ieeexplore.ieee.org/document/10247321/
Multi-Rhythm Capsule Network Recognition Structure for Motor Imagery Classification,Meiyan Xu | 06feng Yao | Yifeng Zheng | Yaojin Lin,"Xiamen University, China | Xiamen University, China | Minnan Normal University, China | Minnan Normal University, China",Capsule network | deep learning | brain machine interface | motor imagery | classification,"Existing machine learning methods for classification and recognition of EEG motor imagery usually suffer from reduced accuracy for limited training data. To address this problem, this paper proposes a multi-rhythm capsule network (FBCapsNet) that uses as little EEG information as possible with key features to classify motor imagery and further improves the classification efficiency. The network conforms to a small recognition model with only 3 acquisition channels but it can effectively use the limited data for feature learning. Based on the BCI Competition IV 2b data set, experimental results show that the proposed network can achieve 2.41% better performance than existing cutting-edge methods.",JWE,2021,,20,3,,759-774,2,0,https://ieeexplore.ieee.org/document/10246197/
A Novel Negative Sampling Based on Frequency of Relational Association Entities for Knowledge Graph Embedding,Yi Zhang | Wanhua Cao | 06tao Liu | Ziyun Rao,"College of Computer Science and Technology, Harbin Engineering University, Harbin, China | College of Computer Science and Technology, Harbin Engineering University, Harbin, China | Wuhan Digital Engineering Research Institute, Wuhan, China | Wuhan Digital Engineering Research Institute, Wuhan, China",Knowledge embeddings | negative sampling | link prediction | knowledge graph,"Knowledge graph embedding improves the performance of relation extraction and knowledge reasoning by encoding entities and relationships in low-dimensional semantic space. During training, negative samples are usually constructed by replacing the head/tail entity. And the different replacing relationships lead to different accuracy of the prediction results. This paper develops a negative triplets construction framework according to the frequency of relational association entities. The proposed construction framework can fully consider the quantitative of relations and entities in the dataset to assign the proportion of relation and entity replacement and the frequency of the entities associated with each relationship to set reasonable proportions for different relations. To verify the validity of the proposed construction framework, it is integrated into the state-of-the-art knowledge graph embedding models, such as TransE, TransH, DistMult, ComplEx, and Analogy. And both the evaluation criteria of relation prediction and entity prediction are used to evaluate the performance of link prediction more comprehensively. The experimental results on two commonly used datasets, WN18 and FB15K, show that the proposed method improves entity link and triplet classification accuracy, especially the accuracy of relational link prediction.",JWE,2021,,20,6,,1867-1884,2,4,https://ieeexplore.ieee.org/document/10246885/
A Study on Hybrid Hierarchical Network Representation Learning,Yongxiang Hu,"Huanggang Normal University, Hubei, China",Network representation learning | dimension reduction | graph contraction,"Network representation learning (NRL) aims to convert nodes of a network into vector forms in Euclidean space. The information of a network is needed to be preserved as much as possible when NRL converts nodes into vector representation. A hybrid approach proposed in this paper is a framework to improve other NRL methods by considering the structure of densely connected nodes (community-like structure). HARP [1] is to contract a network into a series of contracted networks and embed them from the high-level contracted network to the low-level one. The vector representation (or embedding) for a high-level contracted network is used to initialize the learning process of a low-level contracted graph hierarchically. In this method (Hybrid Approach), HARP is revised by using a well-designed initialization process on the most high-level contracted network to preserve more community-like structure information.",JWE,2021,,20,6,,1923-1934,2,0,https://ieeexplore.ieee.org/document/10246887/
Detecting APT Attacks Based on Network Traffic Using Machine Learning,Cho Do Xuan,"Information Assurance dept., FPT University, Hanoi, Vietnam",Advanced Persistent Threat | APT attack detection | Network traffic | domain | abnormal behaviour | machine learning,"Advanced Persistent Threat (APT) attacks are a form of malicious, intentionally and clearly targeted attack. By using many sophisticated and complicated methods and technologies to attack targets in order to obtain confidential and sensitive information. In fact, in order to detect APT attacks, detection systems often need to apply many parallel and series techniques in order to make the most of the advantages as well as minimize the disadvantages of each technique. Therefore, in this paper, we propose a method of detecting APT attacks based on abnormal behaviors of Network traffic using machine learning. Accordingly, in our research, the abnormal behavior of APT attacks in Network Traffic will be defined on both components: Domain and IP. Then, these behaviors are evaluated and classified based on the Random Forest classification algorithm to conclude about the behavior of APT attacks. Details of the definition of abnormal behaviors of the Domain and IP will be presented in Section 3.2 of the paper. The synchronous APT attack detection method proposed in this paper is a novel approach, which will help information security systems detect quickly and accurately signs of the APT attack campaign in the organization. The experimental results presented in Section 4 will demonstrate the effectiveness of our proposed method.",JWE,2021,,20,1,,171-190,2,46,https://ieeexplore.ieee.org/document/10246856/
Application Research of Tethered UAV Platform in Marine Emergency Communication Network,Zhiqiang Xu,"QingDao Jari Automation Company LTD., Shandong, China",Tethered UAV platform | communication support ship | command and communication ship | communication load | repeater communication | emergency communication network | MESH | AIS,"In order to meet the needs of emergency communication for major emergency disaster rescue, a wireless emergency communication relay system based on tethered UAV platform is studied. From the perspective of practical application, the characteristics and network coverage of the emergency communication system are analyzed. The mooring UAV platform is equipped with various communication loads such as MESH (wireless grid network communication), 4G-LTE (Long term evolution fourth generation mobile communication) base station, AIS (Automatic Identification System) and so on, which are kept on the communication support ship. When the communication support ship enters the scene of maritime emergencies, the tethered UAV platform lifts off, stays for a long time and realizes the relay communication service of various carriers within a radius of tens of kilometers through its various communication payloads, which provides key communication support for the Marine emergency communication network. The actual field test of the prototype system shows that the data transmission is stable and reliable, and the short message transmission is normal, which can meet the emergency communication demand of disaster rescue.",JWE,2021,,20,2,,491-511,2,27,https://ieeexplore.ieee.org/document/10247316/
A New Collaborative Filtering Approach Based on Game Theory for Recommendation Systems,Selma Benkessirat | Narhimene Boustia | Rezoug Nachida,"SIIR/LRDSI, Blida 1 University, Blida, Algeria | SIIR/LRDSI, Blida 1 University, Blida, Algeria | SIIR/LRDSI, Blida 1 University, Blida, Algeria",Recommendation systems | collaborative filtering | cooperative game theory | Shapley Value,"Recommendation systems can help internet users to find interesting things that match more with their profile. With the development of the digital age, recommendation systems have become indispensable in our lives. On the one hand, most of recommendation systems of the actual generation are based on Collaborative Filtering (CF) and their effectiveness is proved in several real applications. The main objective of this paper is to improve the recommendations provided by collaborative filtering using clustering. Nevertheless, taking into account the intrinsic relationship between users can enhance the recommendations performances. On the other hand, cooperative game theory techniques such as Shapley Value, take into consideration the intrinsic relationship among users when creating communities. With that in mind, we have used SV for the creation of user communities. Indeed, our proposed algorithm preforms into two steps, the first one consists to generate communities user based on Shapley Value, all taking into account the intrinsic properties between users. It applies in the second step a classical collaborative filtering process on each community to provide the Top-N recommendation. Experimental results show that the proposed approach significantly enhances the recommendation compared to the classical collaborative filtering and k-means based collaborative filtering. The cooperative game theory contributes to the improvement of the clustering based CF process because the quality of the users communities obtained is better.",JWE,2021,,20,2,,303-326,2,25,https://ieeexplore.ieee.org/document/10247320/
Research on Data Release and Location Monitoring Technology of Sensor Network Based on Internet of Things,Bin Lin,"School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China",Internet of Things sensor network | data location monitoring technology | WSNs location algorithm | Huffman coding | industrial systems monitor the Internet of Things,"The Internet of Things is another information technology revolution and industrial wave after computer, Internet and mobile communication. It is becoming a key foundation and an important engine for the green, intelligent and sustainable development of economic society. The new networked intelligent production mode characterized by the integration innovation of the Internet of Things is shaping the core competitiveness of the future manufacturing industry. The application of sensor network data positioning and monitoring technology based on the Internet of Things in industry, power and other industries is a hot field for the development of the Internet of Things. Sensor network processing and industrial applications are becoming increasingly complex, and new features have appeared in the sensor network scale and infrastructure in these fields. Therefore, the Internet of Things perception data processing has become a research hotspot in the deep integration process between industry and the Internet of Things. This paper deeply analyzes and summarizes the characteristics of sensor network perception data under the new trend of the Internet of Things as well as the research on location monitoring technology, and makes in-depth exploration from the release and location monitoring of sensor network perception data of the Internet of Things. Sensor network technology integrated sensor technology, microelectromechanical system technology, wireless communication technology, embedded computing technology and distributed information processing technology in one, with easy layout, easy control, low power consumption, flexible communication, low cost and other characteristics. Therefore, based on the release and location monitoring technologies of sensor network data based on the Internet of Things in different applications, this paper studies the corresponding networking technologies, energy management, data management and fusion methods. Standardization system in wireless sensor network low cost, and convenient data management needs, design the iot oriented middleware, and develops the software and hardware system, the application demonstration, the results show that the design of wireless sensor network based on iot data monitoring and positioning technology is better meet the application requirements, fine convenient integration of software and hardware, and standardized requirements and suitable for promotion.",JWE,2021,,20,3,,689-712,2,14,https://ieeexplore.ieee.org/document/10246203/
Blockchain-Based Access Control and Data Sharing Mechanism in Cloud Decentralized Storage System,Yogesh M. Gajmal | R. Udayakumar,"Bharath Institute of Higher Education and Research, Bharath University, Selaiyur, Chennai, Tamil Nadu, India | Bharath Institute of Higher Education and Research, Bharath University, Selaiyur, Chennai, Tamil Nadu, India",Data sharing | cloud storage system | Blockchain | smart agreement | interplanetary file system (IPFS),"Access control is a major factor in enhancing data security in the cloud storage system. However, the existing data sharing and the access control method have privacy data leakage and key abuse, which is a major challenge in the research community. Therefore, an effective method named Blockchain-based access control and data sharing approach is developed in the cloud storage system to increase data security. The proposed Blockchain-based access control and data sharing approach effectively solve single-point failure in the cloud system. It provides more benefits by increasing the throughput and reducing the cost. The Data user (DU) makes the registration request using the ID and password and forwards it to the Data Owner (DO), which processes the request and authenticates the Data user. The information of the data owner is embedded in the transactional blockchain using the encrypted master key. The Data owner achieves the data encryption process, and encrypted files are uploaded to the Interplanetary File System (IPFS). Based on the encrypted file location and encrypted key, the Data owner generates the ciphertext metadata and is embedded in the transactional blockchain. The proposed Blockchain-based access control and data sharing approach achieved better performance using the metrics, like a better genuine user detection rate of 95% and lower responsiveness of 25sec with the blockchain of 100 sizes.",JWE,2021,,20,5,,1359-1388,2,17,https://ieeexplore.ieee.org/document/10246871/
Design and Implementation of Smart Ocean Visualization System Based on Extended Reality Technology,Xu Han | Jingming Liu | Baohua Tan | Lucheng Duan,"School of Industrial Design, Hubei University of Technology, Wuhan, China | School of Industrial Design, Hubei University of Technology, Wuhan, China | School of Science, Hubei University of Technology, Wuhan, China | School of Science, Hubei University of Technology, Wuhan, China",Smart ocean | extended reality technology | Unity3D | visual interaction,"In the context of building a maritime power, building a smart ocean is one of the important means to promote ocean development. However, there is currently a lack of effective smart solutions for ocean development to integrate and manage ocean information. To solve the problem of insufficient development of smart ocean systems, a smart ocean visualization app based on extended reality technology has been developed, using Python crawler technology to collect ocean big data, and produce the system through Unity software. The app is built using C# programming, and the AR animation on the app is realized with the AR Foundation plug-in. Through terminals such as mobile phones or computers, it provides users with real-time ocean data query and expanded realistic ocean tourism services. The visualization function of the system realizes innovation in the way of querying marine data and makes up for the lack of development of smart marine apps.",JWE,2021,,20,2,,557-574,2,11,https://ieeexplore.ieee.org/document/10247324/
Internet of Things (IoTs) Security: Intrusion Detection using Deep Learning,Ozgur Koray Sahingoz | Ugur Cekmez | Ali Buldu,"Department of Computer Engineering, Faculty of Engineering and Natural Sciences, Biruni University, Istanbul, Turkey | Chooch Intelligence Technologies Co., California, USA | Department of Computer Engineering, Faculty of Technology, Marmara University, Istanbul, Turkey",Convolutional neural networks | deep learning | imbalanced datasets | Internet of Things | IoTs | web security,"With the development of sensor and communication technologies, the use of connected devices in industrial applications has been common for a long time. Reduction of costs during this period and the definition of Internet of Things (IoTs) concept have expanded the application area of small connected devices to the level of end-users. This paved the way for IoT technology to provide a wide variety of application alternative and become a part of daily life. Therefore, a poorly protected IoT network is not sustainable and has a negative effect on not only devices but also the users of the system. In this case, protection mechanisms which use conventional intrusion detection approaches become inadequate. As the intruders' level of expertise increases, identification and prevention of new kinds of attacks are becoming more challenging. Thus, intelligent algorithms, which are capable of learning from the natural flow of data, are necessary to overcome possible security breaches. Many studies suggesting models on individual attack types have been successful up to a point in recent literature. However, it is seen that most of the studies aiming to detect multiple attack types cannot successfully detect all of these attacks with a single model. In this study, it is aimed to suggest an all-in-one intrusion detection mechanism for detecting multiple intrusive behaviors and given network attacks. For this aim, a custom deep neural network is designed and implemented to classify a number of different types of network attacks in IoT systems with high accuracy and F1-score. As a test-bed for comparable results, one of the up-to-date dataset (CICIDS2017), which is highly imbalanced, is used and the reached results are compared with the recent literature. While the initial propose was successful for most of the classes in the dataset, it was noted that achievement was low in classes with a small number of samples. To overcome imbalanced data problem, we proposed a number of augmentation techniques and compared all the results. Experimental results showed that the proposed methods yield highest efficiency among observed literature.",JWE,2021,,20,6,,1721-1760,2,10,https://ieeexplore.ieee.org/document/10246886/
Keyframe Generation Method via Improved Clustering and Silhouette Coefficient for Video Summarization,Fengsui Wang | Jingang Chen | Furong Liu,"School of Electrical Engineering, Anhui Polytechnic University, Wuhu, China | School of Electrical Engineering, Anhui Polytechnic University, Wuhu, China | School of Electrical Engineering, Anhui Polytechnic University, Wuhu, China",Video analysis | video summarization | hierarchical clustering | k-means clustering | silhouette coefficient,"In order to solve the issue that the traditional k-means algorithm falls into the local optimal solution in video summarization due to unreasonable initial parameter setting, a video summarization generation algorithm by using improved clustering and silhouette coefficient was proposed. Firstly, color features and texture features are extracted and fused from the decomposed video frames. Secondly, the hierarchical clustering algorithm is used to obtain the initial clustering results. And then, the improved k-means algorithm with silhouette coefficient is introduced to optimize the initial clustering results. Finally, the nearest frame from the cluster center is selected as the keyframe, and all the final keyframes are arranged in the order of the time sequence in the original video to constitute video summarization. The proposed algorithm is evaluated on two video datasets and the results show that the proposed algorithm achieves an average 84% accuracy rate and only 24% error rate in YouTube dataset. At the same time, the algorithm is validated on the benchmark Open Video Database dataset with an average 71% precision, 84% recall rate, and 76% F-score, which is higher than state-of-the-art video summarization methods. Moreover, it generates video keyframes that are closer to user summaries, and it improves effectively the overall quality of the generated summary.",JWE,2021,,20,1,,147-170,2,12,https://ieeexplore.ieee.org/document/10246861/
"Hot-Rolled, Heavy-Rail Image Recognition Based on Deep-Learning Network",Xie Changgui | Xu Hao | Liu Yuxi | Chen Ping,"Chongqing Vocational Institute of Engineering, Chongqing, China | Chongqing Vocational Institute of Engineering, Chongqing, China | Chongqing Vocational Institute of Engineering, Chongqing, China | Chongqing University, Chongqing, China",Heavy rail | deep learning | defect recognition | error recognition rate | network,"A new method for image-defect recognition is proposed that is based on a convolution network with repeated stacking of small convolution kernels and a maximum pooling layer. By improving the speed and accuracy of image-defect recognition, this new method can be applied to image recognition such as heavy-rail images with high noise and many types of defects. The experimental results showed that the new algorithm effectively improved the accuracy of heavy-rail image-defect recognition. As evidenced by the simulation study, the proposed method has a lower error rate in heavy-rail image recognition than traditional algorithms, and the method may also be applied to defect recognition of nonlinear images under strong noise conditions. Its robustness and nonlinear processing ability are impressive, and the method is featured with high theoretical depth and important application value.",JWE,2021,,20,5,,1623-1640,2,5,https://ieeexplore.ieee.org/document/10246873/
Distributed Energy Transaction Model Based on the Alliance Blockchain in Case of China,Yongxiu He | Wei Xiong | Bin-you Yang | Rui Zhang | Ming-li Cui | Tian-tian Feng | Yi-er Sun,"School of Economics and Management, North China Electric Power University, Beijing, China | School of Economics and Management, North China Electric Power University, Beijing, China | State Grid Hunan Electric Power Company limited, Changde Power Supply Company, Hunan, China | State Grid Hunan Electric Power Company limited, Changde Power Supply Company, Hunan, China | School of Economics and Business Administration, Heilongjiang University, Harbin, China | School of Economics and Management, China University of Geosciences, Beijing, China | School of Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",Blockchain | distributed energy trading | energy Internet,"Distributed energy, mainly composed of new energy, plays an important role in promoting the development of new energy. At present, the development of distributed energy is greatly hindered by imperfect trading platform and unstable output of new energy. Blockchain is decentralized, autonomous and requires collaborative management. Its own technical characteristics have the inherent advantages of reconstructing the energy system. The alliance chain in the blockchain is more suitable for building a distributed energy trading platform. The paper constructs a distributed energy transaction model based on alliance blockchain, studies the integration mode of blockchain and distributed energy transaction, and explores the application of blockchain in distributed transaction. The paper provides a new idea for optimizing and reconstructing the traditional distributed energy trading platform, and providing decision support for promoting distributed energy trading.",JWE,2021,,20,2,,359-385,2,11,https://ieeexplore.ieee.org/document/10247319/
Knowledge Based Deep Inception Model for Web Page Classification,Amit Gupta | Rajesh Bhatia,"Department of Computer Science and Engineering, Punjab Engineering College (Deemed to be University), Chandigarh, India | Department of Computer Science and Engineering, Punjab Engineering College (Deemed to be University), Chandigarh, India",Web page classification | transfer learning | knowledge graph embedding | pre-trained model,"Web Page Classification is decisive for information retrieval and management task and plays an imperative role for natural language processing (NLP) problems in web engineering. Traditional machine learning algorithms excerpt covet features from web pages whereas deep leaning algorithms crave features as the network goes deeper. Pre-trained models such as BERT attains remarkable achievement for text classification and continue to show state-of-the-art results. Knowledge Graphs can provide rich structured factual information for better language modelling and representation. In this study, we proposed an ensemble Knowledge Based Deep Inception (KBDI) approach for web page classification by learning bidirectional contextual representation using pre-trained BERT incorporating Knowledge Graph embeddings and fine-tune the target task by applying Deep Inception network utilizing parallel multi-scale semantics. Proposed ensemble evaluates the efficacy of fusing domain specific knowledge embeddings with the pre-trained BERT model. Experimental interpretation exhibit that the proposed BERT fused KBDI model outperforms benchmark baselines and achieve better performance in contrast to other conventional approaches evaluated on web page classification datasets.",JWE,2021,,20,7,,2131-2168,2,5,https://ieeexplore.ieee.org/document/10246785/
Elastic Performance Test Method of Web Server in Cloud Computing Environment,Xin Su | Xiaohui Li,"Department of Computer & Information, Hebei Petroleum University of Technology, ChengDe, China | Department of Computer & Information, Hebei Petroleum University of Technology, ChengDe, China",Cloud computing | Web server | elastic performance | jitter times,"In the process of traditional web server elastic performance test, the performance of tracking data is poor, which leads to excessive server jitter and poor accuracy of elastic test results. Therefore, this paper studies the network server elastic performance test method in cloud computing environment. In this method, cloud monitoring technology is used to track the operation data of Web server. According to the multi platform call mode of Web server, a statistical regression model is established to determine the elasticity measurement index. The load balancing algorithm is used to test the server load balancing to obtain the elasticity value of Web server. Experimental results: in the whole running period of Web server, the jitter times of the proposed method are 15.6066 times, 16.5600 times and 16.5733 times lower than those of the three traditional methods, respectively. It can be seen that the new test method can accurately track the response ability of the server and obtain more accurate elasticity value.",JWE,2021,,20,5,,1641-1658,2,3,https://ieeexplore.ieee.org/document/10246870/
A Probability Distribution and Location-aware ResNet Approach for QoS Prediction,Wenyan Zhang | Ling Xu | Meng Yan | Ziliang Wang | Chunlei Fu,"School of Big Data & Software Engineering, ChongQing University, Chongqing, China | School of Big Data & Software Engineering, ChongQing University, Chongqing, China | School of Big Data & Software Engineering, ChongQing University, Chongqing, China | School of Big Data & Software Engineering, ChongQing University, Chongqing, China | School of Big Data & Software Engineering, ChongQing University, Chongqing, China",QoS prediction | deep learning | ResNet | probability distribution,"In recent years, the number of online services has grown rapidly, invoking the required services through the cloud platform has become the primary trend. How to help users choose and recommend high-quality services among huge amounts of unused services has become a hot issue in research. Among the existing QoS prediction methods, the collaborative filtering (CF) method can only learn low-dimensional linear characteristics, and its effect is limited by sparse data. Although existing deep learning methods could capture high-dimensional nonlinear features better, most of them only use the single feature of identity, and the problem of network deepening gradient disappearance is serious, so the effect of QoS prediction is unsatisfactory. To address these problems, we propose an advanced probability distribution and location-aware ResNet approach for QoS Prediction (PLRes). This approach considers the historical invocations probability distribution and location characteristics of users and services, and first uses the ResNet in QoS prediction to reuses the features, which alleviates the problems of gradient disappearance and model degradation. A series of experiments are conducted on a real-world web service dataset WS-DREAM. At the density of 5%-30%, the experimental results on both QoS attribute response time and throughput indicate that PLRes performs better than the existing five state-of-the-art QoS prediction approaches.",JWE,2021,,20,4,,1251-1290,2,11,https://ieeexplore.ieee.org/document/10246224/
Machine Learning Modeling: A New Way to Do Quantitative Research in Social Sciences in the Era of AI,Jiaxing Zhang | Shuaishuai Feng,"The Institute of Social Development Studies, Wuhan University, China | School of Sociology, Wuhan University, Wuhan, Hubei, China",Era of artificial intelligence | machine learning modeling | over-fitting | prediction studies,"Improvements in big data and machine learning algorithms have helped AI technologies reach a new breakthrough and have provided a new opportunity for quantitative research in the social sciences. Traditional quantitative models rely heavily on theoretical hypotheses and statistics but fail to acknowledge the problem of overfitting, causing the research results to be less generalizable, and further leading to Social predictions in the social sciences being ignored when they should have been meaningful. Machine learning models that use cross validation and regularization can effectively solve the problem of overfitting, providing support for the Social predictions based on these models. This paper first discusses the sources and internal mechanisms of overfitting, and then introduces machine learning modeling by discussing its high-level ideas, goals, and concrete methods. Finally, we discuss the shortcomings and limiting factors of machine learning models. We believe that using machine learning in social sciences research is an opportunity and not a threat. Researchers should adopt an objective attitude and make sure that they know how to combine traditional methods with new methods in their research based on their needs.",JWE,2021,,20,2,,281-302,2,13,https://ieeexplore.ieee.org/document/10247322/
Unified Model for Learning Style Recommendation,Unhawa Ninrutsirikun | Debajyoti Pal | Chonlameth Arpnikanondt | Bunthit Watanapa,"School of Information Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand | School of Information Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand | School of Information Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand | School of Information Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand",Association evaluation | association rules | guideline | learning styles | moderation analysis | style-fit strategy,"Studying computer programming requires not only an understanding of theories and concepts but also coding adeptness. Success in studying or conducting such a course is definitely a challenge. This paper proposes a systematic learning style recommendation. The model is designed to evaluate students' attributes and ongoing or formative learning outcomes for suggesting the effective style-fit strategy that facilitates learners to enhance their learning performances in terms of knowledge and skill. A two-stage association analysis was designed and conducted on a dataset collected from IT major students who enrolled in the Introduction to Computer Programming course. The first stage of association rules is to analyze and discover important relationships amongst learning styles, students' attribute, and learning performance. The second stage of moderation analysis is then applied to probe the moderation effect of the different learning preferences on the relationship between student attributes and learning achievement. Experiments expose many insights, for example, mathematics and logical thinking are powerful assets of success in computer programming study. Association rules can effectively identify associations of learning styles and the learning performance in terms of knowledge or skills. By moderation analysis, students in the “Excellent” cluster have a broad learning style than other students. Two types of significant moderators, the universal and specific, exemplify how lecturers can flexibly post style-fit teaching strategies for a class-wide and specific group, respectively.",JWE,2021,,20,5,,1487-1526,2,4,https://ieeexplore.ieee.org/document/10246878/
Joint Representations of Texts and Labels with Compositional Loss for Short Text Classification,Ming Hao | Weijing Wang | Fang Zhou,"School of computer and communication engineering, University of science and technology Beijing, Beijing, China | Department of bioengineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA | School of computer and communication engineering, University of science and technology Beijing, Beijing, China",Ambiguous text | deep language models | label embedding | text classification | triplet loss,"Short text classification is an important foundation for natural language processing (NLP) tasks. Though, the text classification based on deep language models (DLMs) has made a significant headway, in practical applications however, some texts are ambiguous and hard to classify in multi-class classification especially, for short texts whose context length is limited. The mainstream method improves the distinction of ambiguous text by adding context information. However, these methods rely only the text representation, and ignore that the categories overlap and are not completely independent of each other. In this paper, we establish a new general method to solve the problem of ambiguous text classification by introducing label embedding to represent each category, which makes measurable difference between the categories. Further, a new compositional loss function is proposed to train the model, which makes the text representation closer to the ground-truth label and farther away from others. Finally, a constraint is obtained by calculating the similarity between the text representation and label embedding. Errors caused by ambiguous text can be corrected by adding constraints to the output layer of the model. We apply the method to three classical models and conduct experiments on six public datasets. Experiments show that our method can effectively improve the classification accuracy of the ambiguous texts. In addition, combining our method with BERT, we obtain the state-of-the-art results on the CNT dataset.",JWE,2021,,20,3,,669-688,2,5,https://ieeexplore.ieee.org/document/10246201/
Digital Forensics Security Analysis on iOS Devices,Min-Hao wu | Ting-Cheng Chang | Yi Li-Min,"College of Information Engineering, Guangzhou Panyu Polytechnic, Guangdong, China | College of Information Engineering, Guangzhou Panyu Polytechnic, Guangdong, China | College of Information Engineering, Guangzhou Panyu Polytechnic, Guangdong, China",Mobile forensics | iOS forensics | Instant messaging | Social networking | WeChat | QQ | Jailbreak,"With the rapid development of the Internet era, cell phones play an essential and indispensable role in nowadays life. Smartphones have profoundly influenced our social relationships and our daily lives. Generally speaking, the most common tools we hear about in our daily lives are QQ, WeChat, and other Internet communication services that allow users to send text messages, pictures, and documents, providing a more convenient and faster medium for people to communicate and chat. The popularity and convenience of mobile technology have changed people's habits of communication. People no longer need to rely on computers to communicate, and computers cannot communicate anytime and anywhere. In the kernel of Linux and Windows, as long as the Message Hooker will install, it can monitor the messages of other programs, including WeChat and QQ, in this research. We can provide relevant law enforcement officers with effective evidence collection so that criminals will not be able to hide. The suspects often delete their WeChat or QQ records after committing the crime. It impossible for our law enforcement agencies to obtain evidence directly from the cell phone and the crime facts. Our research hopes to use some technology to help law enforcement units effectively obtain strong evidence in the iPhone not to hide the crime facts.",JWE,2021,,20,3,,775-794,2,3,https://ieeexplore.ieee.org/document/10246211/
A New Semantic Approach to Improve Webpage Segmentation,Saeedeh Sadat Sajjadi Ghaemmaghami | James Miller,"University of Alberta, Canada | University of Alberta, Canada",Webpage analysis | webpage segmentation | semantic text similarity | Gestalt Law of grouping,"Webpage analysis is carried out for various purposes such as webpage segmentation. The goal of webpage segmentation is to divide a page into blocks that have similar elements. A fusion approach that combines different analyses is required in order to obtain high segmentation accuracy. In this paper, we propose a new fusion model for webpage segmentation, where we (1) merge webpage content into basic-blocks by simulating human perception; and, (2) identify similar blocks using semantic text similarity and regroup these similar blocks as fusion blocks. This approach is applied to three public datasets and evaluated by comparing with state-of-the-art algorithms. The results characterize that our proposed approach outperforms other existing webpage segmentation methods, in terms of accuracy.",JWE,2021,,20,4,,963-992,2,7,https://ieeexplore.ieee.org/document/10246784/
A Prescriptive Model for Migration to Microservices Based on SDLC Artifacts,Deepali Bajaj | Urmil Bharti | Anita Goel | S. C. Gupta,"Department of Computer Science, Shaheed Rajguru College of Applied Sciences for Women, University of Delhi, Delhi, India | Department of Computer Science, Shaheed Rajguru College of Applied Sciences for Women, University of Delhi, Delhi, India | Department of Computer Science, Dyal Singh College, University of Delhi, Delhi, India | Department of Computer Science, Indian Institute of Technology, Delhi, India",Microservices | decomposition | migration | extraction | slicing | identifying | brownfield development | greenfield development | microservices architecture (MSA),"Microservices architectural style is gaining popularity in industry and is being widely adopted by large corporations like Amazon, Netflix, Spotify, eBay, and many more. Several other organizations are also preferring to migrate their existing enterprise scale applications to microservices architecture. Researchers have proposed various approaches for microservices decomposition to be used in migrating or rebuilding a monolithic application to microservices. Applying any available approach to an existing monolithic application is not a straightforward decision; thus, there is a need for guidelines that assist in the migration process. There are various challenges in a migration process because different migration approaches use different sets of input data to identify microservices. Since the available migration techniques are not structured, logically, selection of an appropriate migration strategy is a difficult decision for any system architect. So, it is a recurrent open research question - which migration technique should be adopted to get microservices for a legacy monolithic application? This paper addresses this research challenge by examining existing approaches for microservices migration and groups them based on software development life cycle (SDLC) artifacts. Our research also proposes a microservices prescriptive model (MPM) from the existing prominent microservice migration techniques. This model provides recommendation (1) for refactoring an existing legacy system to microservices, and (2) for new microservices development projects. Our study also helps in gaining more insight about greenfield and brownfield development approaches in microservices applications. Moreover, researchers and practitioners of the field can benefit from this model to further validate their migration approaches based on the available system artifacts.",JWE,2021,,20,3,,817-852,2,11,https://ieeexplore.ieee.org/document/10246213/
Rice Disease Recognition Using Effective Deep Neural Networks,S. Mathulaprangsan | S. Patarapuwadol | K. Lanthong | D. Jetpipattanapong | S. Sateanpattanakul,"Department of Computer Engineering, Faculty of Engineering at Kamphaeng Sean, Kasetsart University, Thailand | Department of Plant Pathology, Faculty of Agriculture at Kamphaeng Saen, Kasetsart University, Thailand | Department of Computer Engineering, Faculty of Engineering at Kamphaeng Sean, Kasetsart University, Thailand | Department of Computer Engineering, Faculty of Engineering at Kamphaeng Sean, Kasetsart University, Thailand | Department of Computer Engineering, Faculty of Engineering at Kamphaeng Sean, Kasetsart University, Thailand",Rice disease recognition | deep neural network | ResNet | DenseNet | image recognition | image augmentation,"Rice is the most important grain in Thailand for both consuming and exporting. One of the critical problems in rice cultivation is rice diseases, which affects directly to the yield. Early disease recognition is handled by a human, which is difficult to achieve high accuracy and the performance depends on the farmer's experience. To overcome this problem, we did three folds of contributions. First, an infield rice diseases image dataset, named K5RD, was created. Second, a number of additional techniques to enhance the classification scores including data augmentations and learning rate adjustment strategies were carefully surveyed. Third, a set of selective deep learning models including ResNets and DenseNets were applied to classify such rice diseases. The experimental results reveal that the proposed framework can achieve high performance, which its F1 score is higher than 98% on average, and has the potential to be implemented as a practical system to provide to Thai farmers in the future.",JWE,2021,,20,3,,853-878,2,11,https://ieeexplore.ieee.org/document/10246786/
Optimal Design of Electrical Capacitance Tomography Sensor and Improved ART Image Reconstruction Algorithm Based On the Internet of Things,Feng Chen | Deyun Chen | Lili Wang | Botao Yang,"School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China | School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China | School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China | School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China",Electrical capacitance tomography | optimal design of sensor | image reconstruction | modified ART iterative algorithm | convergence,"For the problems of low sensitivity, weak signal of high and low frequency and low signal-to-noise ratio in ECT, the mathematical model of the sensor is established. From the aspects of electrostatic field distribution and soft field effect, the influence of the structural parameters of the sensor on the sensor performance is analyzed. According to the influence of the components of the sensor on the sensitivity, the principle of optimal design is put forward. Based on the optimized Landweber image reconstruction algorithm, an ART image reconstruction algorithm with iterative correction is proposed, and the mathematical model of the algorithm is designed. According to constructing the target functional regularization term in the negative problems of electrical capacitance tomography, the iterative process of the modified art algorithm is deduced, and with adaptive step size, the convergence is speeded and accuracy of image reconstruction is improved. The experimental results show that the semi-convergence in the improved algorithm is obviously weakened, and the reconstructed image quality is better than that of the traditional art algorithm.",JWE,2021,,20,4,,1087-1112,2,3,https://ieeexplore.ieee.org/document/10246221/
Blockchain Smart Contract Meta-modeling,N. Sánchez-Gómez | J. Torres-Valderrama | Manuel Mejías Risoto | Alejandra Garrido,"Web Engineering and Early Testing Research Group, ETSII, University of Seville, Spain | Web Engineering and Early Testing Research Group, ETSII, University of Seville, Spain | Web Engineering and Early Testing Research Group, ETSII, University of Seville, Spain | LIFIA, Fac. de Inform., Univ. Nac. de La Plata & CONICET, Argentina",Smart contract | model-based | meta-model | UML,"One of the key benefits of blockchain technology is its ability to keep a permanent, unalterable record of transactions. In business environments, where companies interact with each other without a centralized authority to ensure trust between them, this has led to blockchain platforms and smart contracts being proposed as a means of implementing trustworthy collaborative processes. Software engineers must deal with them to ensure the quality of smart contracts in all phases of the smart contract lifecycle, from requirements specifications to design and deployment. This broad scope and criticality of smart contracts in business environments means that they have to be expressed in a language that is intuitive, easy-to-use, independent of the blockchain platform employed, and oriented towards software quality assurance. In this paper we present a key component: a first outline of a UML-based smart contract meta-model that would allow us to achieve these objectives. This meta-model will be enriched in future work to represent blockchain environments and automated testing.",JWE,2021,,20,7,,2059-2080,2,7,https://ieeexplore.ieee.org/document/10246225/
Intelligent Model-Based Integrity Assessment of Nonstationary Mechanical System,Hanxin Chen | Yuzhuo Miao | Yongting Chen | Lu Fang | Li Zeng | 06 Shi,"School of Mechanical and Electrical Engineering Wuhan Institute of Technology, Wuhan, China | School of Mechanical and Electrical Engineering Wuhan Institute of Technology, Wuhan, China | Wuhan Britain-China School, Wuhan, China | School of Mechanical and Electrical Engineering Wuhan Institute of Technology, Wuhan, China | School of Mechanical and Electrical Engineering Wuhan Institute of Technology, Wuhan, China | School of Mechanical and Electrical Engineering Wuhan Institute of Technology, Wuhan, China",Integrity assessment | nonstationary mechanical system | model-based | improved particle filter,"The fault diagnosis model for nonstationary mechanical system is proposed in the condition monitoring. The algorithm with an improved particle filter and Back Propagation for intelligent fault identification is developed, which is used to reduce the noise of the experimental vibration signals to delete the negative effect of the noise on the feature extraction of the original vibration signal. The proposed integrated method is applied for the trouble shoot of the impellers inside the centrifugal pump. The principal component analysis (PCA) method optimizes the clean vibration signal to choose the optimal eigenvalue features. The constructed (back propagation)BP neural network is trained to get the condition models for fault identification. The proposed novel model is compared with the BP neural network based on traditional PF and particle swarm optimization particle filter (PSO-PF) algorithm. The BP neural network diagnosis method based on the improved PF algorithm is much better for the integrity assessment of the centrifugal pump impeller. This method is much significant for big data mining in the fault diagnosis method of the complex mechanical system.",JWE,2021,,20,2,,253-280,2,30,https://ieeexplore.ieee.org/document/10247317/
Web Service Access Control Based on Browser Fingerprint Detection,Liu Hui | He Xudong | Gao Fan | Wang KaiLun | Yuan Enze,"Beijing Jiaotong University, China | Beijing Jiaotong University, China | Beijing Jiaotong University, China | Beijing Jiaotong University, China | Beijing Jiaotong University, China",Access control | adversarial learning | browser fingerprint | web service,"Web services have covered all areas of social life, and various browsers have become necessary software on computers and mobile phones, and they are also the entrances to Web services. All kinds of threats to web data security continue to appear, so web services and browsers have become the focus of security. In response to the requirements of Web service for access entity identification and data access control, this paper proposes a multi-dimensional browser fingerprint detection method based on adversarial learning, and designs a Web service access control framework combined with browser fingerprint detection. Through the joint use of multi-dimensional browser features, adversarial learning is used to improve the accuracy and robustness of browser fingerprint detection; a cross-server and browser-side Web service access control framework is established by creating tags for Web data resources and access entities. Based on the mapping relationship between browser fingerprint detection entities and data resources, finegrained hierarchical data access control is realized. Through experiments and analysis, the browser fingerprint detection method proposed in this paper is superior to existing machine learning detection methods in terms of accuracy and robustness. Based on the adversarial learning method, good detection results can be obtained in the case of a small number of user samples. At the same time, the open source data set is further used to verify the advantages of the method in this paper. The Web service access control framework can satisfy the requirements of Web data security control, is an effective supplement to user identification technology, and is implementable.",JWE,2021,,20,5,,1587-1622,2,5,https://ieeexplore.ieee.org/document/10246879/
F-ONTOCOM: A Fuzzified Cost Estimation Approach for Ontology Engineering,Sonika Malik | Sarika Jain,"Department of IT, Maharaja Surajmal Institute of Technology, New Delhi, National Institute of Technology, Kurukshetra, Research Scholar, New Delhi, India | Department of Computer Applications, NIT, Kurukshetra, New Delhi, India",Ontology engineering | effort estimation | fuzzy logic | ontology cost model | uncertainty | ONTOCOM,"Estimating effort is an essential prerequisite for the wide-scale dispersal of ontologies. Not much attention has yet been paid to this essential aspect of ontology building. To date, ONTOCOM is the most prominent model for ontology cost estimation. Many factors influencing the building cost of an ontology are depicted by linguistic terms like Very High, High, … and so on; making them vague and indistinct. This fuzziness is quite uncertain and must be taken into consideration. The available effort estimation models do not consider the uncertainty of fuzziness. In this work, we propose an effort estimation methodology for ontology engineering using Fuzzy Logic i.e. F-ONTOCOM (Fuzzy-ONTOCOM) to overcome of uncertainty and imprecision. We have defined the corresponding Fuzzy sets for each effort multiplier and its associated linguistic value, and represented the same by triangular membership functions. F-ONTOCOM is applied to a dataset of 148 ontology projects and evaluated over various evaluation criteria. F-ONTOCOM outperforms the existing effort-estimation models; it has been concluded that F-ONTOCOM improves the cost estimation accuracy and estimated cost is very close to actual cost.",JWE,2021,,20,7,,2169-2198,2,2,https://ieeexplore.ieee.org/document/10246781/
Research on Mining and Application of Group Events Based on Network Public Opinion Big Data,Weimin Gao | Jiaming Zhong | Yuan Xiao,"School of Computer Science and Engineering, Central South University, ChangSha, China | College of Economic and Management, Xiangnan University, Chenzhou, China | College of Economic and Management, Xiangnan University, Chenzhou, China",Mining and application | network group events | simulation | SIR (Susceptible Infected Recovered Model),"Network Public Opinion is significant in maintaining social harmony and stability and promoting transparency in government affairs. However, with the development of economy and transformation of society, our country has entered a high-risk period, which is full of unexpected public events. Unexpected mass accidents also cause hot discussions among the Internet users once they are exposed on the network. Different ideas, opinions, emotions, and attitudes about unexpected public events will be collected and collide on the Internet. It makes Network Public Opinion play an increasingly important role in the evolution of unexpected public events. It could promote the spread and upgrade of unexpected public events and bring more and more profound influence on to our social life. We use the case study method to analyze and solve the problems by applying the dynamic principles of the SIR epidemic model, comprehensively considering the social environment and various influencing factors, and constructing a mathematical model for the spread of network group events. The study uses Matlab to simulate the change trajectory of the number of participants in the network group events. By adjusting the number of contacts φ in the model, the development of network group emergencies can be effectively controlled and managed. As long as the government takes timely intervention measures, the dissemination of network group events can be basically controlled. Combined with public opinion big data to discover the important factors affecting the spread of public opinion, the control effect is obvious..",JWE,2021,,20,6,,1885-1908,2,4,https://ieeexplore.ieee.org/document/10246889/
Fine-Grained User Location Prediction using Meta-Path Context with Attention Mechanism,Zhixiao Wang | Wenyao Yan | Ang Gao,"Xi'an University of Technology, China | Xi'an Innovation of Yan'an University, China | China Meteorological Administration, National Satellite Meteorological Center, China",Geo-social network (GSN) | attention mechanism | meta-path contexts learning | location-based social networks (LBSNs) | pairwise learning | user location prediction,"The prevalence of Location-Based Social Networks (LBSNs) significantly improves the location-aware capability of services by providing Geo-tagged information. Relied on a great number of user check-in data in the location-based social networks, their essential mobility modes are able to be comprehensively studied, which is basic for forecasting the next venue where a specific user is going to visit considering his relevant historical check-in data. Since there exist different kinds of nodes and interactions between nodes, these information could be look upon as a network that is made up of heterogeneous information. In this network a few of different semantic meta paths could be obtained. Enlightened from the competitive advantage of embedding method relied upon meta-path contexts in the heterogeneous information network, we study a joint deep learning scheme exploring different meta-path context information to forecast fine-grained location. In order to capture different semantics in a user-location interaction, we adopt a simple but high-efficient attention method to learn the meta-path importance or weights. In the terms of model optimization, considering we have only positive sample data and there exists intrinsically latent feedback in check-in information, herein a pairwise learning method is utilized for maximizing the margin between visited and invisible venues. Experiment in different data-sets validate the competitive performance of the suggested approach under different assessment criterion.",JWE,2021,,20,3,,597-614,2,2,https://ieeexplore.ieee.org/document/10246212/
A Survey of Ontologies and Their Applications in e-Learning Environments,Yi Wang | Ying Wang,"College of Computer & Information Science, Southwest University, Chongqing, China | College of Computer & Information Science, Southwest University, Chongqing, China",Ontology | semantic web | e-learning | adaptive learning,"Ontology technology has been investigated in a wide range of areas and is currently being utilized in many fields. In the e-learning context, many studies have used ontology to address problems such as the interoperability in learning objects, modeling and enriching learning resources, and personalizing educational content recommendations. We systematically reviewed research on ontology for e-learning from 2008 to 2020. The review was guided by 3 research questions: “How is ontology used for knowledge modeling in the context of e-learning?”, “What are the design principles, building methods, scale, level of semantic richness, and evaluation of current educational ontologies?”, and “What are the various ontology-based applications for e-learning?” We classified current educational ontologies into 6 types and analyzed them by 5 measures: design methodology, building routine, scale of ontology, level of semantic richness, and ontology evaluation. Furthermore, we reviewed 4 types of ontology-based e-learning applications and systems. The observations obtained from this survey can benefit researchers in this area and help to guide future research.",JWE,2021,,20,6,,1675-1720,2,8,https://ieeexplore.ieee.org/document/10247158/
Towards the Importance of the Type of Deep Neural Network and Employment of Pre-trained Word Vectors for Toxicity Detection: An Experimental Study,Abdullah Talha Kabakus,"Department of Computer Engineering, Faculty of Engineering, Duzce University, Turkey",Word embedding | word vector | deep neural network | convolutional neural network | recurrent neural network | toxic comment detection,"As a natural consequence of offering many advantages to their users, social media platforms have become a part of their daily lives. Recent studies emphasize the necessity of an automated way of detecting offensive posts in social media since these ‘toxic’ posts have become pervasive. To this end, a novel toxic post detection approach based on Deep Neural Networks was proposed within this study. Given that several word embedding methods exist, we shed light on which word embedding method produces better results when employed with the five most common types of deep neural networks, namely, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), GRU (Gated Recurrent Unit), Bidirectional Long Short-Term Memory (BiLSTM), and a combination of CNN and BiLSTM. To this end, the word vectors for the given comments were obtained through four different methods, namely, (i) Word2vec, (ii) fastText, (iii) GloVe, and (iv) the Embedding layer of deep neural networks. Eventually, a total of twenty benchmark models were proposed and both trained and evaluated on a gold standard dataset which consists of 16K tweets. According to the experimental result, the best F1 - score, 84.844%, was obtained on the proposed CNN model without employing pre-trained word vectors which outperformed the state-of-the-art works and implies the effective embedding ability of CNNs. Other key findings obtained through the conducted experiments are that the models, that constructed word embeddings through the Embedding layers, obtained higher F1 - scores and converged much faster than the models that utilized pre-trained word vectors.",JWE,2021,,20,8,,2243-2268,2,3,https://ieeexplore.ieee.org/document/10246897/
Wireless Sensor Network Node Localization Algorithm Based on PSO-MA,Wenli Liu | Cuiping Shi | Heng06 Zhu | Hongbo Yu,"Qiqihar University, Heilongjiang, Qiqihar, China | Qiqihar University, Heilongjiang, Qiqihar, China | Qiqihar University, Heilongjiang, Qiqihar, China | Qiqihar University, Heilongjiang, Qiqihar, China",Particle swarm optimization | artificial bee colony algorithm | node location,"Aiming at the large error and low accuracy of wireless sensor node location, this paper proposes a node location method based on the fusion of Particle Swarm Optimization and Monkey Algorithm (PSO-MA). Firstly, this article describes the node location model based on DV-HOP algorithm; secondly, this article uses PSO in node location, uses place Laplace distribution for population initialization, improves population diversity, and optimizes particle weights to avoid algorithm falling into local optimality. In this paper, dynamic guidance factors are used to update individual positions to improve individual optimization capabilities, and Monkey Algorithm is used to select individuals to improve the quality of optimal solutions. In the simulation experiment, the algorithm PSO and MA of this paper are compared to achieve better positioning results in the reference node ratio, node density and communication radius indicators.",JWE,2021,,20,4,,1137-1154,2,9,https://ieeexplore.ieee.org/document/10246218/
Delay and Energy Consumption Optimization Oriented Multi-service Cloud Edge Collaborative Computing Mechanism in IoT,Sujie Shao | Jiajia Tang | Shuang Wu | Jianong Li | Shaoyong Guo | Feng Qi,"State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China | State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China | State Grid Ningxia Electric Power Co. Ltd., Yinchuan, Ningxia, China | China Electronics Standardization Institute, Beijing, China | State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China | State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China",Cloud-edge collaboration | task allocation | genetic algorithm,"The rapid development of the Internet of Things has put forward higher requirements for the processing capacity of the network. The adoption of cloud edge collaboration technology can make full use of computing resources and improve the processing capacity of the network. However, in the cloud edge collaboration technology, how to design a collaborative assignment strategy among different devices to minimize the system cost is still a challenging work. In this paper, a task collaborative assignment algorithm based on genetic algorithm and simulated annealing algorithm is proposed. Firstly, the task collaborative assignment framework of cloud edge collaboration is constructed. Secondly, the problem of task assignment strategy was transformed into a function optimization problem with the objective of minimizing the time delay and energy consumption cost. To solve this problem, a task assignment algorithm combining the improved genetic algorithm and simulated annealing algorithm was proposed, and the optimal task assignment strategy was obtained. Finally, the simulation results show that compared with the traditional cloud computing, the proposed method can improve the system efficiency by more than 25%.",JWE,2021,,20,8,,2433-2456,2,2,https://ieeexplore.ieee.org/document/10246904/
Enhance the ICS Network Security Using the Whitelist-Based Network Monitoring Through Protocol Analysis,Kyu-Seok Shim | Ilkwon Sohn | Eunjoo Lee | Woojin Seok | Wonhyuk Lee,"National Institute of Supercomputing and Networking Advanced KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | National Institute of Supercomputing and Networking Advanced KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | National Institute of Supercomputing and Networking Advanced KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | National Institute of Supercomputing and Networking Advanced KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | National Institute of Supercomputing and Networking Advanced KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea",Network security | protocol analysis | traffic monitoring | ICS network | clutsering algorithm | Apriori algorithm,"In our present technological age, most manual and semi-automated tasks are being automated for efficient productivity or convenience. In particular, industrial sites are rapidly being automated to increase productivity and improve work efficiency. However, while networks are increasingly deployed as an integral part of the automation of industrial processes, there are also many resultant dangers such as security threats, malfunctions, and interruption of industrial processes. In particular, while the security of business networks is reinforced and their information is not easily accessible, intruders are now targeting industrial networks whose security is relatively poor, wherein attacks could directly lead to physical damage. Therefore, numerous studies have been conducted to counter security threats through network traffic monitoring, and to minimize physical loss through the detection of malfunctions. In the case of industrial processes, such as in nuclear facilities and petroleum facilities, thorough monitoring is required as security issues can lead to significant danger to humans and damage to property. Most network traffic in industrial facilities uses proprietary protocols for efficient data transmission, and these protocols are kept confidential because of intellectual property and security reasons. Protocol reverse engineering is a preparatory step to monitor network traffic and achieve more accurate traffic analysis. The field extraction method proposed in this study is a method for identifying the structure of proprietary protocols used in industrial sites. From the extracted fields, the structure of commands and protocols used in the industrial environment can be derived. To evaluate the feasibility of the proposed concept, an experiment was conducted using the Modbus/TCP protocol and Ethernet/IP protocol used in actual industrial sites, and an additional experiment was conducted to examine the results of the analysis of conventional protocols using the file transfer protocol.",JWE,2021,,20,1,,Jan-32,2,3,https://ieeexplore.ieee.org/document/10246868/
Intrusion Detection Using Few-shot Learning Based on Triplet Graph Convolutional Network,Yue Wang | Yiming Jiang | Julong Lan,"PLA Information University, Zhengzhou, China | PLA Information University, Zhengzhou, China | PLA Information University, Zhengzhou, China",Few-shot Learning | intrusion detection | graph convolutional network,"Machine learning and deep learning methods have been widely used in network intrusion detection, most of which are supervised intrusion detection methods, which need to train a lot of marked data. However, in some cases, a small amount of exception data is hidden in a large amount of exception data, making methods that require a large amount of the same markup data to learn features invalid. In order to solve this problem, this paper proposes an innovative method of small sample network intrusion detection. The innovation point is that network data is modeled as graph structure to effectively mine the correlation features between data samples, and by comparing the distance similarity, the triplet network structure is used to detect anomalies. The triplet network is composed of triplet graph convolutional neural network which shares the same parameters and is trained by providing triplet samples to the network. Experiments on network traffic datasets CSE-CIC-IDS2018 and UNSW-NB15 as well as system status monitoring datasets verify the effectiveness of the proposed method in network intrusion detection of small samples.",JWE,2021,,20,5,,1527-1552,2,13,https://ieeexplore.ieee.org/document/10246880/
T-DSES: A Blockchain-powered Trusted Decentralized Service Eco-System,Xing Wu | Zhenfeng Gao | Yushun Fan | Xiu Li | Liang Gu | Jia Zhang | Chang Chen | Hao Zhang | Qiang Wang,"Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Sangfor Technologies Inc., Shenzhen, China | Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Graduated school at shenzhen, Tsinghua University, Shenzhen, China | Sangfor Technologies Inc., Shenzhen, China | Department of Computer Science, Southern Methodist University, TX, USA | Zhigui Technology Inc., Beijing, China | Zhigui Technology Inc., Beijing, China | Zhigui Technology Inc., Beijing, China",Web service | service eco-system | blockchain | system decentralization | Hyperledger Fabric | INKchain,"Existing Web service eco-systems are typically managed in a centralized manner, which hinders their further development due to inherent disadvantages such as trust issues, interest disputes, value separation and so on. The recently emerged blockchains provide distributed ledgers that enable parties who do not fully trust each other to maintain a set of global states, which provide a natural solution. Based on the INKchain, which is an open-source permissioned blockchain mechanism extending the Hyperledger Fabric, this paper proposes Trusted Decentralized Service Eco System (T-DSES). T-DSES achieves not only fundamental functionalities of conventional systems, but also offers mechanisms to stimulate participants to bring trustworthiness to the whole system. The trustworthiness of T-DSES is realized by three strategies: reliable information of services and mashups, reliable records of participants' rights, and reliable measurement of participants' contributions. A customized token “SToken” is created to act as the media of value circulation. In this paper, the overall framework and detailed design of T-DSES are presented, especially including how to utilize Kubernetes to establish a cloud-based environment. A tailored Web front-end ensures the usability of operations. Over real-world data from ProgrammableWeb.com, analyses and experiments have been conducted to verify the feasibility and effectiveness of the presented approach.",JWE,2021,,20,8,,2199-2242,2,1,https://ieeexplore.ieee.org/document/10246894/
A New Geometric Data Perturbation Method for Data Anonymization Based on Random Number Generators,Merve Kanmaz | Muhammed Ali Aydin | Ahmet Sertbas,"Computer Programming Department, Istanbul University-Cerrahpasa, Istanbul, Turkey | Computer Engineering Department, Istanbul University-Cerrahpasa, Istanbul, Turkey | Computer Engineering Department, Istanbul University-Cerrahpasa, Istanbul, Turkey",Privacy-preserving data mining | data anonymization | data perturbation | geometric perturbation | random number generators,"With the technology's rapid development and its involvement in all areas of our lives, the volume and value of data have become a significant field of study. Valuation of the data to this extent has produced some consequences in terms of people's knowledge. Data anonymization is the most important of these issues in terms of the security of personal data. Much work has been done in this area and continues to being done. In this study, we proposed a method called RSUGP for the anonymization of sensitive attributes. A new noise model based on random number generators has been proposed instead of the Gaussian noise or random noise methods, which are being used conventionally in geometric data perturbation. We tested our proposed RSUGP method with six different databases and four different classification methods for classification accuracy and attack resistance; then, we presented the results section. Experiments show that the proposed method was more successful than the other two classification accuracy, attack resistance, and runtime.",JWE,2021,,20,6,,1947-1970,2,1,https://ieeexplore.ieee.org/document/10246896/
Key Distribution Strategy of Wireless Sensor Network Based on Multi-Hash Chain,Peng Xiong | Qinggang Su,"School of Electronics and Information, Shang hai Dianji University, Shanghai, China | Chinesisch-Deutsche Kolleg für Intelligente Produktion, Shanghai Dianji University, Shanghai, China",Wireless sensor network | key pre-distribution | pairwise key | hash chain,"Key management is the basis of the security mechanism for wireless sensor networks and services, and random key pre-distribution is the most effective key management mechanism at present. However, there is a potential challenge to most current random key pre-distribution strategies: it is difficult to achieve both ideal network security connectivity and network survivability. In this paper, we present a novel random key pre-distribution scheme based on the hash chain. By adjusting certain system parameters, such as the hash chain length, the number of common auxiliary nodes and the number of hash chains, a sensor node only need to preload a few of keys, making it possible to establish the pairwise key with high probability among its neighboring nodes. The proposed scheme can still maintain strong network survivability even if there are many compromised nodes. The theoretical analysis and simulation experiments show that the proposed scheme is not only effective and secure, but also scalable.",JWE,2021,,20,3,,713-742,2,4,https://ieeexplore.ieee.org/document/10246193/
Tiny Drone Tracking Framework Using Multiple Trackers and Kalman-based Predictor,Sohee Son | Jeongin Kwon | Hui-Yong Kim | Haechul Choi,"Hanbat National University, South Korea | Hanbat National University, South Korea | Kyung Hee University, South Korea | Hanbat National University, South Korea",Object tracking | unmanned aerial vehicles | drones | surveillance system,"Unmanned aerial vehicles like drones are one of the key development technologies with many beneficial applications. As they have made great progress, security and privacy issues are also growing. Drone tacking with a moving camera is one of the important methods to solve these issues. There are various challenges of drone tracking. First, drones move quickly and are usually tiny. Second, images captured by a moving camera have illumination changes. Moreover, the tracking should be performed in real-time for surveillance applications. For fast and accurate drone tracking, this paper proposes a tracking framework utilizing two trackers, a predictor, and a refinement process. One tracker finds a moving target based on motion flow and the other tracker locates the region of interest (ROI) employing histogram features. The predictor estimates the trajectory of the target by using a Kalman filter. The predictor contributes to keeping track of the target even if the trackers fail. Lastly, the refinement process decides the location of the target taking advantage of ROIs from the trackers and the predictor. In experiments on our dataset containing tiny flying drones, the proposed method achieved an average success rate of 1.134 times higher than conventional tracking methods and it performed at an average run-time of 21.08 frames per second.",JWE,2021,,20,8,,2391-2412,2,4,https://ieeexplore.ieee.org/document/10246840/
Creating and Capturing Artificial Emotions in Autonomous Robots and Software Agents,Claus Hoffmann | Pascal Linden | Maria-Esther Vidal,"Research Group Robots and Software Agents with Emotions, Sankt Augustin, Germany | University of Bonn, Germany | TIB Leibnitz Information Centre for Science and Technology, Hannover, Germany",Autonomous agents | artificial emotions | agent knowledge graphs,"This paper presents ARTEMIS, a control system for autonomous robots or software agents. ARTEMIS can create human-like artificial emotions during interactions with their environment. We describe the underlying mechanisms for this. The control system also captures its past artificial emotions. A specific interpretation of a knowledge graph, called an Agent Knowledge Graph, stores these artificial emotions. ARTEMIS then utilizes current and stored emotions to adapt decision making and planning processes. As proof of concept, we realize a concrete software agent based on the ARTEMIS control system. This software agent acts as a user assistant and executes their orders and instructions. The environment of this user assistant consists of several other autonomous agents that offer their services. The execution of a user's orders requires interactions of the user assistant with these autonomous service agents. These interactions lead to the creation of artificial emotions within the user assistant. The first experiments show that it is possible to realize an autonomous user assistant with plausible artificial emotions with ARTEMIS and record these artificial emotions in its Agent Knowledge Graph. The results also show that captured emotions support successful planning and decision making in complex dynamic environments. The user assistant with emotions surpasses an emotionless version of the user assistant.",JWE,2021,,20,4,,993-1030,2,7,https://ieeexplore.ieee.org/document/10246227/
Named Entity Recognition with Gating Mechanism and Parallel BiLSTM,Yenan Yi | Yijie Bian,"School of Business, Hohai University, Nanjing, China | School of Business, Hohai University, Nanjing, China",Named entity recognition | parallel BiLSTM | gating mechanism | CoNLL-2003,"In this paper, we propose a novel neural network for named entity recognition, which is improved in two aspects. On the one hand, our model uses a parallel BiLSTM structure to generate character-level word representations. By inputting character sequences of words into several independent and parallel BiLSTMs, we can obtain word representations from different representation subspaces, because the parameters of these BiLSTMs are randomly initialized. This method can enhance the expression abilities of character-level word representations. On the other hand, we use a two-layer BiLSTM with gating mechanism to model sentences. Since the features extracted by each layer in a multi-layer LSTM from texts contain different types of information, we use the gating mechanism to assign appropriate weights to the outputs of each layer, and take the weighted sum of these outputs as the final output for named entity recognition. Our model only changes the structure, does not need any feature engineering or external knowledge source, which is a complete end-to-end NER model. We used the CoNLL-2003 English and German datasets to evaluate our model and got better results compared with baseline models.",JWE,2021,,20,4,,1219-1238,2,4,https://ieeexplore.ieee.org/document/10246195/
Web Usage Mining by Neural Hybrid Prediction with Markov Chain Components,Arpad Gellert,"Computer Science and Electrical Engineering Department, Lucian Blaga University of Sibiu, Romania",Web prefetching | webpage prediction | Markov chains | neural networks | browser extension,"This paper presents and evaluates a two-level web usage prediction technique, consisting of a neural network in the first level and contextual component predictors in the second level. We used Markov chains of different orders as contextual predictors to anticipate the next web access based on specific web access history. The role of the neural network is to decide, based on previous behaviour, whose predictor's output to use. The predicted web resources are then prefetched into the cache of the browser. In this way, we considerably increase the hit rate of the web browser, which shortens the load times. We have determined the optimal configuration of the proposed hybrid predictor on a real dataset and compared it with other existing web prefetching techniques in terms of prediction accuracy. The best configuration of the proposed neural hybrid method provides an average web access prediction accuracy of 86.95%.",JWE,2021,,20,5,,1341-1358,2,4,https://ieeexplore.ieee.org/document/10246875/
Efficient Retrieval of Data Using Semantic Search Engine Based on NLP and RDF,Usha Yadav | Neelam Duhan,"National Institute of Fashion Technology, Jodhpur, India | YMCA, J. C. Bose University of Science & Technology, Faridabad, India",Domain ontology | semantic search engine | SPARQL | natural language processing | RDF,"With the evolution of Web 3.0, the traditional algorithm of searching Web 2.0 would become obsolete and underperform in retrieving the precise and accurate information from the growing semantic web. It is very reasonable to presume that common users might not possess any understanding of the ontology used in the knowledge base or SPARQL query. Therefore, providing easy access of this enormous knowledge base to all level of users is challenging. The ability for all level of users to effortlessly formulate structure query such as SPARQL is very diverse. In this paper, semantic web based search methodology is proposed which converts user query in natural language into SPARQL query, which could be directed to domain ontology based knowledge base. Each query word is further mapped to the relevant concept or relations in ontology. Score is assigned to each mapping to find out the best possible mapping for the query generation. Mapping with highest score are taken into consideration along with interrogative or other function to finally formulate the user query into SPARQL query. If there is no search result retrieved from the knowledge base, then instead of returning null to the user, the query is further directed to the Web 3.0. The top “k” documents are considered to further converting them into RDF format using Text2Onto tool and the corpus of semantically structured web documents is build. Alongside, semantic crawl agent is used to get <Subject-Predicate-Object> set from the semantic wiki. The Term Frequency Matrix and Co-occurrence Matrix are applied on the corpus following by singular Value decomposition (SVD) to find the results relevant for the user query. The result evaluations proved that the proposed system is efficient in terms of execution time, precision, recall and f-measures.",JWE,2021,,20,8,,2285-2318,2,3,https://ieeexplore.ieee.org/document/10246838/
Design and Analysis of Low Delay Deterministic Network Based on Data Mining Association Analysis,Jianhu Gong,"School of Data and Computer Science, Guangdong Peizheng College, Guangzhou, P.R. China",Cache | prefetch | unordered pages | association analysis | data mining,"The purpose of this paper is to research on the design and analysis of low delay deterministic network based on data mining association. This paper studies and implements the algorithm of mining page association rules. A session recognition algorithm based on log reference page and request time is proposed by using the time probability relationship of continuous requests. This method improves the accuracy of log data preprocessing and page association rules mining. This paper studies and tests the efficiency, prefetch timing and cache organization of the two page association rules. The results show that in this prefetch scheme, the prefetch performance of the association rules of unordered pages is better than that of the association rules of ordered pages. The prefetch performance when cache hits is better than that when cache fails and the cache fails to hit has better performance. In the case of a certain size of cache space, reasonable organization of cache space can further improve the cache hit rate and reduce the network delay.",JWE,2021,,20,2,,513-532,2,4,https://ieeexplore.ieee.org/document/10247323/
Construction and Application of the User Behavior Knowledge Graph in Software Platforms,Fuhua Shang | Qiuyu Ding | Ruishan Du | Mao06 Cao | Huanyu Chen,"School of Computer and Information Technology, Northeast Petroleum University, China | School of Computer and Information Technology, Northeast Petroleum University, China | School of Computer and Information Technology, Northeast Petroleum University, China | School of Computer and Information Technology, Northeast Petroleum University, China | School of Computer and Information Technology, Northeast Petroleum University, China",User behavior knowledge graph | user knowledge extraction | graph database | knowledge graph construction,"The analysis of user behavior provides a large amount of useful information. After being extracted, this information is called user knowledge. User knowledge plays a guiding role in implementing user-centric updates for software platforms. A good representation and application of user knowledge can accelerate the development of a software platform and improve its quality. This paper aims to further the utilization of user knowledge by mining the user knowledge that is implicit in user behavior and then constructing a knowledge graph of this behavior. First, the association between a software bug and a software component is mined from the user knowledge. Then, the knowledge entity extraction and relationship extraction are performed from the development code and the user behavior. Finally, the knowledge is stored in the graph database, from which it can be visually retrieved. Relevant experiments on CIFLog, an integrated logging processing software platform, have proved the effectiveness of this research. Constructing a user behavior knowledge graph can improve the utilization of user knowledge as well as the quality of software platform development.",JWE,2021,,20,2,,387-411,2,6,https://ieeexplore.ieee.org/document/10247325/
Performance Analysis of Routing Protocols On IPv4 and IPv6 Addressing Networks,Neha Jain | Ashish Payal | Aarti Jain,"USICT, GGSIPU, New Delhi, India | USICT, GGSIPU, New Delhi, India | AIACTR, NSUT, New Delhi, India",Internet Protocol (IP) | IPv4 | IPv6 | Routing Protocols | Routing Information Protocol (RIP) | Routing Information Protocol Next Generation (RIPng),"With IPv4 addresses being exhausted, network engineers and researchers are encouraged to adopt IPv6. But before using the IPv6 network directly, engineers need to test their hardware and network performance under new conditions of IPv6 as it has an extended address, high complexity, overhead performance, and IPsec complications. As routing protocols play a crucial role in network performance, it leads to a network's extended performance by finding the shortest path, good throughput, and lowest delay. As the specifications, viz. frame structure for IPv4 and IPv6 are entirely different, there are modified routing protocols specified for IPv6. Routing Information Protocol (RIP) and Routing Information Protocol Next Generation (RIPng) are distance vector routing protocols and use hop count as a cost. In this paper, we have used RIPng on the IPv6 addressing network and RIP on the IPv4 addressing network and then analyze and compare them on the basis of different performance parameters. For this comparison, three different applications - File Transfer Protocol (FTP), DB Query (DataBase), and electronic mail (e-mail) - are set on a network consisting of three different subnets, each having a diverse network topology. The performance parameters analyzed are global and object statistics, viz. ethernet delay, number of hops, applications response time, background traffic delay, traffic dropped, point-to-point links throughput, links utilization, and links queuing delay. The experimental results determine the strength of the routing protocols. Thus, the quantitative results give the option to choose the routing protocol according to the network scenarios. In terms of ethernet delay, traffic dropped, network convergence, and security, it is found that the RIPng_IPv6 network performs better than RIP_IPv4. RIPng_IPv6 has an ethernet delay of 2.9 milliseconds, traffic dropped of 0.29 packets/second, and network convergence of 17 seconds less than RIP_IPv4 values. However, the RIP_IPv4 network is scalable, uses less hop, and has 40 milliseconds of traffic delay, while RIPng_IPv6 has 0.40 seconds of traffic delay. RIP_IPv4 also has a better response time for all three applications, FTP as 100 milliseconds, DB as 40 milliseconds, and e-mail as 20 milliseconds which is much less than the values obtained for RIPng_IPv6 network. Therefore, according to the performance requirements, the network engineers/operators or researchers can use either the existing IPv4 network or a new IPv6 network to achieve the Quality of Service (QoS) target level.",JWE,2021,,20,5,,1389-1428,2,9,https://ieeexplore.ieee.org/document/10246883/
Generation of Realistic Navigation Paths for Web Site Testing Using RNN and GAN,Silvio Pavanetto | Marco Brambilla,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy | Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy",Web engineering | deep learning | data mining | generative adversarial networks | recurrent neural networks | testing,"For applications that have not yet been launched, a reliable way for creating online navigation logs may be crucial, enabling developers to test their products as though they were being used by real users. This might lead to faster and lower-cost program testing and enhancement, especially in terms of usability and interaction. In this work we propose a method for using deep learning approaches such as recurrent neural networks (RNN) and generative adversarial neural networks (GANN) to produce high-quality weblogs. Eventually, we can utilize the created data for automated testing and improvement of Web sites prior to their release with the aid of model-driven development tools such as IFML Editor.",JWE,2021,,20,8,,2571-2604,2,2,https://ieeexplore.ieee.org/document/10246917/
Bayesian Probability and Tanimoto Based Recurrent Neural Network for Question Answering System,Veeraraghavan Jagannathan,"Department of Computer Science and Engineering, Sri Vasavi Engineering College (Autonomouus), Pedatadepalli, Tadepalligudem, Andhra Pradesh, India",Question answering system | question classification | recurrent neural network | Bayesian probability | machine learning,"Question Answering (QA) has become one of the most significant information retrieval applications. Despite that, most of the question answering system focused to increase the user experience in finding the relevant result. Due to the continuous increase of web content, retrieving the relevant result faces a challenging issue in the Question Answering System (QAS). Thus, an effective Question Classification (QC), and retrieval approach named Bayesian probability and Tanimoto-based Recurrent Neural Network (RNN) are proposed in this research to differentiate the types of questions more efficiently. This research presented an analysis of different types of questions with respect to the grammatical structures. Various patterns are identified from the questions and the RNN classifier is used to classify the questions. The results obtained by the proposed Bayesian probability and Tanimoto-based RNN showed that the syntactic categories related to the domain-specific types of proper nouns, numeral numbers, and the common nouns enable the RNN classifier to reveal better result for different types of questions. However, the proposed approach obtained better performance in terms of precision, recall, and F-measure with the values of 90.14, 86.301, and 90.936 using dataset-2.",JWE,2021,,20,3,,903-934,2,3,https://ieeexplore.ieee.org/document/10246214/
An MDA Proposal To Integrate the Measurement Lifecycle Into the Process Lifecycle,Ayman Meidan | J. A. García-García | Isabel Ramos Ramos | David Lizcano | María José Escalona,"University of Seville, Seville, Spain | University of Seville, Seville, Spain | University of Seville, Seville, Spain | School of Computer Science, Madrid Open University (UDIMA), Madrid, Spain | University of Seville, Seville, Spain",Software development process | process measurement | process metrics and indicators | measurement lifecycle,"Context: Measuring the Software Development Process (SDP) supports organizations in their endeavor to understand, manage, and improve their development processes and projects. In the last decades, the SDP has evolved to meet the market needs and keep abreast of modern technologies and infrastructures. These changes in the development processes have increased the importance of the measurement and caused changes in the measurement process and the used measures. Objective: This work aims to develop a solution to support the measurement activities throughout the process lifecycle. Method: Study the current state of the art to identify existing gaps. Then, propose a solution to support the process measurement throughout the SDP life-cycle. Results: The proposed solution consists of two main components: (i) Measurement lifecycle, which defines the measurement activities throughout the SDP lifecycle, (ii) Measurement definition metamodel (MDMM), which supports the measurement lifecycle and its integration into the process life-cycle. Conclusion: This proposal allows organizations to define, manage, and improve their processes; the proposed information model supports the unification of the measurement concepts and vocabulary. The defined measurement lifecycle provides a comprehensive guide for the organizations to establish the measurement objectives and carry out the necessary activities to achieve them. The proposed MDMM supports and guides the engineers in the complete and operational definition of the measurement concepts.",JWE,2021,,20,7,,2081-2129,2,0,https://ieeexplore.ieee.org/document/10246216/
Development of Digital Libraries with Software Product Line Engineering,Delfina Ramos-Vidal | Alejandro Cortiñas | Miguel R. Luaces | Oscar Pedreira | Angeles Saavedra-Places,"Universidade da Coruña, Centro de Investigación CITIC, Laboratorio de Bases de Datos, Facultade de Informática, Elviña, A Coruña, Spain | Universidade da Coruña, Centro de Investigación CITIC, Laboratorio de Bases de Datos, Facultade de Informática, Elviña, A Coruña, Spain | Universidade da Coruña, Centro de Investigación CITIC, Laboratorio de Bases de Datos, Facultade de Informática, Elviña, A Coruña, Spain | Universidade da Coruña, Centro de Investigación CITIC, Laboratorio de Bases de Datos, Facultade de Informática, Elviña, A Coruña, Spain | Universidade da Coruña, Centro de Investigación CITIC, Laboratorio de Bases de Datos, Facultade de Informática, Elviña, A Coruña, Spain",Software product lines engineering | digital libraries | generation engine,"Digital Libraries have become popular nowadays since important libraries all over the world started distributing their collections online, properly classified, and, in many cases, with access to the digital version of the resource. These programs have been beneficial to the general population as well as research groups in fields such as language and literature. Nonetheless, since their creation is a time-consuming and costly process, small organizations are forced to rely on obsolete or poorly designed software. However, most of the features, including the data model, are shared by this type of system, with minor variations depending on the type of resources to be handled. This article presents a Software Product Line (SPL) for the semi-automatic generation of Digital Libraries (DL). Our SPL allows developers to specify which DL features are required, which will define the data model variation and the generated source code. The specification is then transformed into a fully functional DL application with the specified features that is ready for deployment. We present the feature model, the SPL implementation, and a case study on three sample projects that enabled us to evaluate the resulting software, with a focus on development effort savings.",JWE,2021,,20,7,,2017-2058,2,8,https://ieeexplore.ieee.org/document/10246220/
A Novel Automated Guided Vehicle (AGV) Remote Path Planning Based on RLACA Algorithm in 5G Environment,Wangwang Yu | 06 Liu | Jie Zhou,"School of Electrical Engineering, Shanghai DianJi University, Shanghai, China | School of Electrical Engineering, Shanghai DianJi University, Shanghai, China | School of Electrical Engineering, Shanghai DianJi University, Shanghai, China",5G | path planning | ant colony algorithm | reinforcement learning | path correction,"Remote control and monitoring will become the future trend. High-quality automated guided vehicle (AGV) path planning through web pages or clients can reduce network data transmission capacity and server resource occupation. Many Remote path planning algorithms in AGV navigation still have blind search, path redundancy, and long calculation time. This paper proposed an RLACA algorithm based on 5G network environment through remote control of AGV. The distribution of pheromone in each iteration of the ant colony algorithm had an impact on the follow-up. RLACA algorithm changed the transfer rules and pheromone distribution of the ant colony algorithm to improve the efficiency of path search and then modify the path to reduce path redundancy. Considering that there may be unknown obstacles in the virtual environment, the path obtained by the improved ant colony algorithm is used as the training data of reinforcement learning to obtain the Q-table. During the movement, the action of each step is selected by the Q-table until the target point is reached. Through experimental simulation, it can be concluded that the enhanced ant colony algorithm can quickly obtain a reasonable and adequate path in a complex environment and effectively avoid unknown obstacles in the environment.",JWE,2021,,20,8,,2491-2520,2,4,https://ieeexplore.ieee.org/document/10246900/
Sibelius as a Tool to Improve Student's Ability of Making Counterpoint Melody,Oriana Tio Parahita Nainggolan | Ayu Niza Machfazia | Fortunata Tyasrinestu | Djohan | Phakkharawat Sittiprapaporn,"Department of Music Education, Faculty of Performing Arts, Indonesia Institute of the Arts, Yogyakarta, Indonesia | Department of Music Education, Faculty of Languages and Arts, Yogyakarta State University, Yogyakarta, Indonesia | Department of Music Education, Faculty of Performing Arts, Indonesia Institute of the Arts, Yogyakarta, Indonesia | Department of Performing Arts, Faculty of Performing Arts, Indonesia Institute of the Arts, Yogyakarta, Indonesia | Neuropsychological Research Laboratory, Department of Anti-Aging and Regenerative Science, School of Anti-Aging and Regenerative Medicine, Mae Fah Luang University, Bangkok, Thailand",Sibelius | counterpoint melody | music | student's ability,"As a subject for music students, counterpoint contributes to the ability to create a melody. The melody in counterpoint usually consists of two or more layers. In order to make a counterpoint melody, students must acknowledge the rules to construct the counterpoint melody. A good counterpoint melody involves two important things: the flow of the melody in a vertical and horizontal in vertical line (interval) and the musical texture of the melody. As a beginner in learning counterpoint, writing a counterpoint melody might be difficult at first. Learning counterpoint investigation was found that students spent a lot of their time following the counterpoint rules. They particularly did not focus on the musical sense of the counterpoint melody causing the melody loses its musical senses. Sibelius was used here as a tool to solve the problem. Sibelius is a music software which commonly used in writing musical scores. This study examined Sibelius in making a counterpoint melody in learning counterpoint. The data were gathered through observation and interviews with students during learning counterpoint course. The result showed that by using Sibelius, making counterpoint melody more efficient, and it helped student not only focused on the counterpoint rules but also the musical senses of the counterpoint melody. Furthermore, students also showed the improvement of their skills in making a counterpoint melody.",JWE,2021,,20,8,,2361-2390,2,1,https://ieeexplore.ieee.org/document/10246899/
An Empirical Study of Web Page Structural Properties,Xavier Chamberland-Thibeault | Sylvain Hallé,"Laboratoire d'informatique formelle, Université du Québec à, Chicoutimi, Canada | Laboratoire d'informatique formelle, Université du Québec à, Chicoutimi, Canada",,"The paper reports results on an empirical study of the structural properties of HTML markup in websites. A first large-scale survey is made on 708 contemporary (2019-2020) websites, in order to measure various features related to their size and structure: DOM tree size, maximum degree, depth, diversity of element types and CSS classes, among others. The second part of the study leverages archived pages from the Internet Archive, in order to retrace the evolution of these features over a span of 25 years. The goal of this research is to serve as a reference point for studies that include an empirical evaluation on samples of web pages.",JWE,2021,,20,4,,1031-1062,2,3,https://ieeexplore.ieee.org/document/10246222/
Enhanced Real-Time Intermediate Flow Estimation for Video Frame Interpolation,Minseop Kim | Haechul Choi,"Department of Multimedia Engineering, Hanbat National University, Daejeon, Republic of Korea | Department of Multimedia Engineering, Hanbat National University, Daejeon, Republic of Korea",Video frame interpolation | optical flow estimation | contextual information | multiscale fusion,"Recently, the demand for high-quality video content has rapidly been increasing, led by the development of network technology and the growth in video streaming platforms. In particular, displays with a high refresh rate, such as 120 Hz, have become popular. However, the visual quality is only enhanced if the video stream is produced at the same high frame rate. For the high quality, conventional videos with a low frame rate should be converted into a high frame rate in real time. This paper introduces a bidirectional intermediate flow estimation method for real-time video frame interpolation. A bidirectional intermediate optical flow is directly estimated to predict an accurate intermediate frame. For real-time processing, multiple frames are interpolated with a single intermediate optical flow and parts of the network are implemented in 16-bit floating-point precision. Perceptual loss is also applied to improve the cognitive performance of the interpolated frames. The experimental results showed a high prediction accuracy of 35.54 dB on the Vimeo90K triplet benchmark dataset. The interpolation speed of 84 fps was achieved for 480p resolution.",JWE,2021,,20,8,,2413-2432,2,0,https://ieeexplore.ieee.org/document/10246902/
Chirp Spreading Spectrum in Imperfect Environment and Wireless Tree Topology Network,Hongqiang Li | Dongyan Zhao | Xiaoke Tang | Jie Gan | Xu Zhao | Yubing Zhang,"Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China | Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China | Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China | Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China | Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China | Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China",LoRa | LPWAN | FSCM | chirp | IoT | DCoMP | Tree topology,"With the rapid development of IoT technology in recent years, higher requirements have been put forward for wireless communication technology. Low Power Wide Area Network (LPWAN) technology is emerging rapidly, the technology is characterized by low power consumption, low bandwidth, long-distance, and a large number of connections, and is specifically designed for Internet of Things applications. LoRa (Low Power Long Range Transceiver), as a typical representative of LPWAN technology, has been widely concerned and studied. This paper analyzes the performance of LoRa modulation in the tree topology network and analyzes the performance of LoRa modulation in the imperfect environment for point-to-point communication and multipoint-to-point communication. From theoretical analysis and performance simulation, it can be seen that the influence of frequency offset or multipath fading on LoRa signal is very obvious. However, when LoRa modulation is used for networking, multi-user interference will be introduced. Under the influence of many imperfect factors, the signal receiver performance of LoRa modulation will be difficult to guarantee. Because of these effects, Coordinated Multiple Points based on Timing Delay (DCoMP) is presented. Multiple nodes close to each other send the same data to the target node. Due to the inaccurate synchronization between nodes, there will be a certain relative delay when sending signals to the same target node. After the receiving node combines the signals of multiple nodes according to different relative delays, the reception performance of the signals can be improved. At the same time, the cooperative node can also actively adjust the signal sending time to improve the reception performance of the receiving node signal merging algorithm. LoRa modulation, by using DCoMP transmission, improves the reception of signals and thus the overall capacity of the system. Through the analysis of multipoint communication and single point communication, this paper is of great help to LoRa network deployment.",JWE,2021,,20,1,,191-216,2,1,https://ieeexplore.ieee.org/document/10246866/
An Ontology Representation Language for Multimedia Event Applications,Nisha Pahal | Brejesh Lall | Santanu Chaudhury,"Department of Electrical Engineering, Indian Institute of Technology, Delhi, India | Department of Electrical Engineering, Indian Institute of Technology, Delhi, India | Department of Electrical Engineering, Indian Institute of Technology, Delhi, India",Multimedia web ontology language (MOWL) | event | multimedia event ontology language (E-MOWL) | Bayesian network (BN) | inference,"This paper presents formalization of a new Multimedia Web Ontology Language (E-MOWL) to handle events with media depictions. The temporal, spatial and entity aspects that are implicitly linked to an event are represented through this language to model the context of events. The language EMOWL provides a rich method for representing knowledge corresponding to a specific domain wherein the context specifies the intended meaning of each element of the domain of discourse; an element in different context may correspond to different functional role. The context information associated with an event ties the audiovisual data with event related aspects. In this work, we have extended E-MOWL to model the geographic properties associated with an event by exploiting the geospatial knowledge. This facilitates in identifying the geographic context of an event. All these aspects when considered altogether provide the evidence and contribute towards recognizing an event from multimedia documents. The language also enables reasoning with the uncertainty associated with the events and is organized in the form of Bayesian Network (BN). The media items that are semantically relevant can be assimilated together on the basis of their association with events. We have demonstrated the efficacy of our approach by utilizing an ontology for the entertainment category in news domain to offer an application news aggregation and event-based book recommendations.",JWE,2021,,20,2,,217-252,2,0,https://ieeexplore.ieee.org/document/10247314/
An Algorithm with Efficiently Collecting and Aggregating Data for Wireless Sensor Networks,Peng Xiong | Qinggang Su,"School of Electronics and Information, Shang hai Dianji University, Shanghai, China | Chinesisch-Deutsche Kolleg für Intelligente Produktion, Shanghai Dianji University, Shanghai, China",Collecting data | aggregating data | minimum spanning tree | cluster,"Due to the resource constraint, in wireless sensor network, the node processing ability, wireless bandwidth and battery capacity and other resources are scarcer. For improving the energy efficient and extend the lifetime of the network, this paper proposes a novel algorithm with the distributed and energy-efficient for collecting and aggregating data of wireless sensor network. In the proposed protocol, nodes can autonomously compete for the cluster head based on its own residual energy and the signal strength of its neighbouring nodes. To reduce the energy overhead of cluster head nodes, with a multi-hop way among cluster heads, the collected data from cluster heads is sent to a designated cluster head so as to further send these data to a base station. For improving the performance of the proposed protocol, a new cluster coverage method is proposed to fit the proposed protocol so that when the node density increases, network lifetime can be increased linearly as the number of nodes is increased. Simulations experiments show that network lifetime adopting the proposed protocol is sharply increased. And, the proposed protocol makes all the nodes die (network lifetime is defined as the death of last one node) in the last 40 rounds so that networks adopting the proposed protocol have higher reliability than networks adopting compared protocols.",JWE,2021,,20,3,,615-640,2,1,https://ieeexplore.ieee.org/document/10246192/
Comparing Voice Assistant Risks and Potential with Technology-Based Users: A Study from Germany and Spain,Andreas M. Klein | Maria Rauschenberger | Jörg Thomaschewski | Maria José Escalona,"Department of Computer Languages and Systems, University of Seville, Spain | Faculty of Technology, University of Applied Sciences, Emden/Leer, Germany | Faculty of Technology, University of Applied Sciences, Emden/Leer, Germany | Department of Computer Languages and Systems, University of Seville, Spain",Voice user interface | VUI | voice assistant | user experience | UX | context of use | frequency of use | questionnaire,"Currently, voice assistants (VAs) are trendy and highly available. The VA adoption rate of internet users differs among European countries and also in the global view. Due to speech intelligibility and privacy concerns, using VAs is challenging. Additionally, user experience (UX) assessment methods and VA improvement possibilities are still missing, but are urgently needed to overcome users' concerns and increase the adoption rate. Therefore, we conducted an intercultural study of technology-based users from Germany and Spain, expecting that higher improvement potential would outweigh concerns about VAs. We investigated VA use in terms of availability versus actual use, usage patterns, concerns, and improvement proposals. Comparing Germany and Spain, our findings show that nearly the same amount of intensive VA use is found in both technology-based user groups. Despite cultural differences, further results show very similar tendencies, e.g., frequency of use, privacy concerns, and demand for VA improvements.",JWE,2021,,20,7,,1991-2016,2,15,https://ieeexplore.ieee.org/document/10246226/
Enriching Web Services Tags to Improve Data-Driven Web Services Composition,Nahid Dara | Sima Emadi,"Diabetes Research Center, Shahid Sadoughi University of Medical Sciences, Yazd, Iran | Department of Computer Engineering, Yazd Branch, Islamic Azad University, Yazd, Iran",Service composition | clustering | enrichment tag | data-driven | web service | WSDL,"Due to the large number of existing services and complexity of manual composition, automatic service composition is provided to enable automatic search of the service compositions for the given queries. Many solutions for automatic service composition have been developed, including integer programming, graph planning, artificial intelligence, and so on in this paper, a heuristic method is proposed to improve the data-driven composition of web services by enriching tags based on tags semantic. To do so, firstly, useful information on web services is collected from various sources and is turned into collections of tags. In the next step, using the hierarchical clustering algorithm, the tags are clustered based on semantic similarity. Thereafter, for services which do not have enough tags, enrichment of the tag is carried out and finally, using an algorithm, composition solutions based on QoS parameters are extracted, which can formulate user targets or even provide potential compositions. Moreover, a series of tests were conducted on the web services, which validate the efficiency of the proposed approach. The experimental results confirm the effectiveness of the proposed service composition method and high quality of tag enriching strategies.",JWE,2021,,20,2,,327-358,2,6,https://ieeexplore.ieee.org/document/10247318/
Research on Semantic Similarity of Short Text Based on Bert and Time Warping Distance,Shijie Qiu | Yan Niu | 06 Li | Xing Li,"School of Computer Science, Hubei University of Technology, Wuhan, China | School of Computer Science, Hubei University of Technology, Wuhan, China | School of Computing, Hubei University of Technology, Wuhan, China | China Communications Services Sci and Tech Co., Ltd., Wuhan, China",BERT | CTW | time warping distance | lexical ambiguity | semantic similarity,"The research on semantic similarity of short text plays an important role in machine translation, emotion analysis, information retrieval and other AI business applications. However, according to existing short text similarity research, the characteristics of ambiguous vocabularies are difficult to be effectively analyzed, the solution of the problem caused by words order needs to be further optimized as well. This paper proposes a short text semantic similarity calculation method that combines BERT and time warping distance algorithm, in order to solve the problem of vocabulary ambiguity. The model first uses the pre trained Bert model to extract the semantic features of the short text from the whole level, and obtains a 768 dimensional short text feature vector. Then, it transforms the extracted feature vector into a point sequence in space, uses the CTW algorithm to calculate the time warping distance between the curves connected by the point sequence, and finally uses the weight function designed by the analysis, according to the smaller the time warpage distance is, the higher the degree of small similarity is, to calculate the similarity between short texts. The experimental results show that this model can mine the feature information of ambiguous words, and calculate the similarity of short texts with lexical ambiguity effectively. Compared with other models, it can distinguish the semantic features of ambiguous words more accurately.",JWE,2021,,20,8,,2521-2544,2,0,https://ieeexplore.ieee.org/document/10246912/
Managing Factors to Stages of the Online Customer Journey Influence on Brand Trust,Laksamon Archawaporn | Adisorn Leelasantitham,"Technology of Information System Management Division Faculty of Engineering, Mahidol University, Nakhon Pathom, Thailand | Technology of Information System Management Division Faculty of Engineering, Mahidol University, Nakhon Pathom, Thailand",Customer journey | brand awareness | purchase | brand trust | marketing funnel,"This study examines the possibilities of enhancing relationship between external factors and five main steps of the customer journey influence on brand trust. Our aim is to fill a gap of empirical studies on the online channel in Thailand. We identify four external factors that contribute to each step of customer journey base on customer journey map theory. Data collected from 400 respondents was tested against the research model using a partial least squares (PLS) approach. Our hypotheses testing the determinants set of the customer journey with a statistical inferential analysis that, show the results support 7 of the 9 hypotheses, with a significant relationship between analysed constructs (Social influencer, eWom, and Marketing campaign) which are the factors that might contribute to online customer journey at the present.",JWE,2021,,20,5,,1429-1457,2,0,https://ieeexplore.ieee.org/document/10246876/
Transformation Approach of Open Web Data to Linked Open Data,Amina Meherhera | Imene Mekideche | Leila Zemmouchi-Ghomari | Abdessamed Réda Ghomari,"Ecole Nationale Supérieure d’Informatique, ESI, Algiers, Algeria | Ecole Nationale Supérieure d’Informatique, ESI, Algiers, Algeria | Ecole Nationale Supérieure de Technologie, ENST, Algiers, Algeria | LMCS Laboratory, Ecole Nationale Supérieure d'Informatique, ESI, Algiers, Algeria",Web data | open data | linked data | semantic web | transformation approaches,"A large amount of data available over the Web and, in particular, the open data have, generally, heterogeneous formats and are not machine-readable. One promising solution to overcome the problems of heterogeneity and automatic interpretation is the Linked Data initiative, which aims to provide unified practices for publishing and contextually to link data on the Web, by using World Wide Web Consortium standards and the Semantic Web technologies. LinkedIn data promote the Web's transformation from a web of documents to a web of data, ensuring that machines and software agents can interpret the semantics of data correctly and therefore infer new facts and return relevant web data search results. This paper presents an automatic generic transformation approach that manipulates several input formats of open web data to linked open data. This work aims to participate actively in the movement of publishing data compliant with linked data principles.",JWE,2021,,20,5,,1309-1339,2,3,https://ieeexplore.ieee.org/document/10246882/
Secure Browsing in Local Government: The Case of Portugal,Hélder Gomes | André Zúquete | Gonçalo Paiva Dias | Fábio Marques,"Escola Superior de Tecnologia e Gestão de Águeda (ESTGA), Universidade de Aveiro, Portugal | Departamento de Eletrónica, Telecomunicações e Informática (DETI), Universidade de Aveiro, Portugal | Escola Superior de Tecnologia e Gestão de Águeda (ESTGA), Universidade de Aveiro, Portugal | Escola Superior de Tecnologia e Gestão de Águeda (ESTGA), Universidade de Aveiro, Portugal",e-government | local government | HTTPS | privacy | confidentiality | security | Web,"This article addresses the adoption and use of Hypertext Transfer Protocol Secure (HTTPS) in the entry pages of the official websites of all (308) Portuguese municipalities. This is relevant because such websites are typically used to provide transactional services to citizens, and citizens need to trust that websites are authentic and that confidentiality and integrity of the information exchanged is assured in the communication process. Automated and, whenever needed, manual analyses were used to investigate the entry pages. Specifically, we checked for the existence of an HTTPS site; the correctness of website certificates and their certification chain; coherence between contents of the HTTP and HTTPS versions of websites; redirection from the HTTP version of a website to its HTTPS version; the existence of resources fetched using HTTP in HTTPS versions of websites; and exploitation of HSTS. A Quality Indicator was then defined and a classification of the municipalities into quality groups was produced. Possible determinants for the results obtained by the municipalities were also investigated. The general conclusion is that there is still much to be done to assure that citizens can communicate securely with the websites of all Portuguese municipalities, since only 3.6% of the municipalities were considered good, while 46.1% do not guarantee the minimum conditions. We argue that these results are associated with the fact that most Portuguese municipalities do not have the critical technical and managerial mass to correctly implement and maintain their websites. To mitigate this limitation, we propose the dissemination of technical instructions on how to correctly configure and deploy municipal HTTPS websites and the creation of shared services between the smaller municipalities.",JWE,2021,,20,4,,935-962,2,1,https://ieeexplore.ieee.org/document/10246782/
ARMPatch: A Binary Patching Framework for ARM-based IoT Devices,Mingyi Huang | Chengyu Song,"Department of Computer Science and Engineering, University of California, Riverside, CA, United States | Department of Computer Science and Engineering, University of California, Riverside, CA, United States",ARMPatch | ARM-based IoT devices | ARM platforms,"With the rapid advancement of hardware and internet technologies, we are surrounded by more and more Internet of Things (IoT) devices. Despite the convenience and boosted productivity that these devices have brought to our lives and industries, new security implications have arisen. IoT devices bring many new attack vectors, causing an increment of cyber-attacks that target these systems in the recent years. However, security vulnerabilities on numerous devices are often not fixed. This may due to providers not being informed in time, they have stopped maintaining these models, or they simply no longer exist. Even if an official fix for a security issue is finally released, it usually takes a long time. This gives hackers time to exploit vulnerabilities extensively, which in many cases requires customers to disconnect vulnerable devices, leading to outages. As the software is usually closed source, it is also unlikely that the community will review and modify the source code themselves and provide updates. In this study, we present ARMPatch, a flexible static binary patching framework for ARM-based IoT devices, with a focus on security fixes. After identified the unique challenges of performing binary patching on ARM platforms, we have provided novel features by replacing, modifying, and adding code to already compiled programs. Then, the viability and usefulness of our solution has been verified through demos and final programs on real devices. Finally, we have discussed the current limitations of our approach and future challenges.",JWE,2021,,20,6,,1829-1852,2,3,https://ieeexplore.ieee.org/document/10246888/
Crawling the Deep Web Using Asynchronous Advantage Actor Critic Technique,Kapil Madan | Rajesh Bhatia,"Computer Science & Engineering Department, Punjab Engineering College (Deemed to be University), Chandigarh, India | Computer Science & Engineering Department, Punjab Engineering College (Deemed to be University), Chandigarh, India",Web crawler | deep web | reinforcement learning | A3C,"In the digital world, World Wide Web magnitude is expanding very promptly. Now a day, a rising number of data-centric websites require a mechanism to crawl the information. The information accessible through hyperlinks can easily be retrieved with general-purpose search engines. A massive chunk of the structured information is invisible behind the search forms. Such immense information is recognized as the deep web and has structured information as compared to the surface web. Crawling the content of deep web is very challenging and requires filling the search forms with suitable queries. This paper proposes an innovative technique using an Asynchronous Advantage Actor-Critic (A3C) to explore the unidentified deep web pages. It is based on the policy gradient deep reinforcement learning technique that parameterizes the policy and value function based on the reward system. A3C has one coordinator and various agents. These agents learn from different environments, update the local gradients to a coordinator, and produce a more stable system. The proposed technique has been validated with Open Directory Project (ODP). The experimental outcome shows that the proposed technique outperforms most of the prevailing techniques based on various metrics such as average precision-recall, average harvest rate, and coverage ratio.",JWE,2021,,20,3,,879-902,2,1,https://ieeexplore.ieee.org/document/10246207/
An Efficient Method for Automatic Antipatterns Detection of REST Web Services,Sobhan Mohammadnia | Rasool Esmaeilyfard | Reza Akbari,"Department of Computer Engineering and Information Technology, Shiraz University of Technology, Shiraz, Iran | Department of Computer Engineering and Information Technology, Shiraz University of Technology, Shiraz, Iran | Department of Computer Engineering and Information Technology, Shiraz University of Technology, Shiraz, Iran",REST | web services | anti-patterns detection | service-oriented architecture (SOA) | quality of service (QoS),"REST Web Services is a lightweight, maintainable, and scalable service accelerating client application development. The antipatterns of these services are inadequate and counter-productive design solutions. They have caused many qualitative problems in the maintenance and evolution of REST web services. This paper proposes an automated approach toward antipattern detection of the REST web services using Genetic Programming (GP). Three sets of generic, REST-specific and code-level metrics are considered. Twelve types of antipatterns are examined. The results are compared with the manual rule-based approach. The statistical analysis indicates that the proposed method has an average precision and recall scores of 98% (95% CI, 92.8% to 100%) and 82% (95% CI, 79.3% to 84.7%) and effectively detects REST antipatterns.",JWE,2021,,20,6,,1761-1780,2,5,https://ieeexplore.ieee.org/document/10247161/
News Article Based Industry Risk Index Prediction for Industry-Specific Evaluation,Kyungwon Kim | Kyoungro Yoon,"Korea Electronics Technology Institute, Mapo-gu, Seoul, Republic of Korea | Konkuk University, Gwangjin-gu, Seoul, Republic of Korea",Industry evaluation | industry-specific risk prediction | unstructured data | multiple classification | time-series data analysis,"The existing industry evaluation method utilizes the method of collecting the structured information such as the financial information of the companies included in the relevant industry and deriving the industrial evaluation index through the statistical analysis model. This method takes a long time to calculate the structured data and cause the time delay problem. In this paper, to solve this time delay problem, we derive monthly industry-specific interest and likability as a time series data type, which is a new industry evaluation indicator based on unstructured data. In addition, we propose a method to predict the industrial risk index, which is used as an important factor in industrial evaluation, based on derived industry-specific interest and likability time series data.",JWE,2021,,20,3,,795-816,2,1,https://ieeexplore.ieee.org/document/10246215/
Geospatially Partitioning Public Transit Networks for Open Data Publishing,Harm Delva | Julián Andrés Rojas | Pieter Colpaert | Ruben Verborgh,"Department of Electronics and Information Systems, IDLab, Ghent University - imec, Ghent, Belgium | Department of Electronics and Information Systems, IDLab, Ghent University - imec, Ghent, Belgium | Department of Electronics and Information Systems, IDLab, Ghent University - imec, Ghent, Belgium | Department of Electronics and Information Systems, IDLab, Ghent University - imec, Ghent, Belgium",Linked data | open data | mobility | maintainability | web API engineering,"Public transit operators often publish their open data in a data dump, but developers with limited computational resources may not have the means to process all this data efficiently. In our prior work we have shown that geospatially partitioning an operator's network can improve query times for client-side route planning applications by a factor of 2.4. However, it remains unclear whether this works for all network types, or other kinds of applications. To answer these questions, we must evaluate the same method on more networks and analyze the effect of geospatial partitioning on each network separately. In this paper we process three networks in Belgium: (i) the national railways, (ii) the regional operator in Flanders, and (iii) the network of the city of Brussels, using both real and artificially generated query sets. Our findings show that on the regional network, we can make query processing 4 times more efficient, but we could not improve the performance over the city network by more than 12%. Both the network's topography, and to a lesser extent how users interact with the network, determine how suitable the network is for partitioning. Thus, we come to a negative answer to our question: our method does not work equally well for all networks. Moreover, since the network's topography is the main determining factor, we expect this finding to apply to other graph-based geospatial data, as well as other Link Traversal-based applications.",JWE,2021,,20,4,,1063-1086,2,7,https://ieeexplore.ieee.org/document/10246217/
Modified Firefly Algorithm and Fuzzy C-Mean Clustering Based Semantic Information Retrieval,M. Subramaniam | A. Kathirvel | E. Sabitha | H. Anwar Basha,"Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India | Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India | Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India | Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India",Ontology | semantic information | web documents and modified firefly algorithm,"As enormous volume of electronic data increased gradually, searching as well as retrieving essential info from the internet is extremely difficult task. Normally, the Information Retrieval (IR) systems present info dependent upon the user's query keywords. At present, it is insufficient as large volume of online data and it contains less precision as the system takes syntactic level search into consideration. Furthermore, numerous previous search engines utilize a variety of techniques for semantic based document extraction and the relevancy between the documents has been measured using page ranking methods. On the other hand, it contains certain problems with searching time. With the intention of enhancing the query searching time, the research system implemented a Modified Firefly Algorithm (MFA) adapted with Intelligent Ontology and Latent Dirichlet Allocation based Information Retrieval (IOLDAIR) model. In this recommended methodology, the set of web documents, Face book comments and tweets are taken as dataset. By means of utilizing Tokenization process, the dataset pre-processing is carried out. Strong ontology is built dependent upon a lot of info collected by means of referring via diverse websites. Find out the keywords as well as carry out semantic analysis with user query by utilizing ontology matching by means of jaccard similarity. The feature extraction is carried out dependent upon the semantic analysis. After that, by means of Modified Firefly Algorithm (MFA), the ideal features are chosen. With the help of Fuzzy C-Mean (FCM) clustering, the appropriate documents are grouped and rank them. At last by using IOLDAIR model, the appropriate information's are extracted. The major benefit of the research technique is the raise in relevancy, capability of dealing with big data as well as fast retrieval. The experimentation outcomes prove that the presented method attains improved performance when matched up with the previous system.",JWE,2021,,20,1,,33-52,2,24,https://ieeexplore.ieee.org/document/10246865/
Photographic Image Intelligent Fuzzy Assistant Teaching System Based on Augmented Reality and Web,Xiaoying Fan,"The Academy of Fine Arts, Hubei Normal University, Huangshi, China",Augmented reality | photographic image | auxiliary teaching,"Due to the limitation of time and space, the traditional photographic image intelligent fuzzy teaching system can not provide targeted auxiliary teaching for students with different learning abilities. The design of intelligent fuzzy assistant teaching system of photographic image based on augmented reality and web is carried out, including the hardware design of server and peripheral equipment selection, and the design of intelligent fuzzy assistant teaching system of photographic image based on Web and augmented reality, such as intelligent fuzzy assistant teaching display, student learning behavior evaluation software design, etc. Experiments show that, compared with the traditional system, the photographic image intelligent fuzzy assistant teaching system based on augmented reality and web has more correct allocation of teaching resources, stronger pertinence and practical value.",JWE,2021,,20,4,,1155-1176,2,3,https://ieeexplore.ieee.org/document/10246219/
Application of the LDA Model to Semantic Annotation of Web-based English Educational Resources,Wei Du | Haiyan Zhu | Teeraporn Saeheaw,"School of Foreign Languages and Culture, Ningxia University, Ningxia, China | School of Foreign Languages and Culture, Ningxia University, Ningxia, China | College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, Thailand",LDA model | Web English | educational resources | semantic annotation,"Based on the LDA model, this paper builds a three-layer semantic model of Web English educational resources “document-topic-keyword”, models the semantic topics of resource documents, and obtains the semantic topics and keywords of document resources as the semantic labels of resources. The experimental results show that document LDA topic modeling is beneficial to the macroscopic classification of Web English educational resources. The experimental results show that LDA topic modeling of documents is useful for macroscopic cataloging of Web English educational resources, highlighting teaching priorities, difficulties, and interrelationships, while LDA modeling of teaching topics with the same teaching content expands the metadata generation method of resource description based on the basic education metadata standard and provides more information about the inherent characteristics of resources. The semantic information can be used to mine the semantic thematic features and detailed differences inherent in the resources, and the final performance analysis verifies the parallel computing advantages of the LDA model in a big data environment.",JWE,2021,,20,4,,1113-1136,2,8,https://ieeexplore.ieee.org/document/10246223/
How to Retrieve Music using Mood Tags in a Folksonomy,Chang Bae Moon | Jong Yeol Lee | Byeong Man Kim,"ICT-Convergence Research Center, Kumoh National Institute of Technology, Korea | Computer and Software Engineering, Kumoh National Institute of Technology, Korea | Computer and Software Engineering, Kumoh National Institute of Technology, Korea",Music mood | folksonomy | mood tag | Last.fm | mood vector | relationship between mood and tag,"A folksonomy is a classification system in which volunteers collaboratively create and manage tags to annotate and categorize content. The folksonomy has several problems in retrieving music using tags, including problems related to synonyms, different tagging levels, and neologisms. To solve the problem posed by synonyms, we introduced a mood vector with 12 possible moods, each represented by a numeric value, as an internal tag. This allows moods in music pieces and mood tags to be represented internally by numeric values, which can be used to retrieve music pieces. To determine the mood vector of a music piece, 12 regressors predicting the possibility of each mood based on acoustic features were built using Support Vector Regression. To map a tag to its mood vector, the relationship between moods in a piece of music and mood tags was investigated based on tagging data retrieved from Last.fm, a website that allows users to search for and stream music. To evaluate retrieval performance, music pieces on Last.fm annotated with at least one mood tag were used as a test set. When calculating precision and recall, music pieces annotated with synonyms of a given query tag were treated as relevant. These experiments on a real-world data set illustrate the utility of the internal tagging of music. Our approach offers a practical solution to the problem caused by synonyms.",JWE,2021,,20,8,,2335-2360,2,3,https://ieeexplore.ieee.org/document/10246903/
Improved IDR Response System for Sensor Network,A. Kathirvel | M. Subramaniam | S. Navaneethan | C. Sabarinath,"Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India | Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India | Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India | Department of CSE, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India",WSN | EIDR | CAO | MODE | IRA | IDS,"Wireless sensor network (WSN) is highly sophisticated than ad hoc wireless network. Ad hoc wireless network is mostly affected by different resources such as high processing energy, storage capabilities and battery backup and etc. Due to the open nature, poor infrastructure, quick deployment practices, and the conflict environments, make them susceptible to a wide range of attacks. Recently, the network attack affects the performance of networks such as network lifetime, throughput, delay, energy consumption, and packet loss. The conventional security mechanisms like intrusion detection system (IDS) of network security are not enough for these networks. In this thesis, we introduce an enhanced intrusion detection and response (EIDR) system using two tire processes. The first contribution of proposed EIDR system is optimal cluster formation and performed by the chaotic ant optimization (CAO) algorithm. The second contribution is to calculate the trust value of each sensor node using the multi objective differential evolution (MODE) algorithm. The computed trust value is used to design the intrusion response action (IRA) system, which offers additional functions and exhibit multiple characteristics of response to mitigate intrusion impacts. The simulation results display that the proposed EIDR system has a better detection rate and false positive rate without affecting network performance.",JWE,2021,,20,1,,53-88,2,16,https://ieeexplore.ieee.org/document/10246867/
Dynamic Recognition and Tracking of Barium Flow Field Based on Deglutition Video,Guofeng Qin | Jianhuang Zou | Qiufang Xia | Jiahao Qin,"Department of Computer Science and Technology, Tongji University, Shanghai, China | Department of Computer Science and Technology, Tongji University, Shanghai, China | Shanghai first rehabilitation hospital, Shanghai, China | Department of Computer Science and Technology, Tongji University, Shanghai, China",Dynamic fluoroscopy | X-ray barium fluoroscopy | swallowing disorders | interframe difference algorithm | background subtraction algorithm,"Dynamic fluoroscopy was used to study swallowing in 84 adult patients. We proposed a method to extract the barium contrast region by improved interframe difference method, and to indirectly determine the position of epigmatous cartilage and cricopharyngeal muscle according to the location of barium meal. The method is easy to understand, and the extraction effect is good, with 85% probability of successful extraction. On the other hand, in order to evaluate the degree of deglutition difficulty, we used calculation to evaluate variables including displacement, duration, residual quantity, etc., except that there were gender differences in variables and external factors, such as illumination, most of the measurement variables had very good reliability. The experimental results showed that the moving target fluid barium was extracted by quantifying dynamic fluorescence deglutition and using gaussian based background subtraction algorithm. We conclude that this approach significantly reduces the time it takes clinicians to examine moving images. This paper describes how to study swallowing disorders by X-ray barium fluoroscopy, explains the application of interframe difference algorithm and background subtraction in deglutiography, and extracts the residual amounts in three locations: oral cavity, epiglottic cartilage and piriform fosse.",JWE,2021,,20,2,,533-555,2,1,https://ieeexplore.ieee.org/document/10247315/
Research on the Methods and Key Techniques of Web Archive Oriented Social Media Information Collection,Xinping Huang,"School of Management, Jilin University, Changchun, China",Social media | web archive | information collection | long-term preservation | technical strategy,"Social media information collection and preservation is a hot issue in the field of Web Archive. This paper makes a comparative analysis of the different social media information collection methods, deeply analyzes the key techniques of the three important parts-collection, evaluation and preservation in the information collection process, and provides the solutions for the problems in the key techniques. Through analysis, the collection method suitable for the social media information is found. In terms of the problem that social websites impose restrictions on the call frequency of API, the paper provides solutions, for example, use the multiplexing mechanism, use the naive Bayesian algorithm to solve the spam filtering problem, and use MongoDB Dbased distributed storage to store collected massive data.",JWE,2021,,20,8,,2473-2490,2,1,https://ieeexplore.ieee.org/document/10246905/
A Novel Processing Model for P300 Brainwaves Detection,Wanus Srimaharaj | Roungsan Chaisricharoen,"Department of Information Technology, The International College, Payap University, Thailand | Computer and Communication Engineering for Capacity Building Research Center, School of Information Technology, Mae Fah Luang University, Thailand",Event-related potential | ERP | P300 | signal processing | band-pass filter | fast fourier transform | feature extraction | classification | machine learning | decision tree,"Event-related potential (ERP) is a distinctive pattern of brain activity that is elicited by the brain's sensitivity and cognition whereas P300 evoked potential changes in cognitive functions. Since P300 wave is a cognitive response across multiple brain channels correlated between the measured electroencephalogram (EEG) and deviant stimulus in a specific period, it requires a suitable signal processing application for interpretation. Moreover, multiple steps of data processing under neuroscience criteria make the P300 reflection difficult to analyze by common methods. Therefore, this study proposes the processing model for brainwave applications based on P300 peak signal detection in multiple brain channels. This study applies 64 channels ERP datasets throughout bandpass filter in fast Fourier transform (FFT) with the specific ranges of signal processing while ERP averaging is applied as a feature extraction method. Furthermore, the experimental metadata is applied with the filtered P300 peak signals in channel classification via a machine learning method, the Decision Tree. The experimental results indicate the accurate mental reflection of P300 evoked potential in different brain channels with high classification accuracy relying on the contrast condition throughout the original data source averaged across the individual electrodes.",JWE,2021,,20,8,,2545-2570,2,6,https://ieeexplore.ieee.org/document/10246909/
The Collaborative Production Management System of Power Enterprises Based on Online Information Sharing,Yu Guoji | Zhong Jianxu | Yu Shaofeng | Liao Chongyang | Ma Yining,"CSG Power Generation Company Information Communication Branch, GuangZhou, China | CSG Power Generation Company Information Communication Branch, GuangZhou, China | CSG Power Generation Company Information Communication Branch, GuangZhou, China | CSG Power Generation Company Information Communication Branch, GuangZhou, China | CSG Power Generation Company Information Communication Branch, GuangZhou, China",Online information sharing | electricity | power enterprises | production management system,"With the development of online information sharing, high-tech equipment for collaborative production management of power enterprises emerges endlessly. Therefore, it is necessary to design the collaborative production management system of power enterprises based on online information sharing to meet the information sharing needs. In terms of the hardware, the B/S structure was built, and the computer was debugged with Cascading Style Sheet (CSS). In terms of the software, Hadoop horizontal architecture technology framework was designed, the physical deployment was carried out, the production management center module was designed, and the production operation chain was monitored and managed to realize the collaborative production management of power enterprises. The experimental results showed that the designed collaborative production management system of power enterprise had high reliability and friendliness, the highest reliability is 97.2%, the highest friendliness is 99.8%, which meets the current demand.",JWE,2021,,20,5,,1659-1674,2,3,https://ieeexplore.ieee.org/document/10246877/
Comparisons of Machine Learning Methods of Statistical Downscaling Method: Case Studies of Daily Climate Anomalies in Thailand,Kanawut Chattrairat | Waranyu Wongseree | Adisorn Leelasantitham,"Faculty of Engineering, Technology of Information System Management, Mahidol University, Thailand | Department of Electrical and Computer Engineering, King Mongkut's University of Technology North Bangkok, Thailand | Faculty of Engineering, Technology of Information System Management, Mahidol University, Thailand",Global climate model (GCM) | statistical downscaling (SD) method | linear regression (LR) | Gaussian process (GP) | support vector machine (SVM) | deep learning (DL),"The climate change which is essential for daily life and especially agriculture has been forecasted by global climate models (GCMs) in the past few years. Statistical downscaling method (SD) has been used to improve the GCMs and enables the projection of local climate. Many pieces of research have studied climate change in case of individually seasonal temperature and precipitation for simulation; however, regional difference has not been included in the calculation. In this research, four fundamental SDs, linear regression (LR), Gaussian process (GP), support vector machine (SVM) and deep learning (DL), are studied for daily maximum temperature (TMAX), daily minimum temperature (TMIN), and precipitation (PRCP) based on the statistical relationship between the larger-scale climate predictors and predictands in Thailand. Additionally, the data sets of climate variables from over 45 weather stations overall in Thailand are used to calculate in this calculation. The statistical analysis of two performance criteria (correlation and root mean square error (RMSE)) shows that the DL provides the best performance for simulation. The TMAX and TMIN were calculated and gave a similar trend for all models. PRCP results found that in the North and South are adequate and poor performance due to high and low precipitation, respectively. We illustrate that DL is one of the suitable models for the climate change problem.",JWE,2021,,20,5,,1459-1486,2,7,https://ieeexplore.ieee.org/document/10246881/
Information Credibility Evaluation in Presence of Users' Safety in New Retailing,Dong Wang | Kehong Wang | Lemei Yan | Zeyu Yue | Jiewen Zhang,"School of Management, Guangzhou University, Guangzhou, China | School of Management, Guangzhou University, Guangzhou, China | School of Management, Guangzhou University, Guangzhou, China | School of Management, Guangzhou University, Guangzhou, China | School of Management, Guangzhou University, Guangzhou, China",Information credibility | perceived information quality | user judgement motivation | safety preference | new retailing,"Understanding users' safety perception of the credibility of web-based information has become increasingly important in the context of new retailing. This study extends the existing literature by exploring the factors influencing information credibility in the context of new retailing. Based on the technology acceptance model and the rational behavior theory, a theoretical model for the assessment of information credibility in new retailing was developed. We analyzed the factors influencing users' safety preference toward information communication procedures and information credibility in new retailing based on two aspects: perceived information quality and user judgment motivation. The reliability and validity of the model measure were analyzed, and structural equation modeling was used to test the model hypotheses. The following results were obtained: (1) Authenticity, accuracy, and practicability positively affected the perceived information quality of new retailing information; (2) User judgment motivation had a positive impact on information users' safety preference and information credibility; (3) Users' safety preference positively affected information credibility; (4) Information acquisition, social interaction, and self-identity positively affected the perceived credibility of new retailing information.",JWE,2021,,20,3,,Jan-28,2,5,https://ieeexplore.ieee.org/document/10246199/
A General Framework of LSTM and Transfer Learning Based CFDAMA Strategy in Broadband Satellite System,Qiang He | Zheng Xiang | Peng Ren,"School of Telecommunications Engineering, Xidian University, Xi'an, China | School of Telecommunications Engineering, Xidian University, Xi'an, China | School of Telecommunications Engineering, Xidian University, Xi'an, China",Multiple access scheme | LSTM | transfer learning | data traffic prediction | CFDAMA,"With the development of the economy and technology, people's requirement for communication is also increasing. Satellite networks have been paid more and more attention because of its broadband service capability and wide coverage. In this paper, we investigate the framework of a long-short term memory (LSTM) and transfer learning-based Combined Free/Demand Assignment Multiple Access (CFDAMA) scheme (CFDAMA-LSTMTL), which is a new multiple access scheme in the broadband satellite system. Generally, there is a delay time T between sending a request from the user to the satellite and receiving a reply from the satellite. So far, the traditional multiple access schemes has not processed the data traffic generated in this period of time. So, in order to transmit the data traffic in time, we propose a new prediction method, which combines LSTM with transfer learning. We introduce the prediction method into the CFDAMA scheme so that it can reduce data accumulation by the way of sending the sum slots requested by the user and the predicted request slots generated in the delay time T. A comparison with CFDAMA-PA and CFDAMA-PB is provided through simulation results, which gives the effect of the CFDAMA-LSTMTL in a broadband satellite systems.",JWE,2021,,20,2,,431-458,2,0,https://ieeexplore.ieee.org/document/10247331/
Water Moth Search Algorithm-based Deep Training for Intrusion Detection in IoT,Rekha P. M | Nagamani H. Shahapure | Punitha M | Sudha P. R,"Department of Information Science and Engineering, JSS Academy of Technical Education, Bengalru, Karnataka, India | Department of Information Science, JSS Academy of Technical Education, Bangalore, Karnataka, India | Department of Information Science, JSS Academy of Technical Education, Bangalore, Karnataka, India | Department of Information Science, JSS Academy of Technical Education, Bangalore, Karnataka, India",Internet of things | intrusion detection | water wave optimization | deep recurrent neural network | moth search optimization,"The economic growth and information technology leads to the development of Internet of Things (IoT) industry and has become the emerging field of research. Several intrusion detection techniques are introduced but the detection of intrusion and malicious activities poses a challenging task. This paper devises a novel method, namely the Water Moth Search algorithm (WMSA) algorithm, for training Deep Recurrent Neural Network (Deep RNN) to detect malicious network activities. The WMSA algorithm is newly devised by combining Water Wave optimization (WWO) and the Moth Search Optimization (MSO). The pre-processing is employed for the removal of redundant data. Then, the feature selection is devised using the Wrapper approach, then using the selected features; the Deep RNN classifier effectively detects the intrusion using the selected features. The proposed WMSA-based Deep RNN showed improved results with maximal accuracy, specificity, and sensitivity of 0.96, 0.973 and 0.960.",JWE,2021,,20,6,,1781-1812,2,3,https://ieeexplore.ieee.org/document/10246891/
Recognition Method of Abnormal Behavior of Marine Fish Swarm Based on In-Depth Learning Network Model,Liyong Chen | Xiuye Yin,"School of Network Engineering, Zhoukou Normal University, Zhoukou, China | School of Computer Science and Technology, Zhoukou Normal University, Zhoukou, China",In-depth learning network model | marine fish swarm | abnormal behavior | recognition,"In order to solve the problem that individual coordinates are easily ignored in the localization of abnormal behavior of marine fish, resulting in low recognition accuracy, execution efficiency and high false alarm rate, this paper proposes a method of fish abnormal behavior recognition based on deep learning network model. Firstly, the shadow of the fish behavior data is removed, and the background image is subtracted from each frame image to get the gray image of the fish school. Then, the label watershed algorithm is used to identify the fish, and the coordinates of different individuals in the fish swarm are obtained. Combined with the experimental size constraints and the number of fish, and combined with the deep learning network model, the weak link of video tag monitoring of abnormal behavior of marine fish is analyzed. Finally, the multi instance learning method and dual flow network model are used to identify the anomaly of marine fish school. The experimental results show that the method has high recognition accuracy, low false alarm rate and high execution efficiency. This method can provide a practical reference for the related research in this field.",JWE,2021,,20,3,,575-596,2,9,https://ieeexplore.ieee.org/document/10246210/
Special Issue on Advanced Practices in Web Engineering 2021,M. A. Olivero | J. G. Enríquez | A. Jiménez-Ramírez,"Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain | Computer Languages and Systems Department, Escuela Técnica Superior de Ingeniería Informática, Sevilla, Spain",,"Novelty in Web Engineering arises when this area is jointly applied with other emerging and innovative ones. The transference of Web Engineering research results to industrial applications is quick due to the extensive domains of applications that this area of knowledge has. Each year there are more and more users appealing for it. Consequently, the users' expectations and demands on this area are higher and higher. Thus, the ability of researchers and developers to adopt advanced practices and adapt to innovative approaches within Web Engineering has a tremendous and direct impact on society.",JWE,2021,,20,7,,v-vii,2,0,https://ieeexplore.ieee.org/document/10246209/
AMR-CNN: Abstract Meaning Representation with Convolution Neural Network for Toxic Content Detection,Ermal Elbasani | Jeong-Dong Kim,"Department of Computer Science and Engineering, Sun Moon University, Asan, South Korea | Department of Computer Science and Engineering, Sun Moon University, Asan, South Korea",Datacenter design | energy efficiency of datacenter | energy efficient metrics | datacenter carbon footprint computation,"Recognizing the offensive, abusive, and profanity of multimedia content on the web has been a challenge to keep the web environment for user's freedom of speech. As profanity filtering function has been developed and applied in text, audio, and video context in platforms such as social media, entertainment, and education, the number of methods to trick the web-based application also has been increased and became a new issue to be solved. Compared to commonly developed toxic content detection systems that use lexicon and keyword-based detection, this work tries to embrace a different approach by the meaning of the sentence. Meaning representation is a way to grasp the meaning of linguistic input. This work proposed a data-driven approach utilizing Abstract meaning Representation to extract the meaning of the online text content into a convolutional neural network to detect level profanity. This work implements the proposed model in two kinds of datasets from the Offensive Language Identification Dataset and other datasets from the Offensive Hate dataset merged with the Twitter Sentiment Analysis dataset. The results indicate that the proposed model performs effectively, and can achieve a satisfactory accuracy in recognizing the level of online text content toxicity.",JWE,2022,,21,3,,677-692,2,29,https://ieeexplore.ieee.org/document/10243627/
A Study of Profanity Effect in Sentiment Analysis on Natural Language Processing Using ANN,Cheong-Ghil Kim | Young-06 Hwang | Chayapol Kamyod,"Dept. of Computer Science, Namseoul University, CA, USA | Dept. of Computer Science, Namseoul University, CA, USA | Computer and Communication Engineering for Capacity Building Research Center, School of Information Technology, Mae Fah Luang University, Chiang Rai, Thailand",Deep learning | sentiment analysis | opinion mining | natural language processing | stopword,"The development of wireless communication technology and mobile devices has brought about the advent of an era of sharing text data that overflows on social media and the web. In particular, social media has become a major source of storing people's sentiments in the form of opinions and views on specific issues in the form of unstructured information. Therefore, the importance of emotion analysis is increasing, especially with machine learning for both personal life and companies' management environments. At this time, data reliability is an essential component for data classification. The accuracy of sentiment classification can be heavily determined according to the reliability of data, in which case noise data may also influence this classification. Although there is stopword that does not have meaning in such noise data, data that does not fit the purpose of analysis can also be referred to as noise data. This paper aims to provide an analysis of the impact of profanity data on deep learning-based sentiment classification. For this purpose, we used movie review data on the Web and simulated the changes in performance before and after the removal of the profanity data. The accuracy of the model trained with the data and the model trained with the data before removal were compared to determine whether the profanity is noise data that lowers the accuracy in sentiment analysis. The simulation results show that the accuracy dropped by about 2% when judging profanity as noise data in the sentiment classification for review data.",JWE,2022,,21,3,,751-766,2,12,https://ieeexplore.ieee.org/document/10247207/
Performance of End-to-End Model Based on Convolutional LSTM for Human Activity Recognition,Young Ghyu Sun | Soo Hyun Kim | Seongwoo Lee | Joonho Seon | SangWoon Lee | Cheong Ghil Kim | Jin Young Kim,"Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea | Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea | Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea | Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea | Department of Multimedia, Namseoul University, Cheonan, Korea | Department of Computer Science, Namseoul University, Cheonan, Korea | Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea",Human activity recognition | video-based model | deep learning | convolutional long-short term memory | end-to-end model,"Human activity recognition (HAR) is a key technology in many applications, such as smart signage, smart healthcare, smart home, etc. In HAR, deep learning-based methods have been proposed to recognize activity data effectively from video streams. In this paper, the end-to-end model based on convolutional long short-term memory (LSTM) is proposed to recognize human activities. Convolutional LSTM can learn features of spatial and temporal simultaneously from video stream data. Also, the number of learning weights can be diminished by employing convolutional LSTM with an end-to-end model. The proposed HAR model was optimized with various simulation environments using activities data from the AI hub. From simulation results, it can be confirmed that the proposed model can be outperformed compared with the conventional model.",JWE,2022,,21,5,,1671-1689,2,5,https://ieeexplore.ieee.org/document/10246930/
Research on Semantic Information Retrieval Based on Improved Fish Swarm Algorithm,Ming Hu,"Wuhu Institute of Technology, China",Semantic information retrieval | improved fish swarm algorithm | classification accuracy,"In order to improve the effectiveness of semantic information retrieval, the improved fish swarm algorithm is proposed to carry out semantic information retrieval. Firstly, the system of semantic information retrieval is designed, and theory model of search engine is established. Secondly, the information retrieval model based on semantic similarity is constructed, and the mathematical model is deduced. Thirdly, the improved fish algorithm is established, and the analysis procedure of it is designed. Finally, the simulation analysis of semantic information retrieval is carried out, results show that the proposed model can obtain higher classification accuracy, precision rare and recall rate, therefore it has higher performance on semantic information retrieval.",JWE,2022,,21,3,,845-860,2,11,https://ieeexplore.ieee.org/document/10243630/
Research on Cloud Computing Task Scheduling Based on PSOMC,Kun Li | Liwei Jia | Xiaoming Shi,"Computer Teaching and Research Section Department of Public Infrastructure, Henan Medical College, Zhengzhou, Henan, China | Computer Teaching and Research Section Department of Public Infrastructure, Henan Medical College, Zhengzhou, Henan, China | Computer Teaching and Research Section Department of Public Infrastructure, Henan Medical College, Zhengzhou, Henan, China",Cloud computing | task scheduling | chaos | adaptive weights,"How to better reduce the task scheduling time and consumption cost in cloud computing has always been a hot topic of current research. In this paper, we propose a cloud computing task scheduling strategy based on the fusion of Particle Swarm Optimization and Membrane Computing. Firstly, a task scheduling model with time function and cost function as the target is proposed, secondly, on the basis of particle swarm algorithm, chaos operation is used in population initialization to improve the diversity of rich understanding, adaptive weight factor based on sinusoidal function is used to avoid the algorithm falling into local optimum, Membrane Computing is used in individual screening to improve the quality of individual solutions, and finally, in The performance of the PSOMC algorithm is illustrated by comparing six benchmark test functions in simulation experiments, and it is also verified that the completion time and consumption cost are significantly better than those of the ACO, PSO and MC algorithms for different number of tasks.",JWE,2022,,21,6,,1749-1766,2,5,https://ieeexplore.ieee.org/document/10246937/
A Study on Improvement of the Military IdAM Using Edge-Sovereign Identity (ESI),Gyudong Park | Gi-Yoon Jeon | Jong-Oh Kim,"Command and Control Systems PMO, Agency for Defense Development, Seoul, Korea | Command and Control Systems PMO, Agency for Defense Development, Seoul, Korea | Future Innovation Systems Co., Ltd, Daejeon, Korea",Self-sovereign identity | IdAM | Edge-sovereign identity,"A framework-level IdAM integration approach requires a stable network infrastructure. Information framework's operation may be significantly restricted when the network is disconnected from the remote IdAM service. Moreover, military networks, especially tactical networks, are volatile, and network disconnection is also high. In this paper, we proposed an Edge-Sovereign Identity (ESI) that expanded the concept of SSI for use in the military field, designed the structure and function of the proposed concept, and demonstrated its usefulness and validity through examples and prototypes.",JWE,2022,,21,5,,1435-1448,2,2,https://ieeexplore.ieee.org/document/10246924/
Vehicle Classification and Tracking Based on Deep Learning,Hyochang Ahn | Yong-Hwan Lee,"Wonkwang University, Iksan City, Jeonbuk, Republic of Korea | Wonkwang University, Iksan City, Jeonbuk, Republic of Korea",Vehicle classification | Moving object tracking | Deep learning | YOLO,"Traffic volume is gradually increasing due to the development of technology and the concentration of people in cities. As the results, traffic congestion and traffic accidents are becoming social problems. Detecting and tracking a vehicle based on computer vision is a great helpful in providing important information such as identifying road traffic conditions and crime situations. However, vehicle detection and tracking using a camera is affected by environmental factors in which the camera is installed. In this paper, we thus propose a deep learning based on vehicle classification and tracking scheme to classify and track vehicles in a complex and diverse environment. Using YOLO model as deep learning model, it is possible to quickly and accurately perform robust vehicle tracking in various environments, compared to the traditional method.",JWE,2022,,21,4,,1283-1294,2,5,https://ieeexplore.ieee.org/document/10246911/
Contactless Elevator Button Control System Based on Weighted K-NN Algorithm for AI Edge Computing Environment,Sang-Yub Lee | In-Pyo Cho | Chung-Pyo Hong,"Korea Electronic Technology Institute, Republic of Korea | Korea Electronic Technology Institute, Republic of Korea | Division of Computer Engineering, Hoseo University, Republic of Korea",Machine learning | magnetic sensor | weighted K-NN | K-NN | RBF | contactless | elevator control | low-power | edge computing,"In recent years, attempts have been made to create a door-opening or elevator button that operates based on gestures when entering and exiting a building. This can consider the convenience of an individual carrying luggage, and in some cases, has the advantage of preventing the spread of disease between people through contact. In this study, we propose a method for operating elevator buttons without contact. Elevators cannot utilize high-performance processors owing to production costs. Therefore, this paper introduces a prototype of a low-performance processor-based system that can be used in elevators, and then introduces a weighted K-nearest neighbors (K-NN) based user gesture learning and number matching method for application in an optimal non-contact button control method that can be used in such an environment. As a result, through the proposed method, a performance gain of 7.5% in comparison to a conventional K-NN method and a performance improvement of 9.7% compared to a radial basis function were achieved in a relatively low-performance processor-based system.",JWE,2022,,21,2,,443-458,2,4,https://ieeexplore.ieee.org/document/10247337/
Video Streaming Based on Blockchain State Channel with IoT Camera,Min-Hyuk Jeong | Sang-Kyun Kim,"Myongji University, Republic of Korea | Myongji University, Republic of Korea",Video streaming | Internet of Things | blockchain | smart contract | distributed applications,"This paper proposes a system that provides video streaming services from the Internet of Media Things using blockchain and cryptocurrency (token). The user pays the token by the contract terms of the smart contract written on the blockchain through the distributed application (DApp). The IP camera, which is paid the token, streams the taken video to the user in real-time. To investigate the possibility of a blockchain camera streaming service, we upload a smart contract for streaming service on Etherium-based blockchain, and ERC20 tokens necessary for the transaction are created and implemented. To overcome the slow trading speed and the disability of proper refunding, the off-chain transaction, one of the blockchain scaling techniques, was applied and implemented in the system.",JWE,2022,,21,3,,661-675,2,7,https://ieeexplore.ieee.org/document/10243626/
"A Selective Encryption/Decryption Method of Sensitive Music Usage History Information on Theme, Background and Signal Music Blockchain Network",Youngmo Kim | Byeongchan Park | Seok-Yoon Kim,"Dept. of Computer Science and Engineering, Soongsil University, Korea, Republic of | Dept. of Computer Science and Engineering, Soongsil University, Korea, Republic of | Dept. of Computer Science and Engineering, Soongsil University, Korea, Republic of",Theme/background/signal music | monitoring | blockchain | encryption/decryption | music usage history,"The theme, background, and signal music usage history information consists of general information such as music information, platform information, and music usage information, and sensitive information such as rights management information, music usage permission range, and contract information. If sensitive information among these is disclosed, disputes such as trade secrets and infringement of personal information protection between companies or between companies and individuals may arise. We propose a selective encryption/decryption method to secure the confidentiality, integrity, reliability and non-repudiation of sensitive music usage history information used in the theme, background, and signal music blockchain environment. In the proposed method, a monitoring company encrypts sensitive information using a secret key for usage history information, which is combined with general information, and digitally signs it using a private key to register it in a block. A trust group can view and access the information at the time of inquiry by verifying the digital signature with the public key of the monitoring company and then can decrypt the sensitive information using the private key.",JWE,2022,,21,4,,1265-1282,2,8,https://ieeexplore.ieee.org/document/10246906/
Paradigm Shift in Adaptive Cyber Defense for Securing the Web Data: The Future Ahead,Shishir Kumar Shandilya,"School of Data Science & Forecasting, Devi Ahilya University, Indore, MP, India",Web data security | security risks | nature-inspired cyber security | cyber threat analysis,"Web Applications are becoming more sophisticated to cater the ever-growing demand of data processing and computing. Fast technological advancements in web engineering not only facilitate data intensive and high-performance computing, but also raise serious concerns on security. Cyber threats are also ramping up at the equal pace and attackers are now more organised and equipped with high-end servers. The Data over Web needs to be more authenticated and reliable. Data Provenance-aware methods are capable of identification of data breaches and manipulation through various attacks. They analyse underlying data for the potential threats to ensure protection against various attacks. Cyber Security Practitioners are witnessing severe issues in securing the Web Data and applications as the security risks are growing rapidly due to the sudden eruption in internet usage due to the pandemic in the last few years. People and organisations are relying more on Internet and web applications than ever before. The efforts for securing the web data on such a massive scale is premature to counter the ever-evolving attack attempts. Nature-inspired Cyber Security (NICS) facilitates the development and implementation of robust defensive mechanisms which are more adaptive and highly tolerant to online malicious programs. These methods are also capable of dealing with the common algorithmic issues like incompleteness and uncertainty of information and to provide a high-level security mechanism by effectively implementing the bio-inspired methodologies like deception, and camouflage etc. This article will attempt to explore the effectiveness of NICS in web data and application security to provide smart security methods.",JWE,2022,,21,4,,1371-1376,2,3,https://ieeexplore.ieee.org/document/10246914/
Enhancement of 3D Point Cloud Contents Using 2D Image Super Resolution Network,Seonghwan Park | 06sik Kim | Yonghae Hwang | Doug Young Suh | Kyuheon Kim,"Kyung Hee University, Korea | Kyung Hee University, Korea | Kyung Hee University, Korea | Kyung Hee University, Korea | Kyung Hee University, Korea",Point cloud | super resolution | deep learning network | 3D data,"Media technology has been developed to give users a sense of immersion. Recent media using 3D spatial data, such as augmented reality and virtual reality, has attracted attention. A point cloud is a data format that consists of a number of points, and thus can express 3D media using coordinates and color information for each point. Since a point cloud has a larger capacity than 2D images, a technology to compress the point cloud is required, i.e., standardized in the international standard organization MPEG as a video-based point cloud compression (V-PCC). V-PCC decomposes 3D point cloud data into 2D patches along orthogonal directions, and those patches are placed into a 2D image sequence, and then compressed using existing 2D video codecs. However, data loss may occur while converting a 3D point cloud into a 2D image sequence and encoding this sequence using a legacy video codec. This data loss can cause deterioration in the quality of a reconstructed point cloud. This paper proposed a method of enhancing a reconstructed point cloud by applying a super resolution network to the 2D patch image sequence of a 3D point cloud.",JWE,2022,,21,2,,425-442,2,2,https://ieeexplore.ieee.org/document/10247334/
Competitive Capsule Network Based Sentiment Analysis on Twitter COVID'19 Vaccines,V. Diviya Prabha | R. Rathipriya,"Department of Computer Science, Periyar University, Salem, Tamil Nadu, India | Department of Computer Science, Periyar University, Salem, Tamil Nadu, India",Twitter | sentiment analysis | deep learning | capsule network | COVID-19 | machine language,"COVID-19 is an extremely contagious virus that has rapidly spread around the world. This disease has infected people of all ages in India, from children to the elderly. Vaccination, on the other hand, is the only way to preserve human lives. In the midst of a pandemic, it's critical to know what people think of COVID-19 immunizations. The primary goal of this article is to examine corona vaccination tweets from India's Twitter social media. This study introduces CompCapNets, a unique deep learning approach for Twitter sentiment classification. The results suggest that the proposed method outperforms other strategies when compared to existing traditional methods.",JWE,2022,,21,5,,1583-1601,2,6,https://ieeexplore.ieee.org/document/10246928/
An Efficient Scheme to Obtain Background Image in Video for YOLO-Based Static Object Recognition,Hyeong-Jin Kim | Min-Cheol Shin | Man-Wook Han | Chung-pyo Hong | Ho-Woong Lee,"Division of Computer Engineering, Hoseo University, Republic of Korea | Division of Computer Engineering, Hoseo University, Republic of Korea | Division of Computer Engineering, Hoseo University, Republic of Korea | Division of Computer Engineering, Hoseo University, Republic of Korea | Division of Computer Engineering, Hoseo University, Republic of Korea",Background obtainment | histogram | object detection | YOLO,"Detecting backgrounds in videos is an important technology that can be used for many applications such as management of major facilities and military surveillance depending on the purpose. It is difficult to accurately find and identify important objects in the background if there are obstacles such as pedestrian or car in the video. In order to overcome this problem, the following method is used to detect the background. First, a pixel area histogram is generated to determine the amount of change in pixel units of an image over time. Based on the histogram, we propose an algorithm that estimates the background by selecting the case with the smallest rate of change. In addition, in order to strongly respond to changes in the surrounding environment, even when a change in brightness occurs, this is solved through frame overlap. Finally, the desired object is identified by applying YOLO v3 as a model for object detection in the obtained background. Through the above process, this study proposes a method for effectively identifying static objects in the background by precisely estimated background of the video. Experimental results show that the non-detection and false detection rate for the background object is enhanced by 60.2% and 11.2%, respectively, in comparison with when the proposed method was not applied.",JWE,2022,,21,5,,1691-1706,2,4,https://ieeexplore.ieee.org/document/10246931/
Scalable and Dynamic Big Data Processing and Service Provision in Edge Cloud Environments,In-Young Ko | Abhishek Srivastava | Michael Mrissa,"Korea Advanced Institute of Science and Technology, South Korea | Indian Institute of Technology, Indore, India | InnoRenew CoE, University of Primorska, Slovenia",,"Owing to the exponential growth of connected devices and the large amounts of data produced by such devices, clouds are becoming a bottleneck and cause latency while collecting and processing data and providing associated services [1]. The concept of edge computing has been suggested to solve this scalability problem by moving data centers and computing resources close to the data sources [2]. Locally deployed data centers and computing resources form an edge cloud or a fog that can collect and process big data in a distributed and scalable manner [3]. Recently, low-latency and reliable communication technologies such as 5G have enabled more effective realization of edge cloud environments [4].",JWE,2022,,21,1,,v-x,2,0,https://ieeexplore.ieee.org/document/10246010/
Simulation of Web Page Big Data Capture Method Based on WNN Optimized by Locust Algorithm,Zhao-yin Jiang,"School of Information Engineering, Yangzhou Polytechnic College, China",Wavelet neural network | locust optimization algorithm | web page big data capture,"In order to improve web page big data capturing ratio, the wavelet neural network (WNN) optimized by improved locust algorithm is established for capturing web page big data. First, the web page big data method is established, and the corresponding mathematical model is studied. Secondly, the neural network is established, and Legendre wavelet basis function is used as excitation function of hidden layer of WNN, and the theory models of input layer, output layer and hidden layer are constructed, and then the improved locust optimization algorithm is designed based on Levy flight local search strategy, linear decreasing parameter random jump strategy, decreasing coefficient update strategy and weight coefficient update strategy. Finally, a case study is carried out for validating the proposed web big data capturing method, results illustrate that the proposed method based on WNN optimized by improved locust algorithm can effectively improve web page big data capturing efficiency and accuracy, which has wide application view.",JWE,2022,,21,7,,2033-2048,2,0,https://ieeexplore.ieee.org/document/10246955/
Performance of Digital Drone Signage System Based on DUET,Isaac Sim | Young Ghyu Sun | Soo Hyun Kim | SangWoon Lee | Cheong Ghil Kim | Jin Young Kim,"Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea | Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea | Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea | Department of Multimedia, Namseoul University, Cheonan, Seoul, Korea | Department of Computer Science, Namseoul University, Cheonan, Seoul, Korea | Department of Electronic Convergence Engineering, Kwangwoon University, Seoul, Korea",Degenerate unmixing estimation technique (DUET) | digital signage | DUET-based separation scheme (DBSS) | drones,"In this letter, we study a scenario based on degenerate unmixing estimation technique (DUET) that separates original signals from mixture of FHSS signals with two antennas. We have shown that the assumptions for separating mixed signals in DUET can be applied to drone based digital signage recognition signals and proposed the DUET-based separation scheme (DBSS) to classify the mixed recognition drone signals by extracting the delay and attenuation components of the mixture signal through the likelihood function and the short-term Fourier transform (STFT). In addition, we propose an iterative algorithm for signal separation with the conventional DUET scheme. Numerical results showed that the proposed algorithm is more separation-efficient compared to baseline schemes. DBSS can separate all signals within about 0.56 seconds when there are fewer than nine signage signals.",JWE,2022,,21,2,,391-404,2,0,https://ieeexplore.ieee.org/document/10247336/
Effective Algorithm to Control Depth Level for Performance Improvement of Sound Tracing,Eunjae Kim | Juwon Yun | Woonam Chung | Jae-Ho Nah | Youngsik Kim | Cheoung Ghil Kim | Woo-Chan Park,"Sejong University, Seoul, South Korea | Sejong University, Seoul, South Korea | Sejong University, Seoul, South Korea | Sangmyung University, Seoul, South Korea | Korea Polytechnic University, South Korea | Namseoul University, Korea | Sejong University, Seoul, South Korea",Sound tracing | sound rendering | sound propagation | ray tracing | virtual reality,"Sound tracing, a 3D sound rendering technology based on ray tracing, is a very costly method for calculating sound propagation. To reduce its expense, we propose an algorithm for adjusting the depth based on frame coherence and spatial characteristics. The results of the experiment indicate that when the sound source and listener were indoors, the reflection path loss rate was 3%, the diffraction path loss rate was 15.4%, and the total frame rate increased by 6.25%. When the listener was outdoors and the sound source was indoors, the reflection path and diffraction path loss rate were 0%, and the total frame rate was increased by 33.33 compared to the conventional method. Thus, the proposed algorithm can improve rendering performance while minimizing path loss rate.",JWE,2022,,21,3,,713-728,2,0,https://ieeexplore.ieee.org/document/10243625/
An Efficient and Secure Authentication for Ambient Assisted Living System,Myung-Kyu Yi | Taeg-Keun Whangbo,"College of IT Convergence, Gachon University, South Korea | College of IT Convergence, Gachon University, South Korea",Web security and privacy | wearable computing | ambient assisted living | healthcare,"Although the birthrate is declining, the average life expectancy continues to increase. Therefore, it is more important for elderly people to maintain their independence while staying at home. Ambient Assisted Living (AAL) includes the use of devices and methods of ensuring that elderly people can stay safe and age at home rather than at a facility. Assisted living services help people live as independently and safely as possible when they can no longer perform everyday activities on their own. Because the information transmitted in AAL systems is personal, the security and privacy of such data are becoming important issues that must be addressed. Herein, we propose an efficient and secure authentication scheme for an AAL system. Our proposed authentication scheme not only satisfies several important security requirements of such a system but also withstands various types of attacks. Moreover, the proposed authentication scheme achieves lightweight performance by manipulating basic cryptographic operations including bitwise-eXclusive-OR (XOR) and hash functions. We simulated our proposed authentication scheme using Automated Validation of Internet Security Protocols and Applications (AVISPA), which is a prominent security verification tool. Security and performance analysis show that our proposed scheme is not only robust against several attacks and has a lower computational cost in terms of execution time than those of existing authentication schemes.",JWE,2022,,21,3,,693-711,2,0,https://ieeexplore.ieee.org/document/10247205/
A Study on Traffic Prediction for the Backbone of Korea's Research and Science Network Using Machine Learning,Chanjin Park | Wonhyuk Lee | Moon-Hyun Kim | Ung-Mo Kim | Taehong Kim | Seunghae Kim,"Korea Research Environment Network Center, Korea Institute of Science and Technology Information, Daejeon, Korea | Korea Research Environment Network Center, Korea Institute of Science and Technology Information, Daejeon, Korea | College of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea | College of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea | Dept of Korean Medical Data, Korea Institute of Oriental Medicine, Daejeon, Korea | Korea Research Environment Network Center, Korea Institute of Science and Technology Information, Daejeon, Korea",Traffic prediction | machine learning | SVR | LSTM | GRU | KREONET,"To fix network congestion resulting from the increase in high volume traffic in data-intensive science and the increase in internet traffic due to COVID-19, there has been a necessity of traffic engineering through traffic prediction. For this, there have been various attempts from a statistical method such as ARIMA to machine learning including LSTM and GRU. This study aimed to collect and learn KREOENT backbone and subscribers' traffic volume through diverse machine learning techniques (e.g., SVR, LSTM, GRU, etc.) and predict maximum traffic on the following day.",JWE,2022,,21,5,,1419-1433,2,2,https://ieeexplore.ieee.org/document/10246938/
Inverse-Directed Propagation-Based Hexagonal Hogel Sampling for Holographic Stereogram Printing System,Anar Khuderchuluun | Munkh-Uchral Erdenebat | Erkhembaatar Dashdavaa | Ki-Chul Kwon | Jong-Rae Jeong | Nam Kim,"School of Information and Communication Engineering, Chungbuk National University, Cheongju, Chungbuk, South Korea | School of Information and Communication Engineering, Chungbuk National University, Cheongju, Chungbuk, South Korea | School of Information and Communication Engineering, Chungbuk National University, Cheongju, Chungbuk, South Korea | School of Information and Communication Engineering, Chungbuk National University, Cheongju, Chungbuk, South Korea | Department of Information and Communication, Suwon Science College, Hwaseong, Gyeonggi, South Korea | School of Information and Communication Engineering, Chungbuk National University, Cheongju, Chungbuk, South Korea",Holographic printer | holographic stereogram | computer-generated integral imaging | computer-generated hologram (CGH),"Holographic stereogram (HS) printing is a promising holographic technique for three-dimensional (3D) visualization of an object with accurate depth cues. In this paper, unlike the conventional rectangular hogel based HS, efficient hexagonal hogels sampling for HS printing that enhances the volumetric visualization of reconstruction while providing rapidly generated data using inverse-directed propagation (IDP) is proposed. Specifically, an array of hexagonal hogels is sampled by a computer-generated integral imaging technique using an IDP, which acquires the full information of the 3D object prior to higher volumetric 3D reconstruction. To demonstrate the proposed approach, IDP-based hexagonal hogel sampling for HS printing is implemented, and the enhanced image quality of printed holograms is verified both by numerical simulation and in an optical experiment.",JWE,2022,,21,4,,1225-1238,2,4,https://ieeexplore.ieee.org/document/10246915/
SecureOnt: A Security Ontology for Establishing Data Provenance in Semantic Web,Archana Patel | Narayan C. Debnath | Prashant Kumar Shukla,"Department of Software Engineering, School of Computing and Information Technology, Eastern International University, Vietnam | Department of Software Engineering, School of Computing and Information Technology, Eastern International University, Vietnam | Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India",Security ontology | data provenance | ontology evaluation tools | semantic web | ontology richness | anomalies | pitfall rate,"Security becomes a primary concern during sharing of information over the web. To overcome this problem, many security ontologies have been developed so far. The available security ontologies help to track data provenance and contain different aspects of data security like confidentiality, integrity, data availability, and access control. This paper provides a security ontology for establishing data provenance in the semantic web. The proposed ontology contains a comprehensive knowledge base of data security by consolidating all the available security ontologies and derives data provenance with annotations at the extensional level and thus lower maintenance cost. By this paper, analysts and researchers find a road map, an overview of what exists in terms of security ontologies.",JWE,2022,,21,4,,1347-1370,2,48,https://ieeexplore.ieee.org/document/10246913/
XGBoost Regression Classifier (XRC) Model for Cyber Attack Detection and Classification Using Inception V4,K. M. Karthick Raghunath | V. Vinoth Kumar | Muthukumaran Venkatesan | Krishna Kant Singh | T. R. Mahesh | Akansha Singh,"Department of Computer Science & Engineering, MVJ College of Engineering, Bangalore, India | Department of Computer Science and Engineering, Jain (Deemed to be University), Bangalore, India | Department of Mathematics, School of Applied sciences, REVA University, Bangalore, India | Department of Computer Science and Engineering, Jain (Deemed to be University), Bangalore, India | Department of Computer Science and Engineering, Jain (Deemed to be University), Bangalore, India | School of Computer Science Engineering and Technology, Bennett University, India",Cybersecurity | XGBoost regression classifier (XRC) | inception V4 | hybridized classifier | error rate,"Massive reliance on practical systems has resulted in several security concerns. The ability to identify anomalies is a critical safety feature enabled by anomaly diagnostic techniques. The construction of a data system faces a significant issue in cyber security. Because of the exploitation of valuable data, cybersecurity impacts the privacy of such data. Attack incidents must be examined using an appropriate analytics approach in elevating the safety level. Design of advanced analytical, conceptual model creation gives practical guidance and prioritizes threats/attacks across the network system. There is now substantial effectiveness in attack categorization, and evaluation through Convolution Neural Network (CNN) based classifiers. In light of the drawbacks of previous approaches, this research proposes an approach relying on the Deep Learning (DL) strategies for cyberattacks detection and categorization in the context of cyberspace incidents. Likewise, this article presents an XGBoost Regression Classifier (XRC) using Inception V4 to address those restrictions. XGBoost refers to Extreme Gradient Boosting, a decentralized gradient-boosted decision tree (GBDT) supervised learning framework that is robust and can be used in a decentralized context. XGBoost is a well-known machine learning technique because of its ability to produce outstanding accuracy. The concepts of both XGBoost and Regression classifiers are integrated and represented as a suggested hybridized classifier, which is implemented in Inception V4 to further train and test the model. The proposed XRC categorizes and forecasts several common types of network cyberattacks that includes Distributed Denial of Service (DDoS), Phishing, Cross-site Scripting (CS), Internet of Things (IoT). The sigmoidal function is used as a supportive activator to the hybridized classifier to lower the erroneous ratio and increase the effectiveness. Research shows that training and testing errors were substantially decreased when using XRC. In 9 out of 13 instances, over 97% of threats are detected by the XRC, and over 75% of threats are detected in its most challenging datasets.",JWE,2022,,21,4,,1295-1322,2,39,https://ieeexplore.ieee.org/document/10246907/
Vulnerability Assessment for Applications Security Through Penetration Simulation and Testing,Petar Lachkov | Lo'ai Tawalbeh | Smriti Bhatt,"Department of Computing and Cyber Security, Director of the Cyber Engineering Technology/Cyber Security Research Center, Texas A&M University-San Antonio, One University Way, San Antonio, TX, USA | Department of Computing and Cyber Security, Director of the Cyber Engineering Technology/Cyber Security Research Center, Texas A&M University-San Antonio, One University Way, San Antonio, TX, USA | Department of Computing and Cyber Security, Director of the Cyber Engineering Technology/Cyber Security Research Center, Texas A&M University-San Antonio, One University Way, San Antonio, TX, USA",Penetration testing | ethical hacking | applications security | firewall | IDS/IPS | server | client | privacy | vulnerability assessment,"Cybersecurity threats and attacks are a critical concern for computing systems as general and specifically in web applications. There are many types and categories of cyberattacks on web applications. Many of these attacks are made possible due to existing vulnerabilities in the networking environments and platforms that host these web applications. So, the vulnerability assessment and attacks simulations on these networking platforms are of extreme importance to protect and secure the top web applications that play a prime role in our daily life. One of the widely used mechanisms to identify vulnerabilities and defend against different attacks on systems and networks is Penetration Testing. It allows us to simulate real-world attacks on a network or a single device to determine the susceptibility and impact of cybersecurity attacks. Pen testing aims to secure a system or network by performing a full-blown attack against it. Several techniques have been used for that, from port scanning, service, and operating system detection to network enumeration, creating specially crafted packets, and modifying software to exploit vulnerabilities. However, while it is used widely as a defensive technique, some attackers also employ it for malicious intentions utilizing available open-source penetration testing tools. Penetration testing on internal networks such as networks that connect IoT/sensors/web cameras, can be utilized to find vulnerabilities and fix them to secure the networks. In this research, we present a detailed discussion on penetration testing and its seven phases of action and provide a step-by-step procedure with instructions using various open-source tools to conduct penetration testing and vulnerability assessments of a network. We finally demonstrate the process and results of simulated attacks on our network within the testing environment. This research provides a comprehensive introduction to penetration testing and testbed through real-world attack simulation. The IT administrator or security enthusiast can utilize them to secure networks, devices, clients, servers, and applications while enhancing the overall organization's security.",JWE,2022,,21,7,,2187-2208,2,18,https://ieeexplore.ieee.org/document/10251051/
Using Federated Learning to Achieve Proactive Context-Aware IoT Environments,Rubén Rentero-Trejo | Daniel Flores-Martín | Jaime Galán-Jiménez | José García-Alonso | Juan Manuel Murillo | Javier Berrocal,"University of Extremadura, Spain | University of Extremadura, Spain | University of Extremadura, Spain | University of Extremadura, Spain | University of Extremadura, Spain | University of Extremadura, Spain",Federated learning | mobile devices | context-aware | IoT,"The Internet of Things (IoT) is more present in our daily lives than ever before, turning everyday physical objects into smart devices. However, these devices often need excessive human interaction before reaching their best performance, making them time-consuming and reducing their usability. Nowadays, Artificial Intelligence (AI) techniques are being used to process data and to find ways to automate different behaviours. However, achieving learning models capable of handling any situation is a challenging task, worsened by time training restrictions. This paper proposes a Federated Learning solution to manage different IoT environments and provide accurate predictions, based on the user's preferences. To improve the coexistence between devices and users, this approach makes use of other users' previous behaviours in similar environments, and proposes predictions for newcomers to the federation. Also, for existing participants, it provides a closer personalization, immediate availability and prevents most manual interactions. The approach has been tested with synthetic and real data and identifies the actions to be performed with 94% accuracy on regular users.",JWE,2022,,21,1,,53-74,2,21,https://ieeexplore.ieee.org/document/10246009/
A Comparative Analysis of Sentence Embedding Techniques for Document Ranking,Vishal Gupta | Ashutosh Dixit | Shilpa Sethi,"J.C. Bose University of Science & Technology, YMCA, Faridabad, Haryana, India | J.C. Bose University of Science & Technology, YMCA, Faridabad, Haryana, India | J.C. Bose University of Science & Technology, YMCA, Faridabad, Haryana, India",BERT | cosine similarity | document ranking | information retrieval | sentence embedding,"Due to the exponential increase in the information on the web, extracting relevant documents for users in a reasonable time becomes a cumbersome task. Also, when user feedback is scarce or unavailable, content-based approaches to extract and rank relevant documents are critical as they suffer from the problem of determining semantic similarity between texts of user queries and documents. Various sentence embedding models exist today that acquire deep semantic representations through training on a large corpus, with the goal of providing transfer learning to a broad range of natural language processing tasks such as document similarity, text summarization, text classification, sentiment analysis, etc. So, in this paper, a comparative analysis of six pretrained sentence embedding techniques has been done to identify the best model suited for document ranking in IR systems. These are SentenceBERT, Universal Sentence Encoder, InferSent, ELMo, XLNet, and Doc2Vec. Four standard datasets CACM, CISI, ADI, and Medline are used to perform all the experiments. It is found that Universal Sentence Encoder and SentenceBERT outperform other techniques on all four datasets in terms of MAP, recall, F-measure, and NDCG. This comparative analysis offers a synthesis of existing work as a single point of entry for practitioners who seek to use pretrained sentence embedding models for document ranking and for scholars who wish to undertake work in a similar domain. The work can be expanded in many directions in the future as various researchers can combine these strategies to build a hybrid document ranking system or query reformulation system in IR.",JWE,2022,,21,7,,2149-2185,2,11,https://ieeexplore.ieee.org/document/10246952/
A Large-Scale Empirical Assessment of Web API Size Evolution,Fabio Di Lauro | Souhaila Serbout | Cesare Pautasso,"Software Institute (USI), Lugano, Switzerland | Software Institute (USI), Lugano, Switzerland | Software Institute (USI), Lugano, Switzerland",Web API | API evolution | software evolution | OpenAPI,"Like any other type of software, also Web Application Programming Interfaces (APIs) evolve over time. In the case of widely used API, introducing changes is never a trivial task, because of the risk of breaking thousands of clients relying on the API. In this paper we conduct an empirical study over a large collection of OpenAPI descriptions obtained by mining open source repositories. We measure the speed at which Web APIs change and how changes affect their size, simply defined as the number of operations. The dataset of API descriptions was collected over a period of one year and includes APIs with histories spanning across up to 7 years of commits. The main finding is that APIs tend to grow, although some do reduce their size, as shown in the case study examples included in the appendix.",JWE,2022,,21,6,,1937-1979,2,12,https://ieeexplore.ieee.org/document/10246943/
Efficient Pre-Processing Techniques for Improving Classifiers Performance,S. Nickolas | K. Shobha,"Department of Computer Applications, National Institute of Technology, Tiruchirappalli, Tamilnadu, India | Department of Computer Applications, High Performance Computing Lab, National Institute of Technology, Tiruchirappalli, Tamilnadu, India",Data Mining | data pre-processing | decision trees | expectation maximization (EM) algorithms | neural networks,"Data pre-processing plays a vital role in the life cycle of data mining for accomplishing quality outcomes. In this paper, it is experimentally shown the importance of data pre-processing to achieve highly accurate classifier outcomes by imputing missing values using a novel imputation method, CLUSTPRO, by selecting highly correlated features using Correlation-based Variable Selection (CVS) and by handling imbalanced data using Synthetic Minority Over-sampling Technique (SMOTE). The proposed CLUSTPRO method makes use of Random Forest (RF) and Expectation Maximization (EM) algorithms to impute missing. The imputed results are evaluated using standard evaluation metrics. The CLUSTPRO imputation method outperforms existing, state-of-the-art imputation methods. The combined approach of imputation, feature selection, and imbalanced data handling techniques has significantly contributed to attaining an improved classification accuracy (AUC curve) of 40%-50% in comparison with results obtained without any pre-processing.",JWE,2022,,21,2,,203-228,2,7,https://ieeexplore.ieee.org/document/10247340/
"Recommendation System Issues, Approaches and Challenges Based on User Reviews",Khalid Benabbes | Khalid Housni | Ali El Mezouary | Ahmed Zellou,"MISC Laboratory, Faculty of Sciences, Ibn Tofail University, Kénitra, Morocco | MISC Laboratory, Faculty of Sciences, Ibn Tofail University, Kénitra, Morocco | IRF-SIC Laboratory, EST, Ibn Zohr University, Agadir, Morocco | SPM Research Team, ENSIAS, Mohammed V University, Rabat, Morocco",Recommender system | collaborative filtering | content filtering | user reviews,"With the ever-increasing volume of online information, recommender systems have been effective as a strategy to overcome information overload. They have a wide range of applications in many fields, including e-learning, e-commerce, e-government and scientific research. Recommender systems are search engines that are based on the user's browsing history to suggest a product that expresses their interests. Being usually in the form of textual comments and ratings, such reviews are a valuable source of information about users' perceptions. Recommender systems (RSs) apply various approaches to predict users' interest on information, products and services among a huge amount of available items. In this paper, we will describe the recommender system, discuss ongoing research in this field, and address the challenges, limitations and the techniques adopted. This paper also discusses how review texts are interpreted to solve some of the major problems with traditional recommendation techniques. To assess the value of a recommender system, qualitative evaluation measures are discussed as well in this research. Based on a series of selected articles published between 2008 and 2020, the study allowed us to conclude that the efficiency of RSs is strongly centered on the control of information context, the operated exploration algorithm, the method, and the type of processed data in addition to the information on users' trust.",JWE,2022,,21,4,,1017-1054,2,12,https://ieeexplore.ieee.org/document/10246926/
Convolutional Neural Networks Using Log Mel-Spectrogram Separation for Audio Event Classification with Unknown Devices,Soonshin Seo | Changmin Kim | Ji-Hwan Kim,"Dept. of Computer Science and Engineering, Sogang University, Seoul, Republic of Korea | LG Electronics, Seoul, Republic of Korea | Dept. of Computer Science and Engineering, Sogang University, Seoul, Republic of Korea",Audio event classification | unknown device | log melspectrogram | log mel-spectrogram separation | convolutional neural networks,"Audio event classification refers to the detection and classification of non-verbal signals, such as dog and horn sounds included in audio data, by a computer. Recently, deep neural network technology has been applied to audio event classification, exhibiting higher performance when compared to existing models. Among them, a convolutional neural network (CNN)-based training method that receives audio in the form of a spectrogram, which is a two-dimensional image, has been widely used. However, audio event classification has poor performance on test data when it is recorded by a device (unknown device) different from that used to record training data (known device). This is because the frequency range emphasized is different for each device used during recording, and the shapes of the resulting spectrograms generated by known devices and those generated by unknown devices differ. In this study, to improve the performance of the event classification system, a CNN based on the log mel-spectrogram separation technique was applied to the event classification system, and the performance of unknown devices was evaluated. The system can classify 16 types of audio signals. It receives audio data at 0.4-s length, and measures the accuracy of test data generated from unknown devices with a model trained via training data generated from known devices. The experiment showed that the performance compared to the baseline exhibited a relative improvement of up to 37.33%, from 63.63% to 73.33% based on Google Pixel, and from 47.42% to 65.12% based on the LG V50.",JWE,2022,,21,2,,497-522,2,20,https://ieeexplore.ieee.org/document/10251060/
Differential and Access Policy Based Privacy-Preserving Model in Cloud Environment,Rishabh Gupta | Ashutosh Kumar Singh,"Department of Computer Applications, National Institute of Technology, Kurukshetra, Haryana, India | Department of Computer Applications, National Institute of Technology, Kurukshetra, Haryana, India",Cloud computing | differential privacy | machine learning | privacy-preserving | access control,"Cloud computing has multiple benefits in terms of minimum cost, maximum efficiency, and high scalability, which prompts shifting a large amount of data from the local machine to the cloud environment for storage, computation, and data sharing among various parties stakeholders. However, owners do not fully trust the cloud platform operated by a third party. Therefore, security and privacy emerge as critical issues while sharing data among different parties. In this paper, a novel privacy-preserving model is proposed by utilizing encryption, differential privacy, and machine learning approaches. It facilitates data owners to share their data securely in the cloud environment. The model defines access policy and communication protocol among the involved untrusted parties for data processing and privacy preservation. The proposed model is evaluated by executing experiments using distinct datasets. The achieved results reveal that the proposed model provides high accuracy, precision, recall, and f1-score up to 98%, 98%, 97%, and 97%, respectively, over the state of the art methods.",JWE,2022,,21,3,,609-632,2,23,https://ieeexplore.ieee.org/document/10247204/
GAIN-QoS: A Novel QoS Prediction Model for Edge Computing,Jiwon Choi | Jaewook Lee | Duksan Ryu | Suntae Kim | Jongmoon Baik,"Department of Software Engineering, Jeonbuk National University, Korea | Department of Software Engineering, Jeonbuk National University, Korea | Department of Software Engineering, Jeonbuk National University, Korea | Department of Software Engineering, Jeonbuk National University, Korea | School of Computing, Korea Advanced Institute of Science and Technology, Korea",Edge computing | Service recommendation | QoS prediction | Cold-start problem,"With recent increases in the number of network-connected devices, the number of edge computing services that provide similar functions has increased. Therefore, it is important to recommend an optimal edge computing service, based on quality-of-service (QoS). However, in the real world, there is a cold-start problem in QoS data: highly sparse invocation. Therefore, it is difficult to recommend a suitable service to the user. Deep learning techniques were applied to address this problem, or context information was used to extract deep features between users and services. However, edge computing environment has not been considered in previous studies. Our goal is to predict the QoS values in real edge computing environments with improved accuracy. To this end, we propose a GAIN-QoS technique. It clusters services based on their location information, calculates the distance between services and users in each cluster, and brings the QoS values of users within a certain distance. We apply a Generative Adversarial Imputation Nets (GAIN) model and perform QoS prediction based on this reconstructed user service invocation matrix. When the density is low, GAIN-QoS shows superior performance to other techniques. In addition, the distance between the service and user slightly affects performance. Thus, compared to other methods, the proposed method can significantly improve the accuracy of QoS prediction for edge computing, which suffers from cold-start problem.",JWE,2022,,21,1,,27-52,2,6,https://ieeexplore.ieee.org/document/10246008/
Modern Web Frameworks: A Comparison of Rendering Performance,Risto Ollila | Niko Mäkitalo | Tommi Mikkonen,"Intruder Systems Ltd, London, UK | Department of Computer Science, University of Helsinki, Helsinki, Finland | Department of Computer Science, University of Helsinki, Helsinki, Finland",Web framework performance | declarative rendering | virtual DOM | frontend frameworks | single-page application frameworks | angular | react | vue | svelte | blazor,"Recent years have seen the rise of a new generation of UI frameworks for web application development. These frameworks differ from previous generations of JavaScript frameworks in that they define a declarative application development model, where transitions in the state of the UI are managed by the framework. This potentially greatly simplifies application development, but requires the framework to implement a rendering strategy which translates changes in application state into changes in the state of the UI. The performance characteristics of these rendering strategies have thus far been poorly studied. In this article, we describe the rendering strategies used in the frameworks Angular, React, Vue, Svelte and Blazor, which represent some of the most influential and widely used modern web frameworks. We find significant differences in the scaling of costs in their rendering strategies with potentially equally significant practical performance implications. To verify these differences, we implement a number of benchmarks that measure the scaling of rendering costs as an application grows in complexity. The results of our benchmarks confirm that under certain circumstances, performance differences between frameworks can range up to several orders of magnitude when performing the same tasks. Furthermore, we find that the relative performance of a rendering strategy can be effectively estimated based on factors affecting the input sizes of render loops. The best performing rendering strategies are found to be ones which minimize input sizes using techniques such as compile-time optimization and reactive programming models.",JWE,2022,,21,3,,789-813,2,34,https://ieeexplore.ieee.org/document/10243623/
Design and Validation of Quantum Key Management System for Construction of KREONET Quantum Cryptography Communication,Kyu-Seok Shim | Yong-hwan Kim | Ilkwon Sohn | Eunjoo Lee | Kwang-il Bae | Wonhyuk Lee,"Div. of Science and Technology Digital Convergence, Advanced Quantum KREONET Team, KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | Div. of Science and Technology Digital Convergence, Advanced Quantum KREONET Team, KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | Div. of Science and Technology Digital Convergence, Advanced Quantum KREONET Team, KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | Div. of Science and Technology Digital Convergence, Advanced Quantum KREONET Team, KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | Div. of Science and Technology Digital Convergence, Advanced Quantum KREONET Team, KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea | Div. of Science and Technology Digital Convergence, Advanced Quantum KREONET Team, KREONET Center, Korea Institute of Science and Technology Information, Daejon, Korea",Quantum cryptography communication | key management system | KREONET | post quantum cryptography | IPsec,"As it has been recently proven that the public key-based RSA algorithms that are currently used in encryption can be unlocked by Shor's algorithm of quantum computers in a short time, conventional security systems are facing new threats, and accordingly, studies have been actively conducted on new security systems. They are classified into two typical methods: Post Quantum Cryptography (PQC) and Quantum Key Distribution (QKD). PQC aims to design conventional cryptography systems in a more robust way so that they will not be decrypted by a quantum computer in a short time whereas QKD aims to make data tapping and interception physically impossible by using quantum mechanical characteristics. In this paper, we design a quantum key management system, which is most crucial for constructing a QKD network and analyze the design requirements to apply them to Korea Research Environment Open NETwork (KREONET). The quantum key management system not only manages the lifecycle, such as storage, management, derivation, allocation, and deletion of the symmetric key generated in QKD but also enables many-to-many communication in QKD communication based on the key relay function and P2P communication to overcome the limitation of distance, which is a disadvantage of QKD. We have validated the designed quantum key management system through simulations to supplement the parts that were not considered during the initial design.",JWE,2022,,21,5,,1377-1417,2,8,https://ieeexplore.ieee.org/document/10246932/
Semantic Based Weighted Web Session Clustering Using Adapted K-Means and Hierarchical Agglomerative Algorithms,Sowmya HK | R. J. Anandhi,"Department of Information Science and Engineering, New Horizon College of Engineering, Affiliated to Visvesvaraya Technological University, Bengaluru, India | Department of Information Science and Engineering, New Horizon College of Engineering, Affiliated to Visvesvaraya Technological University, Bengaluru, India",Sessionization | dissimilarity matrix | session weight | session cluster | cluster evaluation,"The WWW has a big number of pages and URLs that supply the user with a great amount of content. In an intensifying epoch of information, analysing users browsing behaviour is a significant affair. Web usage mining techniques are applied to the web server log to analyse the user behaviour. Identification of user sessions is one of the key and demanding tasks in the pre-processing stage of web usage mining. This paper emphasizes on two important fallouts with the approaches used in the existing session identification methods such as Time based and Referrer based sessionization. The first is dealing with comparing of current request's referrer field with the URL of previous request. The second is dealing with session creation, new sessions are created or comes in to one session due to threshold value of page stay time and session time. So, authors developed enhanced semantic distance based session identification algorithm that tackles above mentioned issues of traditional session identification methods. The enhanced semantic based method has an accuracy of 84 percent, which is higher than the Time based and Time-Referrer based session identification approaches. The authors also used adapted K-Means and Hierarchical Agglomerative clustering algorithms to improve the prediction of user browsing patterns. Clusters were found using a weighted dissimilarity matrix, which is calculated using two key parameters: page weight and session weight. The Dunn Index and Davies-Bouldin Index are then used to evaluate the clusters. Experimental results shows that more pure and accurate session clusters are formed when adapted clustering algorithms are applied on the weighted sessions rather than the session obtained from traditional sessionization algorithms. Accuracy of the semantic session cluster is higher compared with the cluster of sessions obtained using traditional sessionization.",JWE,2022,,21,2,,239-264,2,7,https://ieeexplore.ieee.org/document/10251062/
An Effective SEO Techniques and Technologies Guide-Map,Konstantinos I. Roumeliotis | Nikolaos D. Tselikas,"Department of Informatics and Telecommunications, Communication Networks and Applications Laboratory, University of Peloponnese, Tripolis, Greece | Department of Informatics and Telecommunications, Communication Networks and Applications Laboratory, University of Peloponnese, Tripolis, Greece",Search engine optimization | search engine optimization techniques | organic traffic | seo prototype tool,"The paper analyzes from a technical point of view the search engine optimization (SEO) techniques and technologies, which lead to effective results up to date. More specifically, it examines the potential SEO alternatives, with ultimate target to increase the organic visitors of a website and climb it up on top of the ranking in respective search engine's queries. The main problem every website's owner has to solve is which of these SEO techniques have to be implemented in order to increase the organic traffic with the minimum budget. This paper aims to present the dominant SEO techniques and evaluate their effectiveness to organic traffic. This paper aims to present the way well-known websites apply SEO nowadays. Taking advantage of this information, Webmasters will know in advance which exactly SEO techniques should apply to their websites and in which specific order to gain higher search results, resulting to higher traffic.",JWE,2022,,21,5,,1603-1649,2,23,https://ieeexplore.ieee.org/document/10246942/
Side-channel Attack Using Word Embedding and Long Short Term Memories,Zixin Liu | Zhibo Wang | Mingxing Ling,"State Key Laboratory of Nuclear Resources and Environment East China, University of Technology, Nanchang, Jiangxi, China | Software college, East China University of Technology, Nanchang, China | State Key Laboratory of Nuclear Resources and Environment East China, University of Technology, Nanchang, Jiangxi, China",Side-channel attack | word embedding | long short term memories,"Side-channel attack (SCA) based on machine learning has proved to be a valid technique in cybersecurity, especially subjecting to the symmetric-key crypto implementations in serial operation. At the same time, parallel-encryption computing based on Field Programmable Gate Arrays (FPGAs) grows into a new influencer, but the attack results using machine learning are exiguous. Research on the traditional SCA has been mostly restricted to pre-processing: Signal Noisy Ratio (SNR) and Principal Component Analysis (PCA), etc. In this work, firstly, we propose to replace Points of Interests (POIs) and dimensionality reduction by utilizing word embedding, which converts power traces into sensitive vectors. Secondly, we combined sensitive vectors with Long Short Term Memories (LSTM) to execute SCA based on FPGA crypto-implementations. In addition, compared with traditional Template Attack (TA), Multiple Multilayer Perceptron (MLP) and Convolutional Neural Network (CNN). The result shows that the proposed model can not only reduce the manual operation, such as parametric assumptions and dimensionality setting, which limits their range of application, but improve the effectiveness of side-channel attacks as well.",JWE,2022,,21,2,,285-306,2,6,https://ieeexplore.ieee.org/document/10247341/
Microservices Identification in Monolith Systems: Functionality Redesign Complexity and Evaluation of Similarity Measures,Samuel Santos | António Rito Silva,"Department of Computer Science and Engineering, INESC-ID, Instituto Superior Técnico, University of Lisbon, Portugal | Department of Computer Science and Engineering, INESC-ID, Instituto Superior Técnico, University of Lisbon, Portugal",Microservices architecture | microservices identification | static code analysis | software architecture,"As monolithic applications grow in size and complexity, they tend to show symptoms of monolithic hell, such as scalability and maintainability problems. To help suppressing these problems, the microservices architectural style is applied. However, identifying the services within the monolith is not an easy task, and current research approaches emphasize different qualities of microservices. In this paper we present an approach for the automatic identification of microservices, which minimizes the cost of the monolith's functionalities redesign. The decompositions are generated based on similarity measures between the persistent domain entities of the monolith. An extensive analysis of the decompositions generated for 121 monolith systems is done. As result of the analysis we conclude that there is not a similarity measure, neither a combination of similarity measures, that provides better decomposition results in terms of complexity associated with the functionalities migration. However, we prove that it is possible to follow an incremental migration process of monoliths. Additionally, we conclude that there is a positive correlation between coupling and complexity, and that it is not possible to conclude on the existence of a correlation between cohesion and complexity.",JWE,2022,,21,5,,1543-1582,2,13,https://ieeexplore.ieee.org/document/10246929/
Data Protection of Internet Enterprise Platforms in the Era of Big Data,Jiaxing Zhang | Anuo Yang | Feng Shuaishuai,"School of Social and Behavioral Sciences, Nanjing University, Nanjing, Jiangsu Province, China | School of Social and Behavioral Sciences, Nanjing University, Nanjing, Jiangsu Province, China | School of Sociology, Wuhan University, Wuhan, Hubei, China",Internet enterprise platform | data protection | cause analysis | protection path,"With the development of big data technology, processed data has become an important source of value. Data has played a pivotal role in the development of enterprises, especially internet enterprises. However, Internet enterprise platform companies generally infringe on personal privacy in various stages of information collection, processing and application, and Internet enterprise platform data protection research is of great significance. The study found that the current problems of data protection on Internet enterprise platforms include: extremely weak user data protection measures, intellectual property risks throughout the whole process of big data processing, and infringements that have both new and high-tech characteristics. The high ambiguity in the definition and attribution of “data rights”, the low cost and high concealment of infringements, and the value difference between intellectual property protection and digital economy are the main causes of these problems. As far as the protection path is concerned, we should start from the three aspects of technology empowerment, governance empowerment and legal empowerment, and work together to promote the proper protection of Internet enterprise platform data.",JWE,2022,,21,3,,861-878,2,9,https://ieeexplore.ieee.org/document/10243632/
Morpheus Web Testing: A Tool for Generating Test Cases for Widget Based Web Applications,Romulo de Almeida Neves | Willian Massami Watanabe | Rafael Oliveira,"Federal Technological University of Parana (UTFPR), Cornélio Procópio, Paraná, Brazil | Federal Technological University of Parana (UTFPR), Cornélio Procópio, Paraná, Brazil | Federal Technological University of Parana (UTFPR), Cornélio Procópio, Paraná, Brazil",User interfaces | widgets | morpheus web testing | code coverage,"Context: Widgets are reusable User Interfaces (UIs) components frequently delivered in Web applications.In the web application, widgets implement different interaction scenarios, such as buttons, menus, and text input. Problem: Tests are performed manually, so the cost associated with preparing and executing test cases is high. Objective: Automate the process of generating functional test cases for web applications, using intermediate artifacts of the web development process that structure widgets in the web application. The goal of this process is to ensure the quality of the software, reduce overall software lifecycle time and the costs associated with tests. Method:We elaborated a test generation strategy and implemented this strategy in a tool, Morpheus Web Testing. Morpheus Web Testing extracts widget information from Java Server Faces artifacts to generate test cases for JSF web applications. We conducted a case study for comparing Morpheus Web Testing with a state of the art tool (CrawlJax). Results: The results indicate evidence that the approach Morpheus Web Testing managed to reach greater code coverage compared to a CrawlJax. Conclusion: The achieved coverage values represent evidence that the results obtained from the proposed approach contribute to the process of automated test software engineering in the industry.",JWE,2022,,21,2,,119-144,2,5,https://ieeexplore.ieee.org/document/10251063/
In-Network Convolution in Grid Shaped Sensor Networks,Niki Hrovatin | Aleksandar Tošić | Jernej Vičič,"Faculty of Mathematics, Natural Sciences and Information Technologies, University of Primorska, Koper, Slovenia | Faculty of Mathematics, Natural Sciences and Information Technologies, University of Primorska, Koper, Slovenia | Faculty of Mathematics, Natural Sciences and Information Technologies, University of Primorska, Koper, Slovenia",Sensor networks | edge computing | fall detection | convolutional neural networks | network simulator ns-3,"Gathering information is the primary purpose of a Sensor Network. The task is performed by spatially distributed nodes equipped with sensing, processing, and communication capabilities. However, data gathered from a sensor network must be processed, and often the collective computation capability of nodes forming the sensor network is neglected in favor of data processing on cloud systems. Nowadays, Edge Computing has emerged as a new paradigm aiming to migrate data processing close to data sources. In this contribution, we focus on the development of a sensor network designed to detect a person's fall. We named this sensor network the smart floor. Fall detection is tackled with a Convolutional Neural Network, and we propose an approach for in-network processing of convolution layers on grid-shaped sensor networks. The proposed approach could lead to the development of a sensor network that detects falls by performing CNN inference processing on the edge. We complement our work with a simulation using the simulator ns- 3. The simulation is designed to emulate the communication overhead of the proposed approach applied to a wired sensor network that resembles the smart floor. Simulation results provide evidence on the feasibility of the proposed concept applied to wired grid shaped sensor networks.",JWE,2022,,21,1,,75-96,2,4,https://ieeexplore.ieee.org/document/10247351/
Federated Learning-Based Privacy Preservation with Blockchain Assistance in IoT 5G Heterogeneous Networks,Sampathkumar Arumugam | Shishir Kumar Shandilya | Nebojsa Bacanin,"Department of Computer Science, Dambi Dollo University, Ethiopia | Liverpool Hope University, UK | Singidunum University, Belgrade, Serbia",Blockchain | 5G network | federated machine | privacy preservation | registration,"In the area where privacy is of greater concern, federated learning, a distributed machine learning strategy for preserving privacy, is widely employed in several privacy concern applications. In the meantime, neural architectures became familiar with deep learning approaches for automatic tuning of the architecture of deep neural networks (DNN). While searching with neural architecture and federated learning has experienced several challenges, optimized neural architecture research in federated learning is extensively on demand. DNN faces numerous issues while training such user privacy and ensuring the integrity of the aggregated results obtained from a server. To provide solutions for the above-mentioned issues, enormous federated learning techniques worked towards preserving privacy and were applied in different situations. Still, it is an open challenge that enables users to verify if the cloud server functions appropriately while ensuring users' privacy while training. Federated Learning Method is a new way to improve the accuracy and precision, since the previous approach failed to opt the solutions. Here, Elliptical Curve Cryptography with Blockchain-based Federated Learning (ECC-BFL)is proposed to ensure the confidentiality of users' local gradients while performing federated learning. The parameters such as classification accuracy, running time, Communication overhead, Computation overhead, and transaction speed are considered. The values obtained for these parameters are compared against three standard methods, namely Biparing Method (BM) Homomorphic Cryptosystem (HC), and Multiple Authorities with Attribute-Based Signature scheme (MA-ABS)against proposed Elliptical Curve Cryptography with Blockchain-based Federated Learning (ECC-BFL). As a result, the proposed ECC-BFL achieved 95% of classification accuracy, 65 sec of running time, 76% of communication overhead, 63% of computation overhead, and 92% of transaction speed.",JWE,2022,,21,4,,1323-1346,2,10,https://ieeexplore.ieee.org/document/10246908/
Sequence Encoder-Based Spatiotemporal Knowledge Graph Completion,Wei Jia | Xuan Wang | Jing Shan | Li Yan | Weinan Niu | Zongmin Ma,"State Key Laboratory of Air Traffic Management System and Technology, China | State Key Laboratory of Air Traffic Management System and Technology, China | Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China",Knowledge graph completion | recursive neural network | spatiotemporal information,"Knowledge graph (KG) completion aims to infer new facts from incomplete knowledge graphs. Most existing solutions focus on learning from timeaware fact triples and ignore the spatial information. In reality, knowledge graphs can evolve with time as well as the changing locations, such as the flight domain. Therefore, integrating spatiotemporal information into knowledge graph representation is important for the knowledge graph completion. To address this problem, this paper proposes two SpatioTemporal-aware knowledge graph completion models based on the Sequence Encoder, namely STSE and S-TSE, which incorporate the spatial and temporal information into relations. Specifically, the model consists of two steps: spatiotemporal-aware relation encoding and final scoring function evaluation. The first stage composes the spatiotemporal information into different tokens. Then two methods are proposed to obtain the embedding of spatiotemporal-aware relation by utilizing the Recursive Neural Network. The second stage proposes different scoring functions for two models. Empirically evaluation of the proposed models is conducted on spatiotemporal-aware KG completion task on two public datasets. Experimental results demonstrate the effectiveness of the proposal for spatiotemporal knowledge graph completion.",JWE,2022,,21,6,,1913-1936,2,5,https://ieeexplore.ieee.org/document/10246949/
Credibility Evaluation of Web Big Data Information Based on Particle Swarm Optimization,Nannan Zhao,"School of Computer Science and Engineering, Guangdong Ocean University at Yangjiang, China",Credibility evaluation | web big data | improved particle swarm algorithm,"In order to improve the credibility evaluation effectiveness of web big data information, the improved particle swarm optimization is established. Firstly, framework of web big data is designed to include web big data source, data storage, data processing and data analysis. The global credibility calculation formula of whole web is established. Secondly, the improved particle swarm algorithm is constructed through updating weight and training factor, introducing cross and mutation operations into the algorithm, and improving population diversification based on mountain climbing algorithm. Finally, ten sample industries and one hundred sample stocks are selected to carry out experiment analysis, and the results show that the proposed algorithm can effectively distinguish trusted and untrustworthy records. And the proposed algorithm of calculating credibility of web big data has high reasonableness.",JWE,2022,,21,2,,405-424,2,3,https://ieeexplore.ieee.org/document/10247330/
Handling Heterogeneous Data in Knowledge Graphs: A Survey,Sushmita Singh | Manvi Siwach,"Department of Computer Engineering, J.C. BOSE University of Science and Technology, YMCA, Faridabad, Haryana, India | Department of Computer Engineering, J.C. BOSE University of Science and Technology, YMCA, Faridabad, Haryana, India",Knowledge graph | knowledge fusion | heterogeneous data | entity linking | entity extraction | entity alignment | ontology | knowledge base,"In this era of information where everything is digital, data tends to be ubiquitous. Data Analytics is a term that covers all the areas that deal with the logical analysis of raw data Graph analytics is one of the emerging domains of data analytics that represents and analyses data in the form of knowledge graphs. Knowledge graphs play a vital role in analysing and processing data in order to make decisions. In knowledge graphs the data is stored in the form of entities, relationships between the entities and the attributes of entities as well as attributes of relationships. Construction of knowledge graph and its analytics face multiple challenges like data redundancy, heterogeneity of data, missing data, dynamic nature of real-world data etc. This paper focuses on the issue related to heterogeneity of data while constructing a knowledge graph, and it provides a systematic literature review over construction of knowledge graphs from heterogeneous data sources. This review compiles state-of-the-art knowledge fusion techniques. To conduct this systematic literature review, an exhaustive approach has been adopted to identify various procedures and algorithms included and adapted by different research works for knowledge graph construction.",JWE,2022,,21,4,,1145-1186,2,7,https://ieeexplore.ieee.org/document/10246920/
Evaluating Annotated Dataset of Customer Reviews for Aspect Based Sentiment Analysis,Dimple Chehal | Parul Gupta | Payal Gulati,"Department of Computer Engineering, J.C. Bose University of Science and Technology, YMCA, Faridabad, India | Department of Computer Engineering, J.C. Bose University of Science and Technology, YMCA, Faridabad, India | Department of Computer Engineering, J.C. Bose University of Science and Technology, YMCA, Faridabad, India",Aspect based sentiment analysis | customer reviews | ecommerce | labelled dataset | machine learning | recommendation system | supervised learning,"Sentiment analysis of product reviews on e-commerce platforms aids in determining the preferences of customers. Aspect-based sentiment analysis (ABSA) assists in identifying the contributing aspects and their corresponding polarity, thereby allowing for a more detailed analysis of the customer's inclination toward product aspects. This analysis helps in the transition from the traditional rating-based recommendation process to an improved aspect-based process. To automate ABSA, a labelled dataset is required to train a supervised machine learning model. As the availability of such dataset is limited due to the involvement of human efforts, an annotated dataset has been provided here for performing ABSA on customer reviews of mobile phones. The dataset comprising of product reviews of Apple-iPhone11 has been manually annotated with predefined aspect categories and aspect sentiments. The dataset's accuracy has been validated using state-of-the-art machine learning techniques such as Naïve Bayes, Support Vector Machine, Logistic Regression, Random Forest, K-Nearest Neighbor and Multi Layer Perceptron, a sequential model built with Keras API. The MLP model built through Keras Sequential API for classifying review text into aspect categories produced the most accurate result with 67.45 percent accuracy. K-nearest neighbor performed the worst with only 49.92 percent accuracy. The Support Vector Machine had the highest accuracy for classifying review text into aspect sentiments with an accuracy of 79.46 percent. The model built with Keras API had the lowest 76.30 percent accuracy. The contribution is beneficial as a benchmark dataset for ABSA of mobile phone reviews.",JWE,2022,,21,2,,145-178,2,7,https://ieeexplore.ieee.org/document/10247338/
Video Face Detection Based on Improved SSD Model and Target Tracking Algorithm,Yilin Liu | Ruian Liu | Shengxiong Wang | Da Yan | Bo Peng | Tong Zhang,"College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin, China | College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin, China | College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin, China | College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin, China | College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin, China | College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin, China",Deep neural network | SSD target detection | continuous frame target tracking | kernel correlation filtering,"Video face detection technology has a wide range of applications, such as video surveillance, image retrieval, and human-computer interaction. However, face detection always has some uncontrollable interference factors in the video sequence, such as changes in lighting, complex backgrounds, and face changes in scale and occlusion conditions, etc. Therefore, this paper introduces deep learning theory and combines the continuity characteristics of video sequences to make related research on video face detection algorithms based on deep learning. First, this algorithm uses the residual network as the basic network of the Single Shot MultiBox Detector (SSD) target detection network model and trains a Rest-SSD face detection model to detect faces. Experimental results show that the method can achieve realtime detection and improve the accuracy of video face detection, which is required for face detection in a video. Then we based on the continuity characteristics of video sequences. This paper proposes a video face detection method based on the training of the Rest-SSD face detection model. The method first uses kernel correlation filtering to track consecutive n frames according to the detection results, sets weights on the confidence of the n frames of tracking results, uses the weighted average method to calculate the best tracking result, and then sets the best tracking result confidence and the current frame sets the appropriate weights for the confidence of the detection result for fusion, thereby improving the video face detection accuracy.",JWE,2022,,21,2,,545-568,2,21,https://ieeexplore.ieee.org/document/10247342/
JITA4DS: Disaggregated Execution of Data Science Pipelines Between the Edge and the Data Centre,Genoveva Vargas-Solar | Md Sahil Hassan | Ali Akoglu,"French Council of Scientific Research (CNRS)-LIRIS, France | University of Arizona, USA | University of Arizona, USA",Disaggregated data centers | data science pipelines | edge computing,"This paper targets the execution of data science (DS) pipelines supported by data processing, transmission and sharing across several resources executing greedy processes. Current data science pipelines environments provide various infrastructure services with computing resources such as general-purpose processors (GPP), Graphics Processing Units (GPUs), Field Programmable Gate Arrays (FPGAs) and Tensor Processing Unit (TPU) coupled with platform and software services to design, run and maintain DS pipelines. These one-fits-all solutions impose the complete externalization of data pipeline tasks. However, some tasks can be executed in the edge, and the backend can provide just in time resources to ensure ad-hoc and elastic execution environments. This paper introduces an innovative composable “Just in Time Architecture” for configuring DCs for Data Science Pipelines (JITA-4DS) and associated resource management techniques. JITA-4DS is a cross-layer man-agement system that is aware of both the application characteristics and the underlying infrastructures to break the barriers between applications, middleware/operating system, and hardware layers. Vertical integration of these layers is needed for building a customizable Virtual Data Center (VDC) to meet the dynamically changing data science pipelines' requirements such as performance, availability, and energy consumption. Accordingly, the paper shows an experimental simulation devoted to run data science workloads and determine the best strategies for scheduling the allocation of resources implemented by JITA-4DS.",JWE,2022,,21,1,,Jan-26,2,7,https://ieeexplore.ieee.org/document/10243631/
Benefits and Challenges of Isomorphism in Single-Page Applications: Case Study and Review of Gray Literature,Aleksi Huotala | Matti Luukkainen | Tommi Mikkonen,"Department of Computer Science, University of Helsinki, Helsinki, Finland | Department of Computer Science, University of Helsinki, Helsinki, Finland | Department of Computer Science, University of Helsinki, Helsinki, Finland",Isomorphic web applications | single-page applications | JavaScript | web programming | server-side rendering | isomorphism,"An isomorphic web application shares code between the server and the client by cleverly combining suitable parts of server-rendered applications and single-page applications. In this article, we study the benefits and challenges of isomorphism in single-page applications in terms of a gray literature review and a case study. The case study was conducted as a developer interview, where developers familiar with isomorphic web applications were interviewed. The results of both studies are then compared and the key findings are compared together. The results show that isomorphism in single-page applications brings benefits to both the developers and the end-users. Isomorphism in single-page applications is challenging to implement and has some downsides, but they mostly affect developers. Implementing isomorphism enables sharing code between the server and the client, but it increases the complexity of the application. Framework and library compatibility are issues that must be addressed by the developers.",JWE,2022,,21,8,,2363-2403,2,4,https://ieeexplore.ieee.org/document/10247348/
Establishment of Production Standards for Web-Based Metaverse Content: Focusing on Accessibility and HCI,Won-06 Jeong | Gi-Sung Oh | Seok-Hee Oh | Taeg-Keun Whangbo,"Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea | Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea | Korea creative content agency, Daejeon gwangyeoksi, Republic of Korea | Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea",Web-based metaverse | Web 3.0 | web application | HCI | UX/UI,"Metaverse technology is expanding to industries in various fields, such as medical, national defense, and education, and training simulation programs have been mainstream so far. However, there have been increasing attempts to apply metaverse content to web-based platforms linked to social media services and, as a result, we face the problem of access to web-based metaverse content. Unlike traditional content, metaverse content interacts with many users, so content accessibility is the first important part to consider. In other words, to maximize the quality of metaverse content, it is essential to pull out the optimal UX through a detailed HCI (human computer interaction) design. Metaverse content development methodologies have effective methods proposed by many researchers. However, they are limited to web-based metaverse content that limits the use of high-end hardware. They are ineffective for platforms such as PCs and VR devices, as most studies focus on improving the visual performance of PCs or high-performance VR devices. Therefore, unlike existing research, the key theme of our research is to study optimized development standards that can be applied to web-based metaverse content and find out their effects through experiments. We created a development standard to be applied to a Web-based platform based on the existing metaverse content development methodology. Then, we redeveloped the VR content into the metaverse content and named them the VR build and the metaverse build. We had 25 people play virtual reality builds and metaverse builds simultaneously. Then, we measured the overall experience with an evaluation tool called the Game Experience Questionnaire (GEQ); the GEQ is a proven tool for evaluating content experiences by dividing them into positive/negative scales. When comparing the results measured from the two builds, the metaverse build showed consistent results with a higher positive scale, and a lower negative scale, than the VR build. The results showed that users indeed rated metaverse content positively. The bottom line is that the web-based metaverse content development standards that we have produced are practical. However, since generalization is limited, continuous research will be needed in more experimental groups in the future.",JWE,2022,,21,8,,2231-2256,2,8,https://ieeexplore.ieee.org/document/10247354/
RDF Graph Summarization Based on Node Characteristic and Centrality,Jimao Guo | Yi Wang,"College of Computer and Information Science, Southwest University, Chongqing, China | College of Computer and Information Science, Southwest University, Chongqing, China",Knowledge graph summarization | node centrality | knowledge graph compression | node characteristic set | graph summarization,"The explosive growth of RDF data makes it difficult to be efficiently queried, understood and used. RDF graph (RDFG) summarization aims to extract the most relevant and crucial data as summaries according to different criteria. Current summarization approaches mainly apply single strategies such as graph structure, pattern mining or relevance metrics to calculate RDFG summaries. Different to the existing approaches, this paper proposes a summarization approach to automatically generating RDFG summary, which can capture both structure and centrality information. Specifically, we present three algorithms, Sum W (merging nodes based on node characteristics or similar types), SumS (merging nodes based on typed node characteristics) and SummaryFL (retrieving central nodes by combining node frequency and bridging coefficient). The three algorithms can be used by two summarization strategies: SumS or SumW only, and SumS+SummaryFL or SumW+SummaryFL. We conducted experiments over large and real-world RDF datasets to verify the effectiveness of our method with respect to time complexity, compression capability and coverage of the summary. The experiment results demonstrate that our approach outperformed the comparative algorithms.",JWE,2022,,21,7,,2073-2093,2,4,https://ieeexplore.ieee.org/document/10246954/
Semantics-Aware Context-Based Learner Modelling Using Normalized PSO for Personalized E-Learning,Hadi Ezaldeen | Sukant Kishoro Bisoy | Rachita Misra | Rawaa Alatrash,"Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India | Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India | Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India | Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India",Personalized E-learning recommendation | contextual learner model | semantic analysis | knowledge graph | normalized PSO | prefix tree,"E-learning proves its importance in the diverse educational levels over traditional education. An adaptive e-learning system needs to deduce the learner model for adding personalization to instructional websites. The learner model is the perception repository about the e-content user, which can be inferred implicitly by employing meaningful semantic analysis of the text. In this research, a novel methodology is proposed to conceptually deduce the semantic learner model for personalized e-learning recommendations. Firstly, Conceptual Learner Model (CLM) is developed based on the learner's behavior and context-based text semantic representation by exploiting concepts from the ConceptNet knowledge base, with a significant association of patterns and rules. Then, Expanded Contextual Learner Model (ECLM) is developed by exploring the latent semantics in graphs to add concepts with the common-sense meanings that exceeded the named entities. The learner's knowledge graph is defined based on contextually associated concepts. Semantic relations in ConceptNet are exploited to extend learner models. The Normalized Particle Swarm Optimization (NPSO) algorithm is used to learn the importance of the relation types between the concepts. Thus, CLM and ECLM each are represented as a vector of weighted concepts in which updating is obtained automatically. The proposed recommendation system incorporates dynamic learner models to predict an appropriate e-content with the highest ranking, matching the true needs of a particular learner. Our simulation results show that the performance of ECLM is better Mean Reciprocal Rank (MRR) value 0.780 than other existing methods.",JWE,2022,,21,4,,1187-1224,2,0,https://ieeexplore.ieee.org/document/10246921/
Optimal Trained Bi-Long Short Term Memory for Aspect Based Sentiment Analysis with Weighted Aspect Extraction,Archana Nagelli | B. Saleena,"School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India | School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India",Aspect-based sentiment analysis | Stanford dependency passer | association rule mining | optimized Bi-LSTM | optimization,"Sentiment analysis based on aspects seeks to anticipate the polarities of sentiment in specified targets related to the text data. Several studies have shown a strong interest in using an attention network to represent the target as well as context on generating an efficient representation of features used for tasks while sentiment classification. Still, the attention score computation of the target using an average vector for context is unequal. While the interaction mechanism is simplistic, it needs to be overhauled. Therefore, this paper intends to introduce a novel aspect-based sentiment analysis with three phases: (i) Preprocessing, (ii) Aspect Sentiment Extraction, (iii) Classification. Initially, the input data is given to the preprocessing phase, in which the tokenization, lemmatization, and stop word removal are performed. From the preprocessed data, the weighted implicit and weighted explicit extraction is determined in the Aspect Sentiment Extraction. Moreover, the weighted implicit aspect extraction is done by Stanford Dependency Passer (SDP) method, and the weighted explicit extraction is done through proposed Association Rule Mining (ARM). Subsequently, the extracted features are provided to the classification phase in which the Optimized Bi-LSTM is utilized. For making the classification more accurate and precise, it is planned to tune the weights of Bi-LSTM optimally. For this purpose, an Opposition Learning Cat and Mouse-Based Optimization (OLCMBO) Algorithm will be introduced in this work. In the end, the outcomes of the presented approach are calculated to the extant approaches with respect to different measures like F1-measure, specificity, Negative Predictive Value (NPV), accuracy, False Negative Rate (FNR), sensitivity, precision, False Positive Rate(FPR), and Matthew's correlation coefficient, respectively.",JWE,2022,,21,7,,2115-2148,2,3,https://ieeexplore.ieee.org/document/10247160/
Hybrid CTC-Attention Network-Based End-to-End Speech Recognition System for Korean Language,Hosung Park | Changmin Kim | Hyunsoo Son | Soonshin Seo | Ji-Hwan Kim,"Sogang University, Seoul, South Korea | LG Electronics, Seoul, Korea | Sogang University, Seoul, South Korea | Naver Corporation, Gyeonggi Province, South Korea | Sogang University, Seoul, South Korea",End-to-End speech recognition | hybrid CTC-attention network | Korean speech recognition,"In this study, an automatic end-to-end speech recognition system based on hybrid CTC-attention network for Korean language is proposed. Deep neural network/hidden Markov model (DNN/HMM)-based speech recognition system has driven dramatic improvement in this area. However, it is difficult for non-experts to develop speech recognition for new applications. End-to-end approaches have simplified speech recognition system into a single-network architecture. These approaches can develop speech recognition system that does not require expert knowledge. In this paper, we propose hybrid CTC-attention network as end-to-end speech recognition model for Korean language. This model effectively utilizes a CTC objective function during attention model training. This approach improves the performance in terms of speech recognition accuracy as well as training speed. In most languages, end-to-end speech recognition uses characters as output labels. However, for Korean, character-based end-to-end speech recognition is not an efficient approach because Korean language has 11,172 possible numbers of characters. The number is relatively large compared to other languages. For example, English has 26 characters, and Japanese has 50 characters. To address this problem, we utilize Korean 49 graphemes as output labels. Experimental result shows 10.02% character error rate (CER) when 740 hours of Korean training data are used.",JWE,2022,,21,2,,265-284,2,8,https://ieeexplore.ieee.org/document/10247343/
Designing a Flow-Based Mechanism for Accessing Electronic Health Records on a Cloud Environment,Tsung-Yin Ou | Wen-Lung Tsai,"Department of Marketing and Distribution Management, National Kaohsiung University of Science and Technology, Kaohsiung, Taiwan | Department of Information Management, Asia Eastern University of Science and Technology, New Taipei, Taiwan",Electronic health records | cloud environment | access control | workflow | doctor-patient communication | web-based system,"Electronic health record (EHR) implementation not only to facilitate doctor-patient communication reduces paper consumption but also allows the rapid exchange of medical records, integrating patients' medical information from different locations. However, the costs of establishing massive and repetitive systems, constructing databases, and maintaining and exchanging data, as well as the energy consumption underscoring such an operation, represent substantial costs for a medical institution. Therefore, it is important to develop a cloud solution for EHRs and to provide a platform where resources are truly shareable. This study investigates the feasibility of cloud EHR services provided by trusted third parties. However, not only do medical records stored in an access environment with multiple users potentially endanger patient privacy, but also, without well-designed access control, such an environment may beget excessive unnecessary data access, which is costly and hinders cloud computing. To address the dual challenge of protecting patient privacy and allowing cloud computing, this study proposes the doctor-patient workflow and implements a web-based system. This mechanism ensures patients' data security and addresses the demand of EHR cloud sharing, i.e., controlling EHR access authorities. The proposed method can protect the privacy of patients' medical records on the cloud and grant users with minimum granularity access, thereby creating a system with the advantages of data security and cloud computing. This study proposes the doctor-patient workflow as the access control mechanism of cloud medical records, which minimizes the granularity of access. In addition, the access authority of the workflow dynamically changes with the environment, which ensures patients' access to their medical records and defines the appropriate timing of cloud data access operations, thereby preventing unnecessary energy consumption. In practice, considerable contributions can be made to the establishment of access control and promotion of the cloud environment for medical records.",JWE,2022,,21,5,,1491-1517,2,1,https://ieeexplore.ieee.org/document/10246933/
Research on Web GUI Image Recognition System Based on Improved Convolutional Neural Network,Nannan Zhao,"School of Computer Science and Engineering, Guangdong Ocean University at Yangjiang, China",Improved convolutional neural network | Web GUI image recognition | l2 regularization | improved particle swarm optimization,"In this paper, a MobileNet V2 convolutional neural network depending on L2 regularization method, a amended particle swarm model and Dropout method are constructed in a bid for enhancing the accuracy and speed of Web GUI image recognition for establishing Web Web GUI image recognition system of Web GUI test. Firstly, an improved MobileNet V2 convolutional neural network is constructed. Secondly, the basic models of L2 regularization method, improved particle swarm method and Dropout method are studied, the improved MobileNet V2 convolution neural network optimization algorithm is proposed, and the basic model of image processing is designed. Finally, simulation analysis is carried out on Web GUI image recognition through using the amended convolutional neural network on basis of MINIST data set as the research object. The simulation results illustrate that the amended convolutional neural network proposed in this study is more accurate and efficient in Web GUI image recognition.",JWE,2022,,21,5,,1727-1747,2,2,https://ieeexplore.ieee.org/document/10246941/
Web Project Development: Emergency Management,Solomiia Fedushko | Olha Trach | Yuriy Syerov | Natalia Kryvinska | Jennifer R. Calhoun,"Social Communication and Information Activity Department, Lviv Polytechnic National University, Ukraine | Social Communication and Information Activity Department, Lviv Polytechnic National University, Ukraine | Social Communication and Information Activity Department, Lviv Polytechnic National University, Ukraine | Faculty of Management, Comenius University in Bratislava, Bratislava, Slovakia | Wall College of Business Administration, Coastal Carolina University, Conway, SC, USA",Web project | project management | member | social network | emergency management | web | data manipulation | data analysis,"Web projects are crucial to a company's online presence and significantly impact its success. Risk management is a component of web project management to identify, assess and potentially control threats to the success of projects. The research methodology includes systematic and analytical analyses of the members' management of risks associated with web project users. The results and implications reveal that assessing the intensity of risk management measures for the sustainability of web projects regarding risks is imperative. The capacity for emergency management in web projects is essential for identifying, assessing, and controlling potential threats, reducing the probability of project delays or failure. Emergency management offers several critical benefits to web projects, including improved data protection, increased continuity of operations, reduced downtime, enhanced reputation, and increased efficiency. Effective emergency management throughout the web project life cycle organization ensures that the project is completed on time, within budget, and to stakeholders' satisfaction while being prepared for potential emergencies. This research develops best practices and standards for future projects, increasing project success rates.",JWE,2022,,21,8,,2257-2286,2,10,https://ieeexplore.ieee.org/document/10247349/
A Scheme of Selecting Vehicles to Assist Download Based on WebGIS for VANET,Qibin Zhou | Qinggang Su | Peng Xiong,"College of International Education, Shanghai Jian Qiao University, Shanghai, China | Kaiserslautern Kolleg für Intelligente Produktion, Shanghai Dianji University, Shanghai, China | School of Electronics and Information, Shanghai Dianji University, Shanghai, China",Assisted download | WebGIS | delay-tolerant networking | VANET,"The assisted download is an effective method solving the problem that the coverage range is insufficient when Wi-Fi access is used in VANET. For the low utilization of time-space resource within blind area and unbalanced download services in VANET, this paper proposes an approximate global optimum scheme to select vehicle based on WebGIS for assistance download. For WebGIS, this scheme uses a two-dimensional matrix to respectively define the time-space resource and the vehicle selecting behavior, and uses Markov Decision Process to solve the problem of time-space resource allocation within blind area, and utilizes the communication features of VANET to simplify the behavior space of vehicle selection so as to reduce the computing complexity. At the same time, Euclidean Distance(Metric) and Manhattan Distance are used as the basis of vehicle selection by the proposed scheme so that, in the case of possessing the balanced assisted download services, the target vehicles can increase effectively the total amount of user downloads. Experimental results show that because of the wider access range and platform independence of WebGIS, when user is in the case of relatively balanced download services, the total amount of downloads is increased by more than 20%. Moreover, WebGIS usually only needs to use Web browser (sometimes add some plug-ins) on the client side, so the system cost is greatly reduced.",JWE,2022,,21,2,,337-364,2,1,https://ieeexplore.ieee.org/document/10247353/
Effectiveness of the VR Cognitive Training for Symptom Relief in Patients with ADHD,Seok Hee Oh | 06g Woon Park | Seong-Jin Cho,"Gachon University, Seongnam, South Korea | Gachon University, Seongnam, South Korea | Gachon University College of Medicine, Incheon, South Korea",Virtual reality | ADHD | sense of presence | VR cognitive training | EEG | game engine,"This study aimed to verify the effectiveness of virtual reality (VR) cognitive training by measuring the sense of presence and electroencephalography (EEG) in children with ADHD. A clinical trial was conducted to verify the effect of VR cognitive training on children with ADHD. The experimental group included eight children with ADHD, and the control group included eight healthy children without ADHD. The sense of presence increased significantly after the VR cognitive training in children with ADHD. Also, no significant changes in the alpha, beta, delta, and gamma wave amplitudes were found in both groups after the VR cognitive training. Thus, the VR training content developed in this study can help measure the patients' behavioral inhibition, increase their sense of presence by inducing interaction with distraction stimuli, and alleviate their symptoms. However, EEG could only be used as an auxiliary means, at the clinician's judgment, for ADHD diagnosis in children because no significant EEG changes were observed in the experimental or control groups after the VR cognitive training.",JWE,2022,,21,3,,767-788,2,12,https://ieeexplore.ieee.org/document/10247208/
MalVulDroid: Tracing Vulnerabilities from Malware in Android Using Natural Language Processing,Shivi Garg | Niyati Baliyan,"Faculty of Informatics and Computing, J. C. Bose University of Science and Technology YMCA, Faridabad, India | Department of Computer Engineering, National Institute of Technology Kurukshetra, Haryana, India",Android | machine learning | malware | mapping | natural language processing | vulnerability,"The Android operating system is often inflicted with mobile malware attacks, which occur due to some system loopholes or vulnerabilities. One malware can exploit numerous vulnerabilities and multiple malware can exploit a single vulnerability, thus, causing many-to-many ($X:Y$) mapping between malware and vulnerability. Therefore, it is crucial to understand malware behaviour to reduce the vulnerabilities. This paper presents the concept of a “MalVulDroid” framework that maps malware to vulnerabilities using a two-dimensional matrix. The many-to-many ($X:Y$)) mapping matrix is obtained by using natural language processing techniques such as Bag-of-Words (BoW) leveraging $n$-gram probability generation and term frequency-inverse document frequency (TF-IDF), in addition to supervised machine learning classifiers such as multilayer perceptron (MLP), a support vector machine (SVM), a ripple down rule learner (RIDOR), and a pruning rule-based classification tree (PART). This study is the first of its kind where malware-to-vulnerability mapping can be leveraged to measure the rigorousness of unknown vulnerabilities and malware during the early phases of application development. The study considers extensive datasets such as Androzoo, AMD, and CICInvesAndMal2019 with 150 malware families and 48,907 malware samples, and nine major vulnerabilities affecting Android. MalVulDroid exhibits highly promising results with an accuracy of 98.04% for unigrams, and precision and F1-scores of over 90% using ensemble classifiers.",JWE,2022,,21,8,,2339-2361,2,3,https://ieeexplore.ieee.org/document/10247355/
A Hybrid Recommendation Integrating Semantic Learner Modelling and Sentiment Multi-Classification,Rawaa Alatrash | Rojalina Priyadarshini | Hadi Ezaldeen | Akram Alhinnawi,"Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India | Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India | Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India | Department Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA",Hybrid recommendation | semantic user modeling | contextual graph | sentiment analysis | word embeddings | deep learning,"Enhancing virtual learning platforms need to adapt new intelligent mechanisms so that long-term learner experience can be improved. Sentiment Analysis gives us perception on how a specific scientific material is suitable to be recommended to the learner. It depends on the feedback of a similar learner taking many factors under consideration such as preference, knowledge level, and learning pattern. In this work, a hybrid e-learning recommendation system is proposed based on individualization and Sentiment Analysis. A new approach is provided for modelling the semantic user model based on the generated semantic matrix to capture the learner's preferences based on their selections of interest. The extracted semantic matrix is used for text representation by utilizing ConceptNet knowledge base which relies on contextual graph and expanded terms to represent the correlation among terms and materials. On the extracted terms from semantic user model, Word Embeddings-Based-Sentiment Analysis (WEBSA) must recommend the learning materials with highest rating to the learners properly. Variant models of (WEBSA) are proposed relying on Natural Language Processing (NLP) to generate effective vocabulary representations along with the use of qualitative customized Convolutional Neural Network (CNN) for sentiment multi-classification tasks. To validate the language model, two datasets are used, a tailored dataset that has been created by scraping reviews of different e-learning resources, and a public dataset. From the experimental results, it has been found that the lowest error rate is achieved with our customized dataset, where the model named CNN-Specific-Task-CBOWBSA outperforms than others with 89.26% accuracy.",JWE,2022,,21,4,,941-988,2,8,https://ieeexplore.ieee.org/document/10246916/
Image Link Through Adaptive Encoding Data Base and Optimized GPU Algorithm for Real-time Image Processing of Artificial Intelligence,Byoungman An | Youngseop Kim,"Electronic and Electrical Engineering, Dankook University, Gyeonggi-do, Korea | Electronic and Electrical Engineering, Dankook University, Gyeonggi-do, Korea",Image link | in-vehicle | GPU algorithm optimization | audio video bridge | AVB | low latency | automotive | multimedia | artificial intelligence | data base,"This paper presents the latest Ethernet standardization of in-vehicle network and the future trends of automotive ethernet technology. The proposed system provides a design and optimization algorithm of in-vehicle networking technologies related Ethernet Audio Video Bridge (AVB) technology. We present a design of in-vehicle network system as well as the optimization of AVB for automotive. A proposal of Reduced Latency of Machin to Machine (RLMM) plays a significant role in reducing the latency between devices. The approach of RLMM on realistic test cases indicated that there was a latency reduction about 30.41% It is expected that the optimized settings for the actual automotive network environment can greatly shorten the time period in the development and design process. The results achieved from the experiments on the latency present in each function are trustworthy since average values are obtained via repeated tests for several months. It would considerably benefit the industry because analyzing the delay between each function in a short period of time is tremendously significant. In addition, through the proposed real-time camera and video streaming via optimized settings of AVB system, it is expected that AI (Artificial Intelligence) algorithms in autonomous driving will be of great help in understanding and analyzing images in real time.",JWE,2022,,21,2,,459-496,2,3,https://ieeexplore.ieee.org/document/10247332/
Taylor Sailfish Optimizer-Based Deep Stacked Auto Encoder for Blackhole Attack Detection in Wireless Sensor Network,Mandeep Kumar | Jahid Ali,"Computer Science & Engineering, I.K. Gujral Punjab Technical University, Kapurthala, India | Computer Applications, Sri Sai Iqbal College of Management and Information Technology, Pathankot, Punjab, India",Blackhole attack | Taylor series | deep stacked autoencoder | SailFish Optimizer | routing,"Sensor nodes in Wireless sensor network (WSN) are distributed over a large area for sensing the pressure, temperature, humidity, and so on. They are at risk due to several attacks. In an attack like a black hole, the malicious node captures the whole data without any consideration of the active route, thus the source node are secured for communication. Hence, a new method name, Taylor SailFish Optimizer (TaylorSFO) is proposed to predict black-hole attacks in WSN. The training of the Deep stacked autoencoder is done through proposed Taylor-SFO, which is the integration of Taylor Series, and SailFish Optimizer (SFO). The newly developed Taylor-SFO is then applied for routing and blackhole attack detection at the WSN base station. Overall, two phases are included in the proposed model, which involves routing and blackhole attack detection at the base station. Initially, the WSN nodes are given to the routing module. Here, the routing is done based on the proposed TaylorSFO. Energy, distance as well as delay are the three fitness parameters considered for the routing. The proposed method shows the lowest delay of 21.23 ms, minimal FNR of 0.083, minimal FPR of 0.134, highest PDR of 94.87%, the highest throughput rate of 119.98 kbps, respectively.",JWE,2022,,21,3,,911-940,2,8,https://ieeexplore.ieee.org/document/10247116/
A New Semi-Automated Method for Service Identification,Shahrzad Hekmat | Saeed Parsa | Babak Vaziri,"Department of Computer Engineering, Central Tehran Branch, Islamic Azad University, Tehran, Iran | Department of Computer Engineering, Iran University of Science and Technology, Tehran, Iran | Department of Computer Engineering, Central Tehran Branch, Islamic Azad University, Tehran, Iran",Business process model | model-driven method | service identification | software engineering,"Service identification plays a key role in the design of service-oriented systems. There are non-model-based and model-based methods for extracting services from business processes. These methods suggest a set of mostly descriptive solutions that do not pay sufficient attention to service design guidelines and the conceptual relations between tasks. The challenge is to develop an algorithm to automatically identify services from business processes to simplify the analysis and reduce the gap between information technology and business needs. In this paper, we develop a semi-automated service identification method that addresses this gap. This method incorporates the Goal, Data, and Business Process Models (BPM) to identify services based on related tasks, shared data, and business requirements. It advances previous methods by simultaneously considering both semantic and structural relations between tasks which permits better and more accurate identification of services. Moreover, the proposed method considers the principles of service design such as internal cohesion of service methods, loose coupling of services, and reusability of the identified services.",JWE,2022,,21,3,,569-607,2,1,https://ieeexplore.ieee.org/document/10247203/
Two-Stage Detection of Semantic Redundancies in RDF Data,Yiming Chen | Daiyi Li | Li Yan | Zongmin Ma,"Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China",RDF redundancy | duplicate data | RDF similarity | candidate selection,"With the enrichment of the RDF (resource description framework), integrating diverse data sources may result in RDF data duplication. Failure to effectively detect the duplicates brings redundancies into the integrated RDF datasets. This not only increases unnecessarily the size of the datasets, but also reduces the dataset quality. Traditionally a similarity calculation is applied to detect if a pair of candidates contains duplicates. For massive RDF data, a simple similarity calculation may lead to extremely low efficiency. To detect duplicates in the massive RDF data, in this paper we propose a detection approach based on RDF data clustering and similarity measurements. We first propose a clustering method based on locality sensitive hashing (LSH), which can efficiently select candidate pairs in RDF data. Then, a similarity calculation is performed on the selected candidate pairs. We finally obtain the duplicate candidates. We show through experiments that our approach can quickly extract the duplicate candidates in RDF datasets. Our approach had the highest $F$ score and time performance in the OAEI (Ontology Alignment Evaluation Initiative) 2019 competition.",JWE,2022,,21,8,,2313-2337,2,2,https://ieeexplore.ieee.org/document/10247350/
Quality Enhancement of 3D Volumetric Contents Based on 6DoF for 5G Telepresence Service,Byung-Seo Park | Woosuk Kim | Jin-Kyum Kim | Dong-Wook Kim | Young-Ho Seo,"Kwangwoon University, Korea | Kwangwoon University, Korea | Kwangwoon University, Korea | Kwangwoon University, Korea | Kwangwoon University, Korea",5G telepresence | web-based graphics | point cloud | 3D reconstruction | RGB-D | illumination compensation | color correction,"In general, the importance of 6DoF (degree of freedom) 3D (dimension) volumetric contents technology is emerging in 5G (generation) telepresence service, Web-based (WebGL) graphics, computer vision, robotics, and next-generation augmented reality. Since it is possible to acquire RGB images and depth images in real-time through depth sensors that use various depth acquisition methods such as time of flight (ToF) and lidar, many changes have been made in object detection, tracking, and recognition research. In this paper, we propose a method to improve the quality of 3D models for 5G telepresence by processing images acquired through depth and RGB cameras on a multi-view camera system. In this paper, the quality is improved in two major ways. The first concerns the shape of the 3D model. A method of removing noise outside the object by applying a mask obtained from a color image and a combined filtering operation to obtain the difference in depth information between pixels inside the object were proposed. Second, we propose an illumination compensation method for images acquired through a multi-view camera system for photo-realistic 3D model generation. It is assumed that the three-dimensional volumetric shooting is done indoors, and the location and intensity of illumination according to time are constant. Since the multi-view camera uses a total of 8 pairs and converges toward the center of space, the intensity and angle of light incident on each camera are different even if the illumination is constant. Therefore, all cameras take a color correction chart and use a color optimization function to obtain a color conversion matrix that defines the relationship between the eight acquired images. Using this, the image input from all cameras is corrected based on the color correction chart. It was confirmed that the quality of the 3D model could be improved by effectively removing noise due to the proposed method when acquiring images of a 3D volumetric object using eight cameras. It has been experimentally proven that the color difference between images is reduced.",JWE,2022,,21,3,,729-750,2,1,https://ieeexplore.ieee.org/document/10247209/
SPARQL Generation with an NMT-Based Approach,Jia-Huei Lin | Eric Jui-Lin Lu,"National Chung Hsing University, Taichung, Taiwan (R.O.C.) | National Chung Hsing University, Taichung, Taiwan (R.O.C.)",SPARQL generation | neural machine translation | question answering | transformer,"SPARQL is a powerful query language which has been widely used in various natural language question answering (QA) systems. As the advances of deep neural networks, Neural Machine Translation (NMT) models are employed to directly translate natural language questions to SPARQL queries in recent years. In this paper, we propose an NMT-based approach with Transformer model to generate SPARQL queries. Transformer model is chosen due to its relatively high efficiency and effectiveness. We design a format to encode a SPARQL query into a simple sequence with only RDF triples reserved. The main purpose of this step is to shorten the sequences and reduce the complexity of the target language. Moreover, we employ entity type tags to further resolve mistranslated problems. The proposed approach is evaluated against three open-domain question answering datasets (QALD-7, QALD-8, and LC-QuAD) on BLEU score and accuracy, and obtains outstanding results (83.49%, 90.13%, and 76.32% on BLEU score, respectively) which considerably outperform all known studies.",JWE,2022,,21,5,,1471-1490,2,4,https://ieeexplore.ieee.org/document/10246950/
A Semantic OctoMap Mapping Method Based on CBAM-PSPNet,Xiaogang Ruan | Peiyuan Guo | Jing Huang,"Faculty of Information Technology, Beijing University of Technology, Beijing, China | Faculty of Information Technology, Beijing University of Technology, Beijing, China | Faculty of Information Technology, Beijing University of Technology, Beijing, China",SLAM | semantic mapping | OctoMap | semantic segmentation,"With the rapid development of computer vision and deep learning, researchers have begun to focus on the semantic characteristics of traditional Simultaneous Localization And Mapping in three-Dimensional scenes. The point cloud map generated by the traditional simultaneous localization and mapping method takes up considerable storage space and cannot extract semantic information from the scene, which cannot meet the requirements of intelligent robot navigation and high-level semantic understanding. To solve this problem, this paper proposes a semantic information fusion OctoMap method. First, the color and depth images obtained from RGB-D by ORB-SLAM2 are used to locate the camera. Second, the Convolutional Block Attention Module-Pyramid Scene Parsing Network is introduced to segment the input RGB image semantically to improve the segmentation accuracy and obtain high-level semantic information in the environment. Then, a semantic fusion algorithm based on Bayesian fusion is introduced to fuse multiview semantic information. Finally, the generated semantic point cloud is inserted into OctoMap, and its octree data structure is used to compress the storage space. Experimental results based on the ADE20K dataset show that, compared with Pyramid Scene Parsing Network, Convolutional Block Attention Module-Pyramid Scene Parsing Network improves Mean Pixel Accuracy by 2.55%, and Mean Intersection over Union by 1.88%. Experimental results based on the TUM dataset show that the proposed method greatly reduces storage space and achieves the effect of voxels by voxel dense semantic mapping compared with point clouds and a traditional OctoMap.",JWE,2022,,21,3,,879-910,2,4,https://ieeexplore.ieee.org/document/10247117/
Semantic Relation Extraction from Cultural Heritage Archives,Watchira Buranasing | Woraphon Lilakiataskun,"Faculty of Information Sciences and Technology, Mahanakorn university of technology, Bangkok, Thailand | Faculty of Information Sciences and Technology, Mahanakorn university of technology, Bangkok, Thailand",Digital archive | relation extraction | cultural archive | word vector representation | information extraction,"Digital preservation technologies are now being increasingly adopted by cultural heritage organizations. This cultural heritage data is often disseminated in the form of digital text through a variety of channels such as Wikipedia, cultural heritage archives, etc. To acquire knowledge from digital data, the extraction technique becomes an important part. However, in the case of digital text, which has characteristics such as ambiguity, complex grammar structures such as the Thai language, and others, it makes it more challenging to extract information with a high level of accuracy. We thus propose a method for improving the performance of data extraction techniques based on word features, multiple instance learning, and unseen word mapping. Word features are used to improve the quality of word definition by concatenating parts of speech (POS) and word position is used to establish the accurate definition of a word and convert all of this into a vector. In addition, we use multiple instance learning to solve issues where words do not fully express the meaning of the triple. We also cluster the particular word to find the predicate word by removing words that are irrelevant between the subject and the object. The difficulty of having a new set of words that have never been trained before can be overcome by using unseen word mapping with subword and nearest neighbor word mapping. We conducted several experiments on a cultural heritage knowledge graph to show the efficacy of the proposed method. The results demonstrated that our proposed technique outperforms existing models currently utilized in relation to extraction systems. It can achieve excellent accuracy since its precision, recall, and F1 score are 0.89, 0.88, and 0.89, respectively. Furthermore, it also performed well in terms of unseen word prediction, precision, recall, and F1 score, which were 0.81, 0.87, and 0.84, respectively.",JWE,2022,,21,4,,1081-1102,2,1,https://ieeexplore.ieee.org/document/10246925/
Identifying the Facilitating Factors for Web-Based Trading: A Case Study of Blockchain & Cryptocurrency,Sang Hoon Lee | Hyun-Seok Hwang | Su-Yeon Kim,"School of Computer and Information Engineering, Daegu University, Republic of Korea | Dept. of Business Administration, Hallym University, Republic of Korea | School of Computer and Information Engineering, Daegu University, Republic of Korea",Web trading | blockchain | crytocurrency | technology acceptance,"Blockchain, which is spotlighted as one of the core technologies in the Web 3.0 era, is being used as a tool for high security and decentralization. In addition, blockchain has been positioned as a core technology for services such as cryptocurrency, NFT, De-Fi, and metaverse, and has already provided high-quality services. In particular, cryptocurrency has shown rapid growth and has been receiving worldwide attention. Cryptocurrency is a web technology and has the property that it can be an investment target, and it is expected to develop further in the future. In this research, we analyzed factors influencing the intention to use cryptocurrency and structural causalities among the factors. We considered personal characteristics, characteristics of cryptocurrency itself, and social characteristic, and a research model has been established for an empirical study. In addition, a multi-group analysis was performed to identify differences between users and non-users. As a result of the analysis, it was found that some of the personal characteristics and cryptocurrency characteristics affect the intention to use. And in the case of non-users, it was found that not only personal and cryptocurrency characteristics, but also social characteristic influence their intention to use. The results of this research are expected to provide implications for cryptocurrency service providers and users, as well as institutions that establish related policies.",JWE,2022,,21,6,,1767-1792,2,2,https://ieeexplore.ieee.org/document/10247162/
Publisher Side Profit Optimization Using Adaptive Keyword Weighted Sponsored Search Technique,Shikha Gupta | Atul Mishra,"JC Bose University of Science and Technology, YMCA, Faridabad, Haryana, India | JC Bose University of Science and Technology, YMCA, Faridabad, Haryana, India",Real-time | keyword-based search | sponsored search | keywords | bid term | bid price | bid period | online advertisement,"One of the most prominent fields of online advertising is Sponsored search and for various search engines, it acts as one of the main sources of revenue. This paper focuses on sponsored links displayed to the user along with search results when a query is fired by the user. Bidding on keywords is done by the advertiser for the expected future queries and accordingly, payment is done if clicked. A novel technique is proposed in this paper which aims to maximize the revenue earned by a search engine by using an Adaptive keyword weighted approach. Normally, the advertisers focus on keywords with a high frequency which leads to underexplored revenue of search engines. The approach proposed in this paper assigns weight to the keywords based on their winning probability. It also merges the assigned weight with the rarity factor leading to more revenue. With this approach, advertisers with relevant keywords which are rare are explored even if the bid value is low. Experimental results are shown in this paper for proving the improvements over the generalized balance algorithm.",JWE,2022,,21,5,,1449-1469,2,2,https://ieeexplore.ieee.org/document/10246927/
Multi-Granularity Decomposition of Componentized Network Applications Based on Weighted Graph Clustering,Ziliang Wang | Fanqin Zhou | Lei Feng | Wenjing Li | Tingting Zhang | Sheng Wang | Ying Li,"State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China | State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China | State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China | State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China | China Mobile Research Institute, Beijing, China | China Mobile Research Institute, Beijing, China | China Mobile Research Institute, Beijing, China",Componentized network application | weighted graph clustering | density peak clustering | multi-granularity task decomposition,"With the development of mobile communication and network technology, smart network applications are experiencing explosive growth. These applications may consume different types of resources extensively, thus calling for the resource contribution from multiple nodes available in probably different network domains to meet the service quality requirements. Task decomposition is to set the functional components in an application in several groups to form subtasks, which can then be processed in different nodes. This paper focuses on the models and methods that decompose network applications composed of interdependent components into subtasks in different granularity. The proposed model characterizes factors that have important effects on the decomposition, such as dependency level, expected traffic, bandwidth, transmission delay between components, as well as node resources required by the components, and a density peak clustering (DPC) -based decomposition algorithm is proposed to achieve the multi-granularity decomposition. Simulation results validate the effect of the proposed approach on reducing the expected execution delay and balancing the computing resource demands of subtasks.",JWE,2022,,21,3,,815-844,2,1,https://ieeexplore.ieee.org/document/10243624/
Botnet Attack Detection Using A Hybrid Supervised Fast-Flux Killer System,Ahmad Al-Nawasrah | Ammar Almomani | Huthaifa A. Al-Issa | Abdulellah A. Alaboudi | Khalid Alissa | Ayat Alrosan | Brij B. Gupta,"Information and communication technology college, British university of Bahrain | IT-department, Al-Huson University College, Al-Balqa Applied University, United Arab Emirates | Electrical and Electronics Engineering Department, Al-Huson University College, Al Balqa Applied University, Jordan | College of Computing and Information Technology, Shaqra University, Riyadh, KSA | Department of Networks and Communication, Saudi ARAMCO Cybersecurity Chair, College of Computer Science and Information Technology, Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia | School of Information Technology, Skyline University College, United Arab Emirates | Department of Computer Engineering, National Institute of Technology, Kurukshetra, India",Hybrid supervised fast-flux | botnet detection | DeSNN,"A Fast Flux Service Network (FFSN) domain name system method is a technique used on botnet that bot herders used to support malicious botnet actions to rapidly change the domain name IP addresses and to increase the life of malicious servers. While several methods for the detection of FFSN domains are suggested, they are still suffering from relatively low accuracy with the zero-day domain in particular. Throughout the current research, a system that's deemed new is proposed. The latter system is called (the Fast Flux Killer System) and is abbreviated as (FFKS)). It allows one to have the FF-Domains “zero-day”, via a deployment built on (ADeSNN). It is a hybrid, which consists of two stages. The online phase according to the learning outcomes from the offline phase works on detecting the zero-day domains while the offline phase helps in enhancing the classification performance of the system in the online phase. This system will be compared to a previously published work that was based on a supervised detection method using the same ADeSNN algorithm to have the FFSNs domains detected, also to show better performance in detecting malicious domains. A public data set for the impacts of the hybrid ADeSNN algorithm is employed in the experiment. When hybrid ADeSNN was used over the supervised one, the experiments showed better accuracy. The detection of zero-day fast-flux domains is highly accurate (99.54%) in a mode considered as an online one.",JWE,2022,,21,2,,179-202,2,0,https://ieeexplore.ieee.org/document/10247339/
Research Into the Security Threat of Web Application,Yanling Zhang | Ting Zhang,"School of Information Engineering, Jiaozuo University, China | School of Information Engineering, Jiaozuo University, China",Security threat | web application | improved butterfly algorithm | optimization model | SQL injection loophole,"In order to effectively analyze the security threat of web application, the security threat model of web application is established. Firstly, the main problems with web application are summarized. Secondly, the main security threat of web application are analyzed, and the corresponding optimization model is constructed. An algorithm based on the improved Butterfly Optimization Algorithm (BOA) security threat optimization model is designed. Finally, a SQL injection loophole is selected for example research, and the security threat path of web application is obtained. The results show IBOA has the advantages of high optimization accuracy, global optimization and stable solution, and average accuracy rate is 99.1% and the average recall rate is 99.1%, which shows that the model has better classification effect, therefore it has the best performance.",JWE,2022,,21,5,,1707-1726,2,0,https://ieeexplore.ieee.org/document/10246935/
A Hybrid Recommendation System Based on the Supply Chain in Social Networks,Abolfazl Zare | Mohammad Reza Motadel | Aliakbar Jalali,"Department of Management, Central Tehran Branch, Islamic Azad University, Tehran, Iran | Department of Management, Central Tehran Branch, Islamic Azad University, Tehran, Iran | Department of Computer Science, University of Maryland, Maryland, USA",Recommendation system | social networks | supply chain | artificial neural network | fuzzy logic,"With the expansion of virtual social networks, finding and recommending appropriate and favorite information and items to users is one of the severe issues in their development. To this end, recommender systems predict and recommend interests based on past behavior reviews and user preferences. However, less research has been done on people to people in social networks, and it is still based on exploring communication and friendship circles, which is generally not desirable for specialized users. Social networks include a variety of entities such as individuals, businesses, companies, and technical communications that also contain a variety of information related to the supply chain interaction, such as industries, functions, and communications between them and users. This paper provides a recommendation system framework for recommending people to people in social networks based on supply chain interactions. For this purpose, it has presented five hybrid methods based on artificial neural networks and fuzzy strategies to provide better and more accurate recommendations than basic methods. Eventually, a case study was conducted on the LinkedIn social network to show the improvements in applying this new approach to primary methods. In this regard, seven specific evaluation criteria of recommender systems have been used.",JWE,2022,,21,3,,633-659,2,9,https://ieeexplore.ieee.org/document/10247206/
Adaptive Redistribution and Replication to Improve the Responsiveness of Mobile Web Apps,Kijin An | Eli Tilevich,"Quality Tool Lab, Samsung Research, Seoul, Republic of Korea | Software Innovations Lab, Virginia Tech, United States",Mobile web apps | JavaScript | dynamic adaptation | program analysis & transformation | web frameworks | replication,"In a mobile web app, a browser-based client communicates with a cloud-based server across the network. An app is statically divided into client and server functionalities, so the resulting division remains fixed at runtime. However, if such static division mismatches the current network conditions and the device's processing capacities, app responsiveness and energy efficiency can deteriorate rapidly. To address this problem, we present Communicating Web Vessels (CWV), an adaptive redistribution and replication framework that improves the responsiveness of full-stack JavaScript mobile apps. Unlike standard computation offloading, in which client functionalities move to run on the server, CWV's redistribution is bidirectional. Without any preprocessing, CWV enables apps to move any functionality from the server to the client and vice versa at runtime, thus adapting to the ever-changing execution environment of the web. Having moved to the client, former server functionalities become regular local functions. To further improve performance, CWV can replicate server-side functionalities on the client and keep the replicas consistent. By monitoring the network, CWV determines if a redistribution or a replication would improve app performance, and then analyzes, transforms, sandboxes, moves, or replicates functions and program state at runtime. An evaluation with third-party mobile web apps shows that CWV optimizes their performance for dissimilar network conditions and client devices. As compared to their original versions, CWV-powered web apps improve their performance (i.e., latency, energy consumption), particularly when executed over limited networks. 11This article is a revised and extended version of our prior paper, published in the 21st International Conference on Web Engineering (ICWE 2021) [9].",JWE,2022,,21,6,,1981-2010,2,0,https://ieeexplore.ieee.org/document/10246939/
Ethical Use of Web-Based Welfare Technology for Caring Elderly People Who Live Alone in Korea: A Case Study,Soyun Choi | Kyungsook Kim | Chayapol Kamyod | Cheong Ghil Kim,"Dept. of Social Welfare, Namseoul University, South Korea | Dept. of Nursing, Namseoul University, South Korea | Computer and Communication Engineering for Capacity Building Research Center, School of Information Technology, Mae Fah Luang University, Chiang Rai, Thailand | Dept. of Computer Science, Namseoul University, South Korea",Welfare technology | ethical indicators | IoT | AI | elderly people who live alone | community care,"This study examined ethical ways to use welfare technology in a situation where the demand for non-face-to-face welfare services using Cloud based healthcare systems had increased rapidly in caring for elderly people who live alone. Through focus group interviews with social workers related to the care of elderly people who live alone, in-depth interviews were conducted on the current situation, problems, ethical issues, and development directions arising in the implementation of welfare technology. The main areas of interest were focused on improving safety in caring them using IoT technology and enhancing emotional support in preventing lonely deaths using companion robot and AI speaker. Issues such as the need for individualization, client-centeredness, privacy, self-determination, competence, informed consent, right to know, convenience, and advocacy were identified as important ethical considerations related to use of welfare technology. The research results suggested that various stakeholders should participate in the development of ethical indicators and welfare technology for the ethical use of welfare technology.",JWE,2022,,21,4,,1239-1264,2,3,https://ieeexplore.ieee.org/document/10246910/
A Systematic Mapping Study on Quality Attribute Traceability,Ehsan Sharifi | Ahmad Abdollahzadeh Barforoush | Haider S. Al Dabbagh,"Department of Computer Engineering, Amirkabir University of Technology, Tehran, Iran | Department of Computer Engineering, Amirkabir University of Technology, Tehran, Iran | Department of Computer Engineering, Amirkabir University of Technology, Tehran, Iran",Traceability | quality attribute | systematic mapping study | concept classification,"Quality attribute traceability (QAT), as a sub-discipline of software traceability, ensures that quality attributes are considered in all phases of software development. QAT is one of the most critical and challenging research areas in requirement engineering. In recent years, several studies have been conducted on quality attribute traceability. However, researchers in this field have problems to identifying the research status of this field due to the lack of a comprehensive secondary study that reveals research trends and gaps. Evidence-based software engineering (EBSE) proposes systematic mapping study (SMS) and systematic literature review (SLR) methods for secondary studies on software engineering. In this paper we use the semantically enhanced SMS method in the QAT research area. In order to improve SMS, we introduce a concept classification approach. In this approach by using a QAT domain ontology, the keywords classification process is improved. The most important innovation of this study is the presentation of the QAT research tree. This research tree has been created by gathering research topics identified in this field along with existing gaps. Identified research topics include “QAT Approach,” “QAT Development,” “QAT Model,” “QAT Framework,” and “QAT Algorithm”. The results also indicate that “QAT Frameworks” is a research trend, and most recent studies have focused on this topic. On the other hand, “Trace Maintenance” and “Trace Integrity” are the research gaps in this field. In this article, active researchers, journals, conferences and countries in the field of QAT are also introduced. We also introduce a set of tools that facilitate the SMS process.",JWE,2022,,21,6,,1853-1912,2,0,https://ieeexplore.ieee.org/document/10246945/
Integration of Computer Virtual Reality Technology to College Physical Education,Yuhuan Feng | Chong You | Yanbing Li | Ya Zhang | Qingxia Wang,"UNIVERSITAS NEGERI JAKARTA Jalan Rawamangun Muka Jakarta timur DKI, JAKARTA, Indonesia | UNIVERSITAS NEGERI JAKARTA Jalan Rawamangun Muka Jakarta timur DKI, JAKARTA, Indonesia | UNIVERSITAS NEGERI JAKARTA Jalan Rawamangun Muka Jakarta timur DKI, JAKARTA, Indonesia | School of Medicine and Science and Technology, Zunyi Medical University, China | College of Educational Science, Xinjiang Normal University, China",Virtual reality | WEB application program | Internet of Things | integration of sports and education | efficient teaching | application analysis,"The progress of the times has brought about a leap forward in people's thinking. Under the rapid economic development environment, the physical field of young people has been unable to withstand the current teaching system, and many problems of poor physical fitness have emerged. In order to solve similar problems, to improve the physical quality of young people, it is bound to find a new teaching method different from the traditional physical education teaching in a special environment, The research on the integration of virtual reality technology and teaching has been rolling forward and never stopped in recent years. With the continuous upgrading of virtual reality technology, virtual reality devices that can be used have already joined the ranks of families. Let these virtual reality devices connect to the Internet through the WEB application settings, and then design according to different situations has become a reality. This research is an application development based on Web virtual reality technology, including network virtual reality technology, application modeling design and the use of Internet connection. With reference to this application, physical education teaching and classroom practice data, this research mainly introduces the current research situation of virtual reality technology and teaching, and establishes the model based on the integration of Web application design and virtual reality technology, Extract, including but not limited to the number of projects, activities and experiences, use the Internet of Things data upload and data processing technology to complete the data screening, obtain valuable data, and then use these data for the practical application value of virtual reality technology in physical education teaching. Complete the improvement. It is in line with the integration of modern virtual reality technology and physical education teaching to obtain data that can reflect the real situation, then conduct practical teaching, obtain reliable practical data, and evaluate teaching. It can be clearly seen from the research results that the combination of virtual reality technology and physical education teaching is of great significance to improve students' interest in learning and enthusiasm for sports, but there are also some shortcomings, such as different teaching steps and goals will affect students' enthusiasm for learning. Therefore, further improvement is needed to find a stable way to improve students' enthusiasm for learning. The integration of virtual reality technology and physical education teaching is proposed.",JWE,2022,,21,7,,2049-2071,2,18,https://ieeexplore.ieee.org/document/10246951/
Enhanced Clustering Technique for Efficient Identification of Independent Groups in Social Networks,R. Srinivasan | V. Ramachandran | Nagaraju Baydeti,"Department of Computer Science and Engineering, National Institute of Technology Nagaland, Dimapur, Nagaland, India | Department of Computer Science and Engineering, DMI College of Engineering, Affiliated by Anna University, Chennai, Tamilnadu, India | Department of Computer Science and Engineering, National Institute of Technology Nagaland, Dimapur, Nagaland, India",Equivalence relation | equivalence class | social networks | social media and clustering,"The main aim of this paper is to develop a new approach for identifying independent groups among users communicating in social networks using social media applications at any instant. Grouping of users as independent clusters is of dynamic nature as communication between known and unknown users can happen randomly at any point of time. It is becoming inherent to identify the groups, where the members of the group have strong relationship who communicate frequently and consistently via social media applications. Louvain's algorithm will identify the clusters in the community detection process but keeps the lightweight nodes in the original groups without making them into one group by considering the dependence relations. The concept of Bernstein conditions is enhanced and applied to identify the dependency among the users of social networks by formulating equivalence relations, which adhere to the properties of Reflexivity, Symmetricity and Transitivity. Then, the equivalence classes are identified which denote the individual groups of clusters where the users of one cluster are loosely coupled with the users of any other cluster but tightly coupled among the users of the same group. The strength of relationship among the users within the same and different clusters is identified with respect to the quantum of messages being propagated among the users using Louvain's algorithm and the results of equivalence class approach are compared using the same set of communication sequences to show the relation dependency among the members in various clusters.",JWE,2022,,21,7,,2011-2032,2,0,https://ieeexplore.ieee.org/document/10246953/
Automatic Evaluation and Comparison of Pub/Sub Systems Performance Improvements,Víctor Rampérez | Javier Soriano | David Lizcano | Carlos Miguel,"Universidad Politécnica de Madrid (UPM), Madrid, Spain | Universidad Politécnica de Madrid (UPM), Madrid, Spain | Madrid Open University (UDIMA), Madrid, Spain | Universidad Politécnica de Madrid (UPM), Madrid, Spain",Content-based | publish/subscribe | workload generator | elasticity,"Event-driven architectures are becoming more prevalent recently in multiple technological paradigms, especially in web applications, with message brokers being the cornerstone of these architectures. One of the most relevant implementations of these message brokers are content-based publish/subscribe systems. The performance of these systems is a critical factor for web engineering, since the web applications they support need to be reactive despite increases and fluctuations in workloads. However, an obstacle to the research of these systems is the lack of real and publicly available workloads, due to the privacy issue involved in disclosing the interests (subscriptions) of users and other commercial interests of the companies. In this paper we present a parameterizable automated system designed to syntactically translate workloads from different content-based publish/subscribe systems as a means to increase the availability of public workloads to solve the aforementioned problem. As a case study, we describe the evolution of a context-aware content-based publish/subscribe system (i.e. E-SilboPS) designed by the authors, which improves up to 5 times the performance of its previous version by reaching the maximum throughput limited by the physical resources of the hardware where it is deployed, as demonstrated by the conducted quantitative evaluation. Then, we validate the utility of the proposed automated workload generation system by using it to make the performance comparison between this new version E-SilboPS and one of the most cited publish/subscribe systems called PADRES, through a real trace of a massively multiplayer online game (MMOG) generated by the latter.",JWE,2022,,21,4,,1055-1080,2,5,https://ieeexplore.ieee.org/document/10246918/
Integrated-Block: A New Combination Model to Improve Web Page Segmentation,Saeedeh Sadat Sajjadi Ghaemmaghami | James Miller,"University of Alberta, Canada | University of Alberta, Canada",Web page analysis | web page segmentation | semantic text similarity | Gestalt law of grouping,"Context: Web page segmentation methods have been used for different purposes such as web page classification and content analysis. These methods categorize a web page into different blocks, where each block contains similar components. Objective: The goal of this paper is to propose a new segmentation approach that semantically segments web pages into integrated blocks and obtains high segmentation accuracy. Method: In this paper, we propose a new segmentation model that semantically segments web pages into integrated blocks, where (1) it merges web page content into basic-blocks by simulating human perception using Gestalt laws of grouping; and, (2) it utilizes semantic text similarity to identify similar blocks and regroup these similar basic-blocks as integrated blocks. Results: To verify the accuracy of our approach, we (1) applied it to three datasets, (2) compared it with the five existing state-of-the-art algorithms. The results show that our approach outperforms all the five comparison methods in terms of precision, recall, F-1 score, and ARI. Conclusion: In this paper, we propose a new segmentation model and apply it to three datasets to (1) generate basic-blocks by simulating human perception to segment a web page, (2) identify semantically related blocks and regroup them as an integrated block, and (3) address limitations found in existing approaches.",JWE,2022,,21,4,,1103-1144,2,2,https://ieeexplore.ieee.org/document/10246922/
Time-Sensitive Satellite Internet Based on Uniform Content Labels,Jie Shen | Wenqi Dong | Jing Wang | Peng Zang | Xuewei Shi | Yang Wang,"State Grid Jibei Zhangjiakou Wind and Solar Energy Storage and Transportation New Energy Co., Ltd, China | State Grid Jibei Zhangjiakou Wind and Solar Energy Storage and Transportation New Energy Co., Ltd, China | State Grid Jibei Zhangjiakou Wind and Solar Energy Storage and Transportation New Energy Co., Ltd, China | State Grid Jibei Zhangjiakou Wind and Solar Energy Storage and Transportation New Energy Co., Ltd, China | State Grid Jibei Zhangjiakou Wind and Solar Energy Storage and Transportation New Energy Co., Ltd, China | State Grid Jibei Zhangjiakou Wind and Solar Energy Storage and Transportation New Energy Co., Ltd, China",Uniform content label | satellite internet | time-sensitive network,"For satellite Internet the content was examined by location and time of day, as well as within the context of online social networks. The ground Information-Centric Networking (ICN) is a paradigm shift from host-to-host Internet Protocol (IP)-based communication to content-based communication. With the development and universal application of satellite technology, an important way to expand the function of satellites is setting up intersatellite networks to make them work together. The Internet and the Global Positioning System are based on the dual structure network and the Uniform Content Label UCL national standard. Through the integration of these two inventions, the integration of time and space is realized, creating an endogenous security environment of both mathematics and physics that is self-consistent in cyberspace, is expected to bring a breakthrough in principle for cracking network security challenges.",JWE,2022,,21,2,,523-544,2,2,https://ieeexplore.ieee.org/document/10251087/
Parsimonious Approach to in Analyzing Brainwaves for VR Users,Gi-Sung Oh | Won-06 Jeong | Sung-Jin Cho | Seok-Hee Oh,"Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea | Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea | Department of Psychiatry, Gachon University, Gil Medical Center, Incheon, Republic of Korea | Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea",VR sickness | EEG | SSQ | PCA | test of independence,"For the development of virtual reality (VR) technology, research to solve the VR Sickness is essential. Many attempts have been made to measure and reduce VR Sickness using questionnaires, analysis, and bio-signals, but it is true that analytical research through clinical practice still lacks. In this paper, the researcher collected bio-signals and questionnaire data to analyze the correlation between VR Sickness and user and perform principal component analysis and chi-square independence test based on the collected data. As a result, the researcher was able to be aware of the user's concentration and relaxation state by EEG and found they are correlated with VR Sickness. Finally, the result of the analysis was cross-checked to confirm that these correlations show a significant difference. The empirical result of this study is expected to be used for the research to reduce VR Sickness through bio-signal.",JWE,2022,,21,5,,1651-1670,2,1,https://ieeexplore.ieee.org/document/10247159/
Fine-Grained Web Service Trust Detection: A Joint Method of Machine Learning and Blockchain,Ruizhong Du | Yan Gao | Cui Liu,"School of Cyber Security and Computer, Hebei University, Baoding, China | School of Cyber Security and Computer, Hebei University, Baoding, China | School of Cyber Security and Computer, Hebei University, Baoding, China",Website defacement | trusted detection | naive Bayes | blockchain | Merkle tree,"Current website defacement detection methods often ignore security and credibility in the detection process. Furthermore, with the gradual development of dynamic websites, false positives and underreports of website defacement have periodically occurred. Therefore, to enhance the credibility of website defacement detection and reduce the false-positive rate and the false-negative rate of website defacement, this paper proposes a fine-grained trust detection scheme called WebTD, that combines machine learning and blockchain. WebTD consists of two parts: an analysis layer and a verification layer. The analysis layer is the key to improving the success rate of website defacement detection. This layer mainly uses the naive Bayes (NB) algorithm to decouple and segment different types of web page content, and then preprocess the segmented data to establish a complete analysis model. Second, the verification layer is the key to establishing a credible detection mechanism. WebTD develops a new blockchain model and proposes a multi-value verification algorithm to achieve a multilayer detection mechanism for the blockchain. In addition, to quickly locate and repair the defaced data of the website, the Merkle tree (MT) algorithm is used to calculate the preprocessed data. Finally, we evaluate WebTD against two state-of-the-art research schemes. The experimental results and the security analysis show that WebTD not only establishes a credible web service detection mechanism but also keeps the detection success rate above 98%, which can effectively ensure the integrity of the website.",JWE,2022,,21,5,,1519-1542,2,2,https://ieeexplore.ieee.org/document/10246934/
A Memory-Driven Neural Attention Model for Aspect-Based Sentiment Classification,Jonathan van de Ruitenbeek | Flavius Frasincar | Gianni Brauwers,"Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands | Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands | Erasmus School of Economics, Erasmus University Rotterdam, Rotterdam, the Netherlands",Aspect sentiment classification | sentiment analysis | deep learning | attention models,"Sentiment analysis techniques are becoming more and more important as the number of reviews on the World Wide Web keeps increasing. Aspect-based sentiment analysis (ABSA) entails the automatic analysis of sentiments at the highly fine-grained aspect level. One of the challenges of ABSA is to identify the correct sentiment expressed towards every aspect in a sentence. In this paper, a neural attention model is discussed and three extensions are proposed to this model. First, the strengths and weaknesses of the highly successful CABASC model are discussed, and three shortcomings are identified: the aspect-representation is poor, the current attention mechanism can be extended for dealing with polysemy in natural language, and the design of the aspect-specific sentence representation is upheld by a weak construction. We propose the Extended CABASC (E-CABASC) model, which aims to solve all three of these problems. The model incorporates a context-aware aspect representation, a multi-dimensional attention mechanism, and an aspect-specific sentence representation. The main contribution of this work is that it is shown that attention models can be improved upon using some relatively simple extensions, such as fusion gates and multi-dimensional attention, which can be implemented in many state-of-the-art models. Additionally, an analysis of the parameters and attention weights is provided.",JWE,2022,,21,6,,1793-1830,2,0,https://ieeexplore.ieee.org/document/10246940/
Spatial Path Selection and Network Topology Optimisation in P2P Anonymous Routing Protocols,Aleksandar Tošić | Jernej Vičič,"Faculty of Mathematics, Natural Sciences and Information Technologies, University of Primorska, Koper, Slovenia | Faculty of Mathematics, Natural Sciences and Information Technologies, University of Primorska, Koper, Slovenia",Lokinet | anonymous routing protocol | geo-sharding | fault tolerance | oxen,"To anonymous internet traffic, many popular protocols route traffic through a network of nodes in order to conceal information about the request. However, routing traffic through other nodes inherently introduces added latency. Over the past two decades, there were many attempts to improve the path selection in order to decrease latency with little or no trade-off in terms of security, and anonymity. In this paper, we show the potential use of geo-sharding in decentralized routing networks to improve fault-tolerance, and latency. Such networks can be used as a communication layer for Edge devices computing huge amounts of data. Specifically, we focus our work on Low Latency Anonymous Routing Protocol (LLARP), a protocol built on top of Oxen blockchain that aims to achieve internet privacy. We analyse the existing network of Service Nodes(SN), observe cloud provider centralisation, and propose a high level protocol that provides incentives for a better geographical distribution mitigating potential cloud provider/country wide service dropouts. Additionally, the protocol level information about geographical location can be used to improve client's path (the string of nodes that will participate in the transaction) selection, decreasing network latency. We show the feasibility of our approach by comparing it with the random path selection in a simulated environment. We observe marginal drops in average latency when selecting paths geographically closer to each other.",JWE,2022,,21,1,,97-118,2,0,https://ieeexplore.ieee.org/document/10243629/
Mining Simple Path Traversal Patterns in Knowledge Graph,Feng Xiong | Hongzhi Wang,"Department of Computer Science, Harbin Institute of Technology, China | Department of Computer Science, Harbin Institute of Technology, China",Knowledge graph | path traversal | data mining,"The data mining has remained a subject of unfailing charm for research. The knowledge graph is rising and showing infinite life force and strong developing potential in recent years, where it is observed that acyclic knowledge graph has capacity for enhancing usability. Though the development of knowledge graphs has provided an ample scope for appearing the abilities of data mining, related researches are still insufficient. In this paper, we introduce path traversal patterns mining to knowledge graph. We design a novel simple path traversal pattern mining framework for improving the representativeness of result. A divide-and-conquer approach of combining each path is proposed to discover the most frequent traversal patterns in knowledge graph. To support the algorithm, we design a linked list structure indexed by the length of sequences with handy operations. The correctness of algorithm is proven. Experiments show that our algorithm reaches a high coverage with low output amounts compared to existing frequent sequence mining algorithms.",JWE,2022,,21,2,,307-336,2,2,https://ieeexplore.ieee.org/document/10247352/
Identification and Classification of Risk Factors in Distributed Agile Software Development,Esha Khanna | Rashmi Popli | Naresh Chauhan,"Computer Engineering, J. C. Bose University of Science and Technology, YMCA, Faridabad, Haryana, India | Computer Engineering, J. C. Bose University of Science and Technology, YMCA, Faridabad, Haryana, India | Computer Engineering, J. C. Bose University of Science and Technology, YMCA, Faridabad, Haryana, India",Risk management | distributed agile software development | agile software developments | distributed software development,"Distributed Agile Software Development (DASD) is an amalgamation of Agile Software Development (ASD) with Distributed Software Development (DSD). Although DASD integrates the speed benefits of ASD with the cost benefits of DSD, however, it brings along various risk factors that arise due to the fact that both ASD and DSD works on a different set of principles. These associated risks must be addressed and managed well in time for the successful completion of the project. This paper reviews the current literature and presents the current challenges of Risk Management in the DASD environment. This paper also determines 71 risk factors associated with DASD and analyses them based on their causes and sources. Further, these risk factors are segregated into 11 different categories. Timely management of these risks may reduce the uncertainty of project failure in the DASD environment.",JWE,2022,,21,6,,1831-1851,2,6,https://ieeexplore.ieee.org/document/10246944/
A Multi-Source Information Graph-Based Web Service Recommendation Framework for a Web Service Ecosystem,Zhixuan Jia | Yushun Fan | Jia Zhang | Xing Wu | Chunyu Wei | Ruyu Yan,"Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Department of Computer Science, Southern Methodist University, TX, USA | Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China",Web service recommendation | web service ecosystem | multisource information | deep learning | graph neural networks | attention mechanism,"Web service recommendation remains a highly demanding yet challenging task in the field of services computing. In recent years, researchers have started to employ side information comprised in a heterogeneous Web service ecosystem to address the issues of data sparsity and cold start in Web service recommendation. Some recent works have exploited the deep learning techniques to learn user/Web service representations accumulating information from multiplex sources. However, we argue that they still struggle to utilize multi-source information in a discriminating, unified and flexible manner. To tackle this problem, this paper presents a novel multi-source information graph-based Web service recommendation framework (MGASR), which can automatically and efficiently extract multifaceted knowledge from the heterogeneous Web service ecosystem. Specifically, different node-type and edge-type dependent parameters are designed to model corresponding types of objects (nodes) and relations (edges) in the Web service ecosystem. We then leverage graph neural networks (GNNs) with an attention mechanism to construct a multi-source information neural network (MIN) layer, for mining diverse significant dependencies among nodes. By stacking multiple MIN layers, each node can be characterized by a highly contextualized representation due to capturing high-order multi-source information. As such, MGASR can generate representations with rich semantic information toward supporting Web service recommendation tasks. Extensive experiments conducted over three real-world Web service datasets demonstrate the superior performance of our proposed MGASR as compared to various baseline methods.",JWE,2022,,21,8,,2287-2312,2,6,https://ieeexplore.ieee.org/document/10247356/
A Defensive Framework for Reflected XSS in Client-Side Applications,Khulud Fisal Alenzi | Onytra Abbas Bashir Abbase,"Department of Information Technology, University of Tabuk, Kingdom of Saudi Arabia | Department of Computer Science, University of Tabuk, Kingdom of Saudi Arabia",Cross-site scripting | XSS | XSS filters | filtering rules | XSSFilter,"Cross-site scripting attack (XSS) is a common vulnerability that is exploited in modern web applications by entering advanced HTML tags and Java Script functions. An attacker could potentially use this vulnerability to steal users' sensitive information, hijack user sessions or rewrite whole website contents displaying fake login forms. This class of attacks affects the client-side of a web application and is a critical vulnerability that is difficult to both detect and remediate for websites, often leading to insufficient server-side protection, which is why the end-users need an extra layer of protection at the client-side. In this paper, we analyze the best-known client-side XSS filters, study their mechanisms, structures and mentioned the advantages and disadvantages of each filter. This paper presents a novel XSS filtering model based on filtering rules, XSSFilter, uses Regular Expression in Xpath to detect reflected content, which makes it more robust for web sites that employ custom input sanitizations. We provide a detailed experimental evaluation to compare the four filters with respect to their usability and protection.",JWE,2022,,21,7,,2209-2229,2,3,https://ieeexplore.ieee.org/document/10246948/
A Semantic Similarity Measure for Scholarly Document Based on the Study of n-gram,Yannick-Ulrich Tchantchou Samen,"Department of Mathematic and Computer Science, Faculty of Science, University of Maroua, Maroua, Cameroon",Semantic similarity | n-gram | natural language processing | scholarly document | similarity measure,"The performance of information retrieval systems is closely related to the ability of similarity measures to accurately determine the similarity value between documents or between a query and a document. In this paper, the issue of similarity measures in the context of scholarly documents is addressed. A semantic similarity measure is proposed. This similarity measure is able to exploit the metadata contained in the scientific articles, as well as the important n-grams identified in them. To evaluate the accuracy of our similarity measure, a dataset of articles is built as well as their similarity values manually estimated by human experts. Experiments performed on this dataset using Pearson correlation show that the similarity values obtained using the proposed measure are very close to those estimated by human experts.",JWE,2022,,21,7,,2095-2113,2,2,https://ieeexplore.ieee.org/document/10246956/
Local Consistency Reinforcement for Enhancing Web Service Composition,Ahad AlQabasani | Ahlem Ben Hassine | Arif Bramantoro | Asma AlMunchi,"CS-AI Department, College of Computer, Science and Engineering, University of Jeddah, Saudi Arabia | CS-AI Department, College of Computer, Science and Engineering, University of Jeddah, Saudi Arabia | School of Computing and Informatics, Universiti Teknologi Brunei, Bandar Seri Begawan, Brunei Darussalam | Cyber-Security Department, College of Computer, Science and Engineering, University of Jeddah, Saudi Arabia",Arc-consistency | constraint problems | NP-complete | web service composition | ontology web language for web services,"Composing Web services to fulfill a user query remains one of the most challenging research problems due to its importance to the world economy. Several composition techniques have been proposed, but these techniques are becoming more and more expensive due to the tremendous growth of data over the internet, the intensive use of services, and the continuous changes of available services. The workflow-based Web service composition problem is an NP-complete problem, due mainly to the property of the workflow structuring the composition and the diversity of underlying constraints. Reinforcing local consistency is one of the well-known pre-processing techniques to reduce the complexity of most NP-complete problems. These techniques are mainly dedicated to binary constraint satisfaction problems. Therefore, only few researchers devoted their efforts toward reinforcing some level of local consistency on Web service composition problems that can be semantically defined in the Ontology Web Language for Web Services (OWL-S) control structure based constraints. The main goal of this paper is to propose a novel approach for reinforcing a reasonable level of local consistency, node and arc-consistency on any Web service composition problems. It is expected to provide a more up-to-date and realistic representation of any Web service composition problems without any user interactions, but with the ability to cope with any types of user's query, such as incomplete, ambiguous, and others. This is due to the existence of several novel rules for reinforcing node and arc-consistency on all types of control structure constraints. Experiments were performed on random problems of different levels of complexity to evaluate the performance of the proposed approach.",JWE,2022,,21,4,,989-1016,2,2,https://ieeexplore.ieee.org/document/10246919/
RealTE: Real-time Trajectory Estimation Over Large-Scale Road Networks,Qibin Zhou | Qingang Su | Dingyu Yang,"School of International Education, Shanghai Jian Qiao University, Shanghai, China | School of Kaiserslautern Intelligent Manufacturing, Shanghai Dian Ji University, Shanghai, China | Alibaba Group, Shanghai, China, School of Electronics and Information, Shanghai Dian Ji University, Shanghai, China",Trajectory prediction | road network partition | histogram estimation,"Real-time traffic estimation focuses on predicting the travel time of one travel path, which is capable of helping drivers selecting an appropriate or favor path. Statistical analysis or neural network approaches have been explored to predict the travel time on a massive volume of traffic data. These methods need to be updated when the traffic varies frequently, which incurs tremendous overhead. We build a system RealTE, implemented on a popular and open source streaming system Storm to quickly deal with high speed trajectory data. In RealTE, we propose a locality-sensitive partition and deployment algorithm for a large road network. A histogram estimation approach is adopted to predict the traffic. This approach is general and able to be incremental updated in parallel. Extensive experiments are conducted on six real road networks and the results illustrate RealTE achieves higher throughput and lower prediction error than existing methods. The runtime of a traffic estimation is less than 1 seconds over a large road network and it takes only 619 microseconds for model updates.",JWE,2022,,21,2,,365-390,2,0,https://ieeexplore.ieee.org/document/10247335/
Special Issue on Advances in Web Data Provenance for Mitigation of Web Application Security Risks,,,,"With the ever-growing increase in data intensive web applications, security risks are also ramping up. Web data need to be authenticated and reliable, before its use. Data Provenance-aware methods are capable of identification of data breaches and manipulation through various attacks. It analyses underlying data for the potential threats to ensure protection against various attacks.",JWE,2022,,21,4,,v-v,2,0,https://ieeexplore.ieee.org/document/10246864/
Document Engineering Special Issue,Steve Simske,"Colorado State University, USA",,"Welcome to the Journal of Web Engineering (JWE) special issue on document engineering. Thanks to River Publishers, and especially Karen Donnison for managing the issue and Nicki Dennis for encouraging the topic, for making this possible. This special issue is focused on document engineering, a topic which garners its own symposium each year (the ACM DocEng Symposium) and features the engineering of content for consumption in a wide variety of media and multimedia, ranging from security labels to dynamic web sites. Obviously, engineering documents for the web is an important element of this symposium, and so a partnership between this symposium and JWE was a natural choice. Authors from the past year of the conference and their colleagues were encouraged to submit research works for review by JWE editors and reviewers, and three papers were down-selected for this special issue.",JWE,2022,,21,7,,v-vi,2,0,https://ieeexplore.ieee.org/document/10246947/
Introduction to the ICWE 2022 Special Issue,Tommaso Di Noia | In-Young Ko | Markus Schedl,"Polytechnic University of Bari, Italy | Korea Advanced Institute of Science and Technology, South Korea | Johannes Kepler University, Linz Institute of Technology, Linz, Austria",International Conference on Web Engineering | ICWE 2022 | invited papers | Web engineering | compression | efficiency | machine learning | security | sentiment classification | feature selection,"The International Conference on Web Engineering (ICWE) is the premier annual conference on Web engineering and associated technologies. ICWE aims to bring together researchers and practitioners from various disciplines in academia and industry to tackle the emerging challenges in the engineering of Web applications, the problems with its associated technologies, and the impact of those technologies on society and culture. ICWE 2022 took place in Bari, Italy on 5-8 July 2022. All sessions of the conference were also offered to online participants. This special issue includes extended articles of the best papers presented at ICWE 2022.",JWE,2023,,22,1,,v-viii,2,0,https://ieeexplore.ieee.org/document/10261418/
A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model,Daeseung Park | Gi-taek An | Chayapol Kamyod | Cheong Ghil Kim,"Department of Computer Science, Namseoul University, Cheonan, Republic of Korea | Korea Food Research Institute, Wanju-gun, Republic of Korea | Computer and Communication Engineering for Capacity Building Research Center, School of Information Technology, Mae Fah Luang University, Chiang Rai, Thailand | Department of Computer Science, Namseoul University, Cheonan, Republic of Korea",AI | large language model | generative AI | few-shot learning | prompt engineering | AI Chatbot,"In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance.",JWE,2023,,22,8,,1187-1206,2,38,https://ieeexplore.ieee.org/document/10452390/
Comparison of Machine Learning Based on Category Theory,Heng Zhao | Yixing Chen | Xianghua Fu,"College of Big Data and Internet, Shenzhen Technology University, Shen Zhen, China | College of Computer Science and Software Engineering, Shenzhen University, Shen Zhen, China | College of Big Data and Internet, Shenzhen Technology University, Shen Zhen, China",Web engineering | Big data | machine learning | preprocessing | category theory | accuracy,"In recent years, machine learning has been widely used in data analysis of network engineering. The increasing types of model and data enhance the complexity of machine learning. In this paper, we propose a mathematical structure based on category theory as a combination of machine learning that combines multiple theories of data mining. We aim to study machine learning from the perspective of classification theory. Category theory utilizes mathematical language to connect the various structures of machine learning. We implement the representation of machine learning with category theory. In the experimental section, slice categories and functors are introduced in detail to model the data preprocessing. We use functors to preprocess the benchmark dataset and evaluate the accuracy of nine machine learning models. A key contribution is the representation of slice categories. This study provides a structural perspective of machine learning and a general method for the combination of category theory and machine learning.",JWE,2023,,22,1,,41-54,2,1,https://ieeexplore.ieee.org/document/10261468/
The Case for Cross-entity Delta Encoding in Web Compression (Extended),Benjamin Wollmer | Wolfram Wingerath | Sophie Ferrlein | Fabian Panse | Felix Gessert | Norbert Ritter,"University of Hamburg, Germany | University of Oldenburg, Germany | Baqend, Hamburg, Gemerany | University of Hamburg, Germany | University of Hamburg, Germany | University of Hamburg, Germany",Delta encoding | caching | dictionary compression,"Delta encoding and shared dictionary compression (SDC) for accelerating Web content have been studied extensively in research over the last two decades, but have only found limited adoption in the industry so far; compression approaches that use a custom-tailored dictionary per website have all failed in practice due to lacking browser support and high overall complexity. General-purpose SDC approaches such as Brotli reduce complexity by shipping the same dictionary for all use cases, while most delta encoding approaches just consider similarities between versions of the same entity (but not between different entities). In this study, we investigate how much of the potential benefits of SDC and delta encoding are left on the table by these two simplifications. As our first contribution, we describe the idea of cross-entity delta encoding that uses cached assets from the immediate browser history for content encoding instead of a precompiled shared dictionary; this avoids the need to create a custom dictionary, but enables highly customized and efficient compression. Second, we present an experimental evaluation of compression efficiency to hold cross-entity delta encoding against state-of-the-art Web compression algorithms. We consciously compare algorithms some of which are not yet available in browsers to understand their potential value before investing resources to build them. Our results indicate that cross-entity delta encoding is over 50% more efficient for text-based resources than compression industry standards. We hope our findings motivate further research and development on this topic. The extended version of our previously published paper [10] includes an additional section on the deltas of HTML files, a more detailed description of our approach (including a new visualization for the different dictionary strategies), a deeper discussion of compression efficiency, and details on additional future and ongoing work.",JWE,2023,,22,1,,131-146,2,3,https://ieeexplore.ieee.org/document/10261476/
A Study on Visual Expression Elements and User Satisfaction in Video Streaming Services on the Web: Focusing on Video Thumbnails,Seungmin Lee,"Namseoul University, Seoul, South Korea",Web streaming | video service | thumbnail | visual elements on the web | viewing attitudes | viewing satisfaction,"With the rapid increase in the use of video services due to the development of network technology, various internet video service platforms have appeared. The consumption of these video services is expected to continue to increase. Video traffic, which accounted for 64% of Internet traffic in 2014, is expected to account for more than 81% of Internet traffic by 2022, and 86% of corporate marketers use video content in online campaigns. Users can immediately check which channel it is through the thumbnail of the video, and the click-through rate of the video changes. Therefore, thumbnails can represent images and play a role in stimulating curiosity. In this situation, this study analysed the relationship between users' attitudes and satisfaction according to the visual expression elements of video streaming service thumbnails on the web. For this purpose, a survey was conducted, with subjects in their 20s. As a result of the study, looking at the effect of visual expression elements of video thumbnails on viewing attitudes, it was found that images and typography had a significant positive (+) effect on the order of images and typography. Also, as a result of analysing the relationship between viewing attitudes and viewing satisfaction, it was found that viewing attitudes toward video had a significant positive (+) effect on viewing satisfaction. Lastly, looking at the effect of visual expression elements of YouTube thumbnails on viewer satisfaction, it was found that images and colours had a significant positive effect on the order of images and colour. It was found that the layout and typography did not have a significant effect on the satisfaction of the viewers. Through this study, we intend to present a practical and efficient application method for web content production and web marketing activities.",JWE,2023,,22,1,,27-40,2,4,https://ieeexplore.ieee.org/document/10261467/
"Deep Neural Networks-based Classification Methodologies of Speech, Audio and Music, and its Integration for Audio Metadata Tagging",Hosung Park | Yoonseo Chung | Ji-Hwan Kim,"Sogang University, Seoul, South Korea | Sogang University, Seoul, South Korea | Sogang University, Seoul, South Korea",Content retrieval | speech recognition | music detection | audio event classification | audio scene classification,"Videos contain visual and auditory information. Visual information in a video can include images of people, objects, and the landscape, whereas auditory information includes voices, sound effects, background music, and the soundscape. The audio content can provide detailed information on the story by conducting a voice and atmosphere analysis of the sound effects and soundscape. Metadata tags represent the results of a media analysis as text. The tags can classify video content on social networking services, like YouTube. This paper presents the methodologies of speech, audio, and music processing. Also, we propose integrating these audio tagging methods and applying them in an audio metadata generation system for video storytelling. The proposed system automatically creates metadata tags based on speech, sound effects, and background music information from the audio input. The proposed system comprises five subsystems: (1) automatic speech recognition, which generates text from the linguistic sounds in the audio, (2) audio event classification for the type of sound effect, (3) audio scene classification for the type of place from the soundscape, (4) music detection for the background music, and (5) keyword extraction from the automatic speech recognition results. First, the audio signal is converted into a suitable form, which is subsequently combined from each subsystem to create meta-data for the audio content. We evaluated the proposed system using video logs (vlogs) on YouTube. The proposed system exhibits a similar accuracy to handcrafted metadata for the audio content, and for a total of 104 YouTube vlogs, achieves an accuracy of 65.83%.",JWE,2023,,22,1,,Jan-26,2,9,https://ieeexplore.ieee.org/document/10261462/
Data Quality Assessment and Recommendation of Feature Selection Algorithms: An Ontological Approach,Aparna Nayak | Bojan Božić | Luca Longo,"SFI Centre for Research Training in Machine Learning, School of Computer Science, Technological University Dublin, Dublin, Republic of Ireland | SFI Centre for Research Training in Machine Learning, School of Computer Science, Technological University Dublin, Dublin, Republic of Ireland | SFI Centre for Research Training in Machine Learning, School of Computer Science, Technological University Dublin, Dublin, Republic of Ireland",Data quality | feature selection algorithm | meta-features | ontology | recommendation,"Feature selection plays an important role in machine learning and data mining problems. Identifying the best feature selection algorithm that helps to remove irrelevant and redundant features is a complex task. This research tries to address it by recommending a feature selection algorithm based on dataset meta-features. The main contribution of the work is the use of Semantic Web principles to develop a recommendation model for the feature selection algorithm. As a result, dataset meta-features are modeled in a domain ontology, and a set of Semantic Web rule language (SWRL) predictive rules have been proposed to recommend a feature selection algorithm. The result of this research is a feature selection algorithm recommendation based on the data characteristics and quality (FSDCQ) ontology, which not only helps with recommendations but also finds the data points with data quality violations. An experiment is conducted on the classification datasets from the UCI repository to evaluate the proposed ontology. The usefulness and effectiveness of the proposed method is evaluated by comparing it with the widely used method in the literature for the recommendation. Results show that the ontology-based recommendations are equally good as the widely used recommendation model, which is k-NN, with added benefits.",JWE,2023,,22,1,,175-196,2,7,https://ieeexplore.ieee.org/document/10261469/
Modified DNA-based Cryptography System in the Cloud: Deep Maxout-based Fined Tuned Key Generation,Garima Verma,"School of Computing, DIT University, Dehradun, India",Cloud security | cryptography | encryption | DNA | deep learning,"Cloud security is a set of practices and tools created to address both internal and external security threats to businesses. Organizations must have cloud security as they implement their digital transformation schemes and include cloud-based tools and services in their infrastructure. Cryptography is a mechanism for preventing illegal access to data. In this paper, modified DNA-based cryptography (MDNAC), which is defined as data hiding with respect to DNA sequence is used. The steps involved in the proposed MDNAC is: encryption and decryption with optimal key generation. A way of converting plain text into cipher text is known as encryption. Two components make up the encryption process: a key and an encryption algorithm. For the encryption algorithm, we employed a modified DNA algorithm. In the decryption phase, the reverse operation is performed to get the plain text from the cipher text. Moreover, a deep learning model is used for generating the keys; the model used is deep maxout. To ensure the appropriate key generation process, the weights of the deep maxout are optimally tuned by the new feedback assisted Archimedes optimization (FAAO) algorithm. Based on the generated keys, the encryption process takes place. Finally, the performance of MDNAC is evaluated using conventional methods with respect to different measures. Additionally, the MDNAC obtained a correlation value of 0.20297 for the mean case scenario, despite the fact that the corresponding values are 0.02%, 0.17%, 0.2%, 0.7%, 0.12%,0.41%, 0.86%, and 0.46% as compared to the other models such as FAT, AOA, BMO, COOT, BOA, SSO, WOA, and LES respectively.",JWE,2023,,22,8,,1075-1099,2,3,https://ieeexplore.ieee.org/document/10452389/
Dynamic Scale-free Graph Embedding via Self-attention,Dingyang Duan | Daren Zha | Xiao Yang | Jiahui Shen | Nan Mu,"Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China | Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China | Aerospace Internet of Things Technology Co., Ltd, Beijing, China | Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China | Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",Dynamic graphs | hyperbolic space | self-attention | representation learning,"Graph neural networks (GNNs) have recently become increasingly popular due to their ability to learn node representations in complex graphs. Existing graph representation learning methods mainly target static graphs in Euclidean space, whereas many graphs in practical applications are dynamic and evolve continuously over time. Recent work has demonstrated that realworld graphs exhibit hierarchical properties. Unfortunately, many methods typically do not account for these latent hierarchical structures. In this work, we propose a dynamic network in hyperbolic space via self-attention, referred to as DynHAT, which leverages both the hyperbolic geometry and attention mechanism to learn node representations. More specifically, DynHAT captures hierarchical information by mapping the structural graph onto hyperbolic space, and time-varying dynamic evolution by flexibly weighting historical representations. Through extensive experiments on three real-world datasets, we show the superiority of our model in embedding dynamic graphs in hyperbolic space and competing methods in a link prediction task. In addition, our results show that embedding dynamic graphs in hyperbolic space has competitive performance when necessitating low dimensions.",JWE,2023,,22,1,,55-78,2,1,https://ieeexplore.ieee.org/document/10261472/
Disclosure: Improving Performance and Security of Web App Migration in Liquid Computing,Jae-Yun Kim | Soo-Mook Moon,"Seoul National University, Seoul, Republic of Korea | Seoul National University, Seoul, Republic of Korea",Web app migration | closure | code instrumentation | liquid computing | multiple migrations | secure migration,"Web app migration refers to capturing a snapshot of the execution state of a web app on a device and restoring it on another device to continue its execution for cross-device liquid computing. Although web apps are relatively easy to migrate due to their high portability, there is a JavaScript language feature called closure that complicates the migration since it requires migrating the variable states of already-finished outer functions. One approach to web app migration is to instrument the source code to trace the closure variables, yet this often suffers from performance slowdown, especially for multiple migrations. In this paper, we propose a new instrumentation-based technique called Disclosure, which moves the declarations of closure variables to a managed data structure and replaces the closure variables with the corresponding references to the data structure. This technique can improve runtime performance while enhancing security. We evaluated our work with eight Octane benchmarks and four real web apps. The runtime performance penalty due to Disclosure is 0-15%, which is a significant improvement over the results of the latest instrumentation-based work that supports similar deep closures and multiple migrations to Disclosure. Furthermore, real web apps are demonstrated to migrate seamlessly, even multiple times. Finally, Disclosure can hide data from exposure during migration with a secure migration technique using data encryption.",JWE,2023,,22,1,,79-104,2,1,https://ieeexplore.ieee.org/document/10261475/
Managing Web-based Information Resources Under Uncertainty: A Probabilistic Approach,Asma Omri | Mohamed-Nazih Omri,"MARS Research Laboratory, University of Sousse, Tunisia | MARS Research Laboratory, University of Sousse, Tunisia",Web resources | data management | uncertainty | probabilistic approach,"“Uncertainty” is related to working with inaccurate data, imprecise and incomplete information, and unreliable results that can lead to irrational decisions. Several approaches to managing uncertain data on the Web have been proposed in the literature to resolve this problem. These approaches have failed to find the solution to this problem with accuracy and performance. Our study aims to propose a new probabilistic approach to manage Web information resources in an uncertain large-scale cloud environment. Our approach is based on three main steps: (1) modelling uncertain Web resources, (2) computing HTTP request model, and (3) interpretation and evaluation of uncertain Web resources in a context of classic hypertext navigation. The experimental study shows that the analysis of the execution time necessary for the composition of the services, by our approach, is negligible, compared to that of the other studied approaches. The algorithm that deals with the impact of the variation in the number of nodes, which we have proposed, has also been evaluated and checks all the possibilities in polynomial time and can adapt to many possibilities of multiplexing of values.",JWE,2023,,22,8,,1133-1161,2,0,https://ieeexplore.ieee.org/document/10452388/
Optimized RMDL with Transfer Learning for Sentiment Classification in the MapReduce Framework,Konda Adilakshmi | Malladi Srinivas | Anuradha Kodali | V. Srilakshmi,"Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India | Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India | Gokaraju Rangaraju Institute of Engineering and Technology (GRIET), Bachupally, Hyderabad, India | Gokaraju Rangaraju Institute of Engineering and Technology (GRIET), Bachupally, Hyderabad, India",MapReduce | deep learning | review document | AlexNet | ResNet 50,"A core task in sentiment analysis is sentiment categorization, and it is crucial to understand user feelings based on their remarks in social media or product evaluations. Due to ambiguous phrases, refusal words, and other factors, categorizing sentiment presents several challenging issues. The objective of this research is to develop a hybrid optimization-based deep learning model and MapReduce framework-based sentiment categorization approach. The review document is taken from a dataset and used in this case with the MapReduce methodology. MapReduce is a software framework and programming model for analyzing massive volumes of data that consists of two phases, mapper and reducer. BERT tokenization and aspect term extraction are executed in the mapper phase, whereas sentiment analysis is performed in the reducer stage utilizing random multimodal deep learning (RMDL) with transfer learning and AlexNet and ResNet 50 as pre-trained models. In addition, the exponential coot political algorithm (ECPA) is offered as an optimization algorithm for weight optimization in RMDL. The ECPA is obtained by combining the exponential weighted moving average model (EWMA) with the coot algorithm, as well as a political optimizer (PO). The proposed ECPA_RMDL model has acquired 90.9% precision, 89.7% recall, and 89.9% f-measure.",JWE,2023,,22,8,,1101-1132,2,0,https://ieeexplore.ieee.org/document/10452392/
Towards Adaptive Continuous Trajectory Clustering Over a Distributed Web Data Stream,Yang Wu | 06hua Fang | Pingfu Chao | Zhicheng Pan | Wei Chen | Lei Zhao,"School of Computer Science and Technology, Soochow University, China | School of Computer Science and Technology, Soochow University, China | School of Computer Science and Technology, Soochow University, China | School of Data Science and Engineering, East China Normal University, Shanghai, China | School of Computer Science and Technology, Soochow University, China | School of Computer Science and Technology, Soochow University, China",Spatio-temporal data | continuous trajectory clustering | distributed stream processing | trajectory analysis,"With the popularity of modern mobile devices and GPS technology, big web stream data with location are continuously generated and collected. The sequential positions form a trajectory, and the clustering analysis on trajectories is beneficial to a wide range of applications, e.g., route recommendation. In the past decades, extensive efforts have been made to improve the efficiency of static trajectory clustering. However, trajectory stream data is received incrementally, and the continuous trajectory clustering inevitably faces the following two problems: (1) physical structure design for trajectory representation leads to severe space overhead, and (2) dynamic maintenance of trajectory semantics and its retrieval structure brings intensive computation. To overcome the above problems, an adaptive continuous trajectory clustering framework (ACTOR) is proposed in this paper. Overall, it covers three key components: (1) Simplifier represents trajectory with a well-designed PT structure. (2) Partitioner utilizes a hexagonal-based indexing strategy to enhance the local computational efficiency. (3) Executor accommodates an adaptive selection of P-clustering and R-clustering approaches according to the ROC (rate of change) matrix. Empirical studies on real-world data validate the usefulness of our proposal and prove the huge advantage of our approach over available solutions in the literature.",JWE,2023,,22,1,,105-130,2,0,https://ieeexplore.ieee.org/document/10261474/
LUBM4OBDA: Benchmarking OBDA Systems with Inference and Meta Knowledge,Julián Arenas-Guerrero | María S. Pérez | Oscar Corcho,"Universidad Politécnica de Madrid, Spain | Universidad Politécnica de Madrid, Spain | Universidad Politécnica de Madrid, Spain",OBDA | semantic web | ontology | data integration,"Ontology-based data access focuses on enabling query evaluation over heterogeneous relational databases according to the model represented by an ontology. The relationships between the ontology and the data sources are commonly defined with declarative mappings, which are used by systems to perform SPARQL-to-SQL query translation or to generate RDF dumps from the relational databases. Besides the potential homogenization of data because of using an ontology, some additional advantages of this paradigm are that it may allow applying reasoning thanks to the ontology, as well as querying for meta knowledge, which describes statements with information such as provenance or certainty. In this paper, (i) we adapt a widely used RDF graph store benchmark, namely LUBM, for ontology-based data access, (ii) extend the benchmark for the evaluation of queries that exploit meta knowledge, and (iii) apply it for performance evaluation of state-of-the-art declarative mapping systems. Our proposal, the LUBM4OBDA Benchmark, considers inference capabilities that are not covered by previous ontology-based data access benchmarks, and it is the first one for the evaluation of meta knowledge and the RDF-star data model. The experimental evaluation shows that current virtualization systems cannot handle some advanced inference tasks, and that optimizations are needed to scale RDF-star materialization.",JWE,2023,,22,8,,1163-1185,2,3,https://ieeexplore.ieee.org/document/10452391/
Diagnostic Classifiers for Explaining a Neural Model with Hierarchical Attention for Aspect-based Sentiment Classification,Kunal Geed | Flavius Frasincar | Maria Mihaela Trusca,"Erasmus University Rotterdam, Rotterdam, the Netherlands | Erasmus University Rotterdam, Rotterdam, the Netherlands | Bucharest University of Economic Studies, Bucharest, Romania",Aspect-based sentiment classification | neural rotatory attention model | diagnostic classification,"The current models proposed for aspect-based sentiment classification (ABSC) are mainly developed with the purpose of providing high rates of accuracy, regardless of the inner working which is usually difficult to understand. Considering the state-of-art model LCR-Rot-hop++ for ABSC, we use diagnostic classifiers to gain insights into the encoded information of each layer. Starting from a set of various hypotheses, we test how sentiment-related information is captured by different layers of the model. Given the model architecture, information about the related words to the target is easily extracted. Also, the model is able to detect to some extent information about the sentiments of the words and, in particular, sentiments of the words related to the target. However, the model is less effective in extracting the aspect mentions associated with a word and the general structure of the sentence.",JWE,2023,,22,1,,147-174,2,0,https://ieeexplore.ieee.org/document/10261473/
Few-Shot Text Classification Method Based on Feature Optimization,Jing Peng | Shuquan Huo,"School of Philosophy, Anhui University, Hefei, China | School of Philosophy and Public Management, Henan University, Kaifeng, China",Few-shot learning | text classification | feature optimization | WDAB-LSTM prototypical network,"For the poor effect of few-shot text classification caused by insufficient data for feature representation, this paper combines wide and deep attention bidirectional long short time memory (WDAB-LSTM) and a prototypical network to optimize text features for better classification performance. With this proposed algorithm, text enhancement and preprocessing are firstly adopted to solve the problem of insufficient samples and WDAB-LSTM is used to increase word attention to get output vectors containing important context-related information. Then the prototypical network is added to optimize the distance measurement module in the model for a better effect on feature extraction and sample representation. To test the performance of this algorithm, Amazon Review Sentiment Classification (ARSC), Text Retrieval Conference (TREC), and Kaggle are selected. Compared with the Siamese network and the prototypical network, the proposed algorithm with feature optimization has a relatively higher accuracy rate, precision rate, recall rate, and $F_{1}$ value.",JWE,2023,,22,3,,497-514,2,4,https://ieeexplore.ieee.org/document/10243557/
Prediction Model of Post-TAVR Complication Using a Medical Twin Web Navigator,Se-Min Hyun | KangYoon Lee,"Department of Computer Engineering, Gachon University, Republic of Korea | Department of Computer Engineering, Gachon University, Republic of Korea",Transcatheter aortic valve replacement (TAVR) | medical twin | web navigator | complication prediction model,"Transcatheter aortic valve replacement (TAVR) has been introduced as an alternative to surgical aortic valve replacement for patients with severe aortic valve disease and is expanding into a universal treatment. However, complications after TAVR can have devastating consequences for patients and must be predicted. By designing a TAVR medical twin architecture based on real-world data (RWD), we can minimize complications and achieve optimal clinical outcomes through analysis and simulation results in a virtual environment that can predict complications. The simulation phase utilizes machine learning algorithms for complication prediction to predict patients with conduction abnormalities, a complication of TAVR, and provides the prediction results through a web-based monitoring system. We also conduct research to identify factors that influence complications, so that complication prediction in a virtualized environment on a medical twin architecture can serve as a guide for personalized care design for patients undergoing TAVR.",JWE,2023,,22,7,,1037-1053,2,0,https://ieeexplore.ieee.org/document/10431809/
Development of Web Content for Music Education Using AR Human Facial Recognition Technology,Eunee Park,"Division of Media Arts, Baekseok Arts University, Republic of Korea",Augmented reality (AR) | unity engine | face recognition | facial expression | real-time tracking | YouTube | web content,"As the media market changes rapidly, market demand is increasing for content that can be consumed on web platforms. It's required to produce differentiated web content that can attract viewers' interest. In order to increase the productivity and efficiency of content creation, cases of content production using AR engines are increasing. This study has a development environment in which parametrics and muscle-based model techniques are mixed. The faces of famous Western classical musicians, such as Mozart, Beethoven, Chopin and List are created as 3D characters and augmented on human's face based on facial recognition technology in this study. It analyzes and traces the changed of facial expression of each person, then apply to 3D character's facial expression in real-time. Each person who augmented musicians' faces can become those who lived in different times, deliver information and communicate with viewers of the present era based on the music educational scripts. This study presents a new direction for video production required in the media market.",JWE,2023,,22,5,,783-796,2,1,https://ieeexplore.ieee.org/document/10374420/
Efficient AI Applications in Edge-Cloud Environments,In-Young Ko | Michael Mrissa | Juan Manuel Murillo | Abhishek Srivastava,"Korea Advanced Institute of Science and Technology, South Korea | InnoRenew CoE, Slovenia | University of Extremadura, Spain | Indian Institute of Technology Indore, India",,"The international workshop on Big Data-Driven Edge Cloud Services (BECS) provides a venue for scholars and practitioners to share their experiences and present their ongoing work in the development of data-driven AI applications and services in a distributed computing environment known as the edge cloud. The third edition of the workshop (BECS 2023)11https://becs.kaist.ac.kr/iwbecs2023/ was held in con06ction with the 23rd International Conference on Web Engineering (ICWE 2023),22https://icwe2023.webengineering.org/ which was held in Alicante, Spain on 06e 6-9, 2023.",JWE,2023,,22,6,,v-viii,2,0,https://ieeexplore.ieee.org/document/10376419/
Improved Design of Concurrent Synchronization System Controller Based on Petri Net,Xu Yang | Shaocui Guo | Dongming Xiang | Yuxin Yang | Yi06 Chen,"Department of Computer Science, Tongji University, Shanghai, China | Open Education College, Yantai Vocational College, Yantai, China | The School of Information Science and Technology, Zhejiang Sci-Tech University, Hangzhou, China | The Experimental High School Affiliated to Shenzhen University, Shenzhen, China | National Maglev Transportation Engineering R&D Center, Tongji University, Shanghai, China",Synchronization concurrent system | Petri net | deadlock detection | deadlock controller | concurrency | deadlock elimination | Petri net with data | data consistent,"At present, the advancement of science and technology has contributed to the emergence of various network parallel environments, web service concurrency environments and massively parallel processors. In order to abstract some practical systems into concurrent system models, it is necessary to conduct model analysis, and to perform deadlock detection of the concurrent system. Despite prior studies on the control problem of the synchronous concurrent system, there remains room for improvement in terms of workload, time, and efficiency. Some very practical methods are explored by introducing locking and unlocking to synchronize the concurrent system, and the algorithm that involves the specific regulation is provided. The Petri net model of the controller is developed to provide an effective method applicable to find the deadlock and to prevent and eliminate the deadlock for synchronous concurrent systems.",JWE,2023,,22,7,,961-981,2,0,https://ieeexplore.ieee.org/document/10431808/
Improving Phishing Website Detection using a Hybrid Two-level Framework for Feature Selection and XGBoost Tuning,Luka Jovanovic | Dijana Jovanovic | Milos Antonijevic | Bosko Nikolic | Nebojsa Bacanin | Miodrag Zivkovic | Ivana Strumberger,"Singidunum University, Belgrade, Serbia | College of academic studies “Dositej”, Belgrade, Serbia | Singidunum University, Belgrade, Serbia | School of Electrical Engineering, Belgrade, Serbia | Singidunum University, Belgrade, Serbia | Singidunum University, Belgrade, Serbia | Singidunum University, Belgrade, Serbia",XGBoost | artificial intelligence | web security | swarm intelligence | metaheuristics optimization | firefly algorithm,"In the last few decades, the World Wide Web has become a necessity that offers numerous services to end users. The number of online transactions increases daily, as well as that of malicious actors. Machine learning plays a vital role in the majority of modern solutions. To further improve Web security, this paper proposes a hybrid approach based on the eXtreme Gradient Boosting (XGBoost) machine learning model optimized by an improved version of the well-known metaheuristics algorithm. In this research, the improved firefly algorithm is employed in the two-tier framework, which was also developed as part of the research, to perform both the feature selection and adjustment of the XGBoost hyper-parameters. The performance of the introduced hybrid model is evaluated against three instances of well-known publicly available phishing website datasets. The performance of novel introduced algorithms is additionally compared against cutting-edge metaheuristics that are utilized in the same framework. The first two datasets were provided by Mendeley Data, while the third was acquired from the University of California, Irvine machine learning repository. Additionally, the best performing models have been subjected to SHapley Additive exPlanations (SHAP) analysis to determine the impact of each feature on model decisions. The obtained results suggest that the proposed hybrid solution achieves a superior performance level in comparison to other approaches, and that it represents a perspective solution in the domain of web security.",JWE,2023,,22,3,,543-574,2,61,https://ieeexplore.ieee.org/document/10247501/
Machine Learning Approaches for Fake Reviews Detection: A Systematic Literature Review,Mohammed Ennaouri | Ahmed Zellou,"Software Project Management Team, Mohammed V University in Rabat, High National School for Computer Science and Systems Analysis, Rabat, Morocco | Software Project Management Team, Mohammed V University in Rabat, High National School for Computer Science and Systems Analysis, Rabat, Morocco",Fake reviews | opinion spam | spam reviews | machine learning,"These days, most people refer to user reviews to purchase an online product. Unfortunately, spammers exploit this situation by posting deceptive reviews and misleading consumers either to promote a product with poor quality or to demote a brand and damage its reputation. Among the solutions to this problem is human verification. Unfortunately, the real-time nature of fake reviews makes the task more difficult, especially on e-commerce platforms. The purpose of this study is to conduct a systematic literature review to analyze solutions put out by researchers who have worked on setting up an automatic and efficient framework to identify fake reviews, unsolved problems in the domain, and the future research direction. Our findings emphasize the importance of the use of certain features and provide researchers and practitioners with insights on proposed solutions and their limitations. Thus, the findings of the study reveals that most approaches focus on sentiment analysis, opinion mining and, in particular, machine learning (ML), which contributes to the development of more powerful models that can significantly solve the problem and thus enhance further the accuracy and efficiency of detecting fake reviews.",JWE,2023,,22,5,,821-848,2,12,https://ieeexplore.ieee.org/document/10374425/
Just-in-Time Defect Prediction for Self-Driving Software via a Deep Learning Model,Jiwon Choi | Taeyoung Kim | Duksan Ryu | Jongmoon Baik | Suntae Kim,"School of Computing, Korea Advanced Institute of Science and Technology, Korea | Department of Software Engineering, Jeonbuk National University, Korea | Department of Software Engineering, Jeonbuk National University, Korea | School of Computing, Korea Advanced Institute of Science and Technology, Korea | Department of Software Engineering, Jeonbuk National University, Korea",Software defect prediction | edge computing applications | self-driving | deep learning,"Edge computing is applied to various applications and is typically applied to autonomous driving software. As the self-driving system becomes complicated and the proportion of software increases, accidents caused by software defects increase. Just-in-time (JIT) defect prediction is a technique that identifies defects during the software development phase, which helps developers prioritize code inspection. Many researchers have proposed various JIT models, but it is difficult to find a case in which JIT defect prediction was performed on edge computing applications. In particular, due to the characteristic of self-driving software, which is frequently updated, there is a high risk of inducing defects into the update process. In this work, we propose a JIT defect prediction model via deep learning for edge computing applications called JIT4EA. Our research goal is to develop an effective model to predict defects in edge computing applications. To do this, we perform defect prediction on self-driving software, a representative edge computing application. We use pre-trained unified cross-modal pre-training for code representation (UniXCoder) to embed commit messages and code changes. We use bidirectional-LSTM(Bi-LSTM) for context and semantic learning. As a result of the experiment, it was confirmed that the proposed JIT4EA performed better than state-of-the-art methods and could reduce the code inspection effort.",JWE,2023,,22,2,,303-326,2,6,https://ieeexplore.ieee.org/document/10243560/
Exploring LLM-Based Automated Repairing of Ansible Script in Edge-Cloud Infrastructures,Sunjae Kwon | Sungu Lee | Taehyoun Kim | Duksan Ryu | Jongmoon Baik,"Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Jeonbuk National University, Jeonju, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Edge-cloud | Ansible | Bard | large langue model | automated program repairing,"Edge-Cloud system requires massive infrastructures located in closer to the user to minimize latencies in handling Big data. Ansible is one of the most popular Infrastructure as Code (IaC) tools crucial for deploying these infrastructures of the Edge-cloud system. However, Ansible also consists of code, and its code quality is critical in ensuring the delivery of high-quality services within the Edge-Cloud system. On the other hand, the Large Langue Model (LLM) has performed remarkably on various Software Engineering (SE) tasks in recent years. One such task is Automated Program Repairing (APR), where LLMs assist developers in proposing code fixes for identified bugs. Nevertheless, prior studies in LLM-based APR have predominantly concentrated on widely used programming languages (PL), such as Java and C, and there has yet to be an attempt to apply it to Ansible. Hence, we explore the applicability of LLM-based APR on Ansible. We assess LLMs' performance (ChatGPT and Bard) on 58 Ansible script revision cases from Open Source Software (OSS). Our findings reveal promising prospects, with LLMs generating helpful responses in 70% of the sampled cases. Nonetheless, further research is necessary to harness this approach's potential fully.",JWE,2023,,22,6,,889-912,2,12,https://ieeexplore.ieee.org/document/10376418/
Detecting Spam E-mails with Content and Weight-Based Binomial Logistic Model,Richa Indu | Sushil Chandra Dimri,"Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India | Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India",Logistic regression | malicious advertisements | maximum likelihood estimation | spam e-mails,"Spam e-mails are continuously increasing and are a serious threats to a network and its users. Several efficient methods are available regarding this context, but still, it is evolving randomly. Considering this, the proposed approach addresses the problem of spam detection by combining traditional content-matching criteria with the modified version of the binomial logistic algorithm. The work generates seven categories for content-matching, which begins from three basic categories, namely: special words, adult content, and specific symbols and digits. The remaining four categories are derived from various possible combinations of these basic categories. The words selected for each category are carefully curated based on the human psychology of action and reaction. Then, a weight is assigned to each of the categories to signify their importance and a threshold criterion is deployed before implementing the binomial logistic algorithm, which not only increases the efficiency of the proposed algorithm but also reduces the rate of misclassification. The proposed model is tested on six separate datasets of Enron Spam Corpus, where 98.31% and 92.575% are the maximum and minimum accuracies achieved, respectively, in spam e-mail classification. The AUC_ROC scores for the entire Spam Corpus range between 0.927 and 0.983. A comparison is also carried out between the proposed algorithm and the other methods of spam detection that have logistic regression. Finally, the suggested method can adequately handle a large sample size without compromising the efficacy, which is measured using accuracy, precision, recall, F-measure, and AUC_ROC score.",JWE,2023,,22,7,,939-959,2,4,https://ieeexplore.ieee.org/document/10431807/
Fine-Grained Sentiment-Enhanced Collaborative Filtering-Based Hybrid Recommender System,Rawaa Alatrash | Rojalina Priyadarshini,"Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India | Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India",E-learning adaptation | recommender system | fine-grained sentiment analysis | collaborative filtering | natural language processing,"Developing online educational platforms necessitates the incorporation of new intelligent procedures in order to improve long-term student experience. Presently, e-learning recommender systems rely on deep learning methods to recommend appropriate e-learning materials to the students based on their learner profiles. Fine-grained sentiment analysis (FSA) can be leveraged to enrich the recommender system. User-posted reviews and rating data are vital in accurately directing the student to the appropriate e-learning resources based on posted comments by comparable learners. In this work, a new e-learning recommendation system is proposed based on individualization and FSA. A hybrid framework is provided by integrating alternating least square (ALS) based collaborative filtering (CF) with FSA to generate an effective e-content recommendation named HCFSAR. ALS attempts to capture the learner's latent factors based on their selections of interest to build the learner profile. Three FSA models based on attention mechanisms and bidirectional long short-term memory (bi-LSTM) are suggested and used to train twelve models in order to predict new ratings from learner-posted book reviews based on the extracted learner profile. HCFSAR used multiplication word embeddings for stronger corpus representation that were trained on a dataset generated for an educational context and showed a better accuracy of 93.39% for the best model entitled MHAM based ABHR-2 with multiplication (MHAAM), which performed better than other models. A tailored dataset that has been created by scraping reviews of different e-learning resources is leveraged to train different proposed models and validate against public datasets.",JWE,2023,,22,7,,983-1035,2,10,https://ieeexplore.ieee.org/document/10431746/
Metaheuristic Aided Improved LSTM for Multi-document Summarization: A Hybrid Optimization Model,Sunilkumar Ketineni | Sheela J,"Department of School of Computer Science and Engineering, VIT-AP University, Amaravathi, Andhra Pradesh, India | Department of School of Computer Science and Engineering, VIT-AP University, Amaravathi, Andhra Pradesh, India",Multi-document summarization | LSTM | score generation | BMICO | optimization,"Multi-document summarization (MDS) is an automated process designed to extract information from various texts that have been written regarding the same subject. Here, we present a generic, extractive, MDS approach that employs steps like preprocessing, feature extraction, score generation, and summarization. The input text goes preprocessing steps such as lemmatization, stemming, and tokenization in the first stage. After preprocessing, features are extracted, including improved semantic similarity-based features, term frequency-inverse document frequency (TF-IDF-based features), and thematic-based features. Finally, an improved LSTM model will be proposed to summarize the document based on the scores considered under the objectives such as content coverage and redundancy reduction. The Blue Monkey Integrated Coot Optimization (BMICO) algorithm is proposed in this paper for fine-tuning the optimal weight of the LSTM model that ensures precise summarization. Finally, the suggested BMICO's effectiveness is evaluated, and the outcome is successfully verified.",JWE,2023,,22,4,,701-730,2,7,https://ieeexplore.ieee.org/document/10301473/
An Automation Script Generation Technique for the Smart Home,Jiayi Kuang | Gang Xue | Zeming Yan | Jing Liu,"School of Software, Yunnan University, Kunming, Yunnan, China | School of Software, Yunnan University, Kunming, Yunnan, China | School of Software, Yunnan University, Kunming, Yunnan, China | School of Software, Yunnan University, Kunming, Yunnan, China",Home automation | automation script generation | first-order logic | natural language processing,"A home automation system means monitoring and controlling various kinds of devices in the home remotely using the Internet of things (IoT). Technologies such as natural language processing techniques, user-friendly visual programming, and machine intelligence programming are already available for home automation. For such systems, the increase in the number of devices often makes users focused on the system's ability to perform complex or composing tasks. However, some existing natural language processing systems can only perform simple tasks and cannot meet users' needs. Thus, it is difficult for users to develop the home automation systems they need using visual programming systems because of the large amount of programming knowledge required. Meanwhile, automatic programming without user action can only write a few lines of code and implement little functionality. There are relatively few tools available for generating home automation scripting languages. To address this problem, we propose a practical method for generating executable home automation scripts using Chinese texts. Our method includes the following steps: it extracts critical information from the command sentences in Chinese; it uses first-order logic to check the validity of the extracted information; based on the validation, the correct sentences are mapped into the intermediate language scripts, which can interface with different home platforms. We conducted experiments on Home Assistant, converted intermediate scripts to Home Assistant, and collected 600 scenario descriptions. The experimental results show that the method can automatically generate executable scripts for the Home Assistant platform, and the correct rate was 93.66%.",JWE,2023,,22,2,,221-254,2,7,https://ieeexplore.ieee.org/document/10247495/
Pre-Trained Model-Based Software Defect Prediction for Edge-Cloud Systems,Sunjae Kwon | Sungu Lee | Duksan Ryu | Jongmoon Baik,"Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Jeonbuk National University, Jeonju, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Just-in-time defect prediction | pre-trained model | edge-cloud system,"Edge-cloud computing is a distributed computing infrastructure that brings computation and data storage with low latency closer to clients. As interest in edge-cloud systems grows, research on testing the systems has also been actively studied. However, as with traditional systems, the amount of resources for testing is always limited. Thus, we suggest a function-level just-in-time (JIT) software defect prediction (SDP) model based on a pre-trained model to address the limitation by prioritizing the limited testing resources for the defect-prone functions. The pre-trained model is a transformer-based deep learning model trained on a large corpus of code snippets, and the fine-tuned pre-trained model can provide the defect proneness for the changed functions at a commit level. We evaluate the performance of the three popular pre-trained models (i.e., CodeBERT, GraphCodeBERT, UniXCoder) on edge-cloud systems in within-project and cross-project environments. To the best of our knowledge, it is the first attempt to analyse the performance of the three pre-trained model-based SDP models for edge-cloud systems. As a result, we can confirm that UniXCoder showed the best performance among the three in the WPDP environment. However, we also confirm that additional research is necessary to apply the SDP models to the CPDP environment.",JWE,2023,,22,2,,255-278,2,4,https://ieeexplore.ieee.org/document/10247502/
Fully Decentralized Horizontal Autoscaling for Burst of Load in Fog Computing,Eunchan Park | Kyeongdeok Baek | Eunho Cho | In-Young Ko,"Korea Advanced Institute of Science and Technology, South Korea | Korea Advanced Institute of Science and Technology, South Korea | Korea Advanced Institute of Science and Technology, South Korea | Korea Advanced Institute of Science and Technology, South Korea",Web services in edge clouds | microservice autoscaling | service elasticity | container orchestration,"With the increasing number of Web of Things devices, the network and processing delays in the cloud have also increased. As a solution, fog computing has emerged, placing computational resources closer to the user to lower the communication overhead and congestion in the cloud. In fog computing systems, microservices are deployed as containers, which require an orchestration tool like Kubernetes to support service discovery, placement, and recovery. A key challenge in the orchestration of microservices is automatically scaling the microservices in case of an unpredictable burst of load. In cloud computing, a centralized autoscaler can monitor the deployed microservice instances and make scaling actions based on the monitored metric values. However, monitoring an increasing number of microservices in fog computing can cause excessive network overhead and thereby delay the time to scaling action. We propose DESA, a fully DEcentralized Self-adaptive Autoscaler through which microservice instances make their own scaling decisions, cloning or terminating themselves through self-monitoring. We evaluate DESA in a simulated fog computing environment with different numbers of fog nodes. Furthermore, we conduct a case study with the 1998 World Cup website access log, examining DESA's performance in a realistic scenario. The results show that DESA successfully reduces the scaling reaction time in large-scale fog computing systems compared to the centralized approach. Moreover, DESA resulted in a similar maximum number of instances and lower average CPU utilization during bursts of load.",JWE,2023,,22,6,,849-870,2,3,https://ieeexplore.ieee.org/document/10376422/
HCNN-LSTM: Hybrid Convolutional Neural Network with Long Short-Term Memory Integrated for Legitimate Web Prediction,Candra Zonyfar | 06g-Been Lee | Jeong-Dong Kim,"Department of Computer Science and Electronics Engineering, Sun Moon University, Korea | Department of Computer Science and Electronics Engineering, Sun Moon University, Korea | Department of Computer Science and Electronics Engineering, Sun Moon University, Korea",Phishing detection | cyber threat | CNN-LSTM | deep learning | machine learning,"Phishing techniques are the most frequently used threat by attackers to deceive Internet users and obtain sensitive victim information, such as login credentials and credit card numbers. So, it is important for users to know the legitimate website to avoid the traps of fake websites. However, it is difficult for lay users to distinguish legitimate websites, considering that phishing techniques are always developing from time to time. Therefore, a legitimate website detection system is an easy way for users to avoid phishing websites. To address this problem, we present a hybrid deep learning model by combining a convolution neural network and long short-term memory (HCNN-LSTM). A one-dimensional CNN with a LSTM network shared estimation of all sublayers, then implements the proposed model in the benchmark dataset for phishing prediction, which consists of 11430 URLs with 87 attributes extracted of which 56 parameters are selected from URL structure and syntax. The HCNN-LSTM model was successful in binary classification with accuracy, precision, recall, and F1-score of 95.19%, 95.00%, 95.00%, 95.00%, successively outperforming the CNN and LSTM. Thus, the results show that our proposed model is a competitive new model for the legitimate web prediction tasks.",JWE,2023,,22,5,,757-782,2,8,https://ieeexplore.ieee.org/document/10374423/
Proposed Secure Hypertext Model in Web Engineering,Madhuri N. Gedam | Bandu B. Meshram,"Department of Computer Engineering, Veermata Jijabai Technological Institute (VJTI), Mumbai, India | Department of Computer Engineering, Veermata Jijabai Technological Institute (VJTI), Mumbai, India",Web engineering methods | WebML | UWE | UML | IFML | web applications | hypertext modelling,"Secure web application development is one of the prime challenges for the software industry. In the last decade, web applications have rapidly developed but web engineering methods have some limitations while designing web applications. The extensive literature survey explores various concepts like web engineering, hypertext modelling, web applications hypertext modelling methods, attacks on web applications, same origin policy (SOP) and cross origin resource sharing (CORS). The complexity of web pages is a major concern for security. The proposed secure hypertext model (SHM) provides hypertext modelling of web applications and helps in the identification of attacks on hypertext links. It provides security stereotypes and precisely specifies vulnerability defences in web application design. This standardized attack vector and defence mechanism will help developers to build more secure applications.",JWE,2023,,22,4,,575-596,2,1,https://ieeexplore.ieee.org/document/10301471/
A Distributed Publish-Subscribe Algorithm Based on Spatial Text Information Flow,Yangtao Liu | Xiaofeng Yu,"School of Computer and Software, Nanyang Institute of Technology, Nanyang, China | School of Computer and Information Technology, Nanyang Vocational College, Nanyang, China",Publish-and-subscribe systems | distributed systems | clustering algorithms,"With the rapid development of society and the popularity of smart devices, the volume of information sent and received is increasing day by day. It has become very difficult to accurately and efficiently match a large number of events with a large number of subscriptions, and the event and subscription matching speed can no longer meet demand. To speed up the matching speed of events and subscriptions, this paper uses similarity and correlation to optimize the clustering operation and increase the data transfer and data throughput of the category fusion strategy. Firstly, the clustering operation is performed on the subscription messages, and the category to which the events belong is found according to the clustering result. Subsequently, in the category, the subscriptions matching the events are found. An on-the-fly subscription publishing algorithm is proposed to coordinate spatial information and event attribute information to handle not only the matching operation of events and subscriptions on-the-fly but also to perform subscription updates and category updates on the distributed environment on-the-fly. It can also perform clustering operations and matching operations instantly without prior knowledge. We design a distributed system for the publish-subscribe algorithm and propose a load balancing strategy for this algorithm on the distributed system. Subsequently, we experimentally validate the proposed publish-subscribe algorithm in this paper by building our own cluster and using real data.",JWE,2023,,22,3,,385-404,2,2,https://ieeexplore.ieee.org/document/10243558/
Federated Latent Dirichlet Allocation for User Preference Mining,Xing Wu | Yushun Fan | Jia Zhang | Zhenfeng Gao,"Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China | Department of Computer Science, Southern Methodist University, Dallas, TX, USA | Sangfor Technologies Inc., Shenzhen, China",Web service composition | user preference mining | federated learning | LDA | homomorphic encryption | blockchain,"In the field of Web services computing, a recent demand trend is to mine user preferences based on user requirements when creating Web service compositions, in order to meet comprehensive and ever evolving user needs. Machine learning methods such as the latent Dirichlet allocation (LDA) have been applied for user preference mining. However, training a high-quality LDA model typically requires large amounts of data. With the prevalence of government regulations and laws and the enhancement of people's awareness of privacy protection, the traditional way of collecting user data on a central server is no longer applicable. Therefore, it is necessary to design a privacy-preserving method to train an LDA model without massive collecting or leaking data. In this paper, we present novel federated LDA techniques to learn user preferences in the Web service ecosystem. On the basis of a user-level distributed LDA algorithm, we establish two federated LDA models in charge of two-layer training scenarios: a centralized synchronous federated LDA (CSFed-LDA) for synchronous scenarios and a decentralized asynchronous federated LDA (DAFed-LDA) for asynchronous ones. In the former CSFed-LDA model, an importance-based partially homomorphic encryption (IPHE) technique is developed to protect privacy in an efficient manner. In the latter DAFed-LDA model, blockchain technology is incorporated and a multi-channel-based authority control scheme (MCACS) is designed to enhance data security. Extensive experiments over a real-world dataset ProgrammableWeb.com have demonstrated the model performance, security assurance and training speed of our approach.",JWE,2023,,22,4,,639-677,2,3,https://ieeexplore.ieee.org/document/10301470/
Visual Quality Assessment of Point Clouds Compared to Natural Reference Images,Aram Baek | Minseop Kim | Sohee Son | Sangwoo Ahn | Jeongil Seo | Hui Yong Kim | Haechul Choi,"Department of Intelligence Media Engineering, Hanbat National University, Daejeon, Republic of Korea | Department of Intelligence Media Engineering, Hanbat National University, Daejeon, Republic of Korea | Department of Intelligence Media Engineering, Hanbat National University, Daejeon, Republic of Korea | Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea | Department of Computer Engineering, Dong-A University, Busan, Republic of Korea | School of Computing, Kyung Hee University, Yongin, Republic of Korea | Department of Intelligence Media Engineering, Hanbat National University, Daejeon, Republic of Korea",Point cloud | quality evaluation | visual quality assessment,"This paper proposes a point cloud (PC) visual quality assessment (VQA) framework that reflects the human visual system (HVS). The proposed framework compares natural images acquired using a digital camera and PC images generated via 2D projection in terms of appropriate objective quality evaluation metrics. Humans primarily consume natural images; thus, human knowledge is typically formed from natural images. Thus, natural images can be more reliable reference data than PC data. The proposed framework performs an image alignment process based on feature matching and image warping to use the natural images as a reference which enhances the similarities of the acquired natural and corresponding PC images. The framework facilitates identifying which objective VQA metrics can be used to reflect the HVS effectively. We constructed a database of natural images and three PC image qualities, and objective and subjective VQAs were conducted. The experimental result demonstrates that the acceptable consistency among different PC qualities appears in the metrics that compare the global structural similarity of images. We found that the SSIM, MAD, and GMSD achieved remarkable Spearman rank-order correlation coefficient scores of 0.882, 0.871, and 0.930, respectively. Thus, the proposed framework can reflect the HVS by comparing the global structural similarity between PC and natural reference images.",JWE,2023,,22,3,,405-432,2,2,https://ieeexplore.ieee.org/document/10247500/
"Using LDA Topic Modeling to Understand Regrowth Factors of the Chinese Gaming Industry in the COVID-19 Era: Current Situation, Future and Predicament",Yi-Qian Han | Won-06 Jeong | Gi-Sung Oh | Seok Hee Oh | Taeg-Keun Whangbo,"Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea | Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea | Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea | Korea creative content agency, Daejeon gwangyeoksi, Republic of Korea | Department of Computer Engineering, Gachon University, Seongnam-si, Gyeonggi-do, Republic of Korea",Topic modeling | games industry | COVID-19 | text mining | latent | Dirichlet allocation | news text,"The gaming industry, which was among the industries least affected by the COVID-19 outbreak, exhibited positive growth trends during the COVID-19 period. This paper explores the impact of COVID-19 on the gaming industry by analyzing news texts from 2020 to 2022 using text mining and LDA (latent Dirichlet allocation) topic classification, and visualizing charts. The study focuses on three themes, namely the current situation, the future, and possible problems of China's game industry in the post-epidemic era. The findings of this study suggest that the development of the game industry during the COVID-19 outbreak prompted the government to regulate policies and promote the transformation of game companies, which had a positive impact on the development of China's game industry. However, this study also found that due to the effects of COVID-19, society and the government have increased their focus on the time management of underage game users, which poses a significant challenge to the games industry. This paper recommends improvements from three perspectives, namely society, policy, and enterprise, with the aim of contributing to the long-term development of China's game industry.",JWE,2023,,22,3,,433-464,2,5,https://ieeexplore.ieee.org/document/10247499/
Embedding a Microblog Context in Ephemeral Queries for Document Retrieval,Shilpa Sethi,"Department of Computer Applications, J. C. Bose University of Science and Technology, Faridabad, Haryana, India",Page ranking | microblogs | temporal queries | query context | ephemeral information,"With the proliferation of information globally, the search engine had become an indispensable tool that helps the user to search for information in a simple, easy and quick way. These search engines employ sophisticated document ranking algorithms based on query context, link structure and user behavior characterization. However, all these features keep changing in the real scenario. Ideally, ranking algorithms must be robust enough to time-sensitive queries. Microblog content is typically short-lived as it is often intended to provide quick updates or share brief information in a concise manner. The technique first determines if a query is currently in high demand, then it automatically appends a time-sensitive context to the query by mining those microblogs whose torrent matches with query-in-demand. The extracted contextual terms are further used in re-ranking the search results. The experimental results reveal the existence of a strong correlation between ephemeral search queries and microblog volumes. These volumes are analyzed to identify the temporal proximity of their torrents. It is observed that approximately 70% of search torrents occurred one day before or after blog torrents for lower threshold values. When the threshold is increased, the match ratio of torrent is raised to ~90%. In addition, the performance of the proposed model is analyzed for different combining principles namely, aggregate relevance (AR) and dis06ctive relevance (DR). It is found that the DR variant of the proposed model outperforms the AR variant of the proposed model in terms of relevance and interest scores. Further, the proposed model's performance is compared with three categories of retrieval models: log-logistic model, sequential dependence model (SDM) and embedding based query expansion model (EQE1). The experimental results reveal the effectiveness of the proposed technique in terms of result relevancy and user satisfaction. There is a significant improvement of ~25% in the result relevance score and ~35% in the user satisfaction score compared to underlying retrieval models. The work can be expanded in many directions in the future as various researchers can combine these strategies to build a recommendation system, auto query reformulation system, Chatbot, and NLP professional toolkit.",JWE,2023,,22,4,,679-700,2,1,https://ieeexplore.ieee.org/document/10301468/
Generating Automated Layout Design Using a Multi-Population Genetic Algorithm,Arun Kumar | Kamlesh Dutta | Abhishek Srivastava,"Department of Computer Science and Engineering, Indian Institute of Technology, Indore, India | Discipline of Computer Science and Engineering, National Institute of Technology, Hamirpur, India | Department of Computer Science and Engineering, Indian Institute of Technology, Indore, India",AutoCAD | layout | layout planning | genetic algorithm (GA),"The problem of space layout planning, constrained by a number of functional and non-functional requirements, not only challenges architects in coming up with a good solution, but is more difficult to give an alternative. Genetic algorithms (GAs) have been found suitable for solving the problem of providing alternative solutions. However, GAs have been found to be susceptible to the problem of local maxima and plateau conditions. To overcome these problems, the multi-population genetic algorithm (MPGA) improves the diversity of the population, thereby improving the quality of the solution. Algorithms are employed to automatically generate layout designs in best-connected ways, either rectangular or square. The area of the floor plans is optimized to minimize the extra area in the layout. The layouts are divided into four groups and these groups are related to each other based on highest proximity. Layout designs have been simulated using GA and MPGA algorithms and MPGA has shown significant improvement in computation time as well as quality over alternative solutions. In addition, the algorithm also provides the architect with the facility to interactively modify the dimensions and adjacent criteria during the design phase. The system works on clouds and shows the result for inputs passed by an architect.",JWE,2023,,22,2,,357-384,2,2,https://ieeexplore.ieee.org/document/10247504/
A Semantics-Preserving Approach for Extracting RDF Knowledge from Object-Oriented Databases,Jing Shan | Jiawen Lu | Xu Chen | Li Yan | Zongmin Ma,"Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China | North Minzu University, China | Nanjing University of Aeronautics and Astronautics, China | Nanjing University of Aeronautics and Astronautics, China",RDF(S) | knowledge extraction | object-oriented databases | db4o | mapping,"The Resource Description Framework and RDF Schema recommended by the World Wide Web Consortium provide a flexible model for semantically representing information about resources on the Web, which are playing an increasingly important role in intelligent processing of large-scale data. With the widespread acceptance and applications of RDF(S), construction of RDF(S) is of increasing importance. Automatic construction of RDF(S) with diverse data has attracted more attention. In this paper, we propose a novel approach for constructing an RDF(S) with object-oriented databases that are suitable for non-traditional applications. We propose the formal rules of mapping an object-oriented database model into a RDF(S) model based on the formal definitions of these two models. We develop a tool named OODB2RDF to verify our approach.",JWE,2023,,22,2,,197-220,2,5,https://ieeexplore.ieee.org/document/10247496/
Validity Analysis of Network Big Data,Peng Wang | Huaxia Lv | Xiaojing Zheng | Wenhui Ma | Weijin Wang,"School of Economics and Management, Weifang University of Science and Technology, Shandong, China | School of Economics and Management, Weifang University of Science and Technology, Shandong, China | School of Economics and Management, Weifang University of Science and Technology, Shandong, China | School of Economics and Management, Weifang University of Science and Technology, Shandong, China | School of International Business, Shandong College of Economics and Business, Shandong, China",Network big data | system dynamics | critical point | scale-free network | F-J model,"False data in network big data has led to considerable ineffectiveness in perceiving the property of fact. Correct conclusions can be drawn only by accurately identifying and eliminating these false data. In other words, analysis is the premise to reaching a correct conclusion. This paper develops a big data network dissemination model based on the properties of the network. We also analyze the attributes of the big data random complex network based on the revised F-J model. Then, based on the scale-free nature of network big data, the evolution law of connected giant components and Bayesian inference, we propose an identification method of effective data in networks. Finally, after obtaining the real data, we analyze the dissemination and evolution characteristics of the network big data. The results show that if some online users intentionally spread false data on a large-scale website, the entire network data becomes false, despite a minimal probability of choosing these dissemination sources.",JWE,2023,,22,3,,465-496,2,0,https://ieeexplore.ieee.org/document/10247498/
Joint Representation of Entities and Relations via Graph Attention Networks for Explainable Recommendations,Rima Boughareb | Hassina Seridi-Bouchelaghem | Samia Beldjoudi,"Department of Computer Science, LabGED Laboratory, Badji Mokhtar - Annaba University, Annaba, Algeria | Department of Computer Science, LabGED Laboratory, Badji Mokhtar - Annaba University, Annaba, Algeria | LTSE (Laboratoire de Technologies des Systèemes Energétiques), National Higher School of Technology and Engineering, Annaba, Algeria",Recommender systems | knowledge graphs | graph attention networks | graph embedding | machine learning | graph representation learning,"The latest advances in Graph Neural Networks (GNNs), have provided important new ideas for solving the Knowledge Graph (KG) representation problem for recommendation purposes. Although GNNs have an effective graph representation capability, the nonlinear transformations over the layers cause a loss of semantic information and make the generated embeddings hard to explain. In this paper, we investigate the potential of large KGs to perform interpretable recommendation using Graph Attention Networks (GATs). Our goal is to fully exploit the semantic information and preserve inherent knowledge ported in relations by jointly learning low-dimensional embeddings for nodes (i.e., entities) and edges (i.e., properties). Specifically, we feed the original data with additional knowledge from the Linked Open Data (LOD) cloud, and apply GATs to generate a vector representation for each node on the graph. Experiments conducted on three real-world datasets for the top-K recommendation task demonstrate the state-of-the-art performance of the system proposed. In addition to improving predictive performance in terms of precision, recall, and diversity, our approach fully exploits the rich structured information provided by KGs to offer explanation for recommendations.",JWE,2023,,22,4,,615-638,2,0,https://ieeexplore.ieee.org/document/10301469/
Sharing Knowledge to Promote Proactive Multi-environments in the WoT,Daniel Flores-Martin | Rubén Rentero-Trejo | Jaime Galán-Jiménez | José García-Alonso | Javier Berrocal | Juan Manuel Murillo,"University of Extremadura, Cáceres, Spain | Global Process and Product Improvement S.L., Cáceres, Spain | University of Extremadura, Cáceres, Spain | University of Extremadura, Cáceres, Spain | University of Extremadura, Cáceres, Spain | Computing and Advanced Technologies Foundation of Extremadura (COMPUTAEX), Cáceres, Spain",Web of Things | knowledge distillation | mobile devices | context-aware,"The main goal of the Web of Things (WoT) is to improve people's quality of life by automating tasks and simplifying human-device interactions with ubiquitous systems. However, the management of devices still has to be done manually, which wastes a lot of time as their number increases. Thus, the expected benefits are not achieved. This management overhead is even greater when users change environments, new devices are added, or existing devices are modified. All this requires time-consuming customization of configurations and interactions. To facilitate this, learning systems help manage automation tasks. However, these require extensive learning times to achieve customization and cannot manage multiple environments so new approaches are needed to manage multiple environments dynamically. This work focuses on knowledge distillation and teacher-student relationships to transfer knowledge between IoT environments in a model-agnostic manner, allowing users to share their knowledge each time they encounter a new environment. This work allowed us to eliminate training times and achieve an average accuracy of 94.70%, making model automation effective from the acquisition in proactive WoT multi-environments.",JWE,2023,,22,2,,327-356,2,1,https://ieeexplore.ieee.org/document/10247503/
Priority Based Scheduler for Asymmetric Multi-Core Edge Computing,Rupendra Pratap Singh Hada | Abhishek Srivastava,"Indin Institute of Technology Indore, India | Indin Institute of Technology Indore, India",Asymmetric multi-core processors | completely fair scheduler | edge computing | scheduling,"Edge computing technology has gained popularity due to its ability to process data near the source or collection device, benefiting from low bandwidth utilization and enhanced security. Edge devices are typically equipped with multiple devices that employ asymmetric multi-cores for efficient data processing. To ensure optimal performance, it is crucial to carefully assign tasks to the appropriate cores in asymmetric multi-core processors. However, the current Linux scheduler needs to consider the capabilities of individual cores when assigning tasks. Consequently, high-priority tasks may be assigned to energy-efficient cores, while low-priority tasks end up on high-performance cores. This sub-optimal task assignment negatively impacts the overall system performance. To address this issue, a new algorithm has been proposed. This algorithm considers both the core's capabilities and the task's priority. However, due to the asymmetric nature of the cores, prior knowledge of each core's speed is necessary. The algorithm fetches the priorities of the tasks and classifies them into high, medium, and low-priority categories. Highpriority tasks are scheduled on high-performance cores, while medium and low-priority tasks are allocated to energy-efficient cores. The proposed algorithm demonstrates superior performance for high-priority tasks compared to the existing Linux task scheduling algorithm. It significantly improves task scheduling time by up to 16%, thereby enhancing the system's overall efficiency.",JWE,2023,,22,6,,871-888,2,1,https://ieeexplore.ieee.org/document/10376421/
Extended Reality Platform for Metaverse Exhibition,Choonsung Shin | Seokhee Oh | Hieyong Jeong,"Graduate School of Culture, Chonnam National University, Gwangju, Republic of Korea | Korea Creative Content Agency, Daejeon, Republic of Korea | Department of Artificial Intelligence Convergence, Chonnam National University, Gwangju, Republic of Korea",webXR | augmented reality | virtual reality | metaverse exhibition | web application,"This paper proposes a web-based extended reality (XR) platform integrating exhibitions based on augmented reality (AR) and virtual reality (VR). The proposed platform includes an XR cloud for managing and sharing data in XR spaces, a VR client for users, and an AR client for real-world users. The XR cloud is a web-based VR service responsible for managing objects and spatial information related to real and virtual spaces while simultaneously facilitating real-time information sharing and synchronization between AR and VR users. The VR client offers a virtual exhibition environment based on the virtual space and information for VR users. The AR client overlays virtual information over objects in a real space, allowing for intuitive interaction with them. The proposed XR platform was implemented with Oculus Quest 2 for VR and HoloLens 2 for AR and was evaluated in a small exhibition environment. In this experimental environment, VR and AR users were able to participate in the same exhibition from different spaces and share their experiences in real time.",JWE,2023,,22,7,,1055-1073,2,5,https://ieeexplore.ieee.org/document/10431810/
Features for a Style for Push-Communication Integrated Rich Web-Based Applications,Nalaka R. Dissanayake | Dharshana Kasthurirathna | Shantha Jayalal,"Department of IT, Faculty of Computing, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka | Department of SE, Faculty of Computing, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka | Department of Industrial Management, Faculty of Science, University of Kelaniya, Kelaniya, Sri Lanka",Architectural style | features | push-communication | rich web-based applications,"The development aspects of rich web-based applications have evolved; however, abstract concepts, like styles and patterns, are still lacking. If an abstract style for rich web-based applications is available, it can support the whole engineering process in many ways, like assisting in designing aspects and the system's evolution. We have produced an abstract architectural style named RiWAArch style for standard rich web-based applications, and we are working on extending the same to realize integrating push-communication. Push-communication has become a contemporary requirement in developing features like real-time notifications in rich web-based applications. However, the features to be expected from a style to realize the integration of the push-communication are not yet recognized. This concept paper proposes a set of features to be expected from a style for push-communication-integrated rich web-based applications. Our ongoing research will later utilize these features to form requirements and design a comprehensive style by extending the RiWAArch style to realize the abstract features of integrating true push-communication into rich web-based applications.",JWE,2023,,22,3,,515-542,2,0,https://ieeexplore.ieee.org/document/10243556/
A Study and Analysis of a New Hybrid Approach for Localization in Wireless Sensor Networks,Rupendra Pratap Singh Hada | Uttkarsh Aggarwal | Abhishek Srivastava,"Department of Computer Science and Engineering, Indian Institute of Technology, Indore, India | Department of Computer Science and Engineering, Indian Institute of Technology, Indore, India | Department of Computer Science and Engineering, Indian Institute of Technology, Indore, India",Localization | random forest | multilateration,"Accurate localization of nodes in a wireless sensor network (WSN) is imperative for several important applications. The use of global positioning systems (GPS) for localization is the natural approach in most domains. In WSNs, however, the use of GPS is challenging because of the constrained nature of deployed nodes as well as the often inaccessible sites of WSN nodes deployment. Several approaches for localization without the use of GPS and harnessing the capabilities of the received signal strength indicator (RSSI) exist in literature, but each of these makes the simplifying assumption that all the WSN nodes are within the communication range of every other node. In this paper, we go beyond this assumption and propose a hybrid technique for node localization in large WSN deployments. The hybrid technique comprises a loose combination of a machine learning (ML) based approach for localization involving random forest and a multilateration approach. This hybrid approach takes advantage of the accuracy of ML localization and the iterative capabilities of multilateration. We demonstrate the efficacy of the proposed approach through experiments on a simulated set-up and follow it up with a feasibility demonstration through a prototypical implementation in the real world.",JWE,2023,,22,2,,279-302,2,2,https://ieeexplore.ieee.org/document/10247497/
Web-based Non-contact Edge Computing Solution for Suspected COVID-19 Infection Classification Model,Tae-Ho Hwang | KangYoon Lee,"Gachon University, SeongnamSi, South Korea | Gachon University, SeongnamSi, South Korea",Edge computing | COVID-19 classification | non-contact biosensor | artificial intelligence | machine learning,"The recent outbreak of the COVID-19 coronavirus pandemic has necessitated the development of web-based, non-contact edge analytics solutions. Non-contact sensors serve as the interface between web servers and edge analytics through web engineering technology. The need for an edge device classification model that can identify COVID-19 patients based on early symptoms has become evident. In particular a non-contact implementation of such a classification model is required to efficiently prevent viral infection and minimize cross-infection. In this work, we investigate the use of diverse non-contact biosensors (e.g., remote photoplethysmography, radar, and infrared sensors) for reducing effective physical contact with patients and for measuring their biometric data and vital signs. We further explain a classification method for suspected COVID-19 infection based on the measured vital signs and symptoms. The results of this study can be applied in patient classification by mobile-based edge computing applications. The correlation between symptoms comprising cough, sore throat, fever, headache, myalgia, and arthralgia are analyzed in the model. We implement a machine learning classification model using vital signs for performance evaluation, and propose an ensemble model realized by fine-tuning the high-performing classification models. The proposed ensemble model successfully distinguishes suspected patients with an accuracy, area under curve, and F1 scores of 94.4%, 98.4%, and 94.4%, respectively.",JWE,2023,,22,4,,597-613,2,1,https://ieeexplore.ieee.org/document/10301472/
Proposition of Rubustness Indicators for Immersive Content Filtering,Youngmo Kim | Seok-Yoon Kim | Chyapol Kamyod | Byeongchan Park,"Dept. of Computer Science and Engineering, Soongsil University, Seoul, Republic of Korea | Dept. of Computer Science and Engineering, Soongsil University, Seoul, Republic of Korea | Computer and Communication Engineering for Capacity Building Research Center, School of Information Technology, Mae Fah Luang University, Chiang Rai, Thailand | Dept. of Computer Science and Engineering, Soongsil University, Seoul, Republic of Korea",Multimedia computing | image processing | image recognition | image resolution | image sampling,"With the full-fledged service of mobile carrier 5G networks, it is possible to use large-capacity, immersive content at high speed anytime, anywhere. It can be illegally distributed in web-hard and torrents through DRM dismantling and various transformation attacks; however, evaluation indicators that can objectively evaluate the filtering performance for copyright protection are required. Since applying existing 2D filtering techniques to immersive content directly is not possible, in this paper we propose a set of robustness indicators for immersive content. The proposed indicators modify and enlarge the existing 2D video robustness indicators to consider the projection and reproduction method, which are the characteristics of immersive content. A performance evaluation experiment has been carried out for a sample filtering system and it is verified that an excellent recognition rate of 95% or more is achieved in about 3 s of execution time.",JWE,2023,,22,4,,731-755,2,0,https://ieeexplore.ieee.org/document/10301474/
Integrating Citizens' Avatars in Urban Digital Twins,Rafael García-Luque | Lorenzo Toro-Gálvez | Nathalie Moreno | Javier Troya | Carlos Canal | Ernesto Pimentel,"ITIS Software, Universidad de Málaga, Spain | ITIS Software, Universidad de Málaga, Spain | ITIS Software, Universidad de Málaga, Spain | ITIS Software, Universidad de Málaga, Spain | ITIS Software, Universidad de Málaga, Spain | ITIS Software, Universidad de Málaga, Spain",Urban digital twin | digital avatar and cloud-to-thing continuum,"Urban Digital Twins (UDT) represent a powerful tool to effectively make cities smart. Generally, UDTs are linked with other Digital Twins to build ecosystems where the citizen is at the heart of the ecosystem. This is why citizens should be considered first-class entities in the UDTs. At the same time, citizens' privacy cannot be compromised. In this paper, we propose to integrate citizens' digital twin in UDTs through their digital avatars (DAs). DAs allow exploiting citizens' information, behavioral habits and personal preferences, while allowing them to have full control of their own data. We present our architecture that makes use of the Cloud-to-Thing Continuum to optimize available processing resources. We focus on a case study of the public transport service of the city of Malaga (Spain) and describe how we are approaching its implementation. Finally, we validate such UDT implementation through tests that evaluate its accuracy and the factors affecting its performance.",JWE,2023,,22,6,,913-938,2,6,https://ieeexplore.ieee.org/document/10376420/
Improving Ranking Using Hybrid Custom Embedding Models on Persian Web,Shekoofe Bostan | Ali Mohammad Zareh Bidoki | Mohammad-Reza Pajoohan,"Department of Computer Engineering, Yazd University, Iran | Department of Computer Engineering, Yazd University, Iran | Department of Computer Engineering, Yazd University, Iran",Word embedding | Word2Vec | BERT | semantic vector | query | ranking,"Ranking plays a crucial role in information retrieval systems, especially in the context of web search engines. This article presents a new ranking approach that utilizes semantic vectors and embedding models to enhance the accuracy of web document ranking, particularly in languages with complex structures like Persian. The article utilizes two real-world datasets, one obtained through web crawling to collect a large-scale Persian web corpus, and the other consisting of real user queries and web documents labeled with a relevancy score. The datasets are used to train embedding models using a combination of static Word2Vec and dynamic BERT algorithms. The proposed hybrid ranking formula incorporates these semantic vectors and presents a novel approach to document ranking called HybridMaxSim. Experiments conducted indicate that the HybridMaxSim formula is effective in enhancing the precision of web document ranking up to 0.87 according to the nDCG criterion.",JWE,2023,,22,5,,797-820,2,1,https://ieeexplore.ieee.org/document/10374421/
Reliable and Scalable Big-Data Applications in Edge Cloud Environments,In-Young Ko | Abhishek Srivastava | Michael Mrissa,"Korea Advanced Institute of Science and Technology, South Korea | Indian Institute of Technology Indore, India | InnoRenew CoE, Slovenia",,"The international workshop on big-data-driven edge cloud services (BECS) is a venue where scholars and practitioners can share their experiences and present ongoing work on developing data-driven applications and services in a distributed computing environment so-called edge cloud. The second edition of the workshop (BECS 2022)1 was held in con06ction with the 22nd International Conference on Web Engineering (ICWE 2022),2 which was held in Bari, Italy on 5-8 July, 2022.",JWE,2023,,22,2,,v-viii,2,0,https://ieeexplore.ieee.org/document/10243561/
Web 3.0 Applications Supported by Artificial Intelligence and Blockchain Technologies,Vijayan Sugumaran | Sooyong Park,"Oakland University, Rochester, Michigan, USA | Sogang University, Seoul, South Korea",,"Web 3.0 is a term used to describe the next generation of the internet that is being built on blockchain technology. It is expected to have a significant impact on society by decentralizing power and control over social media platforms and other mediums of cultural interaction. Web 3.0 gives power to the actual participants in the cultural economy - the creators and the community. With Web 3.0, communities can be more than just consumers of culture - they become active participants in the creator economy. They can become owners and decision-makers in that role instead of just being fans. While research on various aspects of Web 3.0 applications is progressing at a very fast pace, this is only the beginning. There are still a number of issues that have to be explored in terms of the design, implementation and deployment Web 3.0 applications and the enabling technologies. For example, various issues that need to be addressed include extendibility and interoperability of blockchain, NFT based authentication technology based on digital wallet, reward method-based consumer's efforts, Web 3.0 business model etc. This special issue focuses on these issues and present the state of the art in Web 3.0 with AI and its applications.",JWE,2024,,23,5,,v-vii,2,0,https://ieeexplore.ieee.org/document/10654700/
Efficient Machine Learning Systems in Edge Cloud Environments,In-Young Ko | Michael Mrissa | Juan Manuel Murillo | Abhishek Srivastava,"Korea Advanced Institute of Science and Technology, South Korea | InnoRenew CoE, Slovenia | University of Extremadura, Spain | Indian Institute of Technology Indore, India",,"The international workshop on Big Data-Driven Edge Cloud Services (BECS) aims to provide a platform for scholars and practitioners to share their experiences and present ongoing work in developing data-driven AI applications and services within distributed computing environments, commonly referred to as the edge cloud.",JWE,2024,,23,8,,v-vii,2,0,https://ieeexplore.ieee.org/document/10879110/
"Research on Quantum Key, Distribution Key and Post-Quantum Cryptography Key Applied Protocols for Data Science and Web Security",Kyu-Seok Shim | Boseon Kim | Wonhyuk Lee,"Div. of Science and Technology Digital Convergence, Advanced Quantum Network Research Center, Korea Institute of Science and Technology Information, Daejeon, Korea | Div. of Science and Technology Digital Convergence, Advanced Quantum Network Research Center, Korea Institute of Science and Technology Information, Daejeon, Korea | Div. of Science and Technology Digital Convergence, Advanced Quantum Network Research Center, Korea Institute of Science and Technology Information, Daejeon, Korea",Quantum | key management system | PQC | data science | web security,"Currently, data security is one of the most concerning research topics. The traditional RSA encryption system has become vulnerable to quantum algorithms such as Grover and Shor, leading to the development of new security systems for the quantum. As a result, quantum cryptography is gaining importance as a key element of future communication security. This study focuses on quantum key distribution protocols for data quantum encryption, aiming to achieve quantum robustness in all stages of quantum cryptography communication processes. Quantum cryptography communication requires robust quantum encryption not only between end-nodes but also between all components. Therefore, this study demonstrates the process of end-to-end data quantum encryption and proves the overall quantum robustness in this process.",JWE,2024,,23,6,,813-830,2,0,https://ieeexplore.ieee.org/document/10747171/
Run-Time Application Migration Using Checkpoint/Restore In Userspace,Aleksandar Tošić,"University of Primorska Faculty of Mathematics, Natural Sciences and Information Technologies, Koper, Slovenia",Checkpoint/Restore | edge computing | run-time container migration,"This paper presents an empirical study on the feasibility of using Checkpoint/Restore In Userspace (CRIU) for run-time application migration between hosts, with a particular focus on edge computing and cloud infrastructures. The paper provides experimental support for CRIU in Docker and offers insights into the impact of application memory usage on checkpoint size, time, and resources. Through a series of tests, we establish that the time to checkpoint is linearly proportional to the size of the memory allocation of the container, while the restore is significantly lower. Our findings contribute to the understanding of CRIU's performance and its potential use in edge computing scenarios. To obtain accurate and meaningful findings, we monitored system telemetry while using CRIU to observe its impact on the host machine's CPU and RAM utilization. Although our results may not be groundbreaking, they offer a good overview and a technical report on the feasibility of using CRIU on edge devices, which are typically resource constrained. This study's findings and experimental support for CRIU in Docker could serve as a useful reference for future research on performance optimization and application migration using CRIU.",JWE,2024,,23,5,,735-748,2,4,https://ieeexplore.ieee.org/document/10654692/
Collaborative Task Offloading in Edge Computing Enabled Web 3.0,Mohammed Alkhathami,"Information Systems Department, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia",Web 3.0 | task offloading | edge computing,"Web 3.0 is an evolved version of the Web that enables the integration of applications such as the Internet of Things (IoT) with the Web. It involves the storage of large data generated by different users and efficient computation of application and web-related tasks. With the help of edge nodes installed near the users, the computation load of Web 3.0 will be efficiently managed. Thus, efficient task offloading and computation become a key concern in edge computing-enabled Web 3.0. In this paper, a novel algorithm is proposed that solves the challenges of load imbalance at the edge nodes resulting in large queue sizes and increased task delays. The proposed technique identifies the edge nodes with a large network load and pairs them with a lightly loaded edge node that can handle some of their network load. The edge node pairing is based on the Gale-Shapley stable matching algorithm. The preference profile of edge nodes is developed based on factors such as task computation delay and task transmission delay. Once the pairing is done, the number of tasks is offloaded as per the computing capacity of the lightly loaded edge nodes. A detailed simulation-based performance evaluation of the proposed technique is presented showing a reduction in task delay by 20% and task deadline miss ratio by 68%.",JWE,2024,,23,5,,681-697,2,0,https://ieeexplore.ieee.org/document/10654717/
Data Lake Conceptualized Web Platform for Food Research Data Collection,Gi-taek An | Seyoung Oh | Eunhye Kim | 06g-min Park,"Korea Food Research Institute, Wanju-gun, Republic of Korea | Korea Food Research Institute, Wanju-gun, Republic of Korea | Korea Food Research Institute, Wanju-gun, Republic of Korea | Korea Food Research Institute, Wanju-gun, Republic of Korea",Food research data | big data | data platform | data collection | web-based platform,"Food research is uniquely intertwined with everyday life and necessitates the utilization of big data. Within this domain, the research data consist of various forms and formats, encompassing biological experiment results, chemical analysis data, nutritional information, microbiological data, sensor data, images, and videos. This diversity stems from the integration of data from various subdomains within the larger field. With recent advancements in deep learning technology, the importance of data has grown significantly, resulting in increased reliance on data-driven research. Although specialized platforms for sharing and utilizing data have been established at the national level, particularly in the bioscience field, food research lacks a dedicated infrastructure and specialized data-sharing platforms. In this study, we develop a platform that leverages Hadoop-based distributed file systems to create a data lake. This platform enables data storage and sharing through a web-based interface. The distributed file system supports scalability by adding data nodes, making it an effective solution for capacity expansion. In addition, the web-based platform ensures high accessibility, allowing users access from anywhere, at any time, using any device. Finally, we introduce the establishment of a 1.8 PB Hadoop-based physical storage system and present an approach for building a highly accessible web platform with substantial utility.",JWE,2024,,23,3,,377-392,2,1,https://ieeexplore.ieee.org/document/10547279/
Cluster-Based Data Sharing for Web 3.0 in Intelligent Transportation Systems,Mohammed Alkhathami,"Information Systems Department, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia",Intelligent transportation system | vehicular network | Web 3.0 | mobility | data sharing,"Intelligent transportation system (ITS) applications are dependent on secure and robust wireless data sharing among vehicles and roadside units (RSUs). Multiple types of data are shared among the ITS devices which include safety information, road services, web based information retrieval and task computation. Web 3.0 offers a decentralized, distributed and secure data sharing mechanism for ITSs. Allocation of wireless channel resources are critical to enable an efficient ITS system. In this paper, a novel data sharing technique for Web 3.0 based ITS is presented that relies on an intelligent clustering algorithm. In the first step, the proposed technique uses a K-means algorithm to find groups of vehicles with similar speeds. In the second step, each cluster is assigned an RSU which has the highest average data rate with all vehicles in the cluster. This is achieved by using a stable matching technique so that there is no contention and each cluster is assigned a separate RSU. The algorithm periodically updates the clusters and RSU allocation for web data sharing between vehicles and RSUs. Simulation results show that the proposed clustering-based data sharing technique improves sum-rate by 20% and reduces network delay by 23%.",JWE,2024,,23,7,,1025-1040,2,0,https://ieeexplore.ieee.org/document/10815633/
Web 3.0 Chord DHT Resource Clustering,KaiHsiang Chan | Young Yoon,"Department of Computer Engineering, Hongik University, Seoul, South Korea | Department of Computer Engineering, Hongik University, Seoul, South Korea",Chord | DHT | Web 3.0 | resource clustering | load balancing,"This study explores the impact and challenges of new user behaviors in the Web 3.0 environment on distributed networks. The traditional Chord algorithm allows nodes to freely join and leave the network by hashing their IP addresses, and publishing and storing resources through the same hash function. When the keys of the resources are unique, the resources will be evenly distributed across each node, thereby achieving load balancing. However, in cases where many identical resources are published, this method leads to specific nodes bearing too much load, causing performance bottlenecks and resource concentration issues. In Web 3.0, when the nodes use the resource's topic as the key to publish resources, as the topic's popularity increases, the number of nodes using the same key as the publishing node and the nodes with demand for the topic resources will also increase. In the traditional Chord algorithm, the same key will be managed by the same node. The node responsible for the key needs to save the routing information of all related nodes and cope with a large number of resource requests for it. To address these issues, this paper proposes a new variant of the Chord algorithm, which uses two different Chord rings for resource clustering: one based on the hash of resource names and the other based on the hash of IP addresses. This method allows us to allocate resources more effectively, ensuring each node bears a reasonable load share according to capacity. This paper will present the design principles of this method and validate its effectiveness in improving resource distribution and reducing the problem of single-point overload through experiments.",JWE,2024,,23,5,,699-716,2,0,https://ieeexplore.ieee.org/document/10654691/
Self-Sovereign and Secure Data Sharing Through Docker Containers for Machine Learning on Remote Node,06gchul Seo | Younggyo Lee | Young Yoon,"Department of Computer Engineering, Hongik University, Seoul, South Korea | Department of Computer Engineering, Hongik University, Seoul, South Korea | Department of Computer Engineering, Hongik University, Seoul, South Korea",Self-sovereignty | trusted execution environment | data sharing | containers | Web3.0,"Collecting personal data from various sources and using it for machine learning (ML) is prevalent. However, there are increasing concerns about the monopolization and potential breach of private data by greedy and malicious organizations. Interest in Web 3.0 systems is on the rise as an alternative. These systems aim to guarantee the self-sovereignty of personal data in a decentralized setting. Users can share data with others directly for fair compensation. Nevertheless, malicious remote users can still violate the integrity and confidentiality of personal data. Therefore, this paper proposes a novel method of preventing unwanted leakage and counterfeiting of the private data lent on the premise of remote users. This paper focuses on the decentralized nature of Web 3.0 to leverage existing personal storage so that the burden of collecting secure data is relieved. Data owners create a lightweight Docker container to encapsulate their private data sources. The data owners generate another container to be deployed on a remote premise for taking and executing any ML algorithms remote users create. Between the containers forming a distributed trusted execution environment (TEE), data are read through a secure channel. Since the TEE is strictly controlled by the data owner, no malicious ML application can leak or breach the private information. This paper explains the engineering details of how this new method is realized.",JWE,2024,,23,5,,637-655,2,1,https://ieeexplore.ieee.org/document/10654693/
Flight Price Prediction Web-Based Platform: Leveraging Generative AI for Real-Time Airfare Forecasting,Yuanyuan Guan,"School of Tourism, Hainan University, Haikou, China",Flight price prediction | generative artificial intelligence | deep learning | real-time forecasting,"The aviation business encounters difficulties in correctly and swiftly predicting flight fares due to the dynamic nature of the sector. Factors such as variations in demand, fuel costs, and the intricacies of various routes have an impact on this. This work presents a new method to tackle this issue by utilizing generative artificial intelligence (GAI) approaches to accurately forecast airfares in real-time. This paper presents a novel framework that integrates generative models, deep learning architectures, and historical pricing data to improve the precision of future flight price predictions. The study employs a GAI within a cutting-edge web engineering framework. This approach is designed primarily to gather knowledge about complex patterns and relationships present in historical airline data. Through the utilization of this methodology, the model is able to accurately perceive complex connections and adjust to ever-changing market conditions. Our model utilizes deep neural networks to effectively handle various circumstances and extract vital information, so facilitating a comprehensive comprehension of the intricate elements that impact flight cost. Moreover, the suggested approach places significant emphasis on precisely predicting upcoming occurrences in real-time, facilitating prompt reactions to market volatility and offering a valuable resource for airlines, travel agents, and customers alike. In order to enhance the accuracy of real-time forecasts, we utilize a web-based platform that allows for smooth interaction with live data streams and guarantees swift updates. The results demonstrate the model's capacity to adjust to dynamic market conditions, rendering it an attractive option for stakeholders in search of precise and current forecasts of flight prices.",JWE,2024,,23,2,,299-314,2,2,https://ieeexplore.ieee.org/document/10504110/
"Enhancing Security in Low-Power Wide-Area (LPWA) IoT Environments: The Role of HSM, Tamper-Proof Technology, and Quantum Cryptography",Hyung-Sub Han | Tae-hyuk Choi | Jong-Seong Yoon,"SAMIN Geomatics Co., Ltd., Seoul, Korea | SAMIN Geomatics Co., Ltd., Seoul, Korea | SAMIN Geomatics Co., Ltd., Seoul, Korea",Web-based LPWA security framework | ruggedized IoT | HSM | tamper-proof,"Low-power wide-area (LPWA) networks are integral to expanding Internet of Things (IoT) applications, offering extensive coverage with low power consumption. However, these networks face significant security challenges due to their widespread deployment and inherent constraints. In order to provide secure services in an LPWA IoT environment, important information stored in IoT devices (encryption keys, device unique numbers, etc.) must be safely protected from external hacking or theft by physical access, and it is necessary to develop tamper-proof technology to enhance physical security. Meanwhile, with so many ruggedized IoT devices processing and transmitting sensitive information, security systems are essential to protect the integrity and privacy of IoT data. This paper explores the critical role of hardware security modules (HSMs), tamper-proof technology, and quantum cryptography in enhancing the physical, network, and data security of LPWA IoT environments. We propose operational strategies for HSMs, tamper-proof technology in ruggedized LPWA IoT settings, and a quantum key distribution (QKD)-based IPsec solution for robust network and data security.",JWE,2024,,23,6,,787-800,2,1,https://ieeexplore.ieee.org/document/10747167/
Optimal Path Calculation for Multi-Ring Based Packet-Optical Transport Networks,Hyuncheol Kim,"Namseoul university, Cheonan, Korea",MPLS-TP | protection and recovery | optimal path calculation,"Multi-domain optical transport networks are inherently non-interoperable and require integrated orchestration and path provisioning mechanisms at the network-wide level. Moreover, ensuring the network's survivability is a critical issue. While the MPLS-TP (multi-protocol label switching-transport profile) defines various protection and recovery mechanisms as standards, it does not address methods for calculating and selecting protection and recovery paths. Therefore, an algorithm is needed to calculate and set up paths to ensure quick protection and recovery across the entire integrated network, minimizing conflicts in protection and recovery at the packet optical integrated network level. In this paper, we proposed an algorithm that calculates and sets a path that enables rapid protection and recovery in an MPLS-TP network composed of a multi-ring-mesh topology. To this end, this study proposes the concept of a transparent node (T-node) for calculating link-disjoint SPF (shortest path first) in a multi-ring network with dual or more rings. A T-node is a node in a ring with more than a dual ring and indicates that the node has been used once in route calculation. Therefore, during path calculation, a T-node can be used as a source node and an intermediate node but not as a destination node.",JWE,2024,,23,6,,801-812,2,0,https://ieeexplore.ieee.org/document/10747169/
Integration of an Open Source Identity Management System in Educational Platforms,Enrique Barra | Alejandro Pozo | Sonsoles López-Pernas | Alvaro Alonso | Aldo Gordillo,"Universidad Politécnica de Madrid, Madrid, Spain | Universidad Politécnica de Madrid, Madrid, Spain | University of Eastern Finland, Joensuu, Finland | Universidad Politécnica de Madrid, Madrid, Spain | Universidad Politécnica de Madrid, Madrid, Spain",Identity and access management | software integration | single sign on | educational platforms,"Making research advances available to the community in the shape of open source software has the potential to introduce cutting-edge innovations from early on, foster collaborative development, and revolutionize industrial applications. However, including open source software resulting from a research project as part of a production system poses some risks and must be evaluated in detail, considering all pros and cons. This is especially delicate when that piece of software is in charge of authentication and authorization. This article reports on an experience of integrating open source identity and access management (IAM) software that is the result of multiple research projects, the FIWARE Keyrock IAM, into three educational web-based platforms: two learning object repositories and a course management platform. We intend to draw the lessons learned from this experience so they can guide software practitioners when deciding if they should integrate open source software developed in research projects.",JWE,2024,,23,4,,595-609,2,0,https://ieeexplore.ieee.org/document/10634591/
Priority-Based QoS Extensions and IAM Improvements,Gyudong Park | Hyoek Jin Choi,"ADS&TR Institute, Command and Control Systems PMO, Agency for Defense Development, Seoul, Korea | ADS&TR Institute, Command and Control Systems PMO, Agency for Defense Development, Seoul, Korea",Access congestion | priority-based access control (PBAC),"The command and control system operates in a harsh and dynamic environment with limited resources and have a very high risk of failure or malfunction. In the case of military information systems, including the com-mand and control system, the efficiency and effectiveness of system resource management are very important and required. Therefore, the application of a QoS-like approach is necessary to improve the operational effectiveness of all command and control system resources. However, supporting QoS at the entire command and control system level incurs additional costs and burdens for implementation and operation. This paper describes the necessity and possibility of collaboration with QoS and IAM (identity and access management) among the collaboration between core functions within the command and control system. This paper proposes an extended QoS approach to improve the operational effectiveness of the entire command and control system resources. As a result of this research, expanded concepts, structures, standards, and methods of collaboration between QoS and IAM are developed and presented, and their feasibility is demonstrated through prototype development and experiments.",JWE,2024,,23,6,,769-786,2,0,https://ieeexplore.ieee.org/document/10747170/
Increased Productivity and Reduced Waste with Robotic Process Automation and Generative AI-Powered IoE Services,Wei Lo | Chun-Ming Yang | Qiansha Zhang | Mingyuan Li,"School of Business Administration, Guangxi University of Finance and Economics, Nanning, Guangxi, China | School of Economics and Management, Dongguan University of Technology, Dongguan, Guangdong, China | School of Business Administration, Guangxi University of Finance and Economics, Nanning, Guangxi, China | School of Business Administration, Guangxi University of Finance and Economics, Nanning, Guangxi, China",Robotic process automation (RPA) | generative AI (GAI) | Internet of Everything (IoE) | industrial productivity | waste management,"The convergence of robotic process automation (RPA) and generative AI (GAI) within the context of Internet of Everything (IoE) services represents a profound paradigm shift. This fusion of technologies not only streamlines routine tasks but also catalyzes innovation while harnessing the potential of interconnected devices. Such integration empowers organizations to achieve remarkable gains in efficiency and sustainability. This paper embarks on an exploration of these transformative services, designed to elevate productivity, and curtail wasteful practices in contemporary industries. By closely examining intricate case studies, we illuminate the multifaceted advantages of this integrated approach. Our investigation demonstrates how RPA accelerates the execution of repetitive processes, substantially diminishing the margin for human error and amplifying operational efficiency. In contrast, generative AI introduces a disruptive force, generating fresh ideas, designs, and solutions, thereby elevating the quality of products and services. The infusion of these cutting-edge technologies into the fabric of IoE services paves the way for organizations to attain unprecedented levels of automation, intelligence, and connectivity. Furthermore, this paper comprehensively addresses the intricate challenges and considerations associated with the proposed implementation. We delve into ethical concerns, security implications, and the necessary workforce adaptation to offer a balanced perspective on the adoption of these technologies. Additionally, we navigate through potential limitations and constraints, underscoring the imperative need for strategic planning and robust governance.",JWE,2024,,23,1,,53-87,2,18,https://ieeexplore.ieee.org/document/10488437/
Enhancing English Language Education Through Big Data Analytics and Generative AI,Jianhua Liu,"School of Foreign Languages, Anyang Normal University, Anyang, China",Big data analysis | generative AI | language education | learning English,"This research paper provides a comprehensive examination of the significant impact of big data analytics and generative artificial intelligence (GAI) on the field of English language education. Utilizing a meticulous framework rooted in the evolutionary network influence of big data, our study critically analyzes several aspects of student engagement, learning motivation, self-efficacy, and the existing disparities among learners. Our primary objective is to enhance students' active participation, intrinsic interest, and self-confidence in the context of English language learning, thus advancing their overall linguistic competence. To achieve these objectives, our study systematically integrates the concept of practice education with a multidisciplinary approach, leveraging the power of big data analysis and GAI, and reveals profound insights into student learning behaviors, preferences, and personalized educational needs. We employ advanced techniques for meticulous data processing and interpretation, empowering educators to make data-informed decisions and tailor pedagogical strategies to meet the unique requirements of each student. This data-driven pedagogical approach not only facilitates the implementation of effective teaching methodologies but also effectively addresses the disparities stemming from diverse student backgrounds, thereby fostering a more inclusive and personalized learning environment.",JWE,2024,,23,2,,227-249,2,15,https://ieeexplore.ieee.org/document/10504108/
Contextualized Satire Detection in Short Texts Using Deep Learning Techniques,Ashraf Kamal | Muhammad Abulaish | Jahiruddin,"PayPal, Chennai, India | Department of Computer Science, South Asian University, New Delhi, India | Department of Computer Science, Jamia Millia Islamia (A Central University), New Delhi, India",Information retrieval | online social media | figurative language detection | satire detection | deep learning,"Satire is prominent in user-generated content on various online platforms in the form of satirical news, customer reviews, blogs, articles, and short messages that are typically of an informal nature. As satire is also used to disseminate false information on the Internet, its computational detection has become a well-known issue. Existing work focuses primarily on formal document- or sentence-level textual data, whereas informal short texts have gotten less attention for satire detection. This paper presents a new model called BiLSTM self-attention (BiSAT) for detecting satire in informal short texts. It consists of various components such as input, embedding, self-attention, and two bi-directional long short-term memory (BiLSTM) layers for learning crucial contextual information pertaining to the satire present in the texts. The input layer uses the text as input to create an input vector, which is then given to the embedding layer to create the appropriate numeric vector. The output of the embedding layer is passed on to the first BiLSTM layer, which extracts contextual information-based sequences in the opposite direction. Between the first and second BiLSTM layers, a self-attention layer is employed to draw attention to the important satirical information that is acquired by the hidden layer of the first BiLSTM. The BiSAT model also takes a classic feature engineering approach, employing a 13-dimensional auxiliary feature vector comprised of features from four separate feature categories: sentiment, punctuation, hyperbole, and affective. The proposed BiSAT model is empirically evaluated on two benchmark datasets and a newly created dataset called Satire-280. It outperforms existing research and baseline methods by a significant margin. The Satire-280 dataset along with code can be downloaded from GitHub repository: https://github.com/Ashraf-Kamal/Satire-Detection.",JWE,2024,,23,1,,27-52,2,4,https://ieeexplore.ieee.org/document/10488438/
Overcoming Terrain Challenges with Edge Computing Solutions: Optimizing WSN Deployments Over Obstacle Clad-Irregular Terrains,Shekhar Tyagi | Abhishek Srivastava,"Department of Computer Science and Engineering, Indian Institute of Technology, Indore, India | Department of Computer Science and Engineering, Indian Institute of Technology, Indore, India",Wireless sensors | irregular-terrain | obstacles | sensor deployment,"Wireless sensor networks (WSNs) are primarily used for real time data collection and monitoring, especially in environments where direct human involvement is challenging due to harsh conditions. Optimized deployment of WSN nodes is a long standing issue and several ideas have been proposed to address this. Existing deployment strategies are mostly based on the assumption that the terrain for deployment of nodes is perfectly regular. This is an impractical assumption and in this paper we address this gap by proposing a deployment strategy for WSN nodes over irregular terrains. Such terrains comprise uneven elevations, morphology and vegetation based obstacles, rocky obstacles, and so on. Our approach comprises extraction of satellite images of the region of interest (RoI) from Google Earth and generating a KML file (Keyhole Markup Language) for the RoI containing the latitude, longitude, and elevation values of each and every point in the RoI. These points are used to generate a contour map of the RoI containing detailed terrain morphology. A radio frequency path loss model in combination with an advanced inverse distance weighted (IDW)-interpolation technique is proposed to ensure connectivity and coverage in such irregular terrains with varying nature of obstacles. The technique effectively detects occlusions and enables effective deployment. This edge computing approach involves real-time decision-making at the network edge (the sensor nodes) leading to a deterministic deployment of motes in diverse terrain conditions with various obstacles. The approach is compared with existing deployment techniques and the results validate its efficacy. To demonstrate the practicality of our approach, we have also implemented a deployment in real-world environmental conditions, validating our approach in challenging terrains.",JWE,2024,,23,8,,1127-1154,2,1,https://ieeexplore.ieee.org/document/10879109/
Ethereum Smart Contract Account Classification and Transaction Prediction Using the Graph Attention Network,Hankyeong Ko | Sangji Lee | 06gwon Seo,"Graduate School of Metaverse, Sogang University, Mapo-gu, South Korea | Data Science-Artificial Intelligence, Sogang University, Sepul, South Korea | Department of Computer Science and Engineering, Sogang University, Seoul, South Korea",Blockchain | decentralized application(Dapps) | Graph Attention Networks version 2 (GATv2),"This study explores the application of a Graph Attention Networks version 2 (GATv2) model in analyzing the Ethereum blockchain network, addressing the challenge posed by its inherent anonymity. We constructed a heterogeneous graph representation of the network to categorize contract accounts (CAs) into different decentralized application (DApp) categories, such as DeFi, gaming, and NFT markets, using transaction history data. Additionally, we developed a link prediction model to forecast transactions between externally owned accounts (EOAs) and CAs. Our results demonstrated the effectiveness of the heterogeneous graph model in improving node embedding expressiveness and enhancing transaction prediction accuracy. The study offers practical tools for analyzing DApp flows within the Web3 ecosystem, facilitating the automatic prediction of CA service categories and identifying active DApp usage. While currently focused on the Ethereum network, future research could expand to include layer 2 networks like Arbitrum One, Optimism, and Polygon, thereby broadening the scope of analysis in the evolving blockchain landscape.",JWE,2024,,23,5,,657-680,2,2,https://ieeexplore.ieee.org/document/10654715/
Enhancing Suggestion Detection in Online User Reviews through Integrated Information Retrieval and Deep Learning Approaches,Zahra Hadizadeh | Amin Nazari | Muharram Mansoorizadeh,"Computer Engineering Department, Bu-Ali Sina University, Iran | Computer Engineering Department, Bu-Ali Sina University, Iran | Computer Engineering Department, Bu-Ali Sina University, Iran",User generated content analysis | suggestion mining | information retrieval | information extraction | text mining | sentiment analysis | deep learning,"In the aftermath of the COVID-19 pandemic, using web platforms as a communication medium and decision-making tool in online commerce has become widely acknowledged. User-generated comments, reflecting positive and negative sentiments towards specific items, serve as invaluable indicators, offering recommendations for product and organizational improvements. Consequently, the extraction of suggestions from mined opinions can enhance the efficacy of companies and organizations in this domain. Prevailing research in suggestion mining predominantly employs rule-based methodologies and statistical classifiers, relying on manually identified features. However, a recent trend has emerged wherein researchers explore solutions grounded in deep learning tools and techniques. This study aims to employ information retrieval techniques for the automated identification of suggestions. To this end, various methodologies, including distance measurement approaches, multilayer perceptron neural networks, support vector machines, regression logistics, convolutional neural networks utilizing TF-IDF, Bag of Words (BOW), and Word2Vec vectors, along with keyword extraction, have been integrated. The proposed approach is assessed using the SemEval2019 dataset to extract suggestions from the textual content of online user reviews. The obtained results demonstrate a notable enhancement in the F1 score, reaching 0.76 compared to prior research. The experiments further suggest that information retrieval-based approaches exhibit promising potential for this specific task.",JWE,2024,,23,3,,431-463,2,1,https://ieeexplore.ieee.org/document/10547281/
Application of an Improved Convolutional Neural Network Algorithm in Text Classification,Jing Peng | Shuquan Huo,"School of Philosophy, Anhui University, Hefei, China | School of Philosophy and Public Management, Henan University, Kaifeng, China",Text classification | convolutional neural network | support vector machine | attention mechanism,"This paper proposes a text classification model based on a combination of a convolutional neural network (CNN) and a support vector machine (SVM) using Amazon review polarity, TREC, and Kaggle as experimental data. By adding an attention mechanism to simplify the parameters and using the classifier based on SVM to replace the Softmax layer, the extraction effect of feature words is improved and the problem of weak generalization ability of the CNN model is solved. Simulation experiments show that the proposed algorithm performs better in precision rate, recall rate, F1 value, and training time compared with CNN, RNN, BERT and term frequency-inverse document frequency (TF-IDF).",JWE,2024,,23,3,,315-339,2,2,https://ieeexplore.ieee.org/document/10547278/
"Leveraging the Synergy of IPv6, Generative AI, and Web Engineering to Create a Big Data-Driven Education Platform",Gao Yongli | Dong Qi | Chen Zhipeng,"Financial Office, Tangshan Normal University, Tangshan, China | Department of Computer Science, Tangshan Normal University, Tangshan, China | Department of Computer Science, Tangshan Normal University, Tangshan, China",Web engineering | IPv6 | generative AI | education informatization | big data platform,"The rapid advancement of network technology in China has significantly accelerated the implementation of information technology in higher education. Through the utilization of computer technology, multimedia technology, big data technology, artificial intelligence technology, and network communication technology, the integration of these technologies in university teaching has become widespread. This paper presents an analysis and discussion on the utilization of the latest IPv6 network transmission protocol technology to enhance the application of data collection in university education, with a specific focus on gathering information related to university faculties. By leveraging web engineering and multimedia technology as fundamental components, the network facilitates the sharing of educational resources among students, thereby enabling the reform of management approaches, fostering educational progress in China, and establishing a comprehensive big data-driven education platform specifically tailored to colleges and universities. Additionally, the incorporation of big data visualization and analysis tools allows for easy retrieval of existing university educational information, facilitates the creation of data charts, and expedites the utilization of data for its inherent value. Finally, the proposed approach employs generative AI to collect and analyze feedback from students and educators, followed by the application of web engineering techniques to continuously enhance the online education platform based on this feedback.",JWE,2024,,23,2,,197-226,2,7,https://ieeexplore.ieee.org/document/10504107/
Transformative Technologies in the Evaluation of a Vocational Education System,Yan06 Zhang | Xiaoyu Sun | Jiangde Yu,"ZhongShan Polytechnic, Zhongshan, China | ZhongShan Polytechnic, Zhongshan, China | ZhongShan Polytechnic, Zhongshan, China",Intelligent management framework | vocational college teachers | deep learning | generative language model,"The increasing demand for vocational education has necessitated the presence of highly skilled teachers. This study presents a novel framework for the effective management of vocational college instructors' professional development through the utilization of advanced technologies. The system utilizes deep learning technology to analyze many data points, including academic achievements, teaching experience, student comments, and professional activities, in order to assess the performance and potential of teachers. The system evaluates both the positive and negative aspects, offers customized training programs, and enhances the delivery of instruction through the utilization of a generative language model. The effectiveness of the system is supported by a case study, which demonstrates enhancements in talent management, professional development, teaching quality, and student happiness. This proposed solution aims to improve vocational education by empowering educators and transforming the processes of evaluation, support, and guidance throughout their professional trajectories.",JWE,2024,,23,2,,275-298,2,7,https://ieeexplore.ieee.org/document/10504111/
How Are Web APIs Versioned in Practice? A Large-Scale Empirical Study,Souhaila Serbout | Cesare Pautasso,"Software Institute (USI), Lugano, Switzerland | Software Institute (USI), Lugano, Switzerland",API | Web API | OpenAPI | empirical study | versioning,"Web APIs form the cornerstone of modern software ecosystems, facilitating seamless data exchange and service integration. Ensuring the compatibility and longevity of these APIs is paramount. This study delves into the intricate realm of API versioning practices, a crucial mechanism for managing API evolution. Exploring an expanded and diverse dataset of 603 293 APIs specifications created during the 2015-2023 timeframe and gathered from four different sources, we examined the adoption of the following versioning practices: Metadata-based, URL-based, Header-based and Dynamic versioning, with one or more versions in production. API developers use more than 50 different version identifier formats to encode information about the changes introduced with respect to the previous version (i.e., semantic versioning), about when the version was released (i.e., age versioning) and about which phase of the API development lifecycle the version belongs (i.e., stable vs. preview releases).",JWE,2024,,23,4,,465-506,2,2,https://ieeexplore.ieee.org/document/10634592/
Examining the Empirical Relationship Between Quality of Service (QoS) and Trust Mechanisms of Cloud Services,Pooja Goyal | Sukhvinder Singh Deora,"Department of Computer Science and Application, MD University, Rohtak, Haryana, India | Department of Computer Science and Application, MD University, Rohtak, Haryana, India",Cloud broker | MCDM | trust estimation | QoS | risk assessment | multi-tenancy | SMI,"Service selection has emerged as a prominent challenge due to the flourishing demand for computing services and the dynamic nature of its resources. The increasing demand for cloud services makes it challenging to choose a provider offering equal services and facilities at costs that match those of competing providers. Apart from educating customers in the process of choosing cloud services, trust mechanisms include user reviews, reputation systems, and certifications assist to boost consumers' confidence in cloud services. The service measurement index (SMI) offers a disciplined framework combining both functional and non-functional quality of service indicators concurrently, therefore easing decision-making. The main emphasis of the research is on the fundamental elements influencing the choice of cloud services in the present environment, the identification of extra characteristics of cloud services transcending SMI, and the identification of the most suitable approach for some services. By means of the measurement of customer enjoyment and experience, QoS traits provide some insight on the impact of trust mechanisms on service acceptance. Comparisons of SMI and QoS measurements before and after trust mechanism deployment provide insightful analysis. Empirical research guides these comparisons. This study aims to clarify the interactions among QoS, trust mechanisms, and cloud service adoption as well as highlight the implications these elements have for customers and service providers. Furthermore, presented in this paper is an algorithm using a comprehensive method to trust estimation in order to ascertain the degree of confidence worthiness of certain people.",JWE,2024,,23,7,,913-971,2,0,https://ieeexplore.ieee.org/document/10815700/
Semantically Enriched Keyword Prefetching Based on Usage and Domain Knowledge,Sonia Setia | Jyoti | Neelam Duhan | Aman Anand | Nikita Verma,"Department of Computer Science and Engineering, SET, Sharda University, Greater Noida, Uttar Pradesh, India | Faculty of Computer Science, J. C. Bose University of Science and Technology, YMCA, Faridabad, India | Faculty of Computer Science, J. C. Bose University of Science and Technology, YMCA, Faridabad, India | ITS Engineering College, Greater Noida, Uttar Pradesh, India | Greater Noida Institute of Technology, Engineering Institute, Greater Noida, Uttar Pradesh, India",Semantic prediction | web usage mining (WUM) | web content mining (WCM) | domain knowledge | usage data | access logs,"In intelligent web systems [2], web prefetching [27] plays a crucial role. In order to make accurate predictions for web prefetching, it is important but challenging to uncover valuable information from web use statistics [16]. Using statistics and domain expertise, this study presents a new approach dubbed SPUDK for efficient prefetching. In this paper, it is shown how web access logs can be used efficiently for browsing prediction. Our main focus is on the technique needed to manage the queries found in web access logs so that valuable information can be attained. We further process these access logs using a taxonomy and a thesaurus, WordNet, to find the semantics of queries. SPUDK, a system that organises use data into semantic clusters, is one example of this approach. Our contributions in this paper are as follows: (1) A technique to exploit query keywords from access logs. (2) An approach to enrich queries with semantic information. (3) A new similarity measure for finding similarity among URLs present in access logs. (4) A novel clustering technique to find semantic clusters of URLs. (5) Experimental evaluation of the proposed system. The proposed SPUDK system is evaluated using American Online (AOL) logs, which gives improvement of 39% in precision of prediction, 35% in hit ratio and reduction of 50.6% in latency on average as compared to other prediction techniques in the literature.",JWE,2024,,23,3,,341-375,2,1,https://ieeexplore.ieee.org/document/10547277/
A Hypersensitive Intelligent Filter for Detecting Explicit Content in Learning Environments,Yong Yu | Xiaoguo Yin,"Henan Institute of Economics and Trade, Zhengzhou, Henan, China | Henan Institute of Economics and Trade, Zhengzhou, Henan, China",Deep learning | fuzzy logic | GPT-3 | learning environments | explicit content | intelligent filter,"In today's digital age, educational institutions aim to ensure safe learning environments in the light of pervasive explicit and inappropriate content. This study proposes an innovative approach to enhance safety by integrating convolutional neural networks (CNNs) for visual analysis with an intuitionistic fuzzy logic (IFL) filter for explicit content identification. Additionally, it utilizes GPT-3 to generate contextual warnings for users. A large-scale dataset comprising explicit and educational materials is used to evaluate the system. The results show that this hypersensitive filter has high accuracy performance, particularly in handling ambiguous or borderline content. The proposed approach provides an advanced solution to tackle the challenges of detecting explicit content and promotes safer learning environments by show-casing the potential of combining generative AI techniques across various domains.",JWE,2024,,23,1,,89-110,2,0,https://ieeexplore.ieee.org/document/10488433/
A Study on Estimating Theme Park Attendance Using the AdaBoost Algorithm Based on Weather Information from the Korea Meteorological Administration Web,Jinkook Kim | Soohyun Kim,"Korea Institute of Sport Science, South Korea | Dept. of Sport and Healthcare, Namseoul University, South Korea",Machine learning | AdaBoost | theme park | prediction of admission number,"The purpose of this study is to propose an efficient machine learning model based on five years of data for Seoul Grand Park in Republic of Korea, depending on the weather and day characteristics, and to increase its effectiveness as a strategic foundation for national theme park management and marketing. To this end, the AdaBoost model, which reflects the characteristics of the weather and the day of the week, was recently compared with the actual number of visitors and the predicted number of visitors to analyze the accuracy. The analysis showed 30 days of abnormal cases, and the overall annual distribution was found to show similar patterns. Abnormal cases required details of wind speed, average relative humidity, and fine dust concentration for weather information, and it was derived that more accurate predictions would be possible considering variables such as group visitors, new events, and unofficial holidays.",JWE,2024,,23,6,,869-884,2,0,https://ieeexplore.ieee.org/document/10747165/
Code Smell-Guided Prompting for LLM-Based Defect Prediction in Ansible Scripts,Hyunsun Hong | Sungu Lee | Duksan Ryu | Jongmoon Baik,"Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Jeonbuk National University, Jeonju, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Edge-cloud | Ansible | large language models | software defect prediction,"Ensuring the reliability of infrastructure as code (IaC) scripts, like those written in Ansible, is vital for maintaining the performance and security of edge-cloud systems. However, the scale and complexity of these scripts make exhaustive testing impractical. To address this, we propose a large language model (LLM)-based software defect prediction (SDP) approach that uses code-smell-guided prompting (CSP). In some cases, CSP enhances LLM performance in defect prediction by embedding specific code smell indicators directly into the prompts. We explore various prompting strategies, including zero-shot, one-shot, and chain of thought CSP (CoT-CSP), to evaluate how code smell information can improve defect detection. Unlike traditional prompting, CSP uniquely leverages code context to guide LLMs in identifying defect-prone code segments. Experimental results reveal that while zero-shot prompting achieves high baseline performance, CSP variants provide nuanced insights into the role of code smells in improving SDP. This study represents exploration of LLMs for defect prediction in Ansible scripts, offering a new perspective on enhancing software quality in edge-cloud deployments.",JWE,2024,,23,8,,1107-1126,2,0,https://ieeexplore.ieee.org/document/10879172/
A Data Alignment Method for Network Packet Capture Based on DBSCAN,Jiarui Lu | Qinggang Su,"School of Electronic Information, Shanghai Dianji University, Shanghai, China | School of Electronic Information, Shanghai Dianji University, Shanghai, China",DBSCAN | data alignment | network quality detection,"This paper investigates the issues of packet alignment and consistency among PLC devices based on industrial network environments, aiming to ensure the integrity and accuracy of packets from sender to receiver. To achieve this goal, we propose an anomaly detection method that combines the DBSCAN clustering algorithm with the 3-sigma principle to identify and handle abnormal packets that may occur during transmission. By comparing the data between the sending and receiving ends, and analyzing based on timestamps and data content, we validate the alignment of packets in the network environment. Experimental results demonstrate that the proposed method effectively detects and corrects packet loss or delay jitter, thereby enhancing the reliability of communication between PLC devices and the consistency of data transmission. The scheme presented in this paper enables quicker and more precise identification of packet loss and delays, adapting well to various network load conditions. Further experimental analysis indicates that this method excels in reducing both false positive and false negative rates, and it exhibits good scalability, making it applicable to data alignment and consistency verification in other industrial automation scenarios. Ultimately, this novel solution provides stability and accuracy for data transmission among devices in a network environment.",JWE,2024,,23,7,,1003-1023,2,0,https://ieeexplore.ieee.org/document/10815714/
An Effective Scheme to Accelerate NeRF for Web Applications Using Hash-Based Caching and Precomputed Features,OkHwan Bae | Chung-Pyo Hong,"Division of Computer Engineering, Hoseo University, Republic of Korea | Division of Computer Engineering, Hoseo University, Republic of Korea",Neural radiance field | multiresolution hash encoding | 3D reconstruction | cache,"In recent years, 3D reconstruction and rendering technologies have become increasingly important in various web-based applications within the field of web technology. In particular, with the emergence of technologies such as WebGL and WebGPU, which enable real-time 3D content rendering in web browsers, immersive experiences and interactions on the web have been significantly enhanced. These technologies are widely used in applications such as 3D visualization of virtual products or 3D exploration of building interiors on real estate websites. Through these advancements, users can experience 3D content directly in their browsers without the need to install additional software, greatly expanding the possibilities of the web. Amidst this trend, the neural radiance field (NeRF) has garnered attention as a cutting-edge technology that improves the accuracy of 3D reconstruction and rendering. NeRF is a technique widely used in computer vision and graphics for reconstructing 3D spaces from 2D images taken from multiple viewpoints. By predicting the color and density of each pixel, NeRF captures the complex 3D structure and optical properties of a scene, enabling highly accurate 3D reconstructions. However, NeRF's primary limitation is the time-consuming nature of both the training and inference processes. Research efforts to address this issue have focused on two key areas: optimizing network architectures and training procedures to accelerate scene learning, and improving inference speed for faster rendering. While progress has been made in enhancing training speed, challenges remain in improving the inference process. To address these limitations, we propose a two-step approach to significantly improve NeRF's performance. First, we optimize the training phase through a multi-resolution hash encoding technique, reducing the computational complexity and speeding up the learning process. Second, we accelerate the inference phase by caching the input data of the NeRF MLP, which allows for faster rendering without sacrificing quality. Our experimental results demonstrate that this approach reduces training time by 68.42% and increases inference speed by 98.18%.",JWE,2024,,23,7,,1041-1056,2,0,https://ieeexplore.ieee.org/document/10815716/
Risk Score Computation for Android Mobile Applications Using the Twin k-NN Approach,Mahmood Deypir | Toktam Zoughi,"Faculty of Computer Engineering, Shahid Sattari Aeronautical University of Science and Technology, Tehran, Iran | Department of Electrical and Computer Engineering, Shariaty College, Technical and Vocational University (TVU), Tehran, Iran",Malware detection | twin $k-NN$ | realistic risk estimation | security risk,"The Android operating system has a dominant market for use within a wide range of devices. Along with the widespread growth of the use of the Android system and the development of a huge number of apps for this operating system, new malicious apps are released daily by adversaries, which are difficult to identify and deal with. This is due to them using sophisticated techniques and strikes. Although there are a diverse range of classification models and risk estimation metrics for identifying malware in this operating system, there is still a requirement for more effective approaches in this context. In this paper, we present a new algorithm to calculate the security risk score of Android apps, which can be used to identify malicious apps from benign ones. This algorithm uses a novel technique named twin $k$-nearest neighbor. In this technique, to estimate the security risk of an unknown app, its nearest neighbors to malicious apps and its nearest neighbors to normal apps are computed separately using an appropriate distance formula. Then, the security risk of the input app can be computed using a simple formulation. In this formulation, the average distances of both $k$-nearest malicious apps and $k$-nearest non-malicious apps to the input app are used. In this way, the proposed method can calculate a high security risk for malware and a lower security risk for goodware. Experimental evaluations on real datasets show that the proposed algorithm has better performance over the previously proposed ones in terms of detection rate, precision, recall, and f1-score.",JWE,2024,,23,4,,535-559,2,0,https://ieeexplore.ieee.org/document/10634593/
Software Practice and Experience on Smart Mobility Digital Twin in Transportation and Automotive Industry: Toward SDV-Empowered Digital Twin Through EV Edge-Cloud and AutoML,Jonggu Kang,"School of AI Convergence, Sungshin Women's University, Seoul, Republic of Korea",digital twin | internet of things | mobility | connected vehicle | software-defined vehicle | electric vehicle | smart city | transportation | automotive | edge cloud,"A digital twin is a virtual representation of a physical asset that serves as a pivotal convergence technology that facilitates real-time prediction, optimization, monitoring, control, and improved decision-making. It can be widely applied to various domains, such as automotive, manufacturing, logistics, and smart cities. The automotive industry, in particular, is actively integrating digital twins throughout the product life cycle, from research and development, production, sales, and services to enhance the overall customer experience. This paper presents insights and lessons learned on software practice and experience related to implementing smart mobility digital twins, focusing on the potential of transportation digital twins built from data collected by electric vehicles (EVs) with EV edge cloud and automated machine learning (AutoML). Despite current limitations in data sufficiency, we forecast that, as the SDV trend accelerates and the adoption of EVs increases, the digital twin will become essential for the intelligent transportation system (ITS) in future smart cities, enabling accurate traffic predictions even in areas with limited road infrastructure. The successful integration of real-time data, high-performance prediction models, and automated service environments will enhance the effectiveness toward an SDV edge-empowered transportation digital twin.",JWE,2024,,23,8,,1155-1180,2,0,https://ieeexplore.ieee.org/document/10879108/
The Future of Digital Authentication: Blockchain-Driven Decentralized Authentication in Web 3.0,06gwon Seo,"Department of Computer Science and Engineering, Sogang University, Seoul, South Korea",Blockchain | Web 3.0 | Web 3.0 authentication | smart contract,"This paper presents an innovative Web 3.0 authentication technique, designed for a user-centric internet environment. Addressing the rising demand for authentication techniques suitable for Web 3.0, it defines the essential features of such systems and introduces a new approach using smart contracts. This approach utilizes mother and child tokens in con06ction with the lock smart contract to ensure secure authentication. The approach is thoroughly tested against various security threats, including man-in-the-middle, replay, and brute-force attacks, and its practicality is evaluated on Ethereum-based networks.",JWE,2024,,23,5,,611-636,2,2,https://ieeexplore.ieee.org/document/10654714/
SPARQL Optimization Using Re-ordering Joining Patterns with Surrogate Key Concept and Subset Patterns,Rupal Gupta | Sanjay Kumar Malik,"USIC&T, Guru Gobind Singh Indraprastha University, Delhi, India | USIC&T, Guru Gobind Singh Indraprastha University, Delhi, India",SPARQL | RDF | optimization | indexing | reordering | metaheuristics | triple patterns,"Semantic web data resides on the web in the form of knowledge graphs known as RDF graphs and searching around the web has been always a crucial task. For the data retrieval of RDF data of the semantic web, SPARQL query language has been used which in turn is based on triple patterns and joins. Optimization of SPARQL query has been a problematic concern for decades due to the large amount of triple patterns associated with RDF data. Although several researchers have put a lot of effort into the optimization of SPARQL query, it is difficult to understand the concept from scratch due to its diversified nature. This paper analyses various optimization techniques for the SPARQL query used with the semantic web to process knowledge graphs. These techniques include join-based, heuristic-based, rule-based, and indexing-based approaches for optimization. This paper will help researchers in this domain to easily get into the core concept of SPARQL execution along with various optimization approaches used for query processing, which can help in various other domains like linked open data and information retrieval. In this paper, an optimization algorithm HSOA (hybrid SPARQL optimization algorithm) has been proposed, which comprises the features of index-based, cost-based, and triple reordering-based optimization approaches. The proposed hybrid algorithm has been designed specifically for n-triple RDF data, which comprises subset patterns, and surrogate key concepts. The results produced by the proposed algorithm are encouraging and have also been tested and compared with the benchmark dataset and SPARQL queries like LUBM, BSBM, and SP2Bench.",JWE,2024,,23,3,,393-430,2,0,https://ieeexplore.ieee.org/document/10547280/
User Authentication Techniques Using a Dynamic SoulBound Token,Yunjae Joo | 06gwon Seo,"Department of Computer Science and Engineering, Sogang University, Seoul, South Korea | Department of Computer Science and Engineering, Sogang University, Seoul, South Korea",Dynamic SoulBound Token | decentralized authentication | oracle problem | Web 3.0 authentication,"This paper introduces a user authentication technique that utilizes a dynamic SoulBound Token (SBT) to tackle challenges associated with the oracle problem in decentralized environments. The approach uses dual smart contracts - local and global - along with blockchain tokens, removing the need for intermediary verification processes. The proposed method improves security by allowing users direct control over their authentication data, thus mitigating risks associated with centralized authorities and man-in-the-middle attacks. The feasibility and efficacy of this approach are demonstrated through a location-based prototype, indicating significant potential for application in Web 3.0 ecosystems. This paper also provides a comprehensive security analysis, underscoring the robustness of the proposed system against cyber threats.",JWE,2024,,23,5,,717-733,2,0,https://ieeexplore.ieee.org/document/10654716/
An Intelligent Web-Based Energy Management System for Distributed Energy Resources Integration and Optimization,Li06 Zhao | Qingsheng Li | Guanhua Ding,"Electrical and Electronic Engineering Department, Chengde Petroleum College, Chengde, China | Security Division, Chengde Petroleum College, Chengde, China | School of Electronic and Information Engineering, Beihang University, Beijing, China",Energy management systems | web engineering | generative AI | active distribution networks | soft open points | dynamic scenario generation,"The integration of renewable energy sources into power distribution systems frequently presents challenges for conventional energy management systems (EMS) due to the unpredictable and unstable characteristics of such energy sources. As a result, novel and cutting-edge solutions are required. This paper presents an intelligent web-based energy management system (iW-EMS) specifically designed to address the integration and optimization of distributed energy resources, as outlined in the proposed approach. The system incorporates a hybrid novel optimization approach that integrates simulated annealing and cone programming to effectively manage the distribution of energy resources and attain optimal outcomes from the proposed EMS. Additionally, it leverages generative AI services to create optimal scenarios based on historical data and real-time information, ensuring adaptability to the dynamic nature of renewable energy generation, providing a user-friendly and flexible web environment for scenario planning. The proposed framework facilitates seamless communication and collaboration among stakeholders involved in renewable energy integration, while also enabling the incorporation of real-world data sources such as weather forecasts and energy consumption patterns into the planning process.",JWE,2024,,23,1,,165-195,2,3,https://ieeexplore.ieee.org/document/10488436/
Introducing Students to Web Engineering Topics by Teaching Web Augmentation,Iñigo Aldalur,"Electronics and Computing Department, Mondragon Unibertsitatea, Spain",Web engineering | web augmentation | education,"Web augmentation has gained prominence as a promising approach to elevate the user experience by tailoring web content to meet diverse user needs and preferences. It offers the potential to enhance accessibility and personalization, making web experiences more engaging and inclusive. This research study examines the use of web augmentation in the context of web engineering education and its influence on student motivation. The study investigates how the integration of web augmentation techniques motivates students and enhances their learning experience. A questionnaire was administered to gather data on student perceptions and motivation levels following their exposure to web augmentation in the web engineering subject. The findings reveal that the implementation of web augmentation in the web engineering subject has positively motivated students. Students express a strong preference for web augmentation as a learning tool, citing increased engagement and a more interactive learning environment. The findings support the adoption of web augmentation techniques as a valuable pedagogical tool, enhancing the learning experience and fostering student engagement. This study contributes to the field by addressing the gap in related work that focuses on the use of web augmentation specifically in educational settings.",JWE,2024,,23,1,,Jan-26,2,0,https://ieeexplore.ieee.org/document/10488440/
Generative Architecture for Data Imputation in Secure Blockchain-Enabled Spatiotemporal Data Management,Song Li | WenFen Liu | Yan Wu | Jie Zhao,"School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, China | School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, China | Unit 95795 of PLA, Guilin, China | School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, China",Indirect feedback graph algorithm | linked spatiotemporal data | big data analysis | secure access | data retrieval | generative AI | blockchain,"In the era of big data, one of the most critical challenges is ensuring secure access, retrieval, and sharing of linked spatiotemporal data. To address this challenge, this paper introduces a groundbreaking blockchain-enabled evolutionary indirect feedback graph algorithm for the secure management of interconnected spatiotemporal datasets. The algorithm utilizes a generative neural network model for data imputation, predicting and generating plausible values to improve dataset completeness and integrity. The core architecture utilizes blockchain technology to optimize data retrieval efficiency and uphold robust access control mechanisms. The algorithm incorporates indirect feedback mechanisms, allowing users to provide implicit feedback through their interactions, enhancing the relevance and efficiency of data retrieval. In addition. sophisticated graph-based techniques are used to model intricate relationships between data entities, facilitating seamless data retrieval and sharing in interwoven datasets. The algorithm's data security approach includes comprehensive access control mechanisms, encryption, and authentication mechanisms, safeguarding data confidentiality and integrity. Extensive evaluations show significant enhancements in retrieval performance and access control precision, making the proposed model a promising solution for the secure management of expansive interconnected spatiotemporal data.",JWE,2024,,23,1,,111-163,2,2,https://ieeexplore.ieee.org/document/10488442/
Personalized User Models in a Real-World Edge Computing Environment: A Peer-to-Peer Federated Learning Framework,Xiangchi Song | Zhaoyan Wang | KyeongDeok Baek | In-Young Ko,"Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea | Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Peer-to-peer federated learning | personalized federated learning | hierarchical edge computing | edge-cloud environment,"As the number of IoT devices and the volume of data increase, distributed computing systems have become the primary deployment solution for large-scale Internet of Things (IoT) environments. Federated learning (FL) is a collaborative machine learning framework that allows for model training using data from all participants while protecting their privacy. However, traditional FL suffers from low computational and communication efficiency in large-scale hierarchical cloud-edge collaborative IoT systems. Additionally, due to heterogeneity issues, not all IoT devices necessarily benefit from the global model of traditional FL, but instead require the maintenance of personalized levels in the global training process. Therefore we extend FL into a horizontal peer-to-peer (P2P) structure and introduce our P2PFL framework: efficient peer-to-peer federated learning for users (EPFLU). EPFLU transitions the paradigms from vertical FL to a horizontal P2P structure from the user perspective and incorporates personalized enhancement techniques using private information. Through horizontal consensus information aggregation and private information supplementation, EPFLU solves the weakness of traditional FL that dilutes the characteristics of individual client data and leads to model deviation. This structural transformation also significantly alleviates the original communication issues. Additionally, EPFLU has a customized simulation evaluation framework, and uses the EUA dataset containing real-world edge server distribution, making it more suitable for real-world large-scale IoT. Within this framework, we design two extreme data distribution scenarios and conduct detailed experiments of EPFLU and selected baselines on the MNIST and CIFAR-10 datasets. The results demonstrate that the robust and adaptive EPFLU framework can consistently converge to optimal performance even under challenging data distribution scenarios. Compared with the traditional FL and selected P2PFL methods, EPFLU achieves communication time improvements of 39% and 16% respectively.",JWE,2024,,23,8,,1057-1083,2,0,https://ieeexplore.ieee.org/document/10879171/
A Study on Functional Requirements and Inspection Items for AI System Change Management and Model Improvement on the Web Platform,Dongsoo Moon | Seongjin Ahn,"Dept. of Computer Education, Sungkyunkwan University, Seoul, Republic of Korea | Dept. of Computer Education, Sungkyunkwan University, Seoul, Republic of Korea",AI ethics | AI model improvement | AI retraining | AI feedback loop | functional requirements and inspection items for AI,"The rapid adoption of artificial intelligence (AI) on the web platform across multiple sectors has highlighted not only its inherent technical hurdles, such as unpredictability and lack of transparency, but also significant societal concerns. These include the misuse of AI technology, invasions of privacy, discrimination fueled by biased data, and infringements of copyright. Such challenges jeopardize the sustainable growth of AI and risk the erosion of societal trust, industry adoption and financial investment. This analysis explores the AI system's lifecycle, emphasizing the essential continuous monitoring and the need for creating trustworthy AI technologies. It advocates for an ethically oriented development process to mitigate adverse effects and support sustainable progress. The dynamic and unpredictable nature of AI, compounded by variable data inputs and evolving distributions, requires consistent model updates and retraining to preserve the integrity of services. Addressing the ethical aspects, this paper outlines specific guidelines and evaluation criteria for AI development, proposing an adaptable feed-back loop for model improvement. This method aims to detect and rectify performance declines through prompt retraining, thereby cultivating robust, ethically sound AI systems. Such systems are expected to maintain performance while ensuring user trust and adhering to data science and web technology standards. Ultimately, the study seeks to balance AI's technological advancements with societal ethics and values, ensuring its role as a positive, reliable force across different industries. This balance is crucial for harmonizing innovation with the ethical use of data and science, thereby facilitating a future where AI contributes significantly and responsibly to societal well-being.",JWE,2024,,23,6,,831-848,2,0,https://ieeexplore.ieee.org/document/10747166/
Privacy and Performance in Virtual Reality: The Advantages of Federated Learning in Collaborative Environments,Daniel Flores-Martin | Francisco Díaz-Barrancas | Pedro J. Pardo | Javier Berrocal | Juan M. Murillo,"COMPUTAEX, Extremadura Supercomputing Center, Cáceres, Spain | University of Extremadura, Badajoz, Spain | University of Extremadura, Badajoz, Spain | University of Extremadura, Badajoz, Spain | University of Extremadura, Badajoz, Spain",Virtual reality | federated learning | neural networks | training | cloud computing,"Federated Learning has emerged as a promising approach for maintaining data privacy across distributed environments, enabling training on a diverse range of devices from high-performance servers to low-power gadgets. Despite its potential, managing numerous data sources can strain these devices, particularly those with limited capabilities, leading to increased latency. This is especially critical in virtual reality, where real-time responsiveness is crucial due to the need for constant data connectivity. Historically, virtual reality systems have relied on tethered computer setups, restricting their flexibility and the benefits of wireless technology. However, recent advancements have enhanced the computational power of VR devices, allowing them to perform certain tasks independently. This work explores the feasibility of training a neural network on VR devices, using a federated learning approach, to develop a collaborative model aggregated and stored in the cloud. The goal is to assess the computational demands and explore the potential and constraints of leveraging VR devices for artificial intelligence applications.",JWE,2024,,23,8,,1085-1106,2,0,https://ieeexplore.ieee.org/document/10879173/
"Music Curriculum Research Using a Large Language Model, Cloud Computing and Data Mining Technologies",Yuting Shang,"Nanchong Vocational and Technical College, Nanchong, China",Large language model | cloud computing | data mining | music | curriculum model,"This paper presents a method to enhance the scientific nature of the music curriculum model by integrating a large language model, cloud computing and data mining technology for the analysis of the music teaching curriculum model. To maintain the integrity of the mixing matrix while employing the frequency hopping frequency, the paper suggests dividing the mixing matrix into a series of sub-matrices along the vertical time axis. This approach transforms wideband music signal processing into a narrowband processing problem. Additionally, two hybrid matrix estimation algorithms are proposed in this paper using underdetermined conditions. Furthermore, utilizing the estimated mixing matrix and the detected time-frequency support domain, the paper employs the subspace projection algorithm for underdetermined blind separation of music signals in the time-frequency domain. This procedure, along with the integration of the estimated direction of arrival (DoA), enables the completion of frequency-hopping network station music signal sorting. Extensive simulation teaching demonstrates that the music curriculum model proposed in this paper, based on a large language model, cloud computing and data mining technologies, significantly enhances the quality of modern music teaching.",JWE,2024,,23,2,,251-273,2,3,https://ieeexplore.ieee.org/document/10504109/
Advancing Educational Management with the ATT-MR-WL Intelligent Question-Answering Model,Ying Ba,"College of Civil and Architectural Engineering, North China University of Science and Technology, Tangshan, China",Intelligent question-answering | higher education management | Mask R-CNN | Word2Vec+LSTM | ATT-MR-WL,"Higher education plays a critical role in cultivating talent, preserving culture, and promoting social progress. However, current challenges, such as inefficient information dissemination and low problem-solving efficiency among students, highlight the need for intelligent question-answering systems. These systems, leveraging artificial intelligence and natural language processing technologies, enable rapid and accurate responses to student queries, thereby providing intelligent support for higher education management. This study introduces the ATT-MR-WL model, a generative AI system integrating Mask R-CNN and Word2Vec+LSTM to enhance intelligent question-answering functionality. The model, customized to handle both text and visual data, is evaluated using the established VQA v2.0 dataset and a specially developed EM dataset reflecting university management scenarios. The ATT-MR-WL model demonstrates a 3% accuracy improvement over traditional methods and enhances its ability to handle multimodal queries. This research provides important insights for enhancing the efficiency and quality of higher education management and advancing the process of educational informatization.",JWE,2024,,23,7,,973-1002,2,1,https://ieeexplore.ieee.org/document/10815715/
Adversarial Attacks on Pre-Trained Deep Learning Models for Encrypted Traffic Analysis,Byoungjin Seok | Kiwook Sohn,"Korea University, Korea | Seoul National University of Science and Technology, Korea",Encrypted traffic analysis | adversarial attacks | pre-trained deep learning models | bert | web security,"For web security, it's essential to accurately classify traffic across various web applications to detect malicious activities lurking within network traffic. However, the encryption protocols for privacy protection, such as TLS 1.3 and IPSec, make it difficult to apply traditional traffic classification methods like deep packet inspection (DPI). Recently, the advent of deep learning has significantly advanced the field of encrypted traffic analysis (ETA), outperforming traditional traffic analysis approaches. Notably, pre-trained deep learning based ETA models have demonstrated superior analytical capabilities. However, the security aspects of these deep learning models are often overlooked during the design and development process. In this paper, we conducted adversarial attacks to evaluate the security of pre-trained ETA models. We targeted ET-BERT, a state-of-the-art model demonstrating superior performance, to generate adversarial traffic examples. To carry out the adversarial example generation, we drew inspiration from adversarial attacks on discrete data, such as natural language, defining fluency from a network traffic perspective and proposing a new attack algorithm that can preserve this fluency. Finally, in our experiments, we showed our target model is vulnerable to the proposed adversarial attacks.",JWE,2024,,23,6,,749-768,2,0,https://ieeexplore.ieee.org/document/10747168/
"Implementation of Sports Science and Technology Integration Infrastructure: A Case Study of Speed Skating Utilizing Web and Mobile Applications, and Information Visualization Technologies",Minkyu Kim | Soo06g Park,"Dept. of Kinesiology, Inha University, Republic of Korea | Dept. of Kinesiology, Inha University, Republic of Korea",Speed skating | sports science and technology | convergence | infrastructure | web | mobile app,"In the field of sports, there is an active discussion on and an attempt to apply technologies that integrate sports with cutting-edge science and technology for the purpose of enhancing athletic performance. In line with this trend, South Korea is supporting research on the fusion of sports and science technology at an interdepartmental level. For the improvement of performance in elite sports, it is important to consider the athlete's skills, the coach's information analysis, the scientification of equipment, and the environmental optimization. Accordingly, this study aims to propose web and mobile app technologies to establish an integrated infrastructure of sports science and technology for the three factors of athletes, equipment, and environment to improve the performance of speed skating. Furthermore, it aims to make policy recommendations to activate this integration. The application of such technologies and policy recommendations can be transferred and organically integrated into other sports, including track and field, which are time-based competitions. Additionally, it is expected that this approach will lead to the formation of new theories that consider the emotional aspects occurring in sports situations.",JWE,2024,,23,6,,849-868,2,0,https://ieeexplore.ieee.org/document/10747172/
A Web Intelligent Hotel Management Framework Based on IoT and Generative AI,Ling Luo,"Henan Vocational College of Information and Statistics, Zhengzhou, China",Smart hotel management | IoT | generative AI | web engineering,"The hotel industry has faced numerous opportunities and challenges due to the advent of the artificial intelligence (AI) and the data-driven era. To address this, a novel augmented online performance analysis model is proposed for hotel management operations. This model seamlessly integrates the Internet of Things (IoT), generative AI technologies, and web engineering, allowing for the collection and analysis of multifaceted operational data. Consequently, real-time insights pertaining to room reservations, occupancy rates, and revenue streams are derived, serving as the basis for data-driven optimization strategies. Moreover, by incorporating generative AI technologies, the proposed model demonstrates the ability to dynamically generate predictive models, simulate scenarios, synthesize actionable insights, and adapt to evolving trends. As a result, it offers adaptive solutions for complex hotel management scenarios that were previously beyond the reach of traditional methods.",JWE,2024,,23,7,,885-912,2,0,https://ieeexplore.ieee.org/document/10815717/
Classification of Firewall Log Files with Different Algorithms and Performance Analysis of These Algorithms,Ebru Efeoğlu | Gurkan Tuna,"Software Department, Kutahya Dumlupinar University, Turkey | Department of Computer Programming, Trakya University, Turkey",Firewalls | log files | classification | performance metrics | the Simple Cart algorithm,"Classifying firewall log files allows analysing potential threats and deciding on appropriate rules to prevent them. Therefore, in this study, firewall log files are classified using different classification algorithms and the performance of the algorithms are evaluated using performance metrics. The dataset was prepared using the log files of a firewall. It was filtered to make it free from any personal data and consisted of 12 attributes in total and from these attributes the action attribute was selected as the class. In the performance evaluation, Simple Cart and NB tree algorithms made the best predictions, achieving an accuracy rate of 99.84%. Decision Stump had the worst prediction performance, achieving an accuracy rate of 79.68%. As the total number of instances belonging to each of the classes in the dataset was not equal, the Matthews correlation coefficient was also used as a performance metric in the evaluations. The Simple Cart, BF tree, FT tree, J48 and NB Tree algorithms achieved the highest average values. However, although the reset-both class was not predicted successfully by the others, the Simple Cart algorithm made the best predictions for it. The values of other performance metrics used in this study also support this conclusion. Therefore, the Simple Cart algorithm is recommended for use in classifying firewall log files. However, there is a need to develop a prefiltering and parsing approach to process different log files as each firewall brand creates and maintains log files in its own format. Therefore, in this study, a novel prefiltering and parsing approach has been proposed to process log files with different structures and create structured datasets using them.",JWE,2024,,23,4,,561-593,2,1,https://ieeexplore.ieee.org/document/10634590/
Client-Server Code Mobility at Runtime,Sebastian Heil | Lucas Schröder | Martin Gaedke,"Technische Universität Chemnitz, Chemnitz, Germany | Technische Universität Chemnitz, Chemnitz, Germany | Technische Universität Chemnitz, Chemnitz, Germany",Web infrastructure | software architecture | code mobility | frontend | web user interface | WebAssembly | JavaScript | WebSockets,"Application logic is inherently distributed between client and server due to the fundamental Client/Server architecture of the Web. The individual distribution is specified at design time and remains unchanged stable, preventing individual load distribution between clients and server at runtime. Dynamic code mobility at runtime, in contrast, allows to balance the needs of users, through increased responsiveness, and software providers, through better resource usage and cost reductions. Enabled by WebAssembly, the Web ecosystem recently provides the technological foundation for relocating code units during runtime. However, leveraging these capabilities to enhance web applications with dynamic code migration presents challenges for web engineers. In response, we propose an innovative distributed Client/Server software architecture for web applications. This architecture facilitates the dynamic migration of code at runtime, and addresses the technical challenges like dependency management, control and data flow distribution, communication, and interfaces. This novel software architecture serves as a reference for web engineers aiming to enrich their web applications with dynamic code mobility. Additionally, it contributes to the ongoing reevaluation of the Web ecosystem in light of the widespread adoption and standardization of WebAssembly across major browsers. Through experimentation in four scenarios, we demonstrate the feasibility of implementing this architecture, its negligible impact on performance and the optimization potential for individual code distributions across client and server.",JWE,2024,,23,4,,507-534,2,0,https://ieeexplore.ieee.org/document/10634594/
